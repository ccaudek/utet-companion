{
  "hash": "d96f76c083eb6175d4f14c44846ef77d",
  "result": {
    "engine": "knitr",
    "markdown": "# Confronto tra due proporzioni con la regressione logistica {#sec-linear-models-two-proportions}\n\n::: {.epigraph}\n> “In clinical research, many of the most important questions reduce to comparing two proportions: who improves, and who does not.”\n>\n> -- **Robert Rosenthal**, Meta-Analytic Procedures for Social Research (1991)\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nUno dei problemi più frequenti nella ricerca psicologica e clinica è stabilire se due gruppi abbiano la stessa probabilità di ottenere un certo esito binario. Pensiamo, ad esempio, a due trattamenti terapeutici e alla probabilità di guarigione, oppure a due metodi di insegnamento e alla probabilità di superare un esame. In tutti questi casi ogni individuo può trovarsi in una delle due categorie: successo o insuccesso, sì o no, guarito o non guarito.\n\nPer affrontare dati di questo tipo ricorriamo alla *regressione logistica*, che collega la probabilità di successo a una variabile predittiva. Quando i gruppi sono due e indipendenti, il modello si riduce a una forma particolarmente semplice: un unico predittore binario che indica l’appartenenza al gruppo. In questo caso, l’intercetta rappresenta la probabilità (sul logit) di successo nel gruppo di riferimento, mentre il coefficiente del predittore descrive la differenza in log-odds tra i due gruppi.\n\nL’approccio *bayesiano* aggiunge un ulteriore livello di interpretabilità. Possiamo esprimere in modo esplicito le nostre ipotesi iniziali tramite distribuzioni a priori e ottenere come risultato non un singolo valore stimato, ma una *distribuzione a posteriori* che riflette tutta l’incertezza sui parametri. Da questa distribuzione possiamo calcolare probabilità direttamente interpretabili: la probabilità che un trattamento sia più efficace dell’altro, la probabilità che la differenza superi una certa soglia di rilevanza pratica, o la probabilità che le due proporzioni siano sostanzialmente equivalenti.\n\nIn questo capitolo vedremo come formulare il confronto tra due proporzioni come un caso di regressione logistica, come stimarlo in chiave bayesiana con `brms`, e come interpretarne i risultati non solo in termini di odds ratio, ma anche di probabilità e differenze di proporzioni. Questo ci permetterà di collegare il tema del confronto tra proporzioni al quadro più generale dei *modelli lineari generalizzati (GLM)*, di cui la regressione logistica rappresenta un caso centrale.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Comprendere il confronto tra due proporzioni come caso base della regressione logistica.  \n- Tradurre i coefficienti logit in probabilità, differenza di rischio, odds ratio e risk ratio.  \n- Stimare i parametri con approccio bayesiano tramite `brms`.  \n- Interpretare le distribuzioni posteriori e l’incertezza delle stime.  \n- Eseguire controlli predittivi e visualizzare i risultati. \n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere l'articolo \"Children’s arithmetic skills do not transfer between applied and academic mathematics\" [@banerjee2025children]. \n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, cmdstanr, posterior, brms, bayestestR, insight)\n\nconflicts_prefer(dplyr::count)\n```\n:::\n\n:::\n\n\n## Perché usare la regressione logistica per confrontare due proporzioni\n\nConfrontare due proporzioni significa chiedersi se la probabilità di successo osservata in un gruppo differisce da quella osservata nell’altro. Se nel gruppo 0 registriamo $x_0$ successi su $n_0$ prove e nel gruppo 1 osserviamo $x_1$ successi su $n_1$ prove, le proporzioni vere possono essere indicate con $\\theta_0$ e $\\theta_1$. La differenza tra le due proporzioni, $\\Delta = \\theta_1 - \\theta_0$, fornisce una misura diretta del divario. Un altro indice spesso utilizzato è l’odds ratio, che confronta il rapporto tra successi e insuccessi in ciascun gruppo.\n\nLa regressione logistica permette di formalizzare questa idea. Se indichiamo con $D_i$ una variabile che assume valore zero per gli individui del gruppo di riferimento e valore uno per gli individui del gruppo di confronto, possiamo scrivere il modello come\n\n$$\ny_i \\sim \\text{Bernoulli}(p_i), \\qquad \\text{logit}(p_i) = \\alpha + \\gamma D_i .\n$$\n\nIn questo contesto, l’intercetta $\\alpha$ rappresenta i log-odds del gruppo di riferimento, mentre il coefficiente $\\gamma$ esprime la differenza di log-odds fra i due gruppi, cioè il logaritmo dell’odds ratio. L’esponenziale di $\\gamma$ fornisce infatti l’odds ratio vero e proprio. \n\nQuesto schema mostra che confrontare due proporzioni equivale a stimare una regressione logistica con un unico predittore dummy, con il vantaggio di ottenere risultati coerenti con modelli più complessi e di poter passare facilmente da una scala all’altra, dalle probabilità agli odds, fino alle differenze o ai rapporti di rischio. In un quadro bayesiano, questo confronto si arricchisce ulteriormente perché le stime vengono fornite sotto forma di distribuzioni a posteriori, permettendo di esprimere direttamente l’incertezza su ciascuna quantità di interesse.\n\n\n## Un esempio concreto\n\nUn’applicazione particolarmente chiara di queste idee si trova nello studio di @banerjee2025children, che ha confrontato le abilità matematiche di due gruppi di bambini in India: da un lato quelli che lavoravano nei mercati di Kolkata e Delhi, dall’altro quelli che frequentavano la scuola senza lavorare. Lo scopo era verificare se le competenze sviluppate nel lavoro quotidiano, come dare il resto o sommare i prezzi, si trasferissero al contesto scolastico e se, viceversa, l’addestramento scolastico potesse essere utile nei problemi pratici del mercato. I risultati hanno mostrato che i bambini lavoratori erano molto abili nei problemi concreti, ma meno preparati in quelli astratti, mentre gli scolarizzati presentavano lo schema opposto.\n\nConsideriamo i dati relativi ai problemi astratti. Tra i bambini lavoratori si sono registrati 670 successi su 1488 prove, pari a una proporzione di circa 0.45. Tra i bambini scolarizzati i successi sono stati 320 su 542, cioè circa 0.59. La situazione è ancora più marcata nei problemi di mercato: i bambini lavoratori hanno ottenuto 134 successi su 373 prove, pari a 0.36, mentre i bambini scolarizzati hanno risolto solo 3 problemi su 271, cioè appena lo 0.01.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Successi e denominatori\nx_work   <- 670 ; n_work   <- 1488\nx_non    <- 320 ; n_non    <-  542\n\n# Tabella aggregata per il modello binomiale\ndat_a <- tibble(\n  count = c(x_non,   x_work),   # ordine: riferimento (non-working), poi working\n  tot   = c(n_non,   n_work),\n  group = factor(c(\"non-working\", \"working\"),\n                 levels = c(\"non-working\", \"working\"))\n)\n\ndat_a\n#> # A tibble: 2 × 3\n#>   count   tot group      \n#>   <dbl> <dbl> <fct>      \n#> 1   320   542 non-working\n#> 2   670  1488 working\n```\n:::\n\n\n\n## Un rapido controllo\n\nPrima di impostare il modello bayesiano, può essere utile calcolare in chiave frequentista la differenza osservata fra le due proporzioni, insieme a un intervallo di confidenza. Questo non fa parte del nostro approccio principale, ma consente di verificare che i dati siano coerenti con quelli riportati in letteratura e ci offre un punto di riferimento preliminare.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np_non  <- x_non  / n_non\np_work <- x_work / n_work\nrd_obs <- p_non - p_work\n\nalpha  <- 0.05\nse_ci  <- sqrt(p_non*(1-p_non)/n_non + p_work*(1-p_work)/n_work)\nz_crit <- qnorm(1 - alpha/2)\nci_rd  <- c(rd_obs - z_crit*se_ci, rd_obs + z_crit*se_ci)\n\nsprintf(\"Differenza osservata (non-working - working): %.3f (95%% CI: [%.2f, %.2f])\",\n        rd_obs, ci_rd[1], ci_rd[2])\n#> [1] \"Differenza osservata (non-working - working): 0.140 (95% CI: [0.09, 0.19])\"\n```\n:::\n\n\nQuesto rapido controllo conferma che i bambini scolarizzati hanno una proporzione di risposte corrette maggiore rispetto ai bambini lavoratori nei problemi astratti, come già segnalato dagli autori dello studio.\n\n\n## Modello bayesiano con regressione logistica\n\nPassiamo ora al modello bayesiano. Usiamo il pacchetto brms con backend cmdstanr, in continuità con i capitoli precedenti. Per impostare il modello binomiale con esito aggregato, specifichiamo dei prior debolmente informativi sulla scala logit:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npriors <- c(\n  prior(normal(0, 2.5), class = \"Intercept\"),\n  prior(normal(0, 2.5), class = \"b\")\n)\n```\n:::\n\n\nLa stima viene quindi effettuata sul numero di successi in ciascun gruppo, tenendo conto del numero totale di prove, con la variabile categoriale group che distingue fra bambini scolarizzati e bambini lavoratori. Nel gruppo di riferimento, definito come “non-working”, l’intercetta del modello rappresenta i log-odds di successo, mentre il coefficiente associato al predittore misura lo scarto di log-odds del gruppo “working”.\n\n\nDopo aver impostato il modello, procediamo alla stima con `brms`. I dati vengono trattati in forma aggregata, specificando il numero di successi e di prove per ciascun gruppo. Usiamo la famiglia binomiale, fissiamo i prior debolmente informativi sulla scala logit, e chiediamo al campionatore MCMC di esplorare lo spazio dei parametri.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_a <- brm(\n  count | trials(tot) ~ group,\n  data         = dat_a,\n  family       = binomial(),\n  prior        = priors,\n  backend      = \"cmdstanr\",\n  seed         = 1234,\n  iter         = 4000, chains = 4, cores = 4,\n  sample_prior = \"yes\",\n  refresh = 0 \n)\n```\n:::\n\n\nUn primo sguardo ai risultati con `summary(fit_a)` ci mostra i coefficienti stimati sulla scala logit. Tuttavia, per comprendere appieno il significato psicologico e applicativo di questi numeri, è utile trasformarli nelle quantità di maggiore interesse: le probabilità di successo nei due gruppi, la loro differenza, e i rapporti che le mettono a confronto.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fit_a)\n#>  Family: binomial \n#>   Links: mu = logit \n#> Formula: count | trials(tot) ~ group \n#>    Data: dat_a (Number of observations: 2) \n#>   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Regression Coefficients:\n#>              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept        0.37      0.09     0.20     0.54 1.00     3230     3722\n#> groupworking    -0.57      0.10    -0.77    -0.37 1.00     3929     3843\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nA partire dall’intercetta otteniamo la probabilità dei bambini scolarizzati (gruppo di riferimento), mentre aggiungendo il coefficiente della variabile dummy otteniamo la probabilità del gruppo dei bambini lavoratori. La differenza fra le due probabilità definisce la risk difference. Il coefficiente della dummy, espresso come esponenziale, corrisponde invece all’odds ratio. Infine, il rapporto fra le probabilità fornisce il risk ratio.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npost <- as_draws_df(fit_a) %>%\n  mutate(\n    p_ref   = plogis(b_Intercept),\n    p_work  = plogis(b_Intercept + b_groupworking),\n    RD      = p_work - p_ref,\n    OR      = exp(b_groupworking),\n    RR      = p_work / p_ref\n  )\n```\n:::\n\n\nRiepilogando i valori medi e gli intervalli credibili, possiamo osservare direttamente le stime per ciascuna quantità.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npost_summary <- tibble(\n  quantity = c(\"p_ref (non-working)\", \"p_work (working)\", \"RD (work - ref)\", \"OR\", \"RR\"),\n  mean  = c(mean(post$p_ref), mean(post$p_work), mean(post$RD), mean(post$OR), mean(post$RR)),\n  q2.5  = c(quantile(post$p_ref, .025), quantile(post$p_work, .025), quantile(post$RD, .025),\n            quantile(post$OR, .025), quantile(post$RR, .025)),\n  q97.5 = c(quantile(post$p_ref, .975), quantile(post$p_work, .975), quantile(post$RD, .975),\n            quantile(post$OR, .975), quantile(post$RR, .975))\n)\n\npost_summary\n#> # A tibble: 5 × 4\n#>   quantity              mean   q2.5   q97.5\n#>   <chr>                <dbl>  <dbl>   <dbl>\n#> 1 p_ref (non-working)  0.591  0.550  0.632 \n#> 2 p_work (working)     0.450  0.425  0.476 \n#> 3 RD (work - ref)     -0.141 -0.188 -0.0918\n#> 4 OR                   0.569  0.465  0.692 \n#> 5 RR                   0.763  0.698  0.834\n```\n:::\n\n\nPer avere un’impressione immediata della direzione degli effetti, possiamo calcolare le probabilità posteriori che le quantità di interesse siano minori o maggiori di valori soglia. In particolare, ci chiediamo con quale probabilità la proporzione dei bambini lavoratori superi quella degli scolarizzati, oppure la differenza di rischio sia negativa, o ancora l’odds ratio e il risk ratio siano inferiori a uno.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntibble(\n  `Pr(p_work > p_ref)` = mean(post$p_work > post$p_ref),\n  `Pr(RD < 0)`         = mean(post$RD < 0),\n  `Pr(OR < 1)`         = mean(post$OR < 1),\n  `Pr(RR < 1)`         = mean(post$RR < 1)\n)\n#> # A tibble: 1 × 4\n#>   `Pr(p_work > p_ref)` `Pr(RD < 0)` `Pr(OR < 1)` `Pr(RR < 1)`\n#>                  <dbl>        <dbl>        <dbl>        <dbl>\n#> 1                    0            1            1            1\n```\n:::\n\n\nGli intervalli credibili confermano e quantificano l’incertezza. La probabilità stimata di successo per i bambini scolarizzati ha un intervallo al 95% che si colloca attorno a valori medio-alti, mentre quella dei bambini lavoratori si concentra su valori più bassi. L’intervallo credibile della differenza di rischio è per lo più negativo, suggerendo una minore probabilità di successo nel gruppo dei lavoratori. Lo stesso vale per l’odds ratio, con valori che tendono a collocarsi stabilmente al di sotto dell’unità.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhdi_p_ref   <- bayestestR::hdi(post$p_ref, ci = 0.95)\nhdi_p_work  <- bayestestR::hdi(post$p_work, ci = 0.95)\nhdi_RD_89   <- bayestestR::hdi(post$RD, ci = 0.89)\nhdi_OR_95   <- bayestestR::hdi(post$OR, ci = 0.95)\n\nlist(\n  `95% HDI p_ref`  = hdi_p_ref,\n  `95% HDI p_work` = hdi_p_work,\n  `89% HDI RD`     = hdi_RD_89,\n  `95% HDI OR`     = hdi_OR_95\n)\n#> $`95% HDI p_ref`\n#> 95% HDI: [0.55, 0.63]\n#> \n#> $`95% HDI p_work`\n#> 95% HDI: [0.43, 0.48]\n#> \n#> $`89% HDI RD`\n#> 89% HDI: [-0.18, -0.10]\n#> \n#> $`95% HDI OR`\n#> 95% HDI: [0.46, 0.69]\n```\n:::\n\n\nInterpretare questi risultati significa tradurre le diverse scale. Le proporzioni forniscono una misura intuitiva: nei dati considerati, la probabilità di successo dei bambini scolarizzati si aggira intorno al 59 per cento, mentre quella dei bambini lavoratori è più vicina al 45 per cento. La differenza di rischio, cioè lo scarto fra le due proporzioni, risulta negativa e conferma un divario a sfavore dei lavoratori. L’odds ratio esprime lo stesso fenomeno su un’altra scala: un valore inferiore a uno indica che gli odds di successo dei lavoratori sono più bassi di quelli degli scolarizzati. Il risk ratio, infine, mostra che la probabilità di successo dei lavoratori corrisponde solo a una frazione di quella degli scolarizzati.\n\nTutte queste trasformazioni raccontano la stessa storia con linguaggi diversi, e lo fanno in modo coerente con quanto osservato nei dati grezzi. Il vantaggio del modello bayesiano è che non ci limita a un’unica stima puntuale, ma ci offre distribuzioni posteriori complete che quantificano l’incertezza e permettono di rispondere a domande probabilistiche dirette, come “quanto è probabile che la differenza di proporzioni sia negativa?” oppure “quanto è probabile che l’odds ratio sia minore di uno?”.\n\nQuesto capitolo si collega direttamente alla discussione precedente sull’odds ratio. In quel caso avevamo stimato l’indice in modo diretto, come parametro principale di un modello. Qui, invece, vediamo come lo stesso odds ratio emerga naturalmente come trasformazione del coefficiente logit in una regressione con variabile dummy. Le due prospettive non sono in contrasto, ma si integrano: la regressione logistica fornisce un quadro generale dal quale si derivano OR, RR e RD, mentre l’analisi bayesiana dell’odds ratio ci ha mostrato come sia possibile focalizzarsi in modo mirato su un singolo parametro di interesse.\n\n\n## Un secondo esempio: i problemi di mercato\n\nRiprendiamo ora i dati relativi ai problemi di mercato. Qui le differenze tra i due gruppi diventano ancora più evidenti. I bambini lavoratori hanno risolto correttamente 134 problemi su 373, con una proporzione di circa 0.36. I bambini scolarizzati, invece, hanno risposto correttamente solo 3 volte su 271, con una proporzione che sfiora lo zero, appena 0.01. Questo scenario rappresenta una situazione di forte divario, opposta a quella vista nei problemi astratti.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Dati per i problemi di mercato\nx_work_m <- 134 ; n_work_m <- 373\nx_non_m  <-   3 ; n_non_m  <- 271\n\ndat_m <- tibble(\n  count = c(x_non_m, x_work_m),\n  tot   = c(n_non_m, n_work_m),\n  group = factor(c(\"non-working\", \"working\"),\n                 levels = c(\"non-working\", \"working\"))\n)\n\ndat_m\n#> # A tibble: 2 × 3\n#>   count   tot group      \n#>   <dbl> <dbl> <fct>      \n#> 1     3   271 non-working\n#> 2   134   373 working\n```\n:::\n\n\nImpostiamo lo stesso modello bayesiano, mantenendo la struttura logistica con dummy di gruppo.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_m <- brm(\n  count | trials(tot) ~ group,\n  data         = dat_m,\n  family       = binomial(),\n  prior        = priors,\n  backend      = \"cmdstanr\",\n  seed         = 1234,\n  iter         = 4000, chains = 4, cores = 4,\n  sample_prior = \"yes\",\n  refresh = 0 \n)\n```\n:::\n\n\nDopo la stima, estraiamo nuovamente le quantità di interesse: le probabilità nei due gruppi, la loro differenza, l’odds ratio e il risk ratio.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npost_m <- as_draws_df(fit_m) %>%\n  mutate(\n    p_ref   = plogis(b_Intercept),\n    p_work  = plogis(b_Intercept + b_groupworking),\n    RD      = p_work - p_ref,\n    OR      = exp(b_groupworking),\n    RR      = p_work / p_ref\n  )\n\npost_summary_m <- tibble(\n  quantity = c(\"p_ref (non-working)\", \"p_work (working)\", \"RD (work - ref)\", \"OR\", \"RR\"),\n  mean  = c(mean(post_m$p_ref), mean(post_m$p_work), mean(post_m$RD), mean(post_m$OR), mean(post_m$RR)),\n  q2.5  = c(quantile(post_m$p_ref, .025), quantile(post_m$p_work, .025), quantile(post_m$RD, .025),\n            quantile(post_m$OR, .025), quantile(post_m$RR, .025)),\n  q97.5 = c(quantile(post_m$p_ref, .975), quantile(post_m$p_work, .975), quantile(post_m$RD, .975),\n            quantile(post_m$OR, .975), quantile(post_m$RR, .975))\n)\n\npost_summary_m\n#> # A tibble: 5 × 4\n#>   quantity               mean     q2.5    q97.5\n#>   <chr>                 <dbl>    <dbl>    <dbl>\n#> 1 p_ref (non-working)  0.0141  0.00393   0.0312\n#> 2 p_work (working)     0.358   0.310     0.408 \n#> 3 RD (work - ref)      0.344   0.295     0.396 \n#> 4 OR                  51.8    17.0     143.    \n#> 5 RR                  33.4    11.3      91.3\n```\n:::\n\n\nLe stime posteriori raccontano una storia molto chiara. La probabilità di successo per i bambini scolarizzati è praticamente nulla, con un intervallo credibile che resta vicino allo zero. Per i bambini lavoratori, invece, la probabilità si colloca intorno al 36 per cento. La differenza di rischio è quindi nettamente positiva e l’odds ratio assume valori molto superiori a uno, indicando un vantaggio marcato dei lavoratori.\n\nPer rendere ancora più evidente la forza dell’effetto, possiamo calcolare la probabilità a posteriori che la proporzione dei lavoratori sia superiore a quella degli scolarizzati, oppure che la differenza di rischio e l’odds ratio siano strettamente positivi.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntibble(\n  `Pr(p_work > p_ref)` = mean(post_m$p_work > post_m$p_ref),\n  `Pr(RD > 0)`         = mean(post_m$RD > 0),\n  `Pr(OR > 1)`         = mean(post_m$OR > 1),\n  `Pr(RR > 1)`         = mean(post_m$RR > 1)\n)\n#> # A tibble: 1 × 4\n#>   `Pr(p_work > p_ref)` `Pr(RD > 0)` `Pr(OR > 1)` `Pr(RR > 1)`\n#>                  <dbl>        <dbl>        <dbl>        <dbl>\n#> 1                    1            1            1            1\n```\n:::\n\n\nIn questo caso le probabilità posteriori sono praticamente pari a uno, cioè la certezza che i bambini lavoratori abbiano prestazioni migliori nei problemi di mercato.\n\n\n## Confronto fra i due scenari\n\nMettendo insieme i due esempi — problemi astratti e problemi di mercato — si ottiene un quadro coerente con le ipotesi teoriche dello studio. Nei problemi astratti, tipici dell’ambiente scolastico, i bambini scolarizzati mostrano una probabilità di successo più elevata rispetto ai lavoratori. Nei problemi di mercato, invece, il risultato si ribalta: i bambini che hanno esperienza diretta nelle attività quotidiane del lavoro sono nettamente più preparati, mentre gli scolarizzati faticano.\n\nLa regressione logistica in chiave bayesiana ci permette di quantificare entrambi gli scenari con la stessa cornice concettuale. Le differenze non vengono solo osservate nei dati grezzi, ma diventano stime probabilistiche con intervalli credibili che riflettono l’incertezza. È particolarmente utile osservare come le diverse scale (proporzioni, differenza di rischio, odds ratio, risk ratio) restituiscano sempre la stessa conclusione, ciascuna con il proprio linguaggio: più intuitivo nel caso delle proporzioni, più compatto e comparabile in quello dell’odds ratio.\n\nQuesta analisi illustra bene il vantaggio di un modello unificato. Con un’unica struttura logistica possiamo descrivere scenari molto diversi, da un divario moderato a uno estremo, e tradurre i risultati su scale diverse a seconda delle esigenze interpretative.\n\n\n## Visualizzazione dei risultati\n\nPer rendere più intuitiva l’interpretazione, possiamo rappresentare graficamente le distribuzioni posteriori.  \n\n### Differenza di rischio (RD)\n\nNel primo grafico vediamo le distribuzioni posteriori della *risk difference* nei due scenari. Nel caso dei problemi astratti, la distribuzione si concentra su valori negativi, indicando un vantaggio per i bambini scolarizzati. Nei problemi di mercato, al contrario, la distribuzione si colloca interamente su valori positivi, con un vantaggio netto per i bambini lavoratori.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npost_RD <- bind_rows(\n  post %>% select(RD) %>% mutate(scenario = \"Problemi astratti\"),\n  post_m %>% select(RD) %>% mutate(scenario = \"Problemi di mercato\")\n)\n\nggplot(post_RD, aes(x = RD, fill = scenario)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  facet_wrap(~scenario, ncol = 1, scales = \"free_y\") +\n  labs(\n    x = \"RD = p_work - p_non\",\n    y = \"Densità\"\n  ) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](03_two_proportions_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n### Odds ratio (OR)\n\nUn secondo grafico mostra le distribuzioni posteriori dell’odds ratio. Nei problemi astratti, la distribuzione è concentrata al di sotto di 1, evidenziando odds più bassi per i bambini lavoratori. Nei problemi di mercato, l’odds ratio risulta al contrario molto più grande di 1, segnalando un vantaggio consistente per i lavoratori.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npost_OR <- bind_rows(\n  post %>% select(OR) %>% mutate(scenario = \"Problemi astratti\"),\n  post_m %>% select(OR) %>% mutate(scenario = \"Problemi di mercato\")\n)\n\nggplot(post_OR, aes(x = OR, fill = scenario)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(xintercept = 1, linetype = \"dashed\") +\n  facet_wrap(~scenario, ncol = 1, scales = \"free_y\") +\n  scale_x_continuous(trans = \"log\", breaks = c(0.1, 0.5, 1, 2, 5, 10, 50)) +\n  labs(\n    x = \"Odds ratio (scala log)\",\n    y = \"Densità\"\n  ) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](03_two_proportions_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nQueste figure completano l’analisi, mostrando visivamente come lo stesso modello possa descrivere due situazioni opposte. La regressione logistica, in chiave bayesiana, fornisce un linguaggio comune per esprimere risultati che nei dati appaiono così divergenti: vantaggio per i bambini scolarizzati nei compiti astratti, e vantaggio per i bambini lavoratori nei compiti concreti di mercato.\n\n\n## Proporzioni posteriori di successo per gruppo\n\nPer completare il quadro conviene mostrare direttamente le probabilità di successo stimate per ciascun gruppo, nei due scenari. L’idea è di partire dai draw posteriori già calcolati e di riassumerli con mediana e intervalli credibili. Il grafico risultante rende evidente, a colpo d’occhio, sia la distanza fra i gruppi sia l’ampiezza dell’incertezza.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Raccogliamo i draw di p per ciascuno scenario e gruppo\npost_props <- bind_rows(\n  post %>%\n    transmute(\n      scenario = \"Problemi astratti\",\n      `non-working` = p_ref,\n      `working`     = p_work\n    ),\n  post_m %>%\n    transmute(\n      scenario = \"Problemi di mercato\",\n      `non-working` = p_ref,\n      `working`     = p_work\n    )\n) |>\n  pivot_longer(cols = c(`non-working`, `working`),\n               names_to = \"gruppo\", values_to = \"p\")\n\n# Riassunto con mediana e intervalli credibili\nsumm_props <- post_props |>\n  group_by(scenario, gruppo) |>\n  median_qi(p, .width = c(.95, .89)) |>\n  ungroup()\n\n# Grafico punto + intervallo credibile\nggplot(summ_props, aes(x = gruppo, y = p, ymin = .lower, ymax = .upper)) +\n  geom_pointrange(position = position_dodge(width = 0.4)) +\n  facet_wrap(~ scenario, ncol = 1) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    x = NULL,\n    y = \"Probabilità di successo\"\n  ) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](03_two_proportions_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl pannello sui problemi astratti mostra una probabilità di successo più alta per i bambini scolarizzati rispetto ai lavoratori, con intervalli credibili che riflettono l’incertezza ma mantengono un chiaro distacco fra i gruppi. Il pannello sui problemi di mercato, al contrario, evidenzia un’inversione marcata: i lavoratori presentano una probabilità sensibilmente maggiore, mentre gli scolarizzati rimangono vicini allo zero. La lettura combinata di questi due pannelli rafforza l’interpretazione proposta nei paragrafi precedenti e rende visiva la coerenza fra scale diverse, perché le conclusioni tratte da RD, OR e RR trovano una corrispondenza immediata nelle probabilità stimate.\n\n\n## Il modello scritto in Stan\n\nPer completezza, possiamo mostrare come la stessa analisi sia realizzabile direttamente in Stan, senza passare da `brms`. Questo esempio ha uno scopo puramente didattico: nel capitolo “Regressione logistica con Stan” troveremo la discussione più dettagliata della sintassi e delle scelte di modellizzazione. Qui ci interessa soprattutto vedere come la struttura logistica con variabile dummy possa essere implementata in modo molto semplice.\n\n\nIl modello prevede due gruppi. Per ciascun gruppo conosciamo il numero di successi e il numero totale di prove. Introduciamo inoltre un predittore dummy che vale 0 per il gruppo di riferimento (non-working) e 1 per il gruppo di confronto (working). Il modello utilizza una parametrizzazione logit con due coefficienti: l’intercetta $\\alpha$, che descrive i log-odds del gruppo di riferimento, e il coefficiente $\\gamma$, che rappresenta la differenza di log-odds fra i gruppi. A partire da questi due parametri possiamo ricavare tutte le quantità di interesse già discusse, cioè le probabilità di successo nei due gruppi, la differenza di rischio, l’odds ratio e il risk ratio.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_code <- '\ndata {\n  int<lower=1> G;                // numero di gruppi (=2)\n  array[G] int<lower=0> y;       // successi osservati per ciascun gruppo\n  array[G] int<lower=0> n;       // prove totali per ciascun gruppo\n  array[G] int<lower=0,upper=1> D; // dummy: 0 = non-working, 1 = working\n}\nparameters {\n  real alpha;                     // intercetta (log-odds gruppo di riferimento)\n  real gamma;                     // coefficiente della dummy (log-odds ratio)\n}\nmodel {\n  // prior deboli sulla scala logit\n  alpha ~ normal(0, 2.5);\n  gamma ~ normal(0, 2.5);\n\n  // verosimiglianza binomiale per ciascun gruppo\n  for (g in 1:G) {\n    real eta = alpha + gamma * D[g];\n    y[g] ~ binomial(n[g], inv_logit(eta));\n  }\n}\ngenerated quantities {\n  real p_ref    = inv_logit(alpha);             // probabilità nel gruppo di riferimento\n  real p_work   = inv_logit(alpha + gamma);     // probabilità nel gruppo working\n  real RD       = p_work - p_ref;               // differenza di probabilità\n  real OR       = exp(gamma);                   // odds ratio\n  real RR       = p_work / p_ref;               // risk ratio\n}\n'\n```\n:::\n\n\nI dati da fornire a Stan sono molto semplici: i conteggi di successi e prove nei due gruppi, più la variabile dummy che distingue i gruppi.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat_stan <- list(\n  G = 2,\n  y = c(x_non, x_work),\n  n = c(n_non, n_work),\n  D = c(0L, 1L)\n)\n```\n:::\n\n\nCompiliamo quindi il modello e avviamo il campionamento MCMC.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod  <- cmdstan_model(write_stan_file(stan_code))\nfitS <- mod$sample(data = dat_stan, seed = 1234,\n                   chains = 4, parallel_chains = 4)\n```\n:::\n\n\nInfine, estraiamo le quantità derivate di maggiore interesse, esattamente le stesse già calcolate nel caso di `brms`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfitS$summary(variables = c(\"p_ref\",\"p_work\",\"RD\",\"OR\",\"RR\"))\n#> # A tibble: 5 × 10\n#>   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 p_ref     0.590  0.591 0.022 0.022  0.553  0.625 1.005  929.925  853.063\n#> 2 p_work    0.451  0.451 0.013 0.013  0.429  0.472 1.000 3200.938 2588.523\n#> 3 RD       -0.140 -0.140 0.025 0.025 -0.180 -0.098 1.006  877.412  873.285\n#> 4 OR        0.572  0.568 0.059 0.058  0.482  0.676 1.005  874.895  869.354\n#> 5 RR        0.765  0.763 0.036 0.035  0.709  0.826 1.006  929.621 1006.127\n```\n:::\n\n\nI risultati ottenuti coincidono con quelli ricavati tramite `brms`. Questo conferma che la parametrizzazione logit con dummy è del tutto equivalente all’impostazione con predittore categoriale, e che da essa possiamo derivare in modo trasparente tutte le grandezze interpretative: probabilità nei gruppi, differenza di rischio, odds ratio e risk ratio. In questo modo il modello Stan, pur scritto in forma minimale, ci permette di vedere con chiarezza la logica interna dell’analisi e rafforza la comprensione concettuale della regressione logistica come strumento per il confronto fra proporzioni.\n\n\n## Posterior predictive check \n\nUn vantaggio di Stan è che possiamo generare, nello stesso modello, dei *dati replicati* secondo la distribuzione predittiva posteriore. Questo ci consente di confrontare i dati osservati con quelli che il modello si aspetta, valutando così la bontà dell’adattamento.\n\nBasta aggiungere, nella sezione `generated quantities`, delle variabili che rappresentino i successi simulati a posteriori per ciascun gruppo. Queste repliche, combinate con le quantità già calcolate ($p_{ref}$, $p_{work}$, $RD$, $OR$, $RR$), ci permettono di eseguire controlli predittivi direttamente in R dopo l’esecuzione del modello.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_code_ppc <- '\ndata {\n  int<lower=1> G;                  // numero gruppi (=2)\n  array[G] int<lower=0> y;         // successi osservati\n  array[G] int<lower=0> n;         // prove totali\n  array[G] int<lower=0,upper=1> D; // dummy: 0 = non-working, 1 = working\n}\nparameters {\n  real alpha;                       // intercetta (log-odds gruppo di riferimento)\n  real gamma;                       // coefficiente dummy (log-odds ratio)\n}\nmodel {\n  // prior deboli\n  alpha ~ normal(0, 2.5);\n  gamma ~ normal(0, 2.5);\n\n  for (g in 1:G) {\n    real eta = alpha + gamma * D[g];\n    y[g] ~ binomial(n[g], inv_logit(eta));\n  }\n}\ngenerated quantities {\n  real p_ref    = inv_logit(alpha);\n  real p_work   = inv_logit(alpha + gamma);\n  real RD       = p_work - p_ref;\n  real OR       = exp(gamma);\n  real RR       = p_work / p_ref;\n\n  // dati replicati per i due gruppi\n  array[G] int y_rep;\n  for (g in 1:G) {\n    real eta = alpha + gamma * D[g];\n    y_rep[g] = binomial_rng(n[g], inv_logit(eta));\n  }\n}\n'\n```\n:::\n\n\nPrepariamo i dati nello stesso modo di prima:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat_stan <- list(\n  G = 2,\n  y = c(x_non, x_work),\n  n = c(n_non, n_work),\n  D = c(0L, 1L)\n)\n```\n:::\n\n\nCompiliamo e lanciamo il modello:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod_ppc <- cmdstan_model(write_stan_file(stan_code_ppc))\nfit_ppc <- mod_ppc$sample(data = dat_stan, seed = 1234,\n                          chains = 4, parallel_chains = 4)\n```\n:::\n\n\nOra possiamo esaminare le repliche generate a posteriori. Ad esempio, visualizziamo le distribuzioni predittive delle proporzioni replicate e confrontiamole con quelle osservate.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Estraiamo le repliche\ny_rep <- fit_ppc$draws(\"y_rep\") |> as_draws_matrix()\ny_rep_df <- as_tibble(y_rep) |> \n  mutate(draw = row_number()) |> \n  pivot_longer(-draw, names_to = \"var\", values_to = \"count_rep\") |> \n  mutate(group = ifelse(var == \"y_rep[1]\", \"non-working\", \"working\"),\n         tot   = ifelse(group == \"non-working\", n_non, n_work),\n         observed = ifelse(group == \"non-working\", x_non, x_work),\n         prop_rep = count_rep / tot,\n         prop_obs = observed / tot)\n\nggplot(y_rep_df, aes(x = prop_rep)) +\n  geom_density(alpha = 0.5, fill = \"#56B4E9\") +\n  geom_vline(aes(xintercept = prop_obs), linetype = \"dashed\") +\n  facet_wrap(~ group, scales = \"free\") +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    title = \"Posterior predictive check (Stan)\",\n    subtitle = \"Linea tratteggiata = proporzione osservata;\\ncurva = distribuzione delle proporzioni replicate\",\n    x = \"Proporzione di successi (repliche posteriori)\",\n    y = \"Densità\"\n  ) \n```\n\n::: {.cell-output-display}\n![](03_two_proportions_files/figure-html/unnamed-chunk-25-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl grafico mostra che le proporzioni osservate nei due gruppi ricadono all’interno delle distribuzioni predittive generate dal modello. Questo è un segnale positivo: il modello è capace di riprodurre i dati reali con buona coerenza. Naturalmente, controlli più sofisticati possono includere altre statistiche riassuntive o l’uso di funzioni dedicate, ma questo esempio illustra bene il principio fondamentale: Stan non si limita a stimare parametri, ma permette anche di simulare nuovi dati per verificare in modo diretto l’adeguatezza del modello.\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo visto come il problema del *confronto tra due proporzioni* possa essere formulato come un caso particolare di regressione logistica, con un unico predittore binario che distingue i due gruppi. Questo ci ha permesso di interpretare l’intercetta come la probabilità di successo nel gruppo di riferimento e il coefficiente come la differenza in log-odds tra i gruppi.\n\nL’approccio *bayesiano* ci ha dato un vantaggio decisivo: invece di ridurre l’analisi a un verdetto basato su un *p*-value, abbiamo ottenuto una *distribuzione a posteriori* dei parametri. Questa distribuzione ci consente di calcolare probabilità direttamente interpretabili, come la probabilità che un trattamento sia più efficace dell’altro o la probabilità che la differenza superi una soglia di rilevanza pratica. In questo modo, l’analisi diventa più ricca e più utile per guidare decisioni empiriche e cliniche.\n\nDal punto di vista concettuale, abbiamo imparato che il confronto tra due proporzioni non è un problema isolato, ma si inserisce pienamente nel quadro dei *modelli lineari generalizzati*. La regressione logistica, infatti, non è soltanto uno strumento per analizzare variabili dicotomiche, ma anche un linguaggio unificante che ci permette di trattare proporzioni, probabilità e differenze tra gruppi con coerenza e rigore.\n\nNei capitoli successivi vedremo come questa stessa logica possa estendersi ad altri tipi di dati, come i *conteggi*, consolidando ulteriormente l’idea che i GLM costituiscano un quadro flessibile e generale per affrontare molte delle domande tipiche della ricerca psicologica.\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#>  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#> [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [28] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#> [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#> [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#> [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#> [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#> [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#> [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#> [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#> [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#> [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#> [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#> [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#> [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#> [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#> [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#> [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#> [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#> [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#> [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#> [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#> [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#> [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#> [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#> [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#> [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#> [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#> [85] MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n",
    "supporting": [
      "03_two_proportions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}