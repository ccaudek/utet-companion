{
  "hash": "3e2b32c343f46a90e317c034b4e18dff",
  "result": {
    "engine": "knitr",
    "markdown": "# Dal GLM a un modello processuale per dati binari {#sec-ar1}\n\n## Introduzione {.unnumbered .unlisted}\n\nLa *regressione logistica* è lo strumento di riferimento per analizzare esiti binari $y\\in\\{0,1\\}$ in funzione di predittori osservabili $\\mathbf{x}$. Fin qui l’abbiamo usata come *GLM statico*, assumendo osservazioni indipendenti, effetti invarianti nel tempo e un unico meccanismo generativo. Queste ipotesi sono utili per molti problemi, ma diventano limitanti quando vogliamo descrivere *processi psicologici dinamici*, in cui la risposta osservata è l’esito momentaneo di *stati interni* che si evolvono nel tempo.\n\nEsempi classici: in un compito ripetuto, la risposta al *trial* $t$ può dipendere dall’esito al *trial* $t-1$ (rinforzo, frustrazione, fatica), così come da *stati latenti* che variano lentamente (motivazione, attenzione). Il GLM logit standard non “vede” questa *history dependence*: tratta ogni risposta come se nascesse da zero. Per catturare la dimensione temporale, introduciamo una *variabile latente continua* $u_{i,t}$ — la propensione interna a rispondere “1” del soggetto $i$ al tempo $t$ — e le permettiamo di *portare memoria del passato*:\n\n$$\n\\Pr(y_{i,t}=1\\mid u_{i,t})=\\operatorname{logit}^{-1}(u_{i,t}), \\qquad\nu_{i,t}= \\alpha_i + \\mathbf{x}_{i,t}^\\top\\boldsymbol\\beta + \\phi\\,u_{i,t-1} + \\eta_{i,t}.\n$$\n\nQui $\\alpha_i$ cattura la propensione media soggetto-specifica, $\\boldsymbol\\beta$ gli effetti dei predittori, $\\phi$ la *persistenza dinamica* (quanta parte dello stato passato sopravvive), e $\\eta_{i,t}$ il *rumore di processo*. Se $\\phi=0$, torniamo al GLM statico; se $\\phi\\neq 0$, modelliamo esplicitamente la *dipendenza seriale*.\n\nIn questo capitolo mostreremo come passare dal GLM logit a un *modello processuale autoregressivo* (AR) su scala logit, implementato in *Stan*. Partiremo da un’interpretazione latente del logit, introdurremo l’AR(1) e la sua estensione AR($K$) per memorie più lunghe, simuleremo dati per verificare il recupero dei parametri e confronteremo le stime con un *GLMM logit* (via `brms`). Vedremo che distinguere tra *effetto dei predittori* ($\\boldsymbol\\beta$) e *dinamica interna* ($\\phi$) è essenziale per evitare stime distorte e per ancorare l’analisi statistica a *ipotesi psicologiche* sui meccanismi che generano il comportamento.\n\n::: {.callout-caution collapse=\"true\"}\n### Esempio.\n\nImmaginiamo uno studente che affronta un test a scelta multipla. Con un modello logistico classico possiamo prevedere se risponderà correttamente in base alla difficoltà della domanda. Ma se lo stesso studente sta svolgendo una lunga serie di prove, la sua risposta alla domanda 10 dipende anche da come è andata la domanda 9: un errore può ridurre la fiducia, un successo può aumentarla. In più, col passare del tempo, possono intervenire affaticamento o distrazione.\nIl modello statico logit non cattura nulla di tutto ciò. Per includere questi aspetti servono modelli che riconoscano che ogni osservazione porta memoria del passato.\n:::\n\nL’obiettivo di questo capitolo è mostrare come, con *Stan*, sia possibile *esplicitare il meccanismo generativo* delle risposte, superando i limiti della regressione logistica classica e introducendo la nozione di *processi dinamici autoregressivi* che meglio riflettono la natura temporale dei fenomeni psicologici.\n\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Introduzione ai modelli dinamici in psicologia, superando i limiti dei GLM statici.\n- La regressione logistica classica reinterpretata attraverso variabili latenti e soglie.\n- Estensione al modello AR(1) per catturare la dipendenza temporale e la \"memoria\" del passato.\n- Implementazione pratica in Stan, con simulazione dati e confronto con modelli statici (GLMM).\n- Evidenza che i modelli processuali dinamici forniscono stime più fedeli ai meccanismi generativi.\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, cmdstanr, posterior, brms, bayestestR, insight, conflicted)\n\nconflicts_prefer(posterior::mad)\n```\n:::\n\n:::\n\n\n## Dal modello statico al modello processuale\n\n### La regressione logistica classica\n\nNel modello di regressione logistica (GLM logit) la probabilità di osservare una risposta positiva è:\n\n$$\n\\Pr(y_i=1 \\mid \\mathbf{x}_i) = \\operatorname{logit}^{-1}\\!\\left(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol\\beta\\right).\n$$\n\nQui:\n\n* $\\alpha$ è l’*intercetta*, che rappresenta la tendenza di base a rispondere 1;\n* $\\boldsymbol\\beta$ descrive come i predittori osservati influenzano questa probabilità.\n\nUn modo intuitivo per interpretare la formula è introdurre una *variabile latente continua* $u_i$, che possiamo pensare come la *propensione interna* dell’individuo a rispondere “1”:\n\n$$\nu_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol\\beta + \\varepsilon_i, \n\\qquad \\varepsilon_i \\sim \\text{Logistic}(0,1).\n$$\n\nLa regola di decisione è semplice:\n\n* se $u_i > 0$ allora osserviamo $y_i=1$,\n* se $u_i \\leq 0$ allora osserviamo $y_i=0$.\n\nIn altre parole, immaginiamo che l’individuo abbia una *soglia fissa*: quando la propensione supera questa soglia, la risposta osservata diventa positiva.\n\nPossiamo pensare a $u_i$ come a un “serbatoio di propensione”: se il livello supera la soglia, si osserva una risposta positiva. Nei modelli statici il serbatoio si svuota e si riempie indipendentemente a ogni trial; nei modelli dinamici, invece, il livello attuale dipende anche da quanto era pieno al trial precedente.\n\nNella regressione logistica classica, questa soglia è sempre costante nel tempo e uguale per tutti i trial. Ma nei processi psicologici reali ciò non è sempre realistico: la soglia decisionale (o l’intensità della propensione) può cambiare da un momento all’altro, ad esempio per effetto di apprendimento, fatica o variazioni di motivazione.\n\nEd è proprio da qui che nasce la necessità di *estendere il modello logit statico a un modello dinamico*, in cui la variabile latente $u$ (e talvolta anche la soglia) possa variare nel tempo e riflettere la natura evolutiva dei processi psicologici.\n\n\n## Oltre il GLM: dinamica temporale\n\nNella regressione logistica classica abbiamo visto che ogni risposta osservata $y_i$ può essere pensata come il risultato di una *propensione latente* $u_i$, confrontata con una soglia fissa. Questa impostazione funziona bene se consideriamo le osservazioni come indipendenti e isolate.\n\nMa in psicologia le cose vanno spesso diversamente:\n\n* negli *esperimenti con prove ripetute*, le decisioni prese oggi sono influenzate da quelle appena fatte;\n* nelle *misurazioni longitudinali (EMA)*, lo stato emotivo o motivazionale di un momento dipende in parte da quello precedente;\n* nei *compiti di apprendimento*, l’esperienza accumulata modifica gradualmente la propensione a scegliere un’opzione rispetto a un’altra.\n\nIn tutti questi casi, è naturale immaginare che la variabile latente *$u_{i,t}$ non nasca da zero a ogni prova*, ma *porti memoria del passato*.\n\n\n## Il modello AR(1)\n\nPer rendere esplicita la dipendenza dal passato, usiamo un modello *autoregressivo di ordine 1* (AR(1); @chatfield2019analysis):\n\n$$\n\\begin{aligned}\nu_{i,t} &= \\alpha_i \n          + \\mathbf{x}_{i,t}^\\top \\boldsymbol\\beta \n          + \\phi \\, u_{i,t-1} \n          + \\eta_{i,t}, \n& \\eta_{i,t} \\sim \\mathcal{N}(0,\\sigma_u), \\\\[6pt]\ny_{i,t} \\mid u_{i,t} &\\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_{i,t})\\right).\n\\end{aligned}\n$$\n\nPossiamo immaginare $u_{i,t}$ come il livello di un “serbatoio di propensione”: se questo valore supera la soglia implicita dello 0 sulla scala logit, la risposta osservata è positiva $(y_{i,t}=1)$. La novità rispetto al modello statico è che il livello attuale $u_{i,t}$ dipende anche da quello precedente $u_{i,t-1}$, attraverso il termine $\\phi u_{i,t-1}$.\n\n**Significati dei parametri del modello AR(1):**\n\n* *$\\alpha_i$ (intercetta soggetto-specifica):* propensione media di un individuo (es. uno studente molto ansioso potrebbe avere più probabilità di rispondere “no”).\n* *$\\beta$ (effetto dei predittori):* effetto di variabili osservabili (es. domande più facili aumentano la probabilità di risposta corretta).\n* *$\\phi$ (persistenza dinamica):* quanta parte dello stato passato sopravvive:\n\n  * se $\\phi=0$, nessuna memoria: ogni risposta è “indipendente”,\n  * se $\\phi>0$, inerzia: un successo ieri aumenta la probabilità di successo oggi,\n  * se $\\phi<0$, alternanza: un successo ieri rende più probabile un errore oggi (pattern a zig-zag).\n* *$\\sigma_u$ (variabilità del processo):* irregolarità: se grande, le traiettorie diventano rumorose (es. risposte altalenanti per distrazioni).\n\nUn piccolo schema concettuale aiuta a visualizzare:\n\n```\nu(t-1)  ──▶  u(t)  ──▶  y(t)\n   │\n   └─────────── φ ───────────┘\n```\n\nPer esempio:\n\n* $\\alpha_i$: uno studente particolarmente ansioso potrebbe avere un’alta probabilità di rispondere “no” a prescindere dalla domanda;\n* $\\beta$: se la domanda è facile ($x=1$), aumenta la probabilità di risposta corretta;\n* $\\phi$: se lo studente ha risposto correttamente ieri, oggi sarà più probabile che risponda ancora correttamente;\n* $\\sigma_u$: cattura la variabilità inspiegata, come distrazioni improvvise.\n\n\n### Che cos’è $u_{i,t}$?\n\n* $u_{i,t}$ non è osservato: è uno *stato latente*.\n* Possiamo pensarlo come il “livello di propensione” di un individuo in un certo istante $t$.\n* L’osservazione $y_{i,t}$ (corretto/errato, sì/no, 1/0) nasce da questo stato: se $u_{i,t}$ è alto, la probabilità di risposta positiva è alta; se è basso, è bassa.\n* Nei modelli Bayesiani o di stato latente, i valori di $u_{i,t}$ non si calcolano direttamente dai dati ma vengono *stimati/inferiti* dal modello. In pratica, otteniamo una distribuzione a posteriori su ciascun $u_{i,t}$, non un singolo valore deterministico.\n\n\n### E il ruolo di $\\phi$?\n\nIl coefficiente $\\phi$ funziona come un “peso di memoria”:\n\n* Se $\\phi = 0$, il passato non conta: $u\\_{i,t}$ dipende solo dai predittori e dal rumore.\n* Se $\\phi > 0$, c’è *inerzia*: lo stato precedente influenza positivamente quello attuale.\n* Se $\\phi < 0$, c’è *compensazione* o alternanza: uno stato alto ieri spinge verso uno basso oggi.\n\nFormalmente, $\\phi$ è un coefficiente di regressione come $\\alpha$ e $\\beta$, ma agisce *sulla variabile latente del tempo precedente*, quindi introduce dipendenza temporale.\n\n\n### Come “si trovano” i valori di $u_{i,t-1}$?\n\n* All’inizio (al tempo $t=1$), bisogna specificare una *condizione iniziale* per $u_{i,0}$, ad esempio assumendo $u_{i,0} \\sim \\mathcal{N}(0,\\sigma_0)$.\n* Per i tempi successivi, ogni $u_{i,t}$ viene costruito ricorsivamente dal precedente: il modello stesso definisce la sequenza degli stati latenti.\n* In fase di stima (ad esempio con Stan), si usano i dati osservati $y_{i,t}$ per inferire a posteriori quali valori plausibili di $u_{i,t}$ rendono il modello coerente con le risposte osservate.\n\nRiassumendo:\n\n* $u_{i,t}$: stato latente, stimato dal modello, non osservato.\n* $\\phi$: coefficiente che regola quanto lo stato passato influenza quello presente.\n* $\\alpha_i$, $\\beta$: intercetta e predittori osservati, come in una regressione logistica.\n* $\\sigma_u$: variabilità residua del processo latente.\n\n\n### Perché è importante?\n\nCon il modello AR(1) facciamo un passo oltre la regressione logistica classica. La probabilità di risposta non è più determinata solo dai *fattori esterni osservati*, ma anche dagli *stati interni accumulati nel tempo*. In altre parole, il comportamento osservato non nasce “da zero” a ogni prova: porta con sé una *traccia del passato*.\n\nEsempi concreti aiutano a capirlo:\n\n* *Compito di apprendimento:* se un partecipante ha appena ricevuto un rinforzo positivo, la sua propensione a ripetere la stessa scelta sarà più alta al trial successivo.\n* *Diario EMA:* un umore negativo oggi aumenta la probabilità di trovarsi in uno stato simile anche domani, a meno che un evento esterno intervenga a interrompere la continuità.\n\nLa lezione fondamentale è questa: *le scelte non sono indipendenti, ma intrecciate con la storia recente dell’individuo*. Ed è proprio questa “memoria del passato” che rende i modelli dinamici strumenti più realistici e potenti per descrivere processi psicologici rispetto ai modelli statici.\n\n\n::: {.callout-note collapse=\"true\"}\n### Esempio\n\nPer fare un esempio semplice, consideriamo un modello *continuo* con *un solo predittore continuo*.\nLa dipendenza temporale la collochiamo *nei residui*, con una struttura *AR(1)*. In questo modo evitiamo il problema di introdurre variabili latenti non osservabili come $u$.\n\nPer il soggetto $i$ al tempo $t$:\n\n$$\n\\begin{aligned}\ny_{i,t} &= \\alpha_i + \\beta\\,x_{i,t} + e_{i,t},\\\\\ne_{i,t} &= \\phi\\, e_{i,t-1} + \\eta_{i,t}, \\qquad \\eta_{i,t}\\sim\\mathcal N(0,\\sigma_\\eta^2).\n\\end{aligned}\n$$\n\ndove:\n\n* $y_{i,t}$ è la *risposta osservata* (continua),\n* $x_{i,t}$ è il *predittore osservato* (continuo),\n* $e_{i,t}$ è l’*errore* con memoria AR(1),\n* $\\phi$ è l’*autocorrelazione a lag 1* dei residui,\n* $\\sigma_\\eta$ controlla l’*ampiezza del rumore “nuovo”* che entra a ogni passo.\n\nIn altre parole, il valore osservato $y_{i,t}$ è composto da:\n\n* una parte *sistematicamente spiegata* dal predittore $x_{i,t}$, ponderata da $\\beta$,\n* una parte *casuale*, $e_{i,t}$, che però non è indipendente: conserva memoria del residuo precedente ($\\phi e_{i,t-1}$).\n  Se ieri il modello ha sovrastimato, è probabile che anche oggi rimanga un residuo positivo; lo stesso vale per una sottostima.\n\n> **Nota su $e_{i,0}$.** Per generare una serie “stazionaria”, inizializziamo il primo residuo dalla distribuzione stazionaria:\n>\n> $$\n> e_{i,0} \\sim \\mathcal N\\!\\left(0,\\; \\frac{\\sigma_\\eta^2}{1-\\phi^2}\\right).\n> $$\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ---- Funzione di simulazione ----\nsimulate_reg_ar1 <- function(alpha, beta = 0.8, phi = 0.7, sigma_eta = 1.0,\n                             T_ = 60, x_sd = 1, seed = 123) {\n  set.seed(seed)\n  n_subj <- length(alpha)\n  rec <- vector(\"list\", n_subj)\n\n  # Varianza stazionaria dei residui AR(1)\n  sigma_e2 <- sigma_eta^2 / (1 - phi^2)\n\n  for (i in seq_len(n_subj)) {\n    e_prev <- rnorm(1, mean = 0, sd = sqrt(sigma_e2))  # e_{i,0}\n    rows <- vector(\"list\", T_)\n    for (t in seq_len(T_)) {\n      x_t <- rnorm(1, 0, x_sd)             # predittore osservato\n      eta <- rnorm(1, 0, sigma_eta)        # innovazione\n      e_t <- phi * e_prev + eta            # residuo AR(1)\n      y_t <- alpha[i] + beta * x_t + e_t   # risposta continua\n      rows[[t]] <- data.frame(\n        subject = i, time = t,\n        x = x_t, e = e_t, y = y_t\n      )\n      e_prev <- e_t\n    }\n    rec[[i]] <- dplyr::bind_rows(rows)\n  }\n  dplyr::bind_rows(rec)\n}\n\n# ---- Parametri e simulazione ----\nalpha <- c(-1, 0, 1)   # intercette soggetto-specifiche\nbeta  <- 0.8           # effetto del predittore x\nphi   <- 0.7           # autocorrelazione a lag 1 dei residui\nsigma_eta <- 1.0       # deviazione standard innovazione\nT_    <- 60            # lunghezza serie temporale\n\ndf <- simulate_reg_ar1(alpha, beta, phi, sigma_eta, T_)\n\n# ---- Grafico didattico ----\ndf <- df %>%\n  group_by(subject) %>%\n  mutate(x_scaled = (x - mean(x)) / sd(x) * sd(y) + mean(y)) %>%\n  ungroup()\n\nggplot(df, aes(time)) +\n  geom_line(aes(y = y), linewidth = 0.9) +\n  geom_line(aes(y = x_scaled), linetype = \"dashed\") +\n  geom_hline(aes(yintercept = ave_y),\n             data = df %>% group_by(subject) %>% summarise(ave_y = mean(y)),\n             linewidth = 0.3, color = \"grey40\") +\n  facet_wrap(~ subject, ncol = 1,\n             labeller = as_labeller(function(s) {\n               i <- as.integer(s)\n               paste0(\"Soggetto \", s, \" (alpha = \", alpha[i], \")\")\n             })) +\n  labs(title = \"Regressione con residui AR(1): y(t) e x(t) riscalato\",\n       subtitle = paste0(\"phi = \", phi, \", sigma_eta = \", sigma_eta, \", beta = \", beta),\n       y = \"y(t)  (x in tratteggio, riscalato)\", x = \"Tempo\")\n```\n\n::: {.cell-output-display}\n![](05_logistic_process_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n1. **Struttura del modello**\n\n   * La parte regressiva è $\\alpha_i + \\beta x_{i,t}$.\n   * La memoria sta nei residui: $e_{i,t} = \\phi e_{i,t-1} + \\eta_{i,t}$.\n   * Così il predittore $x_{i,t}$ è esogeno e $\\phi$ ha un significato chiaro: è l’*autocorrelazione* tra residui consecutivi.\n\n2. **Grafico a pannelli**\n\n   * Linea piena = $y_{i,t}$.\n   * Tratteggio = $x_{i,t}$, riscalato per confrontarlo visivamente con $y$.\n   * Si vede che $y$ segue $x$, ma non cambia bruscamente: la presenza di $\\phi=0.7$ rende la traiettoria più “liscia” grazie alla memoria nei residui.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ---- Verifica dell'AR(1) sui residui (soggetto 1) ----\ndf1 <- df %>% filter(subject == 1)\nols_fit <- lm(y ~ x, data = df1)\nresid_ols <- resid(ols_fit)\n\npar(mfrow = c(1, 2))\nplot(df1$time, resid_ols, type = \"l\", main = \"Residui OLS (soggetto 1)\",\n     xlab = \"Tempo\", ylab = \"Residuo\")\nacf(resid_ols, main = \"ACF residui OLS (soggetto 1)\")\n```\n\n::: {.cell-output-display}\n![](05_logistic_process_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=85%}\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\n```\n:::\n\n\n3. **ACF dei residui OLS**\n\nNel modello di regressione lineare semplice $y \\sim x$ si assume che i residui siano indipendenti. Nel nostro esempio, però, i residui hanno memoria AR(1): se ieri erano positivi, oggi tendono a esserlo di nuovo.\n\nL’*ACF (autocorrelation function)* dei residui ci permette di vedere questo effetto:\n\n* misura quanto i residui in tempi diversi sono correlati,\n* il valore a *lag 1* (tra residui consecutivi) è chiaramente positivo e vicino a $\\phi$.\n\nQuindi:\n\n* il modello lineare classico che assume residui indipendenti *non descrive bene i dati*,\n* occorre un modello che includa la memoria, come l’AR(1) sui residui o un modello equivalente in stato-spazio.\n:::\n\n\n## Dall’AR(1) all’AR(K)\n\nIl modello AR(1) ci ha mostrato che lo stato latente $u_{i,t}$ non nasce mai da zero, ma porta con sé una traccia del passato immediato. Tuttavia, in molti processi psicologici questa “memoria a un passo” può essere troppo corta.\n\nPensiamo a situazioni in cui:\n\n* l’effetto di un’esperienza non si esaurisce al trial successivo ma dura più a lungo,\n* l’umore di oggi non dipende solo da quello di ieri, ma anche da quello di due o tre giorni fa,\n* l’apprendimento si accumula su una *coda di feedback* estesa.\n\nIn questi casi conviene estendere il modello ad un processo *autoregressivo di ordine $K$ (AR(K))*:\n\n$$\nu_{i,t} = \\alpha_i \n        + \\mathbf{x}_{i,t}^\\top \\boldsymbol\\beta \n        + \\phi_1 u_{i,t-1} \n        + \\phi_2 u_{i,t-2} \n        + \\dots \n        + \\phi_K u_{i,t-K} \n        + \\eta_{i,t},\n$$\n$$\n\\eta_{i,t} \\sim \\mathcal{N}(0,\\sigma_u).\n$$\n\n### Interpretazione psicologica\n\n* *$K=1$ (AR(1))* → memoria cortissima: il presente dipende solo dallo stato immediatamente precedente (es. l’effetto diretto di un feedback appena ricevuto).\n* *$K=2$ (AR(2))* → memoria breve: lo stato attuale risente degli ultimi due passi (es. l’umore influenzato dagli ultimi due giorni consecutivi).\n* *$K \\geq 3$* → memoria più lunga: utile per processi cumulativi o ciclici (es. oscillazioni tra fasi di alta e bassa motivazione).\n\nIn altre parole, aumentando $K$ allarghiamo la “finestra temporale” che il modello utilizza per spiegare il presente.\n\n### Perché è utile?\n\nL’estensione ad AR(K) consente di modellare una gamma più ricca di dinamiche:\n\n* *inerzia semplice* (AR(1)),\n* *effetti ritardati*, che emergono dopo due o più step,\n* *oscillazioni regolari* o *pattern ciclici* (catturabili già con un AR(2) o AR(3)).\n\nCosì il modello diventa più flessibile e aderente alla complessità dei processi psicologici reali, nei quali la memoria del passato non ha sempre la stessa profondità, ma può essere breve, prolungata o ciclica.\n\n::: {.callout-note}\n**Quando usare modelli AR in psicologia?**\n\n* Nei compiti decisionali con *prove ripetute*, quando sospettiamo che non solo l’ultima esperienza ma anche quelle precedenti influenzino la scelta.\n* Negli *studi EMA*, quando l’umore o la motivazione di oggi risentono di più giorni consecutivi.\n* In generale, in tutti i casi in cui la *sequenza temporale* porta informazioni importanti che sarebbe un errore trattare come semplice rumore.\n:::\n\n\n## Simulazione dati \n\nPrima di stimare il modello su dati reali, conviene costruire un dataset *simulato* (AR(1) logit a livello latente). In questo modo possiamo verificare se il modello riesce a recuperare parametri noti e comprendere meglio il suo funzionamento.\n\nImmaginiamo $I=100$ soggetti, ciascuno con $T=30$ prove, e un predittore binario $x_{i,t}$ (ad esempio: tipo di stimolo, 0 = neutro, 1 = emozionale). Lo stato latente $u_{i,t}$ evolve come un AR(1) sulla *scala logit*.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\n\nI   <- 100   # numero di soggetti\nTt  <- 30    # numero di trial per soggetto\nN   <- I*Tt  # osservazioni totali\n\n# Parametri \"veri\" usati per generare i dati\nalpha_mu    <- 0.0   # intercetta media\nalpha_sigma <- 0.7   # variabilità tra-soggetti\nbeta_true   <- 0.6   # effetto del predittore\nphi_true    <- 0.5   # persistenza dinamica\nsigma_u     <- 0.6   # rumore di processo\n\n# Intercette soggetto-specifiche\nalpha_i <- rnorm(I, alpha_mu, alpha_sigma)\n\n# Predittore binario (0/1) random\nx <- rbinom(N, 1, 0.5)\n\n# Costruzione dataset\ndf <- tibble::tibble(\n  id = rep(1:I, each = Tt),\n  t  = rep(1:Tt, times = I),\n  x  = x\n)\n\n# Stato latente e risposta\nu <- numeric(N)\ny <- integer(N)\n\nfor (i in 1:I) {\n  a  <- alpha_i[i]\n  ui <- numeric(Tt)\n  for (tt in 1:Tt) {\n    idx <- (i-1)*Tt + tt\n    mean_ut <- a + beta_true*df$x[idx] + ifelse(tt == 1, 0, phi_true*ui[tt-1])\n    ui[tt]  <- rnorm(1, mean_ut, sigma_u)        # stato latente\n    p       <- 1/(1 + exp(-ui[tt]))              # probabilità risposta\n    y[idx]  <- rbinom(1, 1, p)                   # risposta binaria\n  }\n  u[((i-1)*Tt+1):(i*Tt)] <- ui\n}\n\ndf$u_lat <- u\ndf$y     <- y\n```\n:::\n\n\nIl modello ha bisogno di sapere quale osservazione viene *prima* nello stesso soggetto. Se non stiamo attenti, potremmo collegare l’ultimo trial del soggetto $i$ con il primo del soggetto $i+1$, il che è sbagliato. Per evitare errori, creiamo un indice `prev` che punta al trial precedente *solo dello stesso soggetto*. Se non esiste (primo trial), mettiamo `0`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- df[order(df$id, df$t), ]\nprev <- integer(nrow(df))\nfor (i in unique(df$id)) {\n  idx  <- which(df$id == i)\n  prev[idx] <- c(0, head(idx, -1))  # 0 = nessun precedente\n}\nstopifnot(all(df$t[prev[df$t>1]] == df$t[df$t>1]-1))\n```\n:::\n\n\nEsempio: se il soggetto 5 ha 30 trial, per il trial 12 `prev` punterà al trial 11, mentre per il trial 1 avrà valore `0`.\n\n\n## Tabella-ponte: dall’algebra a Stan\n\nPer tradurre il modello matematico in Stan, costruiamo una “mappa” dei concetti.\n\n| Concetto                           | Simbolo               | Stan                                  | Nota                  |\n| ---------------------------------- | --------------------- | ------------------------------------- | --------------------- |\n| Numero osservazioni                | $N$                 | `int<lower=1> N;`                     |                       |\n| Numero soggetti                    | $I$                 | `int<lower=1> I;`                     |                       |\n| Soggetto per trial                 | —                     | `array[N] int<lower=1,upper=I> id;`   |                       |\n| Trial precedente (stesso soggetto) | —                     | `array[N] int<lower=0,upper=N> prev;` | 0 se non esiste       |\n| Predittori                         | $\\mathbf{x}_{i,t}$ | `array[N] int x;`                     | Estendibile a matrice |\n| Risposta                           | $y_{i,t}$          | `array[N] int y;`                     | Bernoulli             |\n| Stato latente                      | $u_{i,t}$          | `vector[N] u;`                        |                       |\n| Intercetta soggetto                | $\\alpha_i$         | `vector[I] alpha;` (non centrato)     |                       |\n| Persistenza                        | $\\phi$              | `real<lower=-0.99,upper=0.99> phi;`   | vincolo stazionarietà |\n| Rumore di processo                 | $\\sigma_u$         | `real<lower=0> sigma_u;`              | deviazione standard   |\n\n\n## Modello Stan\n\nOra traduciamo il modello AR(1) logit in Stan. L’idea è di rappresentare esplicitamente tre parti del processo:\n\n1. *Intercette soggetto-specifiche* ($\\alpha_i$), stimate in forma *non centrata* per migliorare la mescolanza della catena.\n2. *Evoluzione dello stato latente $u_{i,t}$:*\n\n   * al primo trial di ciascun soggetto, $u_{i,1}$ dipende solo dall’intercetta, dai predittori e dal rumore;\n   * nei trial successivi, $u_{i,t}$ dipende anche dal valore precedente $u_{i,t-1}$, con peso $\\phi$.\n3. *Likelihood:* la risposta osservata $y_{i,t}$ segue una Bernoulli logit con parametro $u_{i,t}$.\n\nInoltre, nel blocco `generated quantities` calcoliamo:\n\n* `y_rep` = repliche simulate, utili per i posterior predictive check;\n* `log_lik` = contributi della verosimiglianza, necessari per il calcolo di LOO/WAIC.\n\nFormalmente, il modello implementato è:\n\n$$\n\\begin{aligned}\nu_{i,1} &\\sim \\mathcal{N}(\\alpha_i + \\mathbf{x}_{i,1}^\\top \\beta, \\sigma_u), \\\\\nu_{i,t} &\\sim \\mathcal{N}(\\alpha_i + \\mathbf{x}_{i,t}^\\top \\beta + \\phi u_{i,t-1}, \\sigma_u) \\quad (t>1), \\\\\ny_{i,t} \\mid u_{i,t} &\\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_{i,t})\\right).\n\\end{aligned}\n$$\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_code <- '\ndata{\n  int<lower=1> N;\n  int<lower=1> I;\n  array[N] int<lower=1,upper=I> id;\n  array[N] int<lower=0,upper=1> x;    // estendibile a vettore\n  array[N] int<lower=0,upper=1> y;\n  array[N] int<lower=0,upper=N> prev; // 0 se non esiste trial precedente dello stesso soggetto\n}\nparameters{\n  vector[I] alpha_raw;\n  real      alpha_mu;\n  real<lower=0> alpha_sigma;\n\n  real beta;\n  real<lower=-0.99, upper=0.99> phi;\n  real<lower=0> sigma_u;\n\n  vector[N] eps; // innovazioni standard N(0,1)\n}\ntransformed parameters{\n  vector[I] alpha = alpha_mu + alpha_sigma * alpha_raw;\n  vector[N] u;\n  for (n in 1:N){\n    real mean_u = alpha[id[n]] + beta * x[n];\n    if (prev[n] == 0) {\n      // opzionale: condizione stazionaria per il primo trial\n      real sd1 = sigma_u / sqrt(1 - square(phi));\n      u[n] = mean_u + sd1 * eps[n];\n    } else {\n      u[n] = mean_u + phi * u[prev[n]] + sigma_u * eps[n];\n    }\n  }\n}\nmodel{\n  // Priori più informative (vedi §2)\n  alpha_raw   ~ normal(0, 1);\n  alpha_mu    ~ normal(0, 0.5);\n  alpha_sigma ~ normal(0, 0.5);   // <lower=0> già impone metà-normale\n  beta        ~ normal(0, 0.5);\n  phi         ~ normal(0, 0.4);   // bounds già imposti\n  sigma_u     ~ normal(0, 0.5);   // metà-normale su sd\n\n  eps ~ normal(0,1);              // innovazioni standard\n  y ~ bernoulli_logit(u);\n}\ngenerated quantities{\n  array[N] int y_rep;\n  vector[N] log_lik;\n  for (n in 1:N){\n    y_rep[n] = bernoulli_logit_rng(u[n]);\n    log_lik[n] = bernoulli_logit_lpmf(y[n] | u[n]);\n  }\n}\n'\nstan_file <- write_stan_file(stan_code)\n```\n:::\n\n\nFocalizziamoci sul blocco di codice che costruisce la *variabile latente dinamica* $u_n$ su cui poi si basa la likelihood logistica dei dati osservati $y_n$.\n\n*Struttura della likelihood.* Il modello assume che la risposta osservata $y_n \\in \\{0,1\\}$ derivi da una regressione logistica:\n\n$$\ny_n \\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_n)\\right),\n$$\n\ndove $u_n$ è il *predittore lineare dinamico* che evolve nel tempo con memoria AR(1).\nIn pratica, invece di avere un predittore statico $u_n = \\alpha_i + \\beta x_n$, qui aggiungiamo una *dipendenza dal passato*: lo stato latente corrente dipende anche da quello precedente.\n\nCostruzione di $u_n$ nel codice:\n\n```stan\nfor (n in 1:N){\n  real mean_u = alpha[id[n]] + beta * x[n];\n  if (prev[n] == 0) {\n    // primo trial del soggetto\n    real sd1 = sigma_u / sqrt(1 - square(phi));\n    u[n] = mean_u + sd1 * eps[n];\n  } else {\n    // trial successivi\n    u[n] = mean_u + phi * u[prev[n]] + sigma_u * eps[n];\n  }\n}\n```\n\n* **Linea 1.** Calcoliamo il contributo sistematico del soggetto e del predittore:\n\n  $$\n  \\texttt{mean\\_u} = \\alpha_{id[n]} + \\beta x_n.\n  $$\n\n  Qui $\\alpha_{id[n]}$ è l’intercetta specifica del soggetto, mentre $\\beta x_n$ è l’effetto del predittore osservato.\n\n* **Caso `prev[n]==0`.** È il *primo trial* di quel soggetto. Non abbiamo uno stato precedente a cui agganciarci, quindi inizializziamo $u_n$ assumendo la *condizione stazionaria* del processo AR(1):\n\n  $$\n  u_n \\sim \\mathcal N\\!\\left(\\texttt{mean\\_u}, \\; \\frac{\\sigma_u^2}{1-\\phi^2}\\right).\n  $$\n\n  Questo è implementato come `mean_u + sd1 * eps[n]`, dove `eps[n] ~ Normal(0,1)` e `sd1 = sigma_u / sqrt{1 - phi^2}`.\n\n* **Caso `prev[n]!=0`.** È un trial successivo. In questo caso $u_n$ dipende *dal valore precedente* $u_{prev[n]}$:\n\n  $$\n  u_n = \\texttt{mean\\_u} + \\phi \\, u_{prev[n]} + \\sigma_u \\, \\varepsilon_n,\n  \\quad \\varepsilon_n \\sim \\mathcal N(0,1).\n  $$\n\n  Qui $\\phi$ è il coefficiente AR(1) che controlla *quanto del passato sopravvive nel presente*.\n\n\nIntuizione:\n\n* *$\\alpha_i$:* propensione media del soggetto.\n* *$\\beta x_n$:* effetto del predittore osservato al trial $n$.\n* *$\\phi u_{prev[n]}$:* memoria: se ieri $u$ era alto, oggi tenderà a restare alto (se $\\phi>0$).\n* *$\\sigma_u \\varepsilon_n$:* rumore nuovo che introduce variabilità tra un trial e l’altro.\n\nIl risultato finale è che la probabilità di risposta positiva è:\n\n$$\n\\Pr(y_n=1) = \\operatorname{logit}^{-1}(u_n),\n$$\n\ne l’intera likelihood del modello è:\n\n$$\np(y \\mid \\alpha, \\beta, \\phi, \\sigma_u) = \\prod_{n=1}^N \\text{Bernoulli}\\!\\left(y_n \\,\\middle|\\, \\operatorname{logit}^{-1}(u_n)\\right),\n$$\n\ndove ciascun $u_n$ è costruito ricorsivamente come sopra.\n\nGenerazione dei dati di input:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_dat <- list(\n  N   = nrow(df),\n  I   = length(unique(df$id)),\n  id  = as.integer(df$id),\n  x   = as.array(as.integer(df$x)),\n  y   = as.array(as.integer(df$y)),\n  prev = as.array(prev)\n)\n```\n:::\n\n\nCompilazione del modello:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod <- cmdstanr::cmdstan_model(stan_file)\n```\n:::\n\n\nCampionamento:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- mod$sample(\n  data = stan_dat,\n  seed = 2024,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 1500,\n  adapt_delta = 0.99,\n  max_treedepth = 15\n)\n```\n:::\n\n\nRiassunto dei parametri chiave:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit$summary(c(\"alpha_mu\",\"alpha_sigma\",\"beta\",\"phi\",\"sigma_u\"))\n#> # A tibble: 5 × 10\n#>   variable     mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#>   <chr>       <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha_mu    0.104  0.098 0.099 0.094 -0.047 0.275 1.004 1146.168 1890.425\n#> 2 alpha_sigma 0.691  0.684 0.116 0.114  0.517 0.895 1.002  936.525 2046.042\n#> 3 beta        0.609  0.607 0.094 0.095  0.456 0.770 1.000 2591.209 4164.984\n#> 4 phi         0.492  0.495 0.069 0.068  0.374 0.601 1.001 1218.997 2733.870\n#> 5 sigma_u     0.695  0.691 0.187 0.176  0.393 1.004 1.005  381.850  561.846\n```\n:::\n\n\n**Lettura dei risultati.**\n\nConfrontiamo i valori stimati con quelli usati nella simulazione:\n\n* *$\\alpha_\\mu$ (vero = 0.0)* → stimato ≈ 0.10.\n  L’intercetta media è molto vicina al valore vero, con intervallo che comprende lo 0. La stima è quindi ben calibrata.\n\n* *$\\alpha_\\sigma$ (vero = 0.7)* → stimato ≈ 0.69.\n  La variabilità tra soggetti è recuperata quasi perfettamente. Questo mostra che il modello distingue bene la propensione media dei soggetti dalle loro differenze individuali.\n\n* *$\\beta$ (vero = 0.6)* → stimato ≈ 0.61.\n  L’effetto del predittore viene stimato con grande precisione, centrato sul valore vero.\n\n* *$\\phi$ (vero = 0.5)* → stimato ≈ 0.49.\n  Anche il parametro di persistenza dinamica è correttamente recuperato: la memoria del passato è catturata in linea con i dati generati.\n\n* *$\\sigma_u$ (vero = 0.6)* → stimato ≈ 0.69.\n  Il rumore di processo è leggermente sovrastimato, ma rimane molto vicino al valore usato nella simulazione.\n\nIn sintesi, il modello MCMC recupera in modo accurato tutti i parametri simulati. Le diagnostiche (Rhat ≈ 1, ESS elevati, nessuna divergenza) confermano che la catena ha esplorato bene lo spazio dei parametri.\n\n\n### Diagnostica e Posterior Predictive Check\n\nUn passo fondamentale è confrontare i dati osservati con quelli simulati dal modello (`y_rep`).\nSe il modello è adeguato, le distribuzioni delle repliche devono sovrapporsi a quella dei dati reali.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nyrep_draws <- fit$draws(\"y_rep\")\n\n# Converte in data.frame e poi in matrice\nyrep_df  <- as_draws_df(yrep_draws)\nyrep_mat <- as.matrix(yrep_df[, grepl(\"^y_rep\", names(yrep_df))])\n\n# proporzione osservata\nprop_obs <- mean(stan_dat$y)\n\n# proporzioni replicate (una per draw)\nprop_rep <- rowMeans(yrep_mat)\n\nppc_dens_overlay(y = stan_dat$y, yrep = yrep_mat[1:100, ])\n```\n\n::: {.cell-output-display}\n![](05_logistic_process_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\nIl *posterior predictive check* mostra che la distribuzione dei dati simulati dal modello (`y_rep`) si sovrappone bene a quella dei dati osservati (`y`).\n\n* La *densità osservata* (linea nera) cade quasi sempre all’interno del ventaglio di densità replicate (linee colorate).\n* Questo significa che il modello riesce a generare dati che “assomigliano” a quelli reali, un segnale che la struttura autoregressiva AR(1) e i parametri stimati catturano i meccanismi principali del processo.\n* Se vedessimo sistematiche discrepanze (ad esempio code troppo corte o una distribuzione spostata), sarebbe un campanello d’allarme che il modello è **mal specificato** o che mancano variabili importanti.\n\nIn sintesi: un buon PPC non prova che il modello sia *vero*, ma aumenta la fiducia che sia *plausibile* e che descriva i dati in modo coerente con le ipotesi teoriche.\n\n\n## Confronto con GLMM logit (via `brm`)\n\nPer confronto abbiamo stimato lo stesso dataset con un GLM logit semplice in `brm`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat <- tibble(\n  y = as.numeric(stan_dat$y),\n  x = as.numeric(stan_dat$x),\n  id = as.numeric(stan_dat$id)\n)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ATTENZIONE: brms ignora la dipendenza seriale e l'eterogeneità nei trials!\nfit_glmer <- brm(\n  y ~ x + (x | id),\n  data = dat,\n  family = bernoulli(link = \"logit\"),\n  prior = c(prior(normal(0, 1), class = \"b\")),\n  chains = 2, iter = 2000, seed = 123,\n  backend = \"cmdstanr\"\n)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fit_glmer)\n#>  Family: bernoulli \n#>   Links: mu = logit \n#> Formula: y ~ x + (x | id) \n#>    Data: dat (Number of observations: 3000) \n#>   Draws: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 2000\n#> \n#> Multilevel Hyperparameters:\n#> ~id (Number of levels: 100) \n#>                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sd(Intercept)        1.20      0.11     1.00     1.44 1.00      608     1062\n#> sd(x)                0.13      0.10     0.00     0.37 1.00      552      821\n#> cor(Intercept,x)    -0.09      0.55    -0.95     0.92 1.00     2199     1438\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     0.42      0.13     0.17     0.68 1.01      347      630\n#> x             0.50      0.09     0.32     0.69 1.00     2547     1579\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\n\n### Interpretazione dei risultati *brm* \n\nIl modello multilevel logit con slope/intercetta casuali, $y \\sim x + (x \\mid id)$, stima:\n\n* *Intercept = 0.42* (SE ≈ 0.13): log-odds media di risposta 1 quando $x=0$, considerando la variabilità tra soggetti.\n* *$x = 0.50$* (SE ≈ 0.09; 95% CI \\[0.32, 0.69]): effetto medio del predittore sulla log-odds, con pooling parziale tra soggetti.\n\n*Eterogeneità tra soggetti:*\n\n* *sd(Intercept) ≈ 1.20:* forte variabilità individuale nella propensione di base.\n* *sd(x) ≈ 0.13:* variabilità più contenuta nell’effetto di $x$.\n* *cor(Intercept, x) ≈ −0.09* con IC molto ampio: nessuna evidenza di relazione sistematica tra tendenza di base e sensibilità al predittore.\n\nIl modello, quindi, distingue l’effetto medio di $x$ dalla notevole eterogeneità individuale, ma non rappresenta esplicitamente la dipendenza seriale tra prove.\n\n\n### Confronto con Stan (modello processuale AR(1))\n\nIl modello AR(1) in Stan, stimato sugli stessi dati simulati, recupera accuratamente i valori veri:\n\n* $\\beta \\approx 0.61$ (vero = 0.60),\n* $\\phi \\approx 0.49$ (vero = 0.50),\n* $\\alpha_\\sigma \\approx 0.69$ (vero = 0.70),\n* $\\sigma_u \\approx 0.69$ (vero = 0.60).\n\nLa differenza principale riguarda l’effetto di $x$:\n\n* Nel GLMM multilevel, $\\hat\\beta \\approx 0.50$,\n* Nel modello processuale AR(1), $\\hat\\beta \\approx 0.61$, perfettamente in linea con il valore vero.\n\nQuesto accade perché il modello *brm* controlla l’eterogeneità individuale ma *non rappresenta la dinamica temporale*: la memoria del passato ($\\phi$) resta non modellata e una parte della dipendenza seriale viene assorbita nelle stime delle varianze casuali o nell’effetto medio del predittore.\n\nIl modello in Stan, invece, *separa esplicitamente* il contributo del predittore ($\\beta$) dalla persistenza dinamica ($\\phi$) e dal rumore di processo ($\\sigma_u$), producendo stime più fedeli al meccanismo generativo.\n\n\n### Messaggio chiave\n\n* Il GLMM con slope/intercette casuali cattura bene l’eterogeneità tra soggetti, ma non la dipendenza temporale.\n* Il modello AR(1) in Stan, introducendo la dinamica degli stati latenti, fornisce un effetto di $x$ più vicino al valore vero e una rappresentazione più realistica del processo psicologico sottostante.\n\n## Riflessioni conclusive {.unnumbered .unlisted} \n\nIn questo capitolo abbiamo superato i limiti del *GLM logit statico* introducendo una *struttura dinamica* sugli stati latenti. L’idea chiave è semplice e potente: la probabilità di risposta non dipende solo da $\\mathbf{x}$, ma anche da *ciò che è appena accaduto*, tramite lo stato $u_{i,t}$ che *accumula* informazioni nel tempo. Con l’AR(1) (ed estensioni AR($K$)) abbiamo reso esplicita la *memoria* del processo; con *Stan* abbiamo separato in modo netto *propensione media* ($\\alpha_i$), *effetto dei predittori* ($\\boldsymbol\\beta$), *persistenza* ($\\phi$) e *rumore di processo* ($\\sigma_u$), ottenendo stime fedeli al *meccanismo generativo*.\n\nIl confronto con un *GLMM logit* ha chiarito il punto: i modelli multilevel gestiscono bene l’eterogeneità tra soggetti, ma se la *dipendenza temporale* non è rappresentata, parte della dinamica viene assorbita in varianze casuali o negli effetti medi, *distorcendo* l’interpretazione. I *posterior predictive checks* hanno confermato che il modello processuale riproduce le caratteristiche salienti dei dati, aumentando la fiducia nella sua adeguatezza.\n\nIl messaggio metodologico è duplice:\n\n1. **Statisticamente**, i GLM restano un quadro unificante, ma vanno estesi quando la struttura dei dati lo richiede: nei compiti ripetuti, nelle misure EMA, nei processi di apprendimento o affaticamento, la *storia* conta.\n2. **Psicologicamente**, passare a un *modello processuale* significa spostarsi dalla *descrizione* all’*ipotesi sui meccanismi*: ciò che stimiamo non è solo “se un predittore influisce”, ma *come* l’influenza si accumula, persiste o si alterna nel tempo.\n\nNei capitoli successivi useremo questa logica per ampliare la modellazione di processi cognitivi e decisionali: la dinamica latente diventerà il filo conduttore che collega il dato osservato al *processo* che lo ha generato.\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#>  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#> [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [28] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#> [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#> [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#> [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#> [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#> [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#> [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#> [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#> [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#> [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#> [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#> [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#> [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#> [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#> [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#> [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#> [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#> [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#> [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#> [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#> [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#> [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#> [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#> [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#> [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#> [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#> [85] MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n\n",
    "supporting": [
      "05_logistic_process_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}