{
  "hash": "c55f9571b7d6639714bdb9d620f2ed76",
  "result": {
    "engine": "knitr",
    "markdown": "# Modello di Poisson {#sec-poisson-model}\n\n## Introduzione  {.unnumbered .unlisted} \n\nNelle sezioni precedenti abbiamo visto come i *modelli lineari generalizzati* possano estendere la logica della regressione a esiti non continui, come variabili dicotomiche o proporzioni. Un altro tipo di dati molto comune nella ricerca psicologica e sociale è costituito dai *conteggi*: quante volte si verifica un certo evento in un intervallo di tempo o in un contesto definito. Pensiamo, ad esempio, al numero di errori commessi in un compito cognitivo, al numero di episodi di un comportamento clinicamente rilevante, o al numero di interazioni osservate in un gruppo.\n\nPer modellare questi dati ricorriamo alla *regressione di Poisson*, che assume che la variabile di risposta $Y$ segua una distribuzione di Poisson e che il logaritmo del suo valore atteso possa essere espresso come una combinazione lineare di parametri sconosciuti. In questo modo, possiamo descrivere il tasso medio di occorrenza di un evento e studiare come esso vari al variare dei predittori.\n\nIn questo capitolo utilizzeremo *CmdStan* per stimare un modello di Poisson in chiave bayesiana. Dopo aver esaminato la media a posteriori e l’incertezza associata al tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ciascun anno, ci chiederemo se vi siano evidenze di una tendenza crescente nel tempo. Questo esempio, oltre a illustrare il funzionamento del modello di Poisson, mostra anche come i GLM possano essere applicati a dati di grande rilevanza sociale.\n\nPer chi volesse approfondire il contesto sostantivo, segnaliamo l’articolo *Racial Disparities in Police Use of Deadly Force Against Unarmed Individuals Persist After Appropriately Benchmarking Shooting Data on Violent Crime Rates* \\[@ross2021racial], che offre uno sfondo importante al fenomeno analizzato. La lettura non è obbligatoria per seguire il capitolo, ma aiuta a comprendere meglio il valore applicativo di questo tipo di analisi.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Introduzione alla regressione di Poisson per dati di conteggio.\n- Studio dell'andamento temporale delle sparatorie fatali della polizia USA (2015-2024).\n- Implementazione del modello in Stan.\n- Posterior predictive check e analisi degli Incidence Rate Ratios (IRR).\n- Traduzione dei coefficienti in termini di conteggi attesi e trend percentuale annuo.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere [Racial Disparities in Police Use of Deadly Force Against Unarmed Individuals Persist After Appropriately Benchmarking Shooting Data on Violent Crime Rates](https://journals.sagepub.com/doi/full/10.1177/1948550620916071) per ottenere una panoramica approfondita su questo fenomeno e sul relativo ambito di ricerca.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, HDInterval, lubridate, brms, bayesplot, tidybayes, posterior, tidyr)\n```\n:::\n\n:::\n\n\n## Regressione di Poisson \n\nLa regressione di Poisson è un caso di GLM per variabili di risposta *di conteggio* (0, 1, 2, …). Denoteremo con $\\lambda_i$ il *valore atteso* (e, sotto il modello di Poisson, anche la varianza) del conteggio $Y_i$ alla $i$-esima osservazione.\n\n\n### Distribuzione di base\n\nUna variabile casuale di Poisson ha funzione di massa\n\n$$\n\\Pr(Y=y)=\\frac{\\lambda^{\\,y}e^{-\\lambda}}{y!},\\qquad y\\in\\{0,1,2,\\dots\\},\n$$\ndove $\\lambda>0$ è sia media sia varianza: $\\mathbb{E}[Y]=\\lambda,\\ \\mathrm{Var}(Y)=\\lambda$.\n\nNel contesto del modello di regressione,\n\n$$\nY_i \\mid \\mathbf{x}_i \\sim \\text{Poisson}(\\lambda_i),\n\\qquad \\lambda_i>0 .\n$$\n\n### Forma GLM e funzione di legame\n\nPer garantire $\\lambda_i>0$ si usa il *link logaritmico* (naturale):\n\n$$\n\\log \\lambda_i = \\eta_i\n\\quad\\text{con}\\quad\n\\eta_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n$$\nEquivalente a:\n\n$$\n\\lambda_i = \\exp(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}).\n$$\n\n> Nota terminologica: il *link* è $\\log(\\cdot)$; l’esponenziale è la sua *inversa*. Non è corretto chiamare “link esponenziale”.\n\n\n### Conteggi e predittori\n\nNel modello di regressione di Poisson assumiamo che ciascun conteggio $Y_i$ segua una distribuzione di Poisson con media $\\lambda_i$. Il legame tra la media $\\lambda_i$ e le variabili esplicative è dato dalla funzione logaritmica:\n\n$$\n\\log \\lambda_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n$$\nIn questo modo il numero medio di eventi attesi $\\lambda_i$ viene sempre stimato come un valore positivo:\n\n$$\n\\lambda_i = \\exp(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}).\n$$\nQuesta formulazione è adatta quando tutti i conteggi si riferiscono a intervalli di osservazione uguali (per esempio, il numero di episodi aggressivi in un anno per ciascuno studente). In tal caso non serve introdurre ulteriori correzioni: il modello lavora direttamente sui conteggi osservati.\n\n\n### Interpretazione dei coefficienti\n\nNel modello di regressione di Poisson ogni osservazione $Y_i$ segue\n\n$$\nY_i \\sim \\text{Poisson}(\\lambda_i), \n\\qquad \\log \\lambda_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n$$\nQui $\\lambda_i$ è il numero medio di eventi attesi per l’osservazione $i$.\n\nPer il j-esimo predittore $x_{ij}$, il rapporto tra i valori attesi quando $x_{ij}$ aumenta di 1 unità è\n\n$$\n\\frac{\\lambda_i(x_{ij}+1)}{\\lambda_i(x_{ij})} = \\exp(\\beta_j).\n$$\nQuesto significa che $\\exp(\\beta_j)$ è il *fattore moltiplicativo* atteso sul numero medio di eventi per un incremento unitario di $x_{ij}$.\n\n* Se $\\beta_j = 0$, non c’è effetto ($\\exp(\\beta_j)=1$).\n* Se $\\beta_j > 0$, i conteggi attesi crescono moltiplicati per $\\exp(\\beta_j)$.\n* Se $\\beta_j < 0$, i conteggi attesi diminuiscono, divisi per $\\exp(|\\beta_j|)$.\n\nPer variabili binarie, $\\exp(\\beta_j)$ confronta direttamente i due gruppi (1 contro 0).\n\n**Esempio.** Se studiamo il *numero di episodi aggressivi in un anno* per ciascuno studente, il modello può essere scritto come\n\n$$\n\\log \\lambda_i = \\beta_0 + \\beta_1 \\,\\text{Stress}_i + \\beta_2 \\,\\text{Supporto}_i + \\beta_3 \\,\\text{Depressione}_i.\n$$\nQui $\\exp(\\beta_1)$ indica di quanto si moltiplica il numero medio di episodi aggressivi attesi quando lo stress aumenta di 1 unità, a parità delle altre variabili.\n\n\n### Assunzioni di base\n\nPer usare la regressione di Poisson facciamo alcune ipotesi semplici:\n\n1. **Risposta a conteggio**: la variabile dipendente è un numero intero non negativo (0, 1, 2, …).\n2. **Indipendenza**: le osservazioni sono considerate indipendenti tra loro.\n3. **Media = varianza**: nella distribuzione di Poisson la media e la varianza coincidono. Se nei dati la varianza è molto più grande della media, il modello di Poisson può non essere adatto.\n4. **Relazione log-lineare**: il logaritmo del numero medio di eventi è una combinazione lineare dei predittori.\n\n\n### Come il modello rappresenta lambda\n\nNella regressione di Poisson non stimiamo direttamente il valore medio $\\lambda_i$, ma il suo logaritmo:\n\n$$\n\\eta_i = \\log \\lambda_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n$$\n\n* **Caso senza predittori**: il modello stima solo l’intercetta $\\alpha$. In questo caso\n\n  $$\n  \\lambda = \\exp(\\alpha).\n  $$\n\n* **Caso con predittori**: dati i valori delle variabili esplicative $\\mathbf{x}_i$, il numero medio di eventi per l’osservazione $i$ è\n\n  $$\n  \\lambda_i = \\exp\\big(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}\\big).\n  $$\nIn altre parole, il modello lavora sempre sulla scala logaritmica (più semplice da trattare matematicamente), e poi si passa alla scala naturale dei conteggi applicando l’esponenziale.\n\n\n## La domanda di ricerca\n\nGrazie all’archivio pubblico del *Washington Post* disponiamo di tutti i casi di sparatorie fatali accadute negli Stati Uniti dal 2015 in poi. L’interesse è stimare quante se vi siano evidenze di una tendenza all'aumento di tale tasso nel corso del tempo.\n\nImportiamo e prepariamo i dati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nurl <- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nraw <- read.csv(url, stringsAsFactors = FALSE)\nraw$date <- as.Date(raw$date)\nraw$year <- lubridate::year(raw$date)\n\n# Escludiamo il 2025 perché l’anno è ancora in corso e i dati sarebbero incompleti\nshootings <- subset(raw, year < 2025)\n\ndf <- shootings %>%\n  dplyr::count(year, name = \"events\")\ndf\n#>    year events\n#> 1  2015    995\n#> 2  2016    959\n#> 3  2017    984\n#> 4  2018    992\n#> 5  2019    993\n#> 6  2020   1021\n#> 7  2021   1050\n#> 8  2022   1097\n#> 9  2023   1164\n#> 10 2024   1175\n```\n:::\n\n\nPer facilitare l'interpretazione, centriamo la colonna `year`. In questo modo, l'intercetta si riferità all'anno 2019.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- df |> \n  mutate(year = year - 2019)\ndf\n#>    year events\n#> 1    -4    995\n#> 2    -3    959\n#> 3    -2    984\n#> 4    -1    992\n#> 5     0    993\n#> 6     1   1021\n#> 7     2   1050\n#> 8     3   1097\n#> 9     4   1164\n#> 10    5   1175\n```\n:::\n\n\nA questo punto abbiamo una tabella `df` con due colonne: `year` (centrato), che va dal -4 (2015) a 5 (2024), ed `events`, che contiene il numero di sparatorie fatali registrate in ciascun anno.\n\n\n### Modello Stan\n\nDefiniamo il seguente modello \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_code <- '\ndata {\n  int<lower=1> N;\n  array[N] int<lower=0> y;   // conteggi\n  vector[N] year;            // -4, -3, ..., 5 (non standardizzato)\n}\n\nparameters {\n  real alpha;                // log media per anno 0\n  real beta;                 // effetto per 1 anno (log-IRR per anno)\n}\n\nmodel {\n  // Priors coerenti con: lambda ~ 600 circa, 400–900 plausibile\n  alpha ~ normal(6.4, 0.25);   // oppure 0.30 se preferisci più ampia\n  beta  ~ normal(0, 0.05);     // oppure 0.10 se vuoi più permissiva\n\n  // Poisson con link log\n  y ~ poisson_log(alpha + beta * year);\n}\n\ngenerated quantities {\n  vector[N] eta = alpha + beta * year;\n  vector[N] lambda = exp(eta);\n  array[N] int<lower=0> y_rep;\n  for (n in 1:N) y_rep[n] = poisson_log_rng(eta[n]);\n}\n'\n```\n:::\n\n\nSpecificare la distribuzione a priori: \n\n* **Intercetta**: $\\alpha=\\log\\lambda$. Poiché riteniamo plausibile, *prima dei dati*, una media annua $\\lambda$ centrata attorno a 600, con intervallo \\~400–900, imponiamo\n  $\\alpha \\sim \\mathcal N(6.40,\\ 0.25)$ (oppure $0.30$ per un intervallo un po’ più ampio).\n* **Pendenza**: $\\beta$ è il log-IRR *per anno*. Attese variazioni annue piccole ⇒\n  $\\beta \\sim \\mathcal N(0,\\ 0.05)$ (più prudente) oppure $\\mathcal N(0,\\ 0.10)$ (più ampia).\n\nDati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat <- data.frame(\n  year   = -4:5,\n  events = c(995, 959, 984, 992, 993, 1021, 1050, 1097, 1164, 1175)\n)\n\nstan_data <- list(\n  N = nrow(dat),\n  y = dat$events,\n  year = dat$year\n)\nglimpse(stan_data)\n#> List of 3\n#>  $ N   : int 10\n#>  $ y   : num [1:10] 995 959 984 992 993 ...\n#>  $ year: int [1:10] -4 -3 -2 -1 0 1 2 3 4 5\n```\n:::\n\n\nCompiliamo il modello e avviamo il campionamento MCMC.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod  <- cmdstan_model(write_stan_file(stan_code))\n```\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- mod$sample(\n  data = stan_data, seed = 1234,\n  chains = 4, parallel_chains = 4\n)\n```\n:::\n\n\nEstraiamo le quantità derivate di maggiore interesse:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit$summary(variables = c(\"alpha\", \"beta\", \"lambda\"))\n#> # A tibble: 12 × 10\n#>    variable       mean   median     sd    mad       q5      q95  rhat ess_bulk\n#>    <chr>         <dbl>    <dbl>  <dbl>  <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n#>  1 alpha         6.936    6.936  0.010  0.010    6.919    6.953 1.002 2204.738\n#>  2 beta          0.022    0.022  0.003  0.003    0.017    0.028 1.001 3921.050\n#>  3 lambda[1]   941.474  941.801 17.650 17.035  912.472  971.438 1.001 2679.962\n#>  4 lambda[2]   962.558  962.748 15.339 15.008  937.673  988.402 1.001 2529.218\n#>  5 lambda[3]   984.125  984.098 13.197 12.980  962.847 1006.315 1.001 2360.153\n#>  6 lambda[4]  1006.188 1006.306 11.435 11.412  987.696 1025.400 1.002 2225.370\n#>  7 lambda[5]  1028.757 1028.715 10.386 10.218 1011.757 1045.887 1.002 2204.743\n#>  8 lambda[6]  1051.845 1051.811 10.420 10.291 1034.962 1069.068 1.001 2432.282\n#>  9 lambda[7]  1075.464 1075.166 11.672 11.765 1056.337 1094.511 1.001 2907.241\n#> 10 lambda[8]  1099.626 1099.600 13.949 14.347 1076.660 1122.705 1.001 3450.415\n#> 11 lambda[9]  1124.344 1124.076 16.959 17.358 1096.501 1152.436 1.002 3873.761\n#> 12 lambda[10] 1149.631 1149.272 20.487 20.926 1116.283 1183.948 1.002 4105.120\n#>    ess_tail\n#>       <dbl>\n#>  1 2351.782\n#>  2 3015.859\n#>  3 2639.793\n#>  4 2550.928\n#>  5 2548.232\n#>  6 2343.254\n#>  7 2351.782\n#>  8 2512.354\n#>  9 2834.135\n#> 10 2973.167\n#> 11 2997.796\n#> 12 3053.556\n```\n:::\n\n\n### Interpretazione\n\nIl parametro `alpha` rappresenta il logaritmo del numero medio atteso di eventi *nell’anno di riferimento* $x=0$. Nel nostro modello l’anno 0 è semplicemente il punto centrale della sequenza di anni osservata (−4,…,5).\n\nIl valore stimato è $\\alpha \\approx 6.94$, con un intervallo di credibilità al 95% compreso tra 6.92 e 6.95. Trasformando sulla scala naturale, otteniamo:\n\n$$\n\\exp(\\alpha) \\approx 1\\,030\n$$\ncioè circa *1030 eventi attesi* nell’anno di riferimento.\n\nIl parametro `beta` misura la variazione logaritmica attesa per ogni anno aggiuntivo. La stima $\\beta \\approx 0.022$ (ICr 95%: 0.017–0.028) indica una crescita positiva.\n\nPer interpretare questo effetto sulla scala dei conteggi:\n\n$$\n\\exp(\\beta) \\approx 1.022 ,\n$$\nossia ogni anno in più corrisponde a un aumento atteso di circa *+2.2%* degli eventi rispetto all’anno precedente.\n\nSe traduciamo questa percentuale in termini assoluti, partendo dal valore base $\\exp(\\alpha)\\approx 1.030$, otteniamo:\n\n$$\n\\exp(\\alpha)\\times(\\exp(\\beta)-1) \\;\\approx\\; 23\n$$\nquindi in media *circa 23 eventi in più per ogni anno successivo*.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Anni da predire (quelli del dataset)\nyears <- -4:5\n\n# Estrai i draw posteriori di alpha e beta da cmdstanr\n# (se vuoi in formato data frame \"largo\")\ndraws <- as_draws_df(fit$draws(variables = c(\"alpha\", \"beta\")))\n\n# Costruisci predizioni posteriori di lambda per ogni anno\npred <- lapply(years, function(y) {\n  tibble(\n    year   = y,\n    lambda = exp(draws$alpha + draws$beta * y)\n  )\n}) |>\n  bind_rows()\n\n# Riassumi: media e intervallo di credibilità 95%\npred_sum <- pred |>\n  group_by(year) |>\n  summarise(\n    lambda_mean = mean(lambda),\n    lambda_q05  = quantile(lambda, 0.05),\n    lambda_q95  = quantile(lambda, 0.95),\n    .groups = \"drop\"\n  )\n\n# (opzionale) unisci i dati osservati\ndat <- tibble(\n  year   = -4:5,\n  events = c(995, 959, 984, 992, 993, 1021, 1050, 1097, 1164, 1175)\n)\n\n# Grafico: banda 90% (5%-95%), linea media e punti osservati\nggplot(pred_sum, aes(x = year)) +\n  geom_ribbon(aes(ymin = lambda_q05, ymax = lambda_q95), alpha = 0.2) +\n  geom_line(aes(y = lambda_mean), linewidth = 1) +\n  geom_point(data = dat, aes(y = events), size = 2) +\n  labs(\n    x = \"Anno (codifica -4 … 5)\",\n    y = \"Numero atteso di eventi\"\n  ) \n```\n\n::: {.cell-output-display}\n![](04_poisson_model_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl modello di regressione di Poisson mostra che il numero medio di eventi segue una *crescita regolare nel tempo*. L’intercetta indica che nell’anno di riferimento ($x=0$) ci si attendono circa *1030 eventi*, mentre la pendenza suggerisce un incremento annuo di circa *+2%*, pari a una ventina di eventi in più ogni anno.\n\nLa banda di credibilità attorno alla curva stimata conferma che l’incertezza sulle previsioni è contenuta e che l’andamento crescente è chiaramente supportato dai dati. In termini sostantivi, il modello descrive bene una *tendenza di crescita graduale ma costante* negli anni osservati.\n\n\n### Posterior predictive check\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Dati osservati\ndat <- tibble::tibble(\n  year   = -4:5,\n  events = c(995, 959, 984, 992, 993, 1021, 1050, 1097, 1164, 1175)\n)\n\n# Estrai i draw di y_rep in matrice (draws x N)\nyrep_mat <- fit$draws(variables = \"y_rep\") |>\n  as_draws_matrix()\n# Seleziona solo le colonne y_rep[...] mantenendo l'ordine\ncols <- grep(\"^y_rep\\\\[\", colnames(yrep_mat))\nyrep_mat <- yrep_mat[, cols, drop = FALSE]\n\n# Calcola quantili per colonna (per ogni anno)\nqs <- colQuantiles(yrep_mat, probs = c(0.05, 0.50, 0.95))\npred_sum <- tibble::tibble(\n  year = dat$year,\n  q05  = qs[, 1],\n  q50  = qs[, 2],\n  q95  = qs[, 3]\n)\n\n# Grafico PPC: banda 90% + mediana + punti osservati\nggplot(pred_sum, aes(x = year)) +\n  geom_ribbon(aes(ymin = q05, ymax = q95), alpha = 0.2) +\n  geom_line(aes(y = q50), linewidth = 1) +\n  geom_point(data = dat, aes(y = events), size = 2) +\n  labs(\n    x = \"Anno (codifica -4 … 5)\",\n    y = \"Conteggio\"\n  ) \n```\n\n::: {.cell-output-display}\n![](04_poisson_model_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n* La *banda* ombreggiata rappresenta il *90%* della distribuzione predittiva del conteggio per ciascun anno (5%–95%).\n* La *linea* è la *mediana* predittiva; i *punti* sono i conteggi osservati.\n* Se i punti stanno per lo più *dentro* le bande, il modello riproduce bene i livelli di conteggio anno per anno.\n* Se molti punti cadono *fuori* (o tutti da un lato), il modello potrebbe essere troppo rigido o mancare di struttura (p.es. overdispersione, forma non lineare nel tempo, effetti non inclusi).\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Media/varianza osservate\nmean_obs <- mean(dat$events)\nvar_obs  <- var(dat$events)\n\n# Media/varianza delle repliche (per draw)\nmean_rep <- rowMeans(yrep_mat)\nvar_rep  <- apply(yrep_mat, 1, var)\n\n# p-value predittivi (proporzione di repliche >= osservato)\np_mean <- mean(mean_rep >= mean_obs)\np_var  <- mean(var_rep  >= var_obs)\n\ntibble::tibble(\n  stat      = c(\"media\", \"varianza\"),\n  osservato = c(mean_obs, var_obs),\n  media_rep = c(mean(mean_rep), mean(var_rep)),\n  p_pred    = c(p_mean, p_var)\n)\n#> # A tibble: 2 × 4\n#>   stat     osservato media_rep p_pred\n#>   <chr>        <dbl>     <dbl>  <dbl>\n#> 1 media        1043      1042.  0.468\n#> 2 varianza     5940.     6093.  0.486\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np1 <- ggplot(data.frame(mean_rep), aes(x = mean_rep)) +\n  geom_histogram(bins = 30) +\n  geom_vline(xintercept = mean_obs, linetype = 2) +\n  labs(title = \"PPC media\", x = \"Media (repliche)\", y = \"Frequenza\")\n\np2 <- ggplot(data.frame(var_rep), aes(x = var_rep)) +\n  geom_histogram(bins = 30) +\n  geom_vline(xintercept = var_obs, linetype = 2) +\n  labs(title = \"PPC varianza\", x = \"Varianza (repliche)\", y = \"Frequenza\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](04_poisson_model_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](04_poisson_model_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl controllo predittivo mostra che i conteggi osservati ricadono interamente entro le bande di credibilità del modello. Inoltre, la media e la varianza osservate sono molto vicine a quelle prodotte dalle repliche simulate (p-value predittivi ~0.5), il che indica che il modello non sottostima né sovrastima la variabilità dei dati. Nel complesso, questi risultati suggeriscono che la regressione di Poisson con legame log e trend lineare nel tempo fornisce una rappresentazione adeguata dei dati osservati.\n\n\n#### Incidence Rate Ratio (IRR)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nirr <- draws |>\n  transmute(\n    IRR = exp(beta)\n  ) |>\n  summarise(\n    mean = mean(IRR),\n    q05  = quantile(IRR, 0.05),\n    q95  = quantile(IRR, 0.95)\n  )\nirr\n#> # A tibble: 1 × 3\n#>    mean   q05   q95\n#>   <dbl> <dbl> <dbl>\n#> 1  1.02  1.02  1.03\n```\n:::\n\n\nIl valore medio stimato dell’IRR è *1.022*, con un intervallo di credibilità al 90% compreso tra 1.017 e 1.028. Questo significa che, a ogni anno in più, il numero medio di eventi attesi aumenta di circa il 2.2%, con un margine di incertezza che va da circa +1.7% a +2.8%.\n\nPoiché l’intero intervallo si colloca *sopra 1*, il modello suggerisce con elevata credibilità che la tendenza temporale sia effettivamente *crescente*: non stiamo osservando fluttuazioni casuali, ma un aumento sistematico anno dopo anno.\n\nIl valore medio dell’IRR è 1.022: questo equivale a un incremento di circa +2.2% per anno.\n\n* In termini assoluti, partendo da una media di circa 1030 eventi, un aumento del 2.2% corrisponde a circa +23 eventi all’anno.\n* L’intervallo di credibilità (1.017–1.028) implica che l’aumento medio sia compreso tra circa +18 e +29 eventi per anno.\n\nIn altre parole, il modello suggerisce che il fenomeno osservato cresce in modo *regolare e consistente*: ogni anno si verificano in media da *una ventina a una trentina di eventi in più* rispetto all’anno precedente.\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo visto come il modello di Poisson possa essere usato per descrivere dati che rappresentano conteggi, come il numero di comportamenti osservati in un certo periodo di tempo o la frequenza con cui si manifesta un sintomo. L’idea centrale è semplice: invece di trattare i dati come proporzioni o medie, li consideriamo come eventi che “accadono” con una certa intensità, rappresentata dal parametro $\\lambda$. Questo ci permette di modellare direttamente le frequenze osservate, rispettando la natura discreta e positiva dei dati.\n\nDal punto di vista psicologico, ciò significa avere uno strumento adatto per studiare fenomeni che non si esprimono in valori continui ma in *conteggi* (ad esempio, il numero di episodi ansiosi in una settimana, o il numero di errori commessi in un compito). L’approccio bayesiano aggiunge un ulteriore vantaggio: possiamo combinare le informazioni provenienti dai dati con ciò che sappiamo (o ipotizziamo) a priori sul fenomeno, ottenendo una stima che riflette sia l’evidenza empirica sia la nostra conoscenza di base.\n\nNei prossimi capitoli vedremo come estendere ulteriormente questa logica ad altri tipi di dati e modelli, consolidando l’idea che i GLM rappresentino un quadro flessibile e potente per affrontare molte delle domande classiche della ricerca psicologica.\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] lubridate_1.9.4       HDInterval_0.2.4      cmdstanr_0.9.0       \n#>  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#> [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [28] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#> [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#> [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#> [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#> [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#> [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#> [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#> [28] stringi_1.8.7         RColorBrewer_1.1-3    estimability_1.5.1   \n#> [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#> [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#> [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#> [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#> [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#> [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#> [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#> [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#> [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#> [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#> [61] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#> [64] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#> [67] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#> [70] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#> [73] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#> [76] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#> [79] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#> [82] MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n\n",
    "supporting": [
      "04_poisson_model_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}