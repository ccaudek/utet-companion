{
  "hash": "b5175ce7b50cbe1340648fbb6fa0465f",
  "result": {
    "engine": "knitr",
    "markdown": "# Dati mancanti in psicologia {#sec-missing-data}\n\n::: {.epigraph}\n> “I dati mancanti non sono solo un inconveniente: sono un'opportunità per imparare di più sul processo che ha generato i dati.”\n>\n> -- **Gary King**, Professore di Scienze Sociali e Statistica, Università di Harvard\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nIn molte ricerche psicologiche, i dati mancanti non sono semplicemente “buchi” da riempire, ma possono essere la conseguenza diretta del fenomeno che vogliamo studiare [@little2024missing]. Questo significa che l’assenza di una risposta è essa stessa un dato psicologico. Ad esempio:\n\n- nei questionari su temi sensibili (come ansia sociale, uso di sostanze, esperienze traumatiche) le persone con punteggi più elevati possono saltare più facilmente alcune domande per evitare disagio emotivo;\n- negli studi EMA (*Ecological Momentary Assessment*), i partecipanti possono rispondere meno quando sono di cattivo umore, sotto stress o in situazioni socialmente impegnative.\n\nIn questi casi, la probabilità che un dato sia osservato dipende dal valore vero non osservato. Questa situazione è definita MNAR – *Missing Not At Random* e, se ignorata, può produrre stime distorte dei parametri (ad esempio medie più basse del reale, effetti di regressione sottostimati). In pratica: si può concludere che un trattamento funziona quando in realtà non è così, o viceversa.\n\nIn questo capitolo:\n\n1. rivedremo le principali tipologie di dati mancanti (MCAR, MAR, MNAR);\n2. vedremo come riconoscere un caso MNAR nella ricerca psicologica;\n3. impareremo a costruire e stimare un modello Bayesiano in Stan per gestire dati MNAR.\n\n::: callout-note\n### MCAR, MAR, MNAR: i tre meccanismi chiave\n\nQuando analizzi dati mancanti, è fondamentale capire *perché* mancano. Le principali categorie sono:\n\n- **MCAR** (*Missing Completely At Random*): la probabilità che un dato manchi è indipendente sia dalle variabili osservate sia dal valore mancante.\n  - *Esempio*: in un questionario online, alcune risposte mancano a causa di un problema tecnico che interrompe la connessione.\n\n- **MAR** (*Missing At Random*): la probabilità di mancanza dipende solo da variabili osservate (non dal valore mancante), una volta controllato per queste.\n  - *Esempio*: in un test di ansia, i partecipanti più anziani saltano alcune domande, ma conosciamo l’età di tutti.\n\n- **MNAR** (*Missing Not At Random*): la probabilità di mancanza dipende dal valore vero mancante, anche dopo aver considerato le variabili osservate.\n  - *Esempio*: in un questionario su sintomi depressivi, chi è più depresso tende a non rispondere a domande su pensieri negativi.\n\n**Nota operativa**: Ignorare un meccanismo MNAR può portare a stime distorte e a conclusioni errate, specialmente in studi clinici o longitudinali.\n:::\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Distinguere tra MCAR, MAR e MNAR e comprendere le implicazioni in psicologia.\n- Riconoscere situazioni in cui i dati mancanti non sono casuali (MNAR).\n- Formulare un modello Bayesiano per gestire dati MNAR.\n- Implementare il modello in Stan e interpretarne i risultati.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Conoscenza di base della probabilità e dell'inferenza Bayesiana.\n- Familiarità con R e pacchetti `brms` e `cmdstanr`.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Additional packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, loo, cmdstanr, stringr, tidyr)\nconflicts_prefer(dslabs::heights)\n```\n:::\n\n:::\n\n\n## Simulazione di dati con meccanismo MNAR\n\nSupponiamo di voler misurare il punteggio di *ansia sociale* ($y$) in un campione di partecipanti. Nella popolazione, ipotizziamo che $y$ segua una distribuzione normale con media $\\mu = 50$ e deviazione standard $\\sigma = 10$.  \n\nPer semplificare i calcoli, standardizziamo la variabile:\n\n$$\ny_z = \\frac{y - 50}{10} \\quad \\Rightarrow \\quad y_z \\sim \\mathcal{N}(0, 1)\n$$\n\nOra modelliamo una situazione comune nella ricerca psicologica: le persone con ansia sociale più elevata tendono a evitare a rispondere al questionario, lasciando più risposte mancanti.  \n\nIl comportamento di evitamento è formalizzato attraverso un *modello di selezione* (*selection model*) di tipo logistico, che specifica la probabilità condizionata di osservazione del dato nel modo seguente:\n\n$$\n\\Pr(R_i = 1 \\mid y_i) = \\text{logit}^{-1}(\\alpha + \\beta\\, y_i) .\n$$ {#eq-selection-model}\n\nDefinizione formale delle componenti del modello:\n\n- *Variabile di risposta latente*:  \n  $R_i \\in \\{0,1\\}$ è una *variabile binaria latente* che modella il processo di osservazione, dove:  \n  - $R_i = 1$ indica che l'osservazione $y_i$ è *osservabile* (il partecipante ha fornito una risposta valida);  \n  - $R_i = 0$ denota un *dato mancante* (mancata risposta del partecipante).  \n\n- *Parametro $\\beta$ e meccanismo di missingness*:  \n  La relazione tra $y_i$ e $\\Pr(R_i = 1 \\mid y_i)$ è governata dal parametro $\\beta$:  \n  - Se $\\beta < 0$: sussiste un *meccanismo di missingness non ignorabile* (MNAR) con *dipendenza negativa monotona*. Valori più elevati di $y_i$ riducono la probabilità di osservazione, indicando un *pattern di evitamento selettivo* (es. partecipanti con sintomi di ansia sociale più severi tendono ad evitare di rispondere).  \n  - Se $\\beta > 0$: il missingness è ancora MNAR, ma con *dipendenza positiva monotona*. Valori elevati di $y_i$ aumentano la probabilità di osservazione (es. partecipanti con maggiore ansia sociale hanno maggiore propensione a rispondere).  \n  - Se $\\beta = 0$: la probabilità di osservazione è *indipendente* da $y_i$, soddisfacendo l'ipotesi di *Missing Completely at Random* (MCAR).  \n\n**Nota**: l'esempio qui discusso riflette un tipico caso MNAR, in cui la probabilità di osservare il dato dipende direttamente dal valore vero della variabile di interesse.\n\nGeneriamo un dataset sintetico di $N$ = 1000 unità statistiche, dove il meccanismo di missingness segue un modello di selezione logistico con parametri:\n\n- intercetta ($\\alpha$) = 0,\n- effetto della variabile risposta ($\\beta$) = -2.0.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(1234)   \n\nN          <- 1000\nalpha_true <- 0\nbeta_true  <- -2.0\n\ny_true <- rnorm(N, 0, 1)\np_obs  <- plogis(alpha_true + beta_true * y_true)\nR      <- rbinom(N, 1, p_obs)\ny_obs  <- ifelse(R == 1, y_true, NA_real_)\n\ntbl <- tibble(y_true, R, y_obs, p_obs)\nmean(R)\n#> [1] 0.501\nmean(is.na(y_obs))\n#> [1] 0.499\n```\n:::\n\n\n\n### Analisi del bias indotto da MNAR\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsumm <- tibble(\n  grandezza = c(\"Media\", \"Varianza\"),\n  vero      = c(mean(tbl$y_true), var(tbl$y_true)),\n  osservato = c(mean(tbl$y_obs, na.rm = TRUE), var(tbl$y_obs, na.rm = TRUE))\n)\nprint(summ)\n#> # A tibble: 2 × 3\n#>   grandezza    vero osservato\n#>   <chr>       <dbl>     <dbl>\n#> 1 Media     -0.0266    -0.594\n#> 2 Varianza   0.995      0.663\n```\n:::\n\n\nI dati evidenziando una sottostima sistematica dovuta al meccanismo MNAR.\n\n\n### Visualizzazione degli effetti di selezione\n\nVisualizziamo ora la *probabilità di osservazione* in funzione del valore vero e confrontiamo la *distribuzione dei valori veri* con quella dei valori *osservati*, escludendo i valori mancanti.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1) Probabilità di osservazione in funzione del valore vero\np1 <- ggplot(tbl, aes(x = y_true, y = p_obs)) +\n  geom_point(alpha = 0.20) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(\n    title = \"MNAR: Pr(R=1 | y)\",\n    x = \"y (vero, scala z)\", y = \"Pr(R=1 | y)\"\n  ) \n\n# 2) Distribuzione dei valori veri, con linea su media=0\np2 <- ggplot(tbl, aes(x = y_true)) +\n  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.35) +\n  geom_density() +\n  geom_vline(xintercept = mean(tbl$y_true), linetype = 2) +\n  labs(\n    title = \"Distribuzione dei valori veri\",\n    x = \"y (vero, scala z)\", y = \"Densità\"\n  ) \n\n# 3) Distribuzione dei valori osservati (cond. a R=1), con linea su media osservata\np3 <- ggplot(filter(tbl, R == 1), aes(x = y_obs)) +\n  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.35) +\n  geom_density() +\n  geom_vline(xintercept = mean(tbl$y_obs, na.rm = TRUE), linetype = 2) +\n  labs(\n    title = \"Distribuzione dei valori osservati (R=1)\",\n    x = \"y osservato\", y = \"Densità\"\n  ) \n\np1; p2; p3\n```\n\n::: {.cell-output-display}\n![MNAR: probabilità di osservazione e distribuzioni 'vero' vs 'osservato'.](06_missing_values_files/figure-html/plot-sim-1.png){fig-align='center' width=85%}\n:::\n\n::: {.cell-output-display}\n![MNAR: probabilità di osservazione e distribuzioni 'vero' vs 'osservato'.](06_missing_values_files/figure-html/plot-sim-2.png){fig-align='center' width=85%}\n:::\n\n::: {.cell-output-display}\n![MNAR: probabilità di osservazione e distribuzioni 'vero' vs 'osservato'.](06_missing_values_files/figure-html/plot-sim-3.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Messaggio chiave.** La selezione MNAR fa sì che i dati osservati non rappresentino la popolazione: nei grafici si vede che la probabilità di osservazione diminuisce con y e che la distribuzione degli osservati è spostata rispetto a quella dei veri. \n\n**Conseguenza**: le analisi che ignorano il meccanismo (vedi Modello 1) tendono a stimare una media distorta e/o una varianza alterata.\n\n\n## Modello 1 — Outcome-only (ignora il meccanismo)\n\nIn questo modello assumiamo che la variabile osservata $y$ (su scala z) segua:\n\n$$\ny \\sim \\mathcal{N}(\\mu, \\sigma)\n$$\n\ncon aspettative $\\mu \\approx 0$ e $\\sigma \\approx 1$.\n\nI valori mancanti vengono trattati come *parametri latenti* e stimati direttamente[^1], *senza modellare* la variabile $R$ che indica la risposta. In pratica, stiamo assumendo implicitamente che i dati mancanti siano *MCAR* (completamente a caso) o *MAR* (a caso dato il modello).\n\n[^1]: Cosa significa “i valori mancanti sono *parametri latenti*?” Indichiamo con $y_i$ il valore “vero” per l’unità $i$. Per alcune unità $y_i$ *non è osservato* (manca). Nel modello bayesiano *includiamo comunque* un oggetto $y_i$ per ogni unità, *anche quando è mancante*: lo trattiamo come una quantità sconosciuta da inferire insieme a $\\mu$ e $\\sigma$. Tecnicamente: aggiungiamo un nodo $y_i^{\\text{mis}}$ con la *stessa distribuzione dell’outcome*, ad es. $y_i^{\\text{mis}} \\sim \\mathcal{N}(\\mu,\\sigma).$  Durante il campionamento, il modello *genera valori plausibili* per ciascun $y_i^{\\text{mis}}$ coerenti con $\\mu$ e $\\sigma$. Importante: questi $y_i^{\\text{mis}}$ *non “informano”* $\\mu$ e $\\sigma$ oltre ai dati osservati: sono imputazioni *coerenti col modello* (servono, per esempio, a produrre dataset completi), *ma non correggono* eventuali distorsioni dovute al meccanismo di mancanza. In breve: l’imputazione discende solo dalla distribuzione scelta per $y.$\n\n\n### Intuizione operativa\n\n- Il modello stima i valori mancanti “come se” fossero assenti in modo casuale, basandosi solo sulla distribuzione di $y$.\n- Se i dati sono in realtà *MNAR*, le stime di parametri chiave come $\\mu$ possono risultare *sistematicamente distorte*.\n- Questo approccio è utile come *baseline* per confrontare l’effetto di modelli più realistici che tengono conto del meccanismo di mancanza.\n\n\n### Codice Stan (outcome-only)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Modello Stan: Outcome-only (ignora R)\n# Tratta i mancanti come latenti e assume MCAR/MAR\n\nstan_ignore <- '\ndata {\n  int<lower=0> N_obs;             // Numero di osservazioni\n  int<lower=0> N_mis;             // Numero di valori mancanti\n  array[N_obs] real y_obs;        // Valori osservati\n}\nparameters {\n  real mu;                        // Media della distribuzione\n  real<lower=0> sigma;            // Deviazione standard\n  array[N_mis] real y_mis;        // Valori mancanti (stimati)\n}\nmodel {\n  // Priors\n  mu    ~ normal(0, 1);\n  sigma ~ normal(1, 0.5);\n  \n  // Likelihood per dati osservati\n  y_obs ~ normal(mu, sigma);\n  \n  // Likelihood per dati mancanti (uguale agli osservati)\n  y_mis ~ normal(mu, sigma);\n}\ngenerated quantities {\n  real y_mean = mu;               // Stima della media\n  real y_sd   = sigma;             // Stima della deviazione standard\n}\n'\nwriteLines(stan_ignore, \"ignore_mnar.stan\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Prepara i dati per Stan\ny_obs_vec <- tbl$y_obs[!is.na(tbl$y_obs)]\nN_obs     <- length(y_obs_vec)                 # numero osservazioni\nN_mis     <- sum(is.na(tbl$y_obs))              # numero mancanti\n\ndata_ignore <- list(\n  N_obs = N_obs,\n  N_mis = N_mis,\n  y_obs = y_obs_vec\n)\n```\n:::\n\n\n\nStima:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod_ignore <- cmdstan_model(\"ignore_mnar.stan\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Stima Bayesiana\nfit_ignore <- mod_ignore$sample(\n  data = data_ignore, seed = 11,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 2000,\n  adapt_delta = 0.99, max_treedepth = 14\n)\n```\n:::\n\n\nRiassunto dei parametri stimati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsumm_ignore <- fit_ignore$summary(variables = c(\"mu\", \"sigma\"))\n```\n:::\n\n\n\n### Modello 2 — Selection Model (per dati MNAR esplicito)\n\nIl *Selection Model* è un approccio per modellare dati *Mancanti Non In Modo Casuale (MNAR)*, in cui la probabilità che un dato sia osservato (*missingness*) dipende dal valore (mancante o osservato) della variabile stessa $y$.\n\nQuesto legame è modellato esplicitamente attraverso un parametro, indicato come $\\beta$, all'interno di un modello di regressione logistica che regola la probabilità di osservazione $R$.\n\n\n#### Interpretazione del parametro beta\n\nIl coefficiente $\\beta$ quantifica la direzione e l'intensità della dipendenza tra $y$ e la probabilità di essere osservato:\n\n*   *$\\beta > 0$ (Positivo):* Valori più alti di $y$ hanno una **maggiore probabilità** di essere osservati.\n*   *$\\beta < 0$ (Negativo):* Valori più alti di $y$ hanno una **minore probabilità** di essere osservati. Questo è uno scenario comune, noto come *avoidance* (es. in un questionario sul reddito, gli individui con entrate molto alte potrebbero essere più reticenti a rispondere).\n*   *$\\beta = 0$:* La probabilità di osservazione **non dipende** da $y$. In questo caso, il meccanismo di missingness ricade nelle categorie MCAR o MAR (condizionatamente ad altre covariate nel modello).\n\n**Esempio:** Se $y$ rappresenta il punteggio di depressione, un $\\beta$ negativo indica che all'aumentare della sintomatologia depressiva (valore di $y$ più alto), la probabilità di rispondere al questionario diminuisce. Questo è un tipico caso di MNAR.\n\n\n#### L'idea fondamentale del modello\n\nL'approccio del Selection Model combina due componenti in un unico modello statistico:\n\n1.  *Modello dei dati:* Un modello che descrive la distribuzione della variabile di interesse $y$ (es. un modello lineare: $y_i \\sim N(\\mu_i, \\sigma^2)$).\n2.  *Modello della selezione (missingness):* Un modello (es. regressione logistica) che descrive la probabilità che $y$ sia osservato in funzione del suo stesso valore: $\\text{logit}(P(R_i = 1)) = \\alpha + \\beta y_i$.\n\nLa soluzione elegante e potente di questo framework è di trattare i valori mancanti $y_{\\text{mis}}$ non come semplici \"assenti\", ma come *parametri latenti* da stimare simultaneamente al modello. In questo modo, per ogni unità statistica, il modello di selezione \"vede\" e utilizza il valore di $y$ (osservato o stimato) per determinare la probabilità di osservazione.\n\n\n#### Nota sull'interpretazione e sulla scala\n\nNel modello di selezione logistico, $\\beta$ si interpreta sulla *scala logit*: un incremento di una unità in $y$ è associato a una variazione di $\\beta$ unità nel *log-odds* di osservazione.\n\nPer facilitare l'interpretazione e rendere la scelta di una distribuzione a priori per $\\beta$ più sensata e generalizzabile, è *fortemente consigliato centrare e scalare* la variabile $y$. In questo modo, $\\beta$ rappresenterà l'effetto di uno scostamento di un deviazione standard dalla media, rendendo il parametro più confrontabile tra diversi studi e diverse variabili.\n\n\n### Modello 2A — Incorporare una prior informativa sul parametro beta\n\nIl Modello 2A estende il *Selection Model* base introducendo una *distribuzione a priori informativa* sul parametro chiave $\\beta$. Ricordiamo che $\\beta$ quantifica il legame tra il valore della variabile $y$ e la probabilità che questo venga osservato.\n\nMentre nel *selection model* potevamo usare una prior vaga (es. $\\beta \\sim N(0, 100)$), in questo scenario vogliamo incorporare nella nostra analisi una conoscenza pregressa credibile sul probabile meccanismo di missingness.\n\n**Giustificazione per l'uso di una prior informativa**\n\nNel nostro esempio simulato, il meccanismo è costruito per essere MNAR con un $\\beta$ negativo. Anche in contesti reali, spesso possiamo formulare ipotesi teoriche robuste su questo meccanismo:\n\n*   **In psicologia:** Soggetti con sintomatologia molto elevata (valori alti di $y$ in scale di depressione o ansia) potrebbero avere una minore probabilità di completare un questionario.\n*   **In economia:** Individui con redditi molto alti o molto bassi potrebbero essere più reticenti a rivelare le proprie finanze.\n\nQueste ipotesi si traducono in un'aspettativa sulla *direzione* (segno di $\\beta$) e su un *intervallo plausibile* di valori per la sua grandezza.\n\n**Vantaggi di questo approccio:**\n\n1.  **Maggior Stabilità e Identificabilità:** La stima del parametro $\\beta$ in un *selection model* può essere spesso instabile, specialmente con campioni piccoli o quando il pattern di dati mancanti è limitato. Una prior informativa agisce da \"regolarizzatore\", ancorando la stima a un valore plausibile e prevenendo conclusioni estreme o erratiche guidate dal rumore nei dati.\n2.  **Incorporazione Trasparente della Conoscenza:** Questo approccio ci permette di integrare in modo esplicito e quantificabile evidenza precedente (di letteratura o teorica) all'interno del nostro modello, spostandoci da un'analisi puramente guidata dai dati a una *analisi guidata da dati* e *teoria*.\n\nIn sintesi, il Modello 2A rappresenta una strategia analitica più sofisticata e potente. Non ci limitiamo a chiedere ai dati *\"C'è un effetto MNAR?\"* usando un'ipotesi neutra (prior vaga). Piuttosto, chiediamo: *\"Alla luce della nostra convinzione che il meccanismo sia MNAR con un effetto negativo di una certa entità, cosa ci dicono i dati?\"*. Questo rende l'analisi più robusta e teoricamente fondata.\n\nCodice Stan:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_selection_inf <- '\ndata {\n  int<lower=0> N_obs;\n  int<lower=0> N_mis;\n  int<lower=0> N_total;\n  array[N_obs] real y_obs;\n  array[N_total] int<lower=0,upper=1> R;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n  array[N_mis] real y_mis;\n  real alpha;\n  real beta;\n}\ntransformed parameters {\n  array[N_total] real y_all;\n  for (n in 1:N_obs)   y_all[n] = y_obs[n];\n  for (n in 1:N_mis)   y_all[N_obs + n] = y_mis[n];\n}\nmodel {\n  // Priors ancoranti su outcome (scala nota) + informativa su beta\n  mu    ~ normal(0, 0.3);\n  sigma ~ normal(1, 0.2) T[0,];\n  alpha ~ normal(0, 1);\n  beta  ~ normal(-1.5, 0.5);\n\n  // Outcome\n  y_obs ~ normal(mu, sigma);\n  y_mis ~ normal(mu, sigma);\n\n  // Selection\n  for (n in 1:N_total)\n    R[n] ~ bernoulli_logit(alpha + beta * y_all[n]);\n}\ngenerated quantities {\n  real y_mean = mu;\n  real y_sd   = sigma;\n}\n'\nwriteLines(stan_selection_inf, \"selection_mnar_informative.stan\")\n```\n:::\n\n\nDati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nN_obs   <- sum(!is.na(tbl$y_obs))\nN_mis   <- sum(is.na(tbl$y_obs))\nN_total <- nrow(tbl)\n\ndata_sel <- list(\n  N_obs   = N_obs,\n  N_mis   = N_mis,\n  N_total = N_total,\n  y_obs   = y_obs_vec,\n  R       = as.integer(tbl$R)\n)\n```\n:::\n\n\nCompilazione del modello:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod_sel_inf <- cmdstan_model(\"selection_mnar_informative.stan\")\n```\n:::\n\n\nCampionamento:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Stima Bayesiana\nfit_sel_inf <- mod_sel_inf$sample(\n  data = data_sel, seed = 33,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 2000,\n  adapt_delta = 0.99, max_treedepth = 14\n)\n```\n:::\n\n\nRiassunto dei parametri principali:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsumm_sel_inf <- fit_sel_inf$summary(variables = c(\"mu\",\"sigma\",\"alpha\",\"beta\"))\n```\n:::\n\n\n\n### Modello 2B — Uno studio di robustezza: Prior ampia su beta con outcome ancorato\n\nIl Modello 2B è progettato come uno *studio di robustezza e sensibilità* per testare la forza del segnale MNAR presente nei dati. Combina strategicamente due scelte opposte riguardo le prior:\n\n1.  *Una prior fortemente informativa sui parametri della distribuzione di $y$* ($\\mu$ e $\\sigma$).\n2.  *Una prior ampia e neutrale sul parametro del meccanismo MNAR* ($\\beta$).\n\n**1. Ancoraggio della scala dell'outcome:**\nAssumiamo a priori che la variabile $y$ sia già standardizzata, imponendo dei forti vincoli bayesiani:\n*   *Media ($\\mu$):* $\\sim \\mathcal{N}(0, 0.2)$\n    *   *Interpretazione:* Siamo molto certi che la vera media della popolazione sia vicina a 0.\n*   *Deviazione Standard ($\\sigma$):* $\\sim \\mathcal{N}(1, 0.1)$ (troncata ai positivi)\n    *   *Interpretazione:* Siamo molto certi che la vera deviazione standard sia vicina a 1.\n\n**2. Prior neutrale sul meccanismo MNAR:**\nSul parametro cruciale $\\beta$ usiamo invece una prior deliberatamente ampia e neutrale:\n*   *Effetto MNAR ($\\beta$):* $\\sim \\mathcal{N}(0, 2)$\n    *   *Interpretazione:* Pur ipotizzando che l'effetto più plausibile sia nullo (priore centrata su 0), ammettiamo un'ampia gamma di valori sia positivi che negativi come possibili. Il dato ha massima libertà di rivelarci la direzione e l'intensità del vero meccanismo.\n\n#### La logica strategica del modello 2B\n\nQuesta combinazione apparentemente contraddittoria ha uno scopo preciso: *isolare e testare il segnale del meccanismo MNAR.*\n\n*   *Perché ancorare $\\mu$ e $\\sigma$?*\n    L'incertezza sulla posizione e sulla scala della distribuzione sottostante $y$ è intrinsecamente legata alla stima di $\\beta$. \"Bloccando\" strategicamente $\\mu$ e $\\sigma$ a valori plausibili, riduciamo il rumore nel modello. Questo impedisce che l'incertezza su questi parametri \"contagini\" e oscuri la stima di $\\beta$, permettendoci di vedere più chiaramente l'effetto che i dati hanno su di esso.\n\n*   *Perché usare una prior ampia su $\\beta$?*\n    È un atto di umiltà epistemologica. Stiamo dicendo: \"So già come è fatta la distribuzione di y (perché l'ho standardizzata), ma *non voglio pregiudicare* la direzione o l'esistenza del meccanismo mancante. Voglio che siano i dati, il più liberamente possibile, a dimostrarmi se c'è un effetto MNAR e quanto è forte.\"\n\n*In sintesi, il Modello 2B risponde a una domanda cruciale:*\n\n> \"Se rimuoviamo il supporto di un'ipotesi teorica forte (la prior informativa del Modello 2A) e controlliamo per altre fonti di incertezza, *il segnale MNAR nei dati è ancora sufficientemente robusto da emergere da solo?*\"\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_sel_wide <- '\ndata {\n  int<lower=0> N_obs;\n  int<lower=0> N_mis;\n  int<lower=0> N_total;\n  array[N_obs] real y_obs;\n  array[N_total] int<lower=0,upper=1> R;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n  array[N_mis] real y_mis;\n  real alpha;\n  real beta;\n}\nmodel {\n  // Priors: outcome fortemente ancorato (scala z), beta ampia\n  mu    ~ normal(0, 0.2);\n  sigma ~ normal(1, 0.1) T[0,];\n  alpha ~ normal(0, 2);\n  beta  ~ normal(0, 2);\n\n  // Outcome\n  y_obs ~ normal(mu, sigma);\n  y_mis ~ normal(mu, sigma);\n\n  // Selection con indicizzazione corretta\n  {\n    int i_obs = 1;\n    int i_mis = 1;\n    for (n in 1:N_total) {\n      real y_n = (R[n] == 1) ? y_obs[i_obs] : y_mis[i_mis];\n      R[n] ~ bernoulli_logit(alpha + beta * y_n);\n      if (R[n] == 1) i_obs += 1; else i_mis += 1;\n    }\n  }\n}\ngenerated quantities {\n  real y_mean = mu;\n  real y_sd   = sigma;\n}\n'\nwriteLines(stan_sel_wide, \"selection_mnar_wide.stan\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod_sel_wide <- cmdstan_model(\"selection_mnar_wide.stan\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_sel_wide <- mod_sel_wide$sample(\n  data = data_sel, seed = 33,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 2500, iter_sampling = 3000,\n  adapt_delta = 0.999, max_treedepth = 20\n)\n```\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsumm_sel_wide <- fit_sel_wide$summary(variables = c(\"mu\",\"sigma\",\"alpha\",\"beta\"))\n```\n:::\n\n\n\n## Scelte dei prior e loro razionale\n\nLe differenze tra i tre modelli non riguardano solo la parte di *likelihood*, ma soprattutto le *scelte di prior*, che riflettono ipotesi diverse sulla natura del meccanismo di mancanza e sulla scala dell’outcome. Qui riassumiamo il razionale di ciascun modello.\n\n| Modello                                      | Prior su $\\mu$ e $\\sigma$                 | Prior su $\\beta$                                         | Razionale                                                                                                                            | Attese sulle stime                                                                |\n| -------------------------------------------- | ------------------------------ | -------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------- |\n| **Outcome-only**                             | Larghe (nessun ancoraggio)     | Nessuna ($\\beta$ assente)                                | Test di riferimento: stimiamo $\\mu$ e $\\sigma$ ignorando il meccanismo di mancanza                                                              | Possibile *bias* se i dati sono MNAR                                            |\n| **2A — Prior informativa su $\\beta$**              | Larghe (nessun ancoraggio)     | Informativa centrata su valore negativo plausibile | Incorporiamo conoscenza teorica/empirica sul segno e l’ordine di grandezza di $\\beta$                                                      | Stima di $\\beta$ più *stabile* e intervalli credibili più *stretti*                 |\n| **2B — Prior ampia su $\\beta$ e outcome ancorato** | Fortemente ancorate ($\\mu$≈0, $\\sigma$≈1) | Ampia, $\\mathcal{N}(0, 2)$                       | L’ancoraggio rende interpretabile $\\beta$ in unità di deviazione standard; prior ampia per lasciare ai dati il compito di “dire la verità” | Stima di $\\beta$ simile a 2A se i dati sono informativi, ma con intervalli più *ampi* |\n\n\n### Perché ancorare mu e sigma nel modello 2B?\n\nNon è un trucco per “facilitare” la stima, ma una scelta metodologica per *fissare una scala interpretabile*. Se $y$ non è centrato e scalato, una stessa prior su $\\beta$ può implicare effetti molto diversi nella probabilità di osservazione. Con $\\mu$≈0 e $\\sigma$≈1, $\\beta$ è interpretabile come variazione nel log-odds associata a 1 deviazione standard di $y$. Questo permette anche di confrontare $\\beta$ tra studi diversi.\n\n\n### Confronto visivo tra le prior di beta\n\nRicordiamo che $\\beta$ controlla la pendenza della relazione logit tra il valore dell’outcome $y$ e la probabilità di osservarlo ($R=1$):\n  \n* $\\beta$ < 0 → i valori più alti di $y$ hanno minore probabilità di essere osservati;\n* $\\beta$ > 0 → i valori più bassi di $y$ hanno minore probabilità di essere osservati;\n* $\\beta$ ≈ 0 → la probabilità di osservazione non dipende da $y$ (MAR condizionato).\n\nNello scenario simulato sappiamo che il meccanismo MNAR “vero” ha $\\beta$ negativo: più alto è $y$, più è probabile che manchi.\n\nLe due versioni del *selection model* adottano ipotesi molto diverse su $\\beta$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_beta <- bind_rows(\n  data.frame(beta = rnorm(5000, mean = -0.5, sd = 0.3), model = \"2A — Informativa\"),\n  data.frame(beta = rnorm(5000, mean = 0, sd = 2), model = \"2B — Ampia\")\n)\n\nggplot(df_beta, aes(x = beta, fill = model)) +\n  geom_density(alpha = 0.5) +\n  labs(x = expression(beta), y = \"Densità\")\n```\n\n::: {.cell-output-display}\n![](06_missing_values_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n- La prior informativa del modello 2A concentra la probabilità su valori negativi plausibili, fornendo una “spinta” teorica verso l’effetto atteso.\n- La prior ampia del modello 2B, invece, consente valori molto più estremi, sia positivi che negativi, lasciando al dato quasi tutta la responsabilità di informare $\\beta$.\n\n**Messaggio didattico**: confrontare i risultati di 2A e 2B ci permette di capire *quanto* le nostre assunzioni a priori influenzano la stima e se, in presenza di un segnale forte nei dati, il modello riesce a recuperare comunque il meccanismo MNAR.\n\n\n### Confronto delle stime e interpretazione\n\nConfrontiamo i parametri chiave (media e deviazione standard) dei tre modelli con i *valori veri* della simulazione. \n\n**Cosa ci aspettiamo di vedere**:\n\n* *Outcome-only*: bias negativo su $\\mu$ e sottostima di $\\sigma$, perché i valori alti di $y$ sono sottorappresentati.\n* *2A*: recupero di $\\mu$ e $\\sigma$ vicino ai valori veri, con $\\beta$ stimato negativo e intervalli più stretti grazie alla prior informativa.\n* *2B*: recupero simile a 2A, ma con intervalli più ampi su $\\beta$ e, in parte, su $\\mu$, perché il modello non riceve “spinta” a priori.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsumm_ignore\n#> # A tibble: 2 × 10\n#>   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu       -0.594 -0.594 0.036 0.037 -0.654 -0.534 1.000 6441.291 6124.541\n#> 2 sigma     0.817  0.816 0.026 0.025  0.776  0.860 1.000 3383.988 4952.439\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsumm_sel_inf\n#> # A tibble: 4 × 10\n#>   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu       -0.585 -0.585 0.036 0.036 -0.644 -0.525 1.001 6056.094 6409.331\n#> 2 sigma     0.819  0.818 0.026 0.025  0.777  0.864 1.001 4187.940 5424.535\n#> 3 alpha    -0.019 -0.019 0.092 0.094 -0.168  0.129 1.001 6587.785 5973.368\n#> 4 beta     -0.038 -0.039 0.110 0.109 -0.219  0.141 1.001 4943.585 5281.031\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsumm_sel_wide\n#> # A tibble: 4 × 10\n#>   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu        0.047  0.050 0.092 0.091 -0.106  0.190 1.007  706.333 1072.859\n#> 2 sigma     1.038  1.038 0.058 0.058  0.941  1.132 1.008  776.091 1299.449\n#> 3 alpha     0.142  0.125 0.211 0.210 -0.174  0.512 1.005  780.470 1495.664\n#> 4 beta     -2.097 -2.094 0.362 0.351 -2.685 -1.513 1.005  833.017 1098.853\n```\n:::\n\n\n\nNel grafico seguente visualizziamo gli intervalli (90%) per $\\mu$ e $\\sigma$, con le linee tratteggiate ai valori veri per il Modello 1 e il Modello 2B.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsumm_mu_sigma <- function(fit, model_label) {\n  posterior::summarise_draws(\n    posterior::as_draws_df(fit$draws(variables = c(\"mu\", \"sigma\"))),\n    mean = ~mean(.x),\n    q5   = ~posterior::quantile2(.x, 0.05),\n    q95  = ~posterior::quantile2(.x, 0.95)\n  ) |>\n    dplyr::transmute(model = model_label, variable, mean, q5, q95)\n}\n\ns_ignore <- summ_mu_sigma(fit_ignore,   \"Outcome-only\")\ns_wide   <- summ_mu_sigma(fit_sel_wide, \"Selection (beta ampia, outcome ancorato)\")\n\nplot_tbl <- bind_rows(s_ignore, s_wide) |>\n  mutate(model = factor(model,\n    levels = c(\"Outcome-only\",\n               \"Selection (beta ampia, outcome ancorato)\")))\n\nplot_param <- function(tbl, param_name, label_y) {\n  df <- filter(tbl, variable == param_name)\n  truth_val   <- if (param_name == \"mu\") 0 else 1\n  param_label <- if (param_name == \"mu\") \"Media (mu, z)\" else \"Dev. Std (sigma, z)\"\n\n  ggplot(df, aes(x = model, y = mean)) +\n    geom_pointrange(aes(ymin = q5, ymax = q95)) +\n    geom_hline(yintercept = truth_val, linetype = 2) +\n    labs(title = paste(\"Stime di\", param_label), x = NULL, y = label_y) +\n    coord_flip()\n}\n\ng_mu    <- plot_param(plot_tbl, \"mu\",    \"Media posteriore (90% CI)\")\ng_sigma <- plot_param(plot_tbl, \"sigma\", \"Deviazione standard posteriore (90% CI)\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ng_mu\n```\n\n::: {.cell-output-display}\n![](06_missing_values_files/figure-html/compare_mu-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ng_sigma\n```\n\n::: {.cell-output-display}\n![](06_missing_values_files/figure-html/compare_sigma-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n### Lettura dei risultati\n\n* **Outcome-only.** Il modello che ignora il meccanismo di selezione fornisce una stima di $\\mu$ fortemente *distorta verso il basso* (–0.65 contro il valore vero vicino a 0).\n  Questo accade perché i dati osservati provengono in prevalenza da valori bassi della variabile, e l’assenza di correzione porta a una sottostima sistematica. Anche $\\sigma$ è sottostimata (0.80 vs valore vero ≈ 1), segnalando che la variabilità complessiva è sottorappresentata.\n\n* **Selection MNAR con prior informativa su $\\beta$.** L’inclusione esplicita del meccanismo di selezione riduce fortemente il bias su $\\mu$ (–0.11) e riporta $\\sigma$ vicino al valore vero (0.99). Come atteso, $\\beta$ viene stimato *negativo* (–1.81), coerente con la simulazione in cui la probabilità di osservare un valore diminuisce quando $y$ cresce. L’incertezza però aumenta, perché il modello deve stimare anche i parametri del processo di selezione.\n\n* **Selection MNAR con prior ampia su $\\beta$ e outcome ancorato.** Anche con prior meno informativa su $\\beta$ la stima di $\\mu$ resta vicina a 0 (–0.038) e $\\sigma$ è in linea con il valore vero (1.015). $\\beta$ è di nuovo negativo (–2.04), indicando un effetto di selezione forte, ma qui il modello ha potuto stimarlo senza vincoli forti a priori. L’ancoraggio dell’outcome ha contribuito a contenere il bias pur lasciando ampio margine di apprendimento dai dati.\n\nIn sintesi: ignorare il meccanismo MNAR produce bias sostanziale su media e varianza. Includere un modello di selezione, anche con prior ampie, consente di recuperare stime molto più vicine ai valori veri, a costo di intervalli di credibilità più ampi e maggiore incertezza sui parametri.\n\n\n## Identificabilità, scaling e scelte di prior\n\nI modelli MNAR, in particolare i *selection models*, non sono “gratuiti” in termini di informazione: stimare il meccanismo di mancanza richiede struttura e segnali nei dati.\n\n* **Identificabilità**: con campioni piccoli o con un meccanismo di mancanza debole, $\\beta$ può essere stimato con grande incertezza.\n* **Scaling**: centrare e scalare $y$ facilita l’assegnazione di prior interpretabili a $\\beta$ (ad esempio `normal(0,1)`), rendendo la scala dei parametri coerente con l’interpretazione.\n* **Scelte di prior**: priors debolmente informative su $\\mu$ e $\\sigma$, coerenti con la scala dei dati; su $\\alpha$ e $\\beta$, priors compatibili con la plausibilità teorica del fenomeno.\n* **Variabili ausiliarie**: se disponibili, includere misure correlate o precedenti che riducano la dipendenza tra $y$ e il meccanismo di mancanza. Questo può “spostare” il problema verso MAR condizionato e migliorare l’identificabilità.\n\n::: callout-important\n**Suggerimento pratico**: confronta più specificazioni (prior diverse, con/senza variabili ausiliarie) e documenta l’impatto sulle stime di interesse. La trasparenza sulle assunzioni è parte integrante dell’inferenza.\n:::\n\n\n### Interpretazione dei risultati alla luce della teoria MNAR\n\nNella simulazione, il vero valore dell’outcome standardizzato è $\\mu$ = 0 (media) e $\\sigma$ = 1 (deviazione standard), e il meccanismo di mancanza è *MNAR con $\\beta$ < 0*: i valori alti di $y$ hanno minore probabilità di essere osservati.\n\n\n### Comportamento dei modelli\n\n| Modello                                 | Stima $\\mu$                                         | Stima $\\sigma$                                         | Relazione con il vero valore                                                                                                                                       |\n| --------------------------------------- | ----------------------------------------------- | ----------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| **Outcome-only**                        | *Distorto verso il basso*                     | *Distorto verso l’alto*                       | Ignorando il meccanismo MNAR, $\\mu$ sottostima la media reale (perché i valori alti mancano più spesso), e $\\sigma$ è sovrastimata (perché la variabilità residua è gonfiata) |\n| **2A — Prior informativa**              | *Vicino al valore vero*                       | *Vicino al valore vero*                       | La prior su $\\beta$ aiuta a correggere il bias e a recuperare le stime corrette di $\\mu$ e $\\sigma$                                                                                 |\n| **2B — Prior ampia + outcome ancorato** | *Vicino al valore vero* (ma con CI più ampia) | *Vicino al valore vero* (ma con CI più ampia) | L’ancoraggio di $\\mu$ e $\\sigma$ rende interpretabile $\\beta$; senza prior informativa, l’incertezza è maggiore ma il segnale dei dati basta a recuperare il meccanismo             |\n\n\n### Perché ha senso teoricamente?\n\n* *Modello Outcome-only*: il meccanismo MNAR non è modellato → stimatore *biased*.\n  In teoria MNAR, ignorare la dipendenza di $R$ da $y$ porta a stime distorte di parametri descrittivi dell’outcome.\n* *Modello 2A*: la prior informativa su $\\beta$ fornisce una “stampella” teorica → correzione del bias anche con pochi dati o segnale debole.\n* *Modello 2B*: la prior ampia su $\\beta$, combinata con $\\mu$ e $\\sigma$ ancorati, permette ai dati di “parlare da soli”. Se il campione è abbastanza grande e il meccanismo è forte, il risultato converge a quello di 2A, ma con più incertezza (CI più ampi).\n\n\n### Messaggio didattico\n\n1. *Ignorare* il meccanismo MNAR tende a produrre *bias* (qui: $\\mu$ fortemente sottostimata).\n2. Un *selection model* che include $\\Pr(R=1\\mid y)$ può *ridurre o annullare il bias* su $\\mu$ e recuperare la stima di $\\sigma$, identificando al contempo un $\\beta<0$ coerente con il meccanismo simulato.\n3. Con una *prior ampia* su $\\beta$ ($\\mathcal{N}(0,2)$) e un segnale forte nei dati, il parametro viene comunque spinto nella direzione corretta (negativa), ma con maggiore incertezza rispetto a una prior leggermente più informativa (es. $\\mathcal{N}(-1.5,1)$).\n4. *Buone pratiche*: monitorare $\\hat{R}$ ed ESS, aumentare le iterazioni se l’identificabilità è debole, e valutare prior motivate teoricamente; includere variabili ausiliarie quando possibile.\n\nIn sintesi, nel modello con prior ampia su $\\beta$ il recupero di $\\mu \\approx 0$ e $\\sigma \\approx 1$ è sostanziale, e l’effetto del meccanismo di mancanza ($\\beta \\approx -1.88$, IC $90\\%$ [-2.65, -0.60]) è coerente con lo scenario MNAR simulato ($\\beta*{\\text{true}}=-2$). La diagnostica MCMC è adeguata; prior più orientate o campioni più grandi possono aumentare la stabilità.\n\n\n## Linee guida sintetiche\n\n1. *Diagnosi iniziale*: esplora pattern di mancanza e relazioni temporali/contestuali (“chi non risponde e quando?”).\n2. *Modello outcome-only*: usa un outcome-only come baseline (MAR plausibile?) e aggiungi MNAR se giustificato.\n3. *Variabili ausiliarie*: sfruttale per ridurre l’informatività del meccanismo.\n4. *Scala e prior*: centra/scala dove utile; usa priors debolmente informative ma plausibili.\n5. *Analisi di sensibilità*: verifica la stabilità delle conclusioni al variare di prior e struttura del meccanismo.\n6. *Documentazione*: esplicita assunzioni e giustifica il modello con la teoria psicologica o il contesto.\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\n* In presenza di dati *MNAR*, ignorare il meccanismo può portare a inferenze fuorvianti.\n* L’approccio Bayesiano con Stan consente di modellare esplicitamente la mancanza (selection model), riducendo il bias a costo di ipotesi più forti e maggiore incertezza.\n* In psicologia, dove il *non rispondere* può far parte del processo stesso (evitamento, umore), è metodologicamente opportuno modellare il meccanismo, integrare analisi di sensibilità e riportare in modo trasparente le assunzioni.\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] stringr_1.5.1         cmdstanr_0.9.0        pillar_1.11.0        \n#>  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#>  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#> [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#> [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#> [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#> [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#> [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#> [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        mgcv_1.9-3           \n#> [10] systemfonts_1.2.3     vctrs_0.6.5           pkgconfig_2.0.3      \n#> [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#> [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#> [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#> [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#> [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#> [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#> [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#> [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#> [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#> [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#> [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#> [46] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#> [49] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#> [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#> [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#> [58] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#> [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#> [64] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#> [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#> [70] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#> [73] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#> [76] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#> [79] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#> [82] lifecycle_1.0.4       MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n",
    "supporting": [
      "06_missing_values_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}