{
  "hash": "280ea9610b1c257f25c255b2bf1423c0",
  "result": {
    "engine": "knitr",
    "markdown": "# Modello di Poisson {#sec-mcmc-poisson-1}\n\n## Introduzione {.unnumbered .unlisted}\n\nNei capitoli precedenti abbiamo visto come utilizzare Stan per analizzare un problema familiare, quello delle proporzioni, introducendo l’odds ratio come primo esempio pratico. In questo capitolo allarghiamo l’orizzonte a un’altra classe di dati molto comune in psicologia: i conteggi.\n\nMolti fenomeni sperimentali e clinici si presentano sotto forma di conteggi. Pensiamo al numero di errori commessi in un compito di attenzione, al numero di risposte corrette in una sessione di apprendimento, o al numero di episodi sintomatici riportati in un diario clinico. In tutti questi casi, il modello probabilistico di riferimento è spesso la distribuzione di Poisson, che descrive il numero di eventi osservati in un dato intervallo di tempo o di prove, quando gli eventi hanno una probabilità media di verificarsi.\n\nIl modello di Poisson rappresenta quindi un banco di prova ideale per consolidare due aspetti fondamentali: da un lato, la generalità dell’inferenza bayesiana – la logica rimane la stessa, cambiano solo la forma della verosimiglianza e i parametri da stimare –; dall’altro, la potenza di Stan come strumento pratico per affrontare modelli che, pur essendo concettualmente semplici, diventano rapidamente complicati se implementati a mano.\n\nIn questo capitolo mostreremo come specificare e stimare un modello di Poisson in Stan, partendo da un esempio psicologico concreto. Questo ci consentirà di acquisire familiarità con un nuovo tipo di dati e di consolidare la logica bayesiana in un contesto diverso, preparandoci ad affrontare nei capitoli successivi modelli più articolati e multilivello.\n\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Capire *quando* usare un modello di Poisson (conteggi non negativi, tendenzialmente rari, indipendenti dato il tasso).\n- Scrivere un modello in Stan con *parametri su scala naturale* (qui: `lambda` come tasso medio).\n- Impostare *prior debolmente informative* su `lambda` o sul suo log (per mantenere positività e stabilità numerica).\n- Eseguire stima MCMC con `cmdstanr` e leggere i diagnostici di convergenza.\n- Fare *posterior predictive checks* (PPC) per valutare l'adeguatezza del modello.\n\n::: {.callout-note collapse=true title=\"Perché questo esempio?\"}\nIn questo capitolo non vogliamo solo calcolare una media dal campione, ma imparare a:\n\n- stimare il *tasso medio di occorrenza nella popolazione* a partire dai dati osservati;  \n- esprimere anche la *nostra incertezza* su quel tasso, non solo un singolo numero;  \n- tradurre un modello teorico (Poisson con prior Gamma) in un *modello computazionale in Stan*;  \n- verificare che Stan fornisce gli stessi risultati della soluzione analitica, così da prendere confidenza con il workflow MCMC.\n\nQuesto esempio funziona come una “palestra”: semplice, ma ci prepara ad affrontare modelli più complessi in cui non avremo formule chiuse e l’uso di Stan diventerà indispensabile.\n:::\n\n::: {.callout-note collapse=true title=\"Perché studiare il modello di Poisson?\"}\n- Molti dati psicologici si presentano come *conteggi* (episodi comportamentali, risposte corrette, eventi clinici).  \n- Il modello di Poisson è lo strumento naturale per stimare il *tasso medio di occorrenza* di questi eventi.  \n- L’approccio bayesiano ci permette non solo di stimare questo tasso, ma anche di esprimere in modo chiaro la *nostra incertezza*.  \n- In questo capitolo usiamo il Poisson come *primo esempio pratico* per imparare a scrivere e stimare un modello in Stan.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, tidyverse, tibble)\nconflicts_prefer(posterior::ess_bulk)\nconflicts_prefer(posterior::ess_tail)\nconflicts_prefer(dplyr::count)\n```\n:::\n\n:::\n\n\n## Dal modello teorico al modello computazionale\n\nQuando raccogliamo dati in psicologia, non ci interessa solo descrivere quello che è accaduto nel nostro campione, ma soprattutto *stimare il processo che genera i dati nella popolazione*.\n\nImmaginiamo di osservare, in *otto finestre temporali di pari durata*, quante volte si verifica un certo evento psicologico o comportamentale. Per esempio, il numero di *compulsioni* in otto momenti della giornata, oppure il numero di *telefonate* ricevute in otto turni orari.\n\nI dati raccolti sono:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny <- c(2, 1, 3, 2, 2, 1, 1, 1)\n```\n:::\n\n\nAbbiamo quindi $N = 8$ osservazioni. Dal campione potremmo calcolare una semplice media ($\\bar y = 1.625$), ma questo ci dice solo *quanto spesso l’evento è avvenuto nei nostri dati*. La domanda più interessante è:\n\n> *qual è il tasso medio di occorrenza nella popolazione?*\n\nChiamiamo questo tasso $\\lambda$: il *numero medio di eventi attesi in una finestra temporale*.\n\n\n### Perché serve un modello probabilistico?\n\nI dati osservati sono solo un piccolo campione e possono variare da una raccolta all’altra.\nUn modello probabilistico ci serve per due motivi principali:\n\n1. *Separare il segnale dal rumore*: capire quanto dell’andamento osservato è dovuto al caso e quanto riflette una regolarità della popolazione.\n2. *Quantificare l’incertezza*: non ci basta stimare $\\lambda$, vogliamo anche dire quanto siamo sicuri (o incerti) di quella stima.\n\n\n### Il modello di Poisson\n\nPer i fenomeni di *conteggio* (quante volte un evento si verifica in un intervallo), il modello naturale è la *distribuzione di Poisson*:\n\n$$\ny_i \\sim \\text{Poisson}(\\mu_i), \\qquad \\mu_i = \\lambda \\cdot t_i\n$$\ndove:\n\n* $y_i$ è il numero osservato di eventi nella finestra $i$,\n* $t_i$ è la durata della finestra,\n* $\\lambda$ è il tasso medio.\n\nNel nostro caso tutte le finestre hanno la stessa durata ($t_i = 1$), e quindi:\n\n$$\nP(y_i \\mid \\lambda) = \\frac{\\lambda^{y_i} e^{-\\lambda}}{y_i!},\n\\qquad \\mathbb{E}[y_i]=\\lambda, \\quad \\mathrm{Var}(y_i)=\\lambda.\n$$\nIn parole semplici: $\\lambda$ rappresenta *quanti eventi in media ci aspettiamo per finestra*.\n\n::: {.callout-tip collapse=true title=\"Esempi in psicologia\"}\nModelli di questo tipo compaiono spesso anche nella ricerca psicologica.  \nAlcuni esempi:\n\n- *Clinica*: numero di episodi compulsivi o attacchi di panico osservati in un certo periodo.  \n- *Psicologia dello sviluppo*: numero di parole nuove prodotte da un bambino in un giorno.  \n- *Psicologia cognitiva*: numero di risposte corrette in una serie di prove a tempo.  \n- *Psicologia sociale*: numero di interazioni tra membri di un gruppo osservate in una sessione.  \n\nIn tutti questi casi, il modello di Poisson ci aiuta a stimare il *tasso medio di occorrenza* dell’evento di interesse e l’incertezza che accompagna tale stima.\n:::\n\n\n### La distribuzione a priori\n\nNell’approccio bayesiano dobbiamo dichiarare che cosa riteniamo plausibile per $\\lambda$ *prima di osservare i dati*. Per i modelli di Poisson la scelta naturale è la *distribuzione Gamma*. Ad esempio, una prior Gamma(9, 2) esprime l’idea che, prima di osservare i dati, ci aspettiamo circa 4–5 eventi per finestra, ma lasciamo spazio a una certa variabilità.\n\n\n### Perché usiamo Stan?\n\nPotremmo calcolare la distribuzione a posteriori anche con formule chiuse (qui la posterior è ancora una Gamma). Ma usiamo Stan per due motivi didattici fondamentali:\n\n1. *Generalizzare*: nella pratica incontreremo modelli per cui non esiste una soluzione analitica semplice. Con Stan impariamo un workflow valido in tutti i casi.\n2. *Quantificare l’incertezza*: Stan ci fornisce direttamente campioni dalla distribuzione a posteriori, che possiamo usare per costruire intervalli credibili, fare previsioni, confrontare modelli, ecc.\n\n::: {.callout-tip collapse=true title=\"Un caso semplice per allenarsi\"}\nIn questo esempio l’uso di Stan può sembrare eccessivo, perché sappiamo già che la posterior è una Gamma e potremmo calcolarla con una formula.  \nIl punto, però, è proprio *esercitarsi*: usiamo un caso semplice come “palestra” per imparare un workflow (specificare un modello, campionare con MCMC, analizzare la posterior) che ci sarà indispensabile quando i modelli diventeranno più realistici e complessi, e non avremo più scorciatoie analitiche.\n:::\n\n### Obiettivi del modello in Stan\n\nCon questo primo esempio vogliamo:\n\n* stimare $\\lambda$, il tasso medio di occorrenza nella popolazione;\n* ottenere una misura della *nostra incertezza* su $\\lambda$;\n* verificare che i campioni generati da Stan coincidano con i risultati della formula analitica (dove è disponibile).\n\nIn questo modo ci abituiamo a un flusso di lavoro che useremo anche per modelli molto più complessi, in cui solo un approccio computazionale ci permette di fare inferenza bayesiana.\n\n## Scrivere il modello in Stan\n\nUn modello Stan è diviso in blocchi: *data* (dati), *parameters* (incognite), *model* (priori + verosimiglianza). Aggiungiamo anche *generated quantities* per quantità derivate utili al confronto con la soluzione analitica (e, volendo, per LOO).\n\nPer evitare dipendenze da percorsi locali, creiamo e compiliamo il modello direttamente dalla stringa:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_code <- \"\ndata {\n  int<lower=0> N;\n  array[N] int<lower=0> y;\n  real<lower=0> alpha_prior;\n  real<lower=0> beta_prior;\n}\nparameters {\n  real<lower=0> lambda;\n}\nmodel {\n  lambda ~ gamma(alpha_prior, beta_prior);\n  y ~ poisson(lambda);\n}\ngenerated quantities {\n  real alpha_post = alpha_prior + sum(y);\n  real beta_post  = beta_prior + N;\n  array[N] real log_lik;\n  for (i in 1:N) log_lik[i] = poisson_lpmf(y[i] | lambda);\n}\n\"\n```\n:::\n\n\nCompiliamo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod <- cmdstan_model(write_stan_file(stan_code))\n```\n:::\n\n\nPrepariamo i dati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nN <- length(y)\nalpha_prior <- 9\nbeta_prior  <- 2\n\nstan_data <- list(N = N, y = y, alpha_prior = alpha_prior, beta_prior = beta_prior)\n```\n:::\n\nUna volta preparati i dati, lanciamo il campionamento:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 3000,\n  iter_warmup = 2000,\n  refresh = 0\n)\n```\n:::\n\n\n### Analizzare i risultati\n\nUna volta che Stan ha terminato il campionamento, otteniamo migliaia di valori possibili di $\\lambda$, campionati dalla distribuzione a posteriori. Questi valori ci permettono di “vedere” la distribuzione a posteriori invece di calcolarla solo con una formula.\n\n#### Estraiamo i campioni di $\\lambda$\n\nEstraiamo i valori campionati di λ dalla posterior. L'oggetto `draws` restituisce tutti i campioni MCMC, noi qui selezioniamo solo il parametro `lambda`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposterior_draws <- fit$draws(\"lambda\", format = \"df\")\n```\n:::\n\n\nCreiamo un vettore con solo i valori di `lambda`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlambda_samples <- posterior_draws$lambda\n```\n:::\n\n\nOra `lambda_samples` contiene migliaia di valori di $\\lambda$: possiamo usarli per calcolare media, intervalli credibili e per costruire grafici.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlength(lambda_samples)\n#> [1] 12000\nhead(lambda_samples)\n#> [1] 1.68 1.52 1.48 2.83 2.84 3.01\n```\n:::\n\n\n#### Calcoliamo i parametri della distribuzione posteriore teorica\n\nDato che in questo caso abbiamo una *posterior coniugata*, conosciamo la formula esatta della distribuzione a posteriori (Gamma). Ci serve per confrontarla con i campioni generati da Stan:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nalpha_post <- alpha_prior + sum(y)   # nuovo parametro shape\nbeta_post  <- beta_prior + N         # nuovo parametro rate\n```\n:::\n\n\n#### Confrontiamo i due risultati (MCMC vs formula)\n\nCreiamo un grafico che mostri l’istogramma dei campioni ottenuti con Stan (in *azzurro*) e la curva della distribuzione Gamma calcolata analiticamente (in *rosso*).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data.frame(lambda = lambda_samples), aes(x = lambda)) +\n  # Istogramma dei campioni posteriori\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 50,\n    alpha = 0.7\n  ) +\n  # Curva teorica Gamma con parametri aggiornati\n  stat_function(\n    fun = function(x) dgamma(x, shape = alpha_post, rate = beta_post),\n    linewidth = 1.2\n  ) +\n  labs(\n    x = \"λ (tasso medio di occorrenza)\",\n    y = \"Densità\"\n  )\n```\n\n::: {.cell-output-display}\n![](08_stan_poisson_model_1_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl confronto visivo è molto utile:\n\n* l’istogramma mostra la distribuzione stimata con Stan tramite campionamento MCMC,\n* la curva rossa rappresenta la distribuzione teorica Gamma–Poisson che conosciamo già.\n\nSe le due coincidono (entro piccole fluttuazioni casuali), significa che Stan ha fatto un buon lavoro: il nostro workflow MCMC funziona!\n\n\n### Intervallo di credibilità\n\nUn grande vantaggio dell’approccio bayesiano è che non otteniamo solo una stima puntuale di $\\lambda$, ma una *distribuzione completa dei valori plausibili*. Da questa distribuzione possiamo ricavare un *intervallo di credibilità*: un intervallo che contiene, ad esempio, il 94% o il 95% della massa a posteriori.\n\n#### Calcoliamo i quantili della distribuzione\n\nCalcoliamo i quantili al 3%, 50% (mediana) e 97%: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncred_interval <- quantile(lambda_samples, probs = c(0.03, 0.5, 0.97))\ncred_interval\n#>   3%  50%  97% \n#> 1.42 2.17 3.18\n```\n:::\n\n\n* il valore al *50%* è la mediana della distribuzione a posteriori,\n* i valori al *3% e 97%* delimitano un intervallo centrale che contiene il 94% della distribuzione.\n\n\n#### Interpretazione dei risultati\n\nI risultati ottenuti indicano che:\n\n* il valore “tipico” di $\\lambda$ (mediana) è circa *2.2 eventi per finestra*,\n* c’è un *94% di probabilità* che $\\lambda$ si trovi tra 1.42 e 3.20.\n\nL’informazione più importante non è tanto la stima puntuale (2.2), ma il fatto che possiamo quantificare la *nostra incertezza*: la posterior ci dice chiaramente quali valori di $\\lambda$ sono più o meno plausibili.\n\n\n### Diagnostica essenziale\n\nDopo il campionamento MCMC, è fondamentale verificare che le catene abbiano esplorato bene la distribuzione a posteriori. Per questo guardiamo due tipi di informazioni: *indici numerici* (come $\\hat{R}$ e ESS) e *grafici delle catene* (traceplot).\n\nPossiamo ottenere una sintesi numerica della distribuzione a posteriore dei parametri con la funzione `summarise_draws` del pacchetto `posterior`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposterior::summarise_draws(fit$draws(\"lambda\"), rhat, ess_bulk, ess_tail)\n#> # A tibble: 1 × 4\n#>   variable  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>    <dbl>    <dbl>\n#> 1 lambda   1.002 4666.651 6265.973\n```\n:::\n\n\n* $\\hat{R}$ (R-hat): misura la convergenza delle catene.\n  Valori vicini a 1.00 indicano che le catene si sono mescolate bene; valori maggiori di 1.01 segnalano possibili problemi.\n\n* ESS (Effective Sample Size): indica quanti campioni “indipendenti” equivalenti abbiamo ottenuto.\n\n  * `ess_bulk` valuta la precisione delle stime centrali (media, mediana).\n  * `ess_tail` valuta la precisione nelle code della distribuzione (intervalli credibili).\n    Più sono grandi, meglio è: in genere migliaia di campioni equivalenti sono più che sufficienti.\n\nPossiamo generare un traceplot con la funzione `mcmc_trace` di `bayesplot`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbayesplot::mcmc_trace(fit$draws(\"lambda\")) \n```\n\n::: {.cell-output-display}\n![](08_stan_poisson_model_1_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl traceplot mostra l’andamento dei valori di $\\lambda$ campionati dalle diverse catene.\nSe le catene:\n\n* oscillano liberamente attorno alla stessa regione,\n* senza trend sistematici o salti strani,\n\nallora possiamo concludere che il campionamento è avvenuto correttamente.\n\nIn sintesi: se $\\hat{R} \\approx 1$, ESS è elevato e i traceplot sono ben mescolati, possiamo fidarci delle stime ottenute.\n\n\n## Sparatorie mortali\n\nNella sezione precedente abbiamo esaminato il processo di derivazione della distribuzione a posteriori per i parametri della distribuzione Gamma, la quale viene impiegata quando si adotta un prior Gamma per una verosimiglianza di Poisson. In questo esempio, useremo tale metodo per affrontare una questione relativa all'analisi di un set di dati reali.\n\n### Domanda della ricerca\n\nCome spiegato [qui](https://github.com/washingtonpost/data-police-shootings), i dati che esamineremo sono raccolti dal Washington Post con lo scopo di registrare ogni sparatoria mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1° gennaio 2015. Il Washington Post ha adottato un approccio sistematico e accurato nella raccolta di queste informazioni, fornendo dati che possono essere utili per valutare i problemi legati alla violenza delle forze di polizia negli Stati Uniti.\n\n*Obiettivo.* Stimare, per il periodo 2015–*ultimo anno completo disponibile*, il *tasso medio annuo* e l’*incertezza* associata. Poiché il *2025* è incompleto, lo escludiamo.\n\n### Svolgimento con R\n\n#### Importazione e pre-processing dei dati\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# URL del dataset\nurl <- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\n\n# Importa i dati\nfps_dat <- read_csv(url, show_col_types = FALSE)\n\n# Conversione colonna date\nfps_dat <- fps_dat %>%\n  mutate(date = ymd(date),\n         year = year(date))\n\n# Esamina le colonne disponibili\ncolnames(fps_dat)\n#>  [1] \"id\"                         \"date\"                      \n#>  [3] \"threat_type\"                \"flee_status\"               \n#>  [5] \"armed_with\"                 \"city\"                      \n#>  [7] \"county\"                     \"state\"                     \n#>  [9] \"latitude\"                   \"longitude\"                 \n#> [11] \"location_precision\"         \"name\"                      \n#> [13] \"age\"                        \"gender\"                    \n#> [15] \"race\"                       \"race_source\"               \n#> [17] \"was_mental_illness_related\" \"body_camera\"               \n#> [19] \"agency_ids\"                 \"year\"\n\n# Filtra eliminando i casi con year == 2025\nfps <- fps_dat %>%\n  filter(year != 2025)\n\n# Conta le occorrenze per anno\nyear_counts <- fps %>%\n  count(year, name = \"events\")\n\n# Mostra i risultati\nprint(year_counts)\n#> # A tibble: 10 × 2\n#>     year events\n#>    <dbl>  <int>\n#>  1  2015    995\n#>  2  2016    959\n#>  3  2017    984\n#>  4  2018    992\n#>  5  2019    993\n#>  6  2020   1021\n#>  7  2021   1050\n#>  8  2022   1097\n#>  9  2023   1164\n#> 10  2024   1175\n```\n:::\n\n\n\n#### Modello di Poisson (pooling completo)\n\nAssumiamo $y_t \\sim \\text{Poisson}(\\lambda)$ con $\\lambda$ costante sul periodo:\n\n$$\ny_t \\,\\sim\\, \\text{Poisson}(\\lambda), \\quad t=1,\\dots,n.\n$$\n\nIl supporto di $\\lambda$ è $[0,\\infty)$. Si noti che abbiamo considerato i dati come iid. Guardando la serie temporale, però, è ovvio che le cose non stanno così: i valori aumentano nel tempo.\n\n\n#### Prior\n\nUsiamo una *prior coniugata Gamma* su $\\lambda$, scelta in modo *debolmente informativo*. Un’ipotesi ragionevole (da verificare e discutere in aula) è una media a priori di *600* eventi/anno, con *deviazione standard 200*. In termini Gamma(shape, rate):\n\n$$\n\\alpha = (\\mu/\\sigma)^2,\\qquad \\beta = \\mu/\\sigma^2.\n$$\n\nVisualizziamo la prior (campionando in R):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmu    <- 600\nsigma <- 200\n\n# Parametrizzazione Gamma(shape = k, scale = theta) per la simulazione\ntheta <- sigma^2 / mu\nk     <- mu / theta\n\nset.seed(2)\nx_draws <- rgamma(50000, shape = k, scale = theta)\n\nggplot(data.frame(x = x_draws), aes(x = x)) +\n  geom_histogram(bins = 30) +\n  labs(\n    x = \"Tasso (eventi/anno)\",\n    y = \"Frequenza\"\n  )\n```\n\n::: {.cell-output-display}\n![](08_stan_poisson_model_1_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n#### Modello di Poisson con Stan\n\nQui stimiamo $\\lambda$ assumendo lo *stesso tasso* per tutti gli anni (pooling completo). Con prior Gamma in *parametrizzazione (shape, rate)*:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_code <- \"\ndata {\n  int<lower=1> N;                 // numero di anni\n  array[N] int<lower=0> y;        // conteggi annuali\n  real<lower=0> alpha_prior;      // shape\n  real<lower=0> beta_prior;       // rate\n}\nparameters {\n  real<lower=0> lambda;           // tasso medio annuo\n}\nmodel {\n  lambda ~ gamma(alpha_prior, beta_prior); // prior Gamma(shape, rate)\n  y ~ poisson(lambda);                     // verosimiglianza\n}\ngenerated quantities {\n  real log_lik = poisson_lpmf(y | lambda);\n}\n\"\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Dati (usa i conteggi 2015...2024 ordinati)\ny_vec <- year_counts$events  # ordine per anno; per Poisson i.i.d. l'ordine non incide\n\n# Prior: coerente con la sezione precedente\nalpha_prior <- (mu / sigma)^2\nbeta_prior  <- mu / sigma^2\n\nstan_data <- list(\n  N = length(y_vec),\n  y = as.integer(y_vec),\n  alpha_prior = alpha_prior,\n  beta_prior  = beta_prior\n)\nstan_data\n#> $N\n#> [1] 10\n#> \n#> $y\n#>  [1]  995  959  984  992  993 1021 1050 1097 1164 1175\n#> \n#> $alpha_prior\n#> [1] 9\n#> \n#> $beta_prior\n#> [1] 0.015\n```\n:::\n\n\n\nCompilazione ed esecuzione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod <- cmdstan_model(write_stan_file(stan_code))\n```\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- mod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  seed = 123,\n  refresh = 0\n)\n```\n:::\n\n\nRiassunto dei parametri:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit$summary(\"lambda\")\n#> # A tibble: 1 × 10\n#>   variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n#>   <chr>       <dbl>    <dbl>  <dbl>  <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n#> 1 lambda   1042.414 1042.349 10.268 10.362 1025.691 1059.529 1.000 6110.780\n#>   ess_tail\n#>      <dbl>\n#> 1 8233.184\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposterior::summarise_draws(\n  fit$draws(\"lambda\"),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n#> # A tibble: 1 × 6\n#>   variable     mean     sd   `2.5%`    `50%`  `97.5%`\n#>   <chr>       <dbl>  <dbl>    <dbl>    <dbl>    <dbl>\n#> 1 lambda   1042.414 10.268 1022.544 1042.349 1062.583\n```\n:::\n\n\nVisualizzazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbayesplot::mcmc_hist(fit$draws(\"lambda\")) \n```\n\n::: {.cell-output-display}\n![](08_stan_poisson_model_1_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbayesplot::mcmc_areas(fit$draws(\"lambda\"), prob = 0.95)\n```\n\n::: {.cell-output-display}\n![](08_stan_poisson_model_1_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl grafico mostra che il tasso di sparatorie fatali ha una media annuale di 1042 con CI [1022, 1062].  \n\nIn sintesi, analizzando i dati compresi tra il 2015 e il 2025 e basandoci su una distribuzione a priori che presuppone una sparatoria mortale al mese per stato, possiamo concludere con un grado di certezza soggettivo del 95% che il tasso stimato di sparatorie fatali da parte della polizia negli Stati Uniti sia di 1028 casi all'anno, con un intervallo di credibilità compreso tra 1022 e 1062. \n\nDiagnostica essenziale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Indicatori numerici chiave: Rhat ~ 1, ESS adeguati\nposterior::summarize_draws(\n  fit$draws(c(\"lambda\")), \"rhat\", \"ess_bulk\", \"ess_tail\"\n)\n#> # A tibble: 1 × 4\n#>   variable  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>    <dbl>    <dbl>\n#> 1 lambda   1.000 6110.780 8233.184\n```\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Traceplot di controllo su OR\nbayesplot::mcmc_trace(fit$draws(\"lambda\")) \n```\n\n::: {.cell-output-display}\n![](08_stan_poisson_model_1_files/figure-html/unnamed-chunk-26-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n#### Derivazione analitica (Gamma–Poisson)\n\nCon prior $\\lambda \\sim \\text{Gamma}(\\alpha,\\beta)$ e dati $y_1,\\dots,y_n$ i.i.d. Poisson($\\lambda$), il posteriore è:\n\n$$\n\\lambda \\mid \\mathbf{y} \\;\\sim\\; \\text{Gamma}\\!\\left(\\alpha + \\sum_{t=1}^n y_t,\\;\\; \\beta + n\\right).\n$$\nQuindi:\n\n* *media posteriore* $\\mathbb{E}[\\lambda\\mid y] = \\dfrac{\\alpha + \\sum y_t}{\\beta + n}$;\n* *ICr 95%* con i quantili Gamma al 2.5% e 97.5%.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Dati e prior come nella sezione Stan\ndata_vec <- year_counts$events\nn        <- length(data_vec)\nsum_y    <- sum(data_vec)\n\nmu    <- 600\nsigma <- 200\nalpha_prior <- (mu / sigma)^2\nbeta_prior  <- mu / sigma^2\n\n# Posterior coniugato\nalpha_post <- alpha_prior + sum_y\nbeta_post  <- beta_prior  + n\n\npost_mean <- alpha_post / beta_post\nci95      <- qgamma(c(0.025, 0.975), shape = alpha_post, rate = beta_post)\n\ncat(\"Posterior mean λ:\", round(post_mean, 2), \"\\n\")\n#> Posterior mean λ: 1042\ncat(\"95% CrI: [\", round(ci95[1], 2), \", \", round(ci95[2], 2), \"]\\n\")\n#> 95% CrI: [ 1022 ,  1062 ]\n```\n:::\n\n\nLa derivazione *analitica* e i risultati *MCMC* coincidono (entro l’errore Monte Carlo).\n\n\n## Riflessioni conclusive\n\nL’esempio del modello di Poisson ci ha permesso di estendere l’inferenza bayesiana a un nuovo tipo di dati, mostrando la versatilità di Stan nel trattare situazioni diverse. Abbiamo visto che la logica rimane invariata: definiamo un prior, specifichiamo la verosimiglianza (in questo caso di Poisson) e otteniamo una distribuzione a posteriori che rappresenta la nostra incertezza sui parametri.\n\nDal punto di vista applicativo, questo esempio è particolarmente rilevante per la ricerca psicologica. I dati di conteggio sono onnipresenti, e spesso la loro analisi viene ridotta a modelli frequentisti standardizzati. Con l’approccio bayesiano, invece, possiamo esplicitare le nostre assunzioni, incorporare conoscenze pregresse e comunicare l’incertezza in modo più trasparente.\n\nIl valore didattico di questo capitolo sta nel mostrare la continuità: ciò che abbiamo imparato con le proporzioni e l’odds ratio si applica senza sforzo concettuale anche a contesti diversi. Al tempo stesso, l’uso di Stan ci ha reso evidente che, anche per modelli semplici, il supporto di un PPL è indispensabile quando vogliamo scalare verso situazioni più complesse.\n\nNei prossimi capitoli faremo proprio questo passo: passeremo da modelli semplici e univariati a strutture più articolate e gerarchiche, scoprendo come l’approccio bayesiano ci permetta di affrontare in modo sistematico la complessità della ricerca psicologica contemporanea.\n\n::: {.callout-tip collapse=true title=\"Cosa abbiamo imparato?\"}\n- Come tradurre un *modello teorico* di conteggio (Poisson con prior Gamma) in un modello Stan.  \n- Come ottenere campioni dalla *distribuzione a posteriori* con il campionamento MCMC.  \n- Come confrontare i risultati con la *soluzione analitica* per verificare che il workflow funziona.  \n- Perché è utile partire da un caso semplice: per allenarsi con il workflow che useremo in modelli più complessi, dove formule chiuse non esistono.\n:::\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] lubridate_1.9.4       forcats_1.0.0         stringr_1.5.1        \n#>  [4] purrr_1.1.0           readr_2.1.5           tidyverse_2.0.0      \n#>  [7] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#> [10] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#> [13] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [16] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [19] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [22] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [25] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [28] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [31] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#> [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#> [13] crayon_1.5.3          pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#> [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#> [19] utf8_1.2.6            rmarkdown_2.29        tzdb_0.5.0           \n#> [22] ps_1.9.1              ragg_1.5.0            bit_4.6.0            \n#> [25] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#> [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#> [31] stringi_1.8.7         RColorBrewer_1.1-3    estimability_1.5.1   \n#> [34] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#> [37] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#> [40] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#> [43] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#> [46] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#> [49] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#> [52] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#> [55] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#> [58] distributional_0.5.0  generics_0.1.4        vroom_1.6.5          \n#> [61] rprojroot_2.1.1       hms_1.1.3             rstantools_2.5.0     \n#> [64] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#> [67] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#> [70] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#> [73] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#> [76] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#> [79] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#> [82] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#> [85] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#> [88] bit64_4.6.0-1         MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n",
    "supporting": [
      "08_stan_poisson_model_1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}