{
  "hash": "b7f0d35e41ebeb85faecdd361a557ede",
  "result": {
    "engine": "knitr",
    "markdown": "# L'algoritmo di Metropolis-Hastings {#sec-mcmc-metropolis}\n\n## Introduzione {.unnumbered .unlisted}\n\nNei capitoli precedenti abbiamo visto che l’inferenza bayesiana può essere risolta esattamente in alcuni casi fortunati, grazie alle famiglie coniugate, oppure approssimata con metodi semplici come l’uso di una griglia di valori. Questi strumenti ci hanno permesso di comprendere a fondo la logica dell’aggiornamento bayesiano, ma hanno anche mostrato chiaramente i loro limiti: i casi coniugati sono eccezioni, e l’approccio su griglia diventa rapidamente impraticabile quando il numero di parametri cresce oltre uno o due.\nPer affrontare problemi realistici, che in psicologia riguardano quasi sempre modelli con più parametri e strutture complesse, dobbiamo introdurre un metodo generale che ci consenta di ottenere campioni dalla distribuzione a posteriori senza doverla calcolare in forma chiusa. Questo metodo esiste, ed è noto come algoritmo di Metropolis [@metropolist_etal_1953; @hastings_1970].\n\nL’algoritmo di Metropolis rappresenta una svolta concettuale: offre una soluzione universale per generare campioni dalla distribuzione a posteriori, indipendentemente dalla forma della verosimiglianza e del prior. In questo senso, risolve in modo definitivo il problema di come rendere praticabile l’inferenza bayesiana. Tuttavia, presenta anche due limiti: è relativamente inefficiente dal punto di vista computazionale e richiede di scrivere codice su misura per ogni modello. Nonostante ciò, la sua logica è così generale e potente che costituisce la base di tutti gli algoritmi moderni di campionamento, incluso il metodo NUTS implementato in Stan.\n\nIn questo capitolo introdurremo passo dopo passo l’algoritmo di Metropolis, ne vedremo il funzionamento intuitivo e lo applicheremo a casi concreti. Questo ci permetterà di capire la logica alla base di gran parte dell’inferenza bayesiana moderna, che rimane immutata anche nei metodi più sofisticati.\n\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Utilizzare metodi Monte Carlo per stimare valori attesi e probabilità, evitando calcoli integrali complessi.\n- Comprendere il ruolo delle catene di Markov nel campionamento dalla distribuzione a posteriori.\n- Implementare l'algoritmo di Metropolis per il campionamento a posteriori.\n- Valutare la convergenza delle catene con strumenti diagnostici come trace plot e autocorrelazione.\n- Gestire la fase di burn-in e utilizzare più catene per garantire stazionarietà e ridurre l'autocorrelazione.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere l'@sec-apx-calculus.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, reshape2)\n```\n:::\n\n:::\n\n## L'obiettivo del metodo MCMC\n\nIl metodo MCMC (Markov Chain Monte Carlo) è un approccio computazionale che consente di approssimare distribuzioni di probabilità complesse generando una sequenza di valori campionati che segue la distribuzione a posteriori di interesse. L'idea di base è la seguente: consideriamo la distribuzione a posteriori come una popolazione da cui desideriamo estrarre dei campioni. Generando un numero sufficientemente grande di campioni (ad esempio diverse migliaia), la distribuzione empirica dei campioni ottenuti si avvicina progressivamente alla distribuzione teorica a posteriori. In questo modo, è possibile stimare quantità di interesse, come la media, la varianza o gli intervalli di credibilità, anche senza conoscere la forma analitica esplicita della distribuzione a posteriori.\n\n### La natura dipendente del campionamento MCMC\n\nA differenza delle tecniche di campionamento indipendente precedentemente esaminate, l'approccio MCMC genera una sequenza di valori correlati tramite un meccanismo di transizione markoviana. La caratteristica distintiva di questo processo risiede nella proprietà di Markov: ogni nuovo campione dipende esclusivamente dallo stato corrente della catena e mostra memoria soltanto a breve termine, piuttosto che dipendere dall'intera storia precedente.\n\nQuesta architettura sequenziale produce inevitabilmente autocorrelazione tra le osservazioni adiacenti. Quando la catena visita una regione ad alta densità della distribuzione target, tende a persistere in tale zona per diverse iterazioni prima di migrare verso altre regioni. Questo comportamento è funzionale all'esplorazione efficiente dello spazio parametrico, ma introduce importanti considerazioni pratiche:\n\n* l'informazione effettiva contenuta in $N$ campioni correlati è inferiore a quella di $N$ campioni indipendenti;\n* la valutazione della convergenza richiede analisi diagnostiche specifiche;\n* la dimensione efficace del campione (*ESS*) diventa un parametro cruciale per la qualità dell'inferenza.\n\nPer compensare questa riduzione dell'informazione per campione, è generalmente necessario generare sequenze più lunghe rispetto al campionamento indipendente. Tuttavia, questo svantaggio apparente è ampiamente compensato dalla capacità di MCMC di affrontare problemi complessi che risulterebbero altrimenti irrisolvibili con i metodi tradizionali.\n\n### Perché utilizzare MCMC\n\nIl metodo MCMC rappresenta uno strumento fondamentale per l'inferenza bayesiana moderna, in quanto consente di affrontare problemi complessi con distribuzioni a posteriori di forma arbitraria e in spazi ad alta dimensionalità. Uno dei suoi principali vantaggi risiede nella capacità di bypassare il calcolo esplicito dell'evidenza, ovvero dell'integrale di normalizzazione richiesto dal teorema di Bayes, che spesso risulta analiticamente intrattabile. Attraverso la simulazione numerica, è possibile generare campioni la cui distribuzione empirica converge alla vera distribuzione a posteriori, permettendo così una stima accurata di qualsiasi quantità inferenziale di interesse.\n\nNel seguito ci concentreremo sull'*algoritmo di Metropolis*, uno dei metodi più semplici ed essenziali per implementare il campionamento MCMC.\n\n## L'algoritmo di Metropolis: introduzione intuitiva\n\nL'algoritmo di Metropolis è un metodo MCMC che consente di esplorare una distribuzione di probabilità complessa costruendo una sequenza di campioni dipendenti tra loro. La logica dell'algoritmo può essere riassunta nei seguenti passaggi fondamentali:\n\n1. **Punto di partenza**: si inizia da un valore iniziale $\\theta_0$ scelto arbitrariamente.\n2. **Proposta di un nuovo punto**: si genera un nuovo valore candidato $\\theta^*$ partendo da $\\theta_0$, utilizzando una distribuzione di proposta (ad esempio una distribuzione normale centrata su $\\theta_0$).\n3. **Valutazione della proposta**: si confrontano le densità a posteriori associate al valore attuale $\\theta_0$ e al valore proposto $\\theta^*$.\n4. **Decisione di accettazione**: \n   - se $\\theta^*$ ha una densità a posteriori più alta di $\\theta_0$, viene accettato automaticamente;\n   - se $\\theta^*$ ha una densità a posteriori inferiore, viene accettato con una certa probabilità proporzionale al rapporto delle densità.\n5. **Registrazione**: in ogni caso, si registra la posizione attuale (sia che si sia accettato un nuovo punto, sia che si sia rimasti fermi).\n\nQuesto processo viene ripetuto per un numero elevato di iterazioni, generando una catena di campioni che, dopo un opportuno periodo iniziale (detto *burn-in*), approssima la distribuzione a posteriori.\n\n## Perché accettiamo anche mosse peggiori\n\nUno degli aspetti caratteristici dell'algoritmo di Metropolis è la regola di accettazione che consente, con una certa probabilità, di accettare anche proposte $\\theta^*$ con densità a posteriori inferiore rispetto allo stato corrente. Questa scelta apparentemente controintuitiva è essenziale per garantire un'adeguata esplorazione dello spazio dei parametri.\n\nSe l'algoritmo accettasse esclusivamente mosse che migliorano la densità, convergerebbe rapidamente verso un picco locale della distribuzione, ma rischierebbe di tralasciare altre regioni significative dello spazio. Accettando occasionalmente mosse verso densità inferiori, la catena può sfuggire a massimi locali ed esplorare in modo più completo la distribuzione target, incluso l'accesso a modalità distinte che altrimenti risulterebbero inaccessibili.\n\nQuesta proprietà è fondamentale per ottenere una catena in grado di rappresentare fedelmente l'intera distribuzione a posteriori, specialmente quando essa è multimodale o presenta regioni di bassa probabilità tra aree ad alta densità. Senza questo meccanismo, l'algoritmo perderebbe la capacità di esplorare globalmente lo spazio dei parametri, compromettendo la validità delle inferenze ottenute.\n\n## La scelta della larghezza della proposta\n\nNell'algoritmo di Metropolis, la proposta di un nuovo valore $\\theta^*$ viene solitamente generata a partire dallo stato corrente $\\theta_t$ utilizzando una *distribuzione di proposta simmetrica*, ad esempio una distribuzione normale $\\mathcal{N}(\\theta_t, \\tau^2)$, dove $\\tau$ rappresenta la deviazione standard della proposta.\n\nLa scelta del valore di $\\tau$ (ovvero della *larghezza della proposta*) è cruciale per il buon funzionamento dell'algoritmo:\n\n- se $\\tau$ è *troppo piccolo*, i passi proposti saranno molto vicini al punto attuale. In questo caso, molte proposte saranno accettate, ma la catena si muoverà lentamente nello spazio dei parametri, esplorandolo inefficientemente (alta correlazione tra i campioni);\n- se $\\tau$ è *troppo grande*, i passi proposti saranno molto lontani dal punto attuale. In questo caso, la maggior parte delle proposte cadrà in regioni di bassa densità, portando a un alto tasso di rifiuto delle proposte e quindi a una scarsa efficienza del campionamento.\n\nUn valore ottimale di $\\tau$ deve bilanciare l'*accettazione* sufficiente di nuove proposte e l'*esplorazione* efficiente dello spazio dei parametri. In generale, si cerca di ottenere un *tasso di accettazione* compreso tra il 40% e il 50% per l'algoritmo di Metropolis a singolo parametro.\n\n## L'importanza dei grafici diagnostici: Trace plot e Correlogramma\n\nPer valutare la qualità della catena generata dall'algoritmo di Metropolis, è fondamentale analizzare alcuni *grafici diagnostici*.\n\n### Trace plot\n\nIl trace plot, che rappresenta la sequenza dei valori campionati di $\\theta$ in funzione delle iterazioni, costituisce uno strumento diagnostico essenziale per valutare il comportamento della catena MCMC. Una catena che si comporta bene mostra fluttuazioni stazionarie attorno a un valore medio costante, senza trend o derive prolungate nel tempo, indicando così una corretta esplorazione della regione di alta densità della distribuzione a posteriori.\n\nAl contrario, trace plot problematici possono rivelare diverse criticità. Una fase iniziale con andamento sistematicamente crescente o decrescente suggerisce un periodo di burn-in insufficiente, richiedendo l’eliminazione di un maggior numero di campioni iniziali. Una catena che presenta bassa variabilità o che si stabilizza prematuramente in una regione ristretta dello spazio dei parametri può indicare una esplorazione incompleta, possibilmente a causa di una parametrizzazione inefficace o di una distribuzione proposta troppo stretta. In casi più gravi, la catena può apparire stazionaria pur essendo bloccata in un massimo locale, senza aver raggiunto la vera distribuzione target, situazione particolarmente insidiosa in presenza di multimodalità.\n\n### Correlogramma\n\nIl correlogramma rappresenta l’autocorrelazione tra i campioni della catena a diversi ritardi (*lag*). In una catena efficiente, l’autocorrelazione decresce rapidamente al crescere del lag, avvicinandosi a zero dopo pochi passi. Questo comportamento indica un adeguato mescolamento della catena, in cui ciascun campione apporta nuova informazione indipendente.\n\nAl contrario, un’autocorrelazione persistentemente elevata — che si mantiene alta anche a lag elevati — segnala una forte dipendenza tra campioni consecutivi. In tali casi, la catena si muove lentamente attraverso lo spazio dei parametri, riducendo l’efficienza del campionamento e richiedendo un numero maggiore di iterazioni per ottenere stime affidabili. Un correlogramma di questo tipo suggerisce spesso la necessità di riparametrizzare il modello o di adottare un algoritmo di campionamento più efficiente.\n\n### Struttura del capitolo\n\nQuesti concetti costituiscono il fondamento necessario per affrontare la comprensione operativa e pratica dell'algoritmo di Metropolis che svilupperemo nei prossimi esempi. A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema. \n\n- Inizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o \"a posteriori,\" sia già conosciuta o disponibile per l'analisi.\n- In seguito, passeremo a illustrare come l'algoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un'approssimazione efficace della distribuzione a posteriori.\n\n## Un esempio concreto\n\nA titolo esemplificativo, utilizzeremo il dataset `moma_sample.csv`, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista. Il nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come $\\pi$ [si veda @Johnson2022bayesrules]. \n\nImportiamo i dati.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmoma_sample <- rio::import(here::here(\"data\", \"moma_sample.csv\"))\n```\n:::\n\n\nEsaminiamo le prime cinque righe del data frame.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmoma_sample |> \n  head()\n#>                artist  country birth death alive  genx gender count\n#> 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n#> 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3\n#> 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n#> 4         David Bates american  1952    NA  TRUE FALSE   male     1\n#> 5          Simon Levy american  1946    NA  TRUE FALSE   male     1\n#> 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n#>   year_acquired_min year_acquired_max\n#> 1              1981              1981\n#> 2              2005              2005\n#> 3              2016              2016\n#> 4              2001              2001\n#> 5              2012              2012\n#> 6              2008              2008\n```\n:::\n\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcoliamo la distribuzione delle generazioni\nresult <- table(moma_sample$genx)\nresult\n#> \n#> FALSE  TRUE \n#>    86    14\n```\n:::\n\n\nIl valore osservato $y = 14$ fornisce informazioni sul campione selezionato, ma la vera proporzione $\\theta$ di opere riconducibili alla Generazione X o successive nell’intera collezione del MOMA rimane ignota. Per modellare l’incertezza su questo parametro, i dati possono essere formalizzati come realizzazione di una variabile casuale binomiale:  \n\n$$\ny \\sim \\text{Binomial}(N = 100, \\theta).\n$$ \n\nPer incorporare la conoscenza a priori sulla probabilità $\\theta$, assumiamo una distribuzione Beta(4, 6) come priore. Questa scelta riflette una credenza pregressa secondo cui $\\theta$ tende a essere inferiore a 0.5, pur consentendo una certa flessibilità nell’inferenza.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntibble(x = seq(0, 1, .01),\n       y = dbeta(x, 4, 6)) |>\n  ggplot(aes(x=x, y=y)) + \n  geom_line()\n```\n\n::: {.cell-output-display}\n![](01_metropolis_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nSfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori. Il modello specificato può essere rappresentato nel modo seguente:\n\n$$\n\\begin{align}\nY &\\sim \\text{Binomiale}(100, \\theta),\\notag\\\\\n\\theta &\\sim \\text{Beta}(4, 6). \\notag\n\\end{align}\n$$\nDopo aver osservato il dato $Y = 14$, la distribuzione a posteriori per $\\theta$ si ottiene per coniugazione:\n$$\n\\theta \\mid (Y = 14) \\sim \\text{Beta}(4 + 14, 6 + 100 - 14) = \\text{Beta}(18, 92)\n$$\n\nNella figura seguente, è rappresentata la distribuzione a posteriori del parametro $\\theta$ ($\\text{Beta}(18, 92)$; colore arancione), insieme alla distribuzione alla *prior* specificata ($\\text{Beta}(4, 6)$; colore blu).\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01_metropolis_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nSe vogliamo conoscere il valore della media a posteriori di $\\theta$, per esempio, il risultato esatto è\n\n$$\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n$$\n\n### Simulazione con distribuzione target nota\n\nUsiamo ora una simulazione numerica per stimare la media a posteriori di $\\theta$. Conoscendo la forma della distribuzione a posteriori $Beta(18, 92)$, possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un'approssimazione della media a posteriori.\n\nSe vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Generiamo 10 campioni dalla distribuzione Beta(18, 92)\nset.seed(1234)  # Per riproducibilità\ny <- rbeta(10, shape1 = 18, shape2 = 92)\ny\n#>  [1] 0.1183 0.1751 0.2147 0.0769 0.1817 0.1852 0.1416 0.1426 0.1419 0.1299\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcoliamo la media dei campioni\nmean(y)\n#> [1] 0.151\n```\n:::\n\n\nTuttavia, con soli 10 campioni, l'approssimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10,000, possiamo ottenere una stima molto più precisa:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Generiamo 10000 campioni e calcoliamo la media\nset.seed(123)  # Per riproducibilità\nmean(rbeta(10000, shape1 = 18, shape2 = 92))\n#> [1] 0.164\n```\n:::\n\n\nQuando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria *converge* al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.\n\nÈ importante sottolineare che l’approccio di simulazione Monte Carlo diretto è applicabile solo quando la forma analitica della distribuzione a posteriori è nota e campionabile mediante apposite funzioni. Questo è stato possibile nel caso presentato, grazie alla coniugazione tra verosimiglianza binomiale e priori beta, che ha condotto a una distribuzione a posteriori beta di parametri noti. Tuttavia, in contesti reali più complessi, le distribuzioni a priori coniugate sono l’eccezione piuttosto che la regola, e la forma della posterior risulta spesso intrattabile analiticamente, impedendo l’uso di metodi di campionamento diretto.\n\nIn tali scenari, gli algoritmi MCMC, come l’algoritmo di Metropolis, offrono una soluzione flessibile ed efficace. Tali metodi permettono di generare campioni approssimati dalla distribuzione a posteriori senza richiederne una forma chiusa, basandosi esclusivamente sulla valutazione della verosimiglianza e della distribuzione a priori fino a una costante di normalizzazione. Grazie a questa proprietà, le tecniche MCMC costituiscono lo strumento computazionale predominante per l’inferenza bayesiana in modelli avanzati e realistici, dove l’analisi esatta non è praticabile.\n\n### L’algoritmo di Metropolis\n\nDopo aver visto che la simulazione diretta è possibile solo in casi eccezionali, possiamo ora introdurre il primo vero strumento generale per affrontare distribuzioni posteriori di forma arbitraria: l’algoritmo di Metropolis. Questo metodo appartiene alla famiglia MCMC e sfrutta la costruzione di una catena di Markov per produrre campioni che, a regime, si distribuiscono secondo la distribuzione a posteriori desiderata.\n\n#### Logica di base\n\nIl procedimento è sorprendentemente semplice. La catena parte da un valore iniziale del parametro. A ogni passo, un nuovo candidato viene generato tramite una distribuzione di proposta (spesso una normale centrata sullo stato corrente). Il punto proposto viene poi confrontato con quello attuale: se la sua densità a posteriori è maggiore, viene accettato; se è minore, viene accettato con una probabilità proporzionale al rapporto delle due densità. In questo modo la catena si muove nello spazio dei parametri favorendo le regioni più plausibili, ma senza rimanere intrappolata in massimi locali, poiché di tanto in tanto vengono accettati anche spostamenti verso aree meno probabili.\n\n#### Convergenza e burn-in\n\nNei primi passi la catena riflette ancora la condizione iniziale e non rappresenta adeguatamente la distribuzione target. È per questo che una quota iniziale di iterazioni, detta *burn-in*, viene eliminata dall’analisi. Dopo questa fase transitoria, la catena tende alla distribuzione stazionaria: i campioni successivi possono allora essere utilizzati per stimare medie, varianze o probabilità a posteriori. La quantità di burn-in necessaria non è fissata a priori, ma deve essere valutata tramite strumenti diagnostici.\n\n#### Accettazione e rifiuto: un equilibrio sottile\n\nIl cuore dell’algoritmo sta nella regola di accettazione. Essa realizza un equilibrio tra due esigenze opposte: da un lato lo *sfruttamento* delle regioni già identificate come ad alta densità, dall’altro l’*esplorazione* di nuove aree che potrebbero rivelarsi rilevanti. Accettare solo proposte migliori renderebbe la catena miopicamente attratta da un singolo massimo, mentre accettare anche proposte peggiori — seppur con probabilità ridotta — consente una copertura globale dello spazio parametrico. È questo meccanismo che garantisce la capacità dell’algoritmo di approssimare fedelmente la distribuzione a posteriori.\n\n### Passaggi fondamentali dell’algoritmo di Metropolis\n\nIl funzionamento dell’algoritmo può essere riassunto in una sequenza ricorsiva di operazioni, che trasforma un singolo punto di partenza in una catena di campioni distribuiti secondo la posteriori:\n\n1. **Inizializzazione.**\n   Si sceglie un valore iniziale $\\theta_1$ per il parametro e si fissa l’indice di iterazione $t = 1$. Questo punto rappresenta il primo elemento della catena.\n\n2. **Generazione di una proposta.**\n   A partire dallo stato corrente $\\theta_t$, si estrae un nuovo candidato $\\theta_p$ da una distribuzione di proposta $g(\\theta_p \\mid \\theta_t)$. Una scelta comune è la distribuzione normale centrata su $\\theta_t$ con deviazione standard $\\tau$, che controlla l’ampiezza dei passi.\n\n3. **Controllo di validità.**\n   Se il campione proposto non appartiene al dominio consentito (ad esempio, se $\\theta$ rappresenta una probabilità, il valore deve rimanere compreso tra 0 e 1), la proposta viene immediatamente rifiutata e si prosegue con il campione corrente.\n\n4. **Calcolo del rapporto di accettazione.**\n   Si valuta il rapporto\n\n   $$\n   \\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)},\n   $$\n\n   che confronta la plausibilità a posteriori del punto proposto $\\theta_p$ con quella dello stato corrente $\\theta_t$.\n\n5. **Decisione di accettazione.**\n\n   * Se $\\alpha \\geq 1$, la proposta viene accettata senza condizioni: lo stato successivo della catena sarà $\\theta_{t+1} = \\theta_p$.\n   * Se $\\alpha < 1$, la proposta viene accettata con probabilità $\\alpha$. In caso contrario, lo stato non cambia e $\\theta_{t+1} = \\theta_t$.\n\n6. **Iterazione.**\n   I passaggi precedenti vengono ripetuti molte volte. La sequenza risultante ${\\theta_1, \\theta_2, \\ldots}$ costituisce la catena di Markov che, dopo una fase di burn-in, riproduce fedelmente la distribuzione a posteriori.\n\n### Alcuni aspetti cruciali\n\n* **Distribuzione di proposta.**\n  La scelta di $g(\\theta_p \\mid \\theta_t)$ determina il ritmo dell’esplorazione. Un valore di $\\tau$ troppo piccolo rende i movimenti minimi: la catena accetta quasi tutte le proposte, ma procede lentamente e i campioni sono fortemente autocorrelati. Viceversa, un $\\tau$ troppo grande genera proposte spesso improbabili, con conseguente alto tasso di rifiuto. L’efficienza dell’algoritmo dipende da un compromesso fra questi due estremi.\n\n* **Ruolo del rapporto di accettazione.**\n  Il meccanismo dell’accettazione probabilistica assicura che la catena non si limiti a inseguire i massimi locali della distribuzione, ma sia in grado di attraversare anche regioni meno dense, favorendo una copertura più completa dello spazio dei parametri.\n\n* **Esplorazione globale.**\n  Proprio grazie a questa possibilità di accettare campioni peggiori, l’algoritmo di Metropolis è in grado di rappresentare accuratamente distribuzioni multimodali e complesse, garantendo robustezza in contesti in cui metodi deterministici fallirebbero.\n\n## Esempio di implementazione\n\nRiprendiamo il caso del MoMA: vogliamo stimare la probabilità $\\theta$ che un artista appartenga alla Generazione X o successiva, osservando 14 artisti su 100. Usiamo un modello binomiale con prior $\\text{Beta}(4,6)$, e implementiamo l’algoritmo di Metropolis in R.\n\n### Componenti del modello\n\n**Distribuzione a priori**\nRappresenta la nostra conoscenza iniziale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprior <- function(p) {\n  dbeta(p, shape1 = 4, shape2 = 6)\n}\n```\n:::\n\n\n**Verosimiglianza**\nLa probabilità di osservare 14 successi su 100 prove:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlikelihood <- function(p) {\n  dbinom(14, size = 100, prob = p)\n}\n```\n:::\n\n\n**Posterior (non normalizzata)**\nCombinazione di priori e verosimiglianza:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposterior <- function(p) {\n  prior(p) * likelihood(p)\n}\n```\n:::\n\n\n**Distribuzione di proposta**\nGenera un candidato vicino al punto attuale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nproposal_distribution <- function(current_state, proposal_sigma) {\n  rnorm(1, mean = current_state, sd = proposal_sigma)\n}\n```\n:::\n\n\n### Algoritmo di Metropolis\n\nL’implementazione segue esattamente i passaggi teorici discussi sopra:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmetropolis <- function(n_samples, start, proposal_sigma) {\n  samples <- numeric(n_samples)   # per salvare la catena\n  current <- start                # stato iniziale\n\n  for (i in seq_len(n_samples)) {\n    # 1. Genera una proposta\n    proposal <- proposal_distribution(current, proposal_sigma)\n\n    # 2. Controlla se la proposta è valida (qui θ deve stare in [0,1])\n    if (proposal >= 0 && proposal <= 1) {\n      # 3. Calcola il rapporto di accettazione\n      alpha <- posterior(proposal) / posterior(current)\n\n      # 4. Decidi se accettare\n      if (runif(1) < alpha) {\n        current <- proposal   # accettata\n      }\n    }\n    # 5. Salva lo stato (attuale o precedente)\n    samples[i] <- current\n  }\n  return(samples)\n}\n```\n:::\n\n\n### Interpretazione intuitiva\n\nSi può immaginare l’algoritmo come una passeggiata su un paesaggio collinare:\n\n* *L’altezza delle colline* corrisponde alla densità a posteriori.\n* *Ogni passo* è una proposta casuale in una direzione vicina.\n* *Se il punto è più alto*, lo accettiamo sempre (meglio!).\n* *Se è più basso*, lo accettiamo con una probabilità proporzionale a quanto è più basso: qualche volta sì, qualche volta no.\n\nRipetendo questa passeggiata migliaia di volte, i luoghi visitati con più frequenza corrispondono alle zone dove la posteriori è più densa.\nOttimo blocco! Ti propongo una versione più pulita e didattica, con micro-migliorie che aiutano a leggere e a verificare (senza aggiungere complessità): aggiungo il calcolo del *tasso di accettazione*, etichette chiare nei grafici, una gestione del burn-in esplicita e un confronto numerico con i valori esatti.\n\n## Esecuzione dell’algoritmo\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Parametri dell'algoritmo\nn_samples <- 10000\nstart <- 0.50\nproposal_sigma <- 0.10\n\n# Esecuzione del campionamento\nset.seed(123)  # riproducibilità\nsamples <- metropolis(n_samples, start, proposal_sigma)\n\n# Tasso di accettazione (quante volte la catena si muove)\naccept_rate <- mean(diff(samples) != 0)\naccept_rate\n#> [1] 0.392\n```\n:::\n\n\nIl tasso di accettazione è un indicatore utile del “ritmo” della catena. In 1D valori \\~0.4–0.5 sono spesso un buon compromesso.\n\n## Analisi dei risultati\n\n### Burn-in\n\nScartiamo i primi 50% dei campioni (criterio semplice e chiaro per questo esempio):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nburnin <- floor(n_samples * 0.50)\npost_burnin_samples <- samples[(burnin + 1):n_samples]\n```\n:::\n\n\n### Riassunti numerici\n\nMedia e deviazione standard a posteriori (stima via MCMC):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(post_burnin_samples)\n#> [1] 0.163\nsd(post_burnin_samples)\n#> [1] 0.0354\n```\n:::\n\n\nConfronto con i valori esatti della Beta(18, 92):\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean_exact <- 18 / (18 + 92)\nsd_exact <- sqrt( (18 * 92) / ( (18 + 92)^2 * (18 + 92 + 1) ) )\nc(media_esatta = mean_exact, sd_esatta = sd_exact)\n#> media_esatta    sd_esatta \n#>       0.1636       0.0351\n```\n:::\n\n\n### Trace plot (inizio catena e tratto post burn-in)\n\nPrime 200 iterazioni: si vede l'avvio e l'assestamento:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntibble(\n  Iterazione = 1:200,\n  Theta = samples[1:200]\n) |>\n  ggplot(aes(x = Iterazione, y = Theta)) +\n  geom_line(linewidth = 0.6) +\n  labs(x = \"Iterazioni (prime 200)\", y = expression(theta)) +\n  theme(axis.title = element_text(face = \"bold\"))\n```\n\n::: {.cell-output-display}\n![](01_metropolis_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nAndamento dopo il burn-in: la catena oscilla intorno alla regione stazionaria:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntibble(\n  Iterazione = seq_along(post_burnin_samples),\n  Theta = post_burnin_samples\n) |>\n  ggplot(aes(x = Iterazione, y = Theta)) +\n  geom_line(linewidth = 0.6) +\n  labs(x = \"Iterazioni (post burn-in)\", y = expression(theta)) +\n  theme(axis.title = element_text(face = \"bold\"))\n```\n\n::: {.cell-output-display}\n![](01_metropolis_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n### Confronto visivo con la posteriore esatta\n\nSovrapponiamo l’istogramma dei campioni post burn-in alla densità Beta(18, 92).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Palette per la legenda\ncolori_custom <- c(\n  \"Istogramma\" = \"#1F77B4\",  # Blu\n  \"Beta(18,92)\" = \"#FF7F0E\"  # Arancione\n)\n\ntibble(Theta = post_burnin_samples) |>\n  ggplot(aes(x = Theta)) +\n  geom_histogram(\n    aes(y = after_stat(density), fill = \"Istogramma\"),\n    bins = 30, color = \"black\", alpha = 0.7, show.legend = TRUE\n  ) +\n  stat_function(\n    aes(color = \"Beta(18,92)\"),\n    fun = dbeta, args = list(shape1 = 18, shape2 = 92),\n    linewidth = 1.1, show.legend = TRUE\n  ) +\n  labs(x = expression(theta), y = \"Densità\") +\n  scale_fill_manual(\n    name = \"Distribuzione\",\n    values = colori_custom,\n    breaks = names(colori_custom)\n  ) +\n  scale_color_manual(\n    name = \"Distribuzione\",\n    values = colori_custom,\n    breaks = names(colori_custom)\n  ) +\n  guides(\n    fill  = guide_legend(override.aes = list(color = NA)),\n    color = guide_legend(override.aes = list(fill = NA))\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output-display}\n![](01_metropolis_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n### Intervallo di credibilità\n\nStimiamo un *94% ETI* dai campioni MCMC e confrontiamolo con l’analitico:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ETI 94% via MCMC\nquantile(post_burnin_samples, probs = c(0.03, 0.97))\n#>    3%   97% \n#> 0.102 0.235\n\n# ETI 94% esatto (Beta)\nqbeta(c(0.03, 0.97), shape1 = 18, shape2 = 92)\n#> [1] 0.103 0.235\n```\n:::\n\n\n### Cosa osservare (guida alla lettura)\n\n* Il *trace plot post burn-in* oscilla senza trend: buon segnale di stazionarietà.\n* L’*istogramma* dei campioni si sovrappone bene alla *Beta(18, 92)*: l’algoritmo sta ricostruendo la posteriore.\n* *Media, deviazione standard e quantili* dai campioni sono molto vicini ai valori esatti: conferma pratica della correttezza dell’implementazione.\n\n## Catene di Markov, convergenza e diagnostiche (anticipazione)\n\nDurante una simulazione Monte Carlo basata su Metropolis — o, più in generale, su un algoritmo MCMC — otteniamo una *catena*, ossia una sequenza ordinata di valori del parametro $\\theta$. Ogni elemento della catena rappresenta uno stato che l’algoritmo ha visitato nello spazio dei parametri. Possiamo immaginare questa sequenza come il percorso di un esploratore che si muove tra diverse regioni del paesaggio della distribuzione a posteriori.\n\nAll’inizio, la catena riflette soprattutto il punto di partenza: i primi passi sono quindi influenzati dalle condizioni iniziali. Con il procedere delle iterazioni, però, l’effetto del punto di partenza si attenua e la catena converge verso una distribuzione stazionaria. È in questa fase che i campioni possono essere considerati rappresentativi della posteriore.\n\nPer verificare che ciò avvenga, è prassi comune eseguire *più catene indipendenti*, ciascuna con un punto di partenza diverso. Questa strategia offre due vantaggi:\n\n* consente di confrontare i *trace plot* e verificare se le catene si stabilizzano attorno alla stessa distribuzione,\n* riduce il rischio che una catena resti bloccata in un massimo locale, aumentando la robustezza complessiva dell’inferenza.\n\nLa valutazione della convergenza e della qualità del campionamento può basarsi su strumenti grafici (trace plot, correlogrammi) o su indicatori quantitativi come la statistica $\\hat{R}$ di Gelman-Rubin e la dimensione del campione effettiva (ESS).\n\nPoiché queste diagnostiche richiedono un’attenzione dedicata, qui ci limitiamo a introdurle brevemente. Il @sec-mcmc-diagnostics offrirà una trattazione completa, con esempi dettagliati e applicazioni pratiche.\n\n::: {.callout-note collapse=true title=\"Per approfondire\"}\nUn ulteriore esempio dell’algoritmo di Metropolis è presentato nell’Appendice, dove viene affrontato il caso Normale–Normale. In quel contesto la distribuzione a posteriori è nota analiticamente, e il confronto diretto con i campioni MCMC permette di verificare passo per passo la correttezza del procedimento.\n:::\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nL’introduzione dell’algoritmo di Metropolis ha rappresentato una svolta decisiva per l’inferenza bayesiana. Prima della sua comparsa, l’analisi era confinata a pochi casi speciali, gestibili grazie alle distribuzioni coniugate o a modelli estremamente semplici. Con Metropolis diventa invece possibile, almeno in linea di principio, ottenere campioni dalla distribuzione a posteriori in qualunque situazione, senza conoscerne la forma analitica.\n\nQuesta è la vera potenza dell’algoritmo: dimostrare che il problema concettuale dell’inferenza bayesiana è risolto. Una volta stabilito il modello, non è più necessario calcolare integrali complicati: possiamo affidare l’esplorazione dello spazio dei parametri a una catena di Markov. Restano, naturalmente, limiti pratici: la velocità del campionamento, l’efficienza nel mescolamento e la necessità di implementazioni accurate. Non a caso, gli sviluppi successivi — dal Metropolis-Hastings fino al moderno algoritmo NUTS usato in Stan — possono essere visti come perfezionamenti tecnici di questa intuizione originaria, volti a rendere l’approccio più stabile e automatizzato [@duane1987hybrid; @geman_geman_1984; @hoffman2014no; @hanada2022mcmc].\n\nDal punto di vista didattico, Metropolis rimane un passaggio fondamentale: non è soltanto un pezzo di storia, ma il nucleo concettuale da cui discendono i metodi odierni. Comprendere la sua logica — fatta di proposte, accettazioni e rifiuti — significa acquisire le chiavi per interpretare anche gli algoritmi più sofisticati, che ne condividono la stessa architettura di base.\n\nIn definitiva, l’algoritmo di Metropolis ci consegna due insegnamenti centrali. Primo: l’inferenza bayesiana non è limitata a pochi casi fortunati, ma può essere sempre condotta. Secondo: ogni modello psicologico, anche complesso e realistico, può essere trattato con questa logica, purché si disponga degli strumenti computazionali adeguati.\n\n::: {.callout-important title=\"Esercizio 1: Autostima negli Studenti Universitari\" collapse=\"true\"}\n\nIn un campione casuale di 100 studenti, 25 hanno mostrato livelli alti di autostima.  \nSupponiamo un prior Beta(2,8) sulla proporzione $\\theta$ di studenti con alta autostima.\n\nObiettivo: stimare la distribuzione a posteriori di $\\theta$ usando l'*algoritmo di Metropolis*.\n\n**Definizione delle Funzioni.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)  # per riproducibilità\n\n# Prior: Beta(2,8)\nprior <- function(p) dbeta(p, shape1 = 2, shape2 = 8)\n\n# Likelihood: binomiale 25 successi su 100\nlikelihood <- function(p) dbinom(25, size = 100, prob = p)\n\n# Posterior non normalizzata\nposterior <- function(p) prior(p) * likelihood(p)\n\n# Distribuzione di proposta\nproposal_distribution <- function(current, proposal_sigma) {\n  rnorm(1, mean = current, sd = proposal_sigma)\n}\n\n# Algoritmo di Metropolis\nmetropolis <- function(n_samples, start, proposal_sigma) {\n  samples <- numeric(n_samples)\n  current <- start\n  \n  for (i in seq_len(n_samples)) {\n    proposal <- proposal_distribution(current, proposal_sigma)\n    if (proposal >= 0 && proposal <= 1) {\n      acceptance_ratio <- min(1, posterior(proposal) / posterior(current))\n      if (runif(1) < acceptance_ratio) {\n        current <- proposal\n      }\n    }\n    samples[i] <- current\n  }\n  samples\n}\n```\n:::\n\n\n**Esecuzione dell'Algoritmo.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Parametri\nn_samples <- 10000\nstart <- 0.5\nproposal_sigma <- 0.1\n\n# Esecuzione\nsamples <- metropolis(n_samples, start, proposal_sigma)\n\n# Burn-in\nburnin <- floor(n_samples * 0.5)\npost_samples <- samples[-seq_len(burnin)]\n```\n:::\n\n\n**Analisi dei Risultati.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Media e deviazione standard\nmean(post_samples)\n#> [1] 0.244\nsd(post_samples)\n#> [1] 0.0395\n```\n:::\n\n\n**Calcolo dell'Intervallo di Credibilità al 94%.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nquantile(post_samples, probs = c(0.03, 0.97))\n#>    3%   97% \n#> 0.170 0.319\n```\n:::\n\n\n**Confronto con la Soluzione Analitica.**\n\nLa distribuzione a posteriori teorica è:\n\n$$\n\\theta \\sim \\text{Beta}(27, 83)\n$$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Media teorica\nmean_beta <- 27 / (27 + 83)\nmean_beta\n#> [1] 0.245\n\n# Intervallo teorico\nqbeta(c(0.03, 0.97), 27, 83)\n#> [1] 0.173 0.326\n```\n:::\n\n\n**Trace Plot.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Trace plot\npost_samples |> \n  tibble(Iteration = 1:length(post_samples), Theta = post_samples) |> \n  ggplot(aes(x = Iteration, y = Theta)) +\n  geom_line() +\n  labs(x = \"Iterazione\", y = expression(theta))\n```\n\n::: {.cell-output-display}\n![](01_metropolis_files/figure-html/unnamed-chunk-28-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Istogramma e Curva Teorica.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Prima generiamo il dataset della curva teorica separatamente\nx <- seq(0, 1, length.out = 1000)\ndens_teorica <- dbeta(x, 27, 83)\ncurva_teorica <- tibble(x = x, y = dens_teorica)\n\n# Ora costruiamo il grafico correttamente\ntibble(Theta = post_samples) |> \n  ggplot(aes(x = Theta)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, \n                 color = \"black\", fill = \"lightblue\", alpha = 0.6) +\n  geom_line(data = curva_teorica, aes(x = x, y = y), \n            color = \"red\", size = 1) +\n  labs(x = expression(theta), y = \"Densità\")\n```\n\n::: {.cell-output-display}\n![](01_metropolis_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Risultati Riassunti.**\n\n| Metodo | Media | Intervallo 94% |\n|:--|:--|:--|\n| MCMC (Metropolis) | circa 0.245 | circa [0.176, 0.320] |\n| Teorico Beta(27,83) | 0.245 | [0.177, 0.318] |\n\n\n**Spiegazioni Didattiche Finali.**\n  \n::: {.callout-note title=\"Distribuzione a posteriori: interpretazione\"}\nLa distribuzione a posteriori ci dice quanto sono plausibili i diversi valori di $\\theta$ dopo aver osservato i dati.\n\n> Ad esempio: \"C'è una probabilità del 94% che la vera proporzione di studenti con alta autostima sia tra 17% e 32%.\"\n:::\n  \n::: {.callout-tip title=\"Accettare mosse peggiori: motivo\"}\nAccettiamo campioni con probabilità più bassa per permettere alla catena di esplorare anche aree meno probabili e *non restare bloccata* nei massimi locali.\n:::\n  \n::: {.callout-warning title=\"Larghezza della proposta: trade-off\"}\n- **Proposta stretta** (piccoli passi): alta accettazione, ma esplorazione lenta.\n- **Proposta larga** (grandi passi): bassa accettazione, ma esplorazione più ampia.\n\nSi cerca un tasso di accettazione tra 40% e 50%.\n:::\n  \n::: {.callout-important title=\"Diagnostica grafica\"}\n- **Trace plot**: deve mostrare fluttuazioni stabili senza trend.\n- **Correlogramma**: l'autocorrelazione deve decrescere rapidamente.\n\nQuesti strumenti aiutano a diagnosticare una buona esplorazione della distribuzione a posteriori.\n:::\n\n:::\n\n::: {.callout-important title=\"Esercizio 2 - Depressione (BDI-II)\" collapse=\"true\"}\nIn uno studio clinico, sono stati raccolti i punteggi BDI-II (Beck Depression Inventory) di 30 pazienti. Vogliamo stimare il valore medio della depressione nella popolazione da cui provengono questi soggetti.\n\nSupponiamo di avere una conoscenza a priori modellata da una distribuzione Normale(30, 5²) per la media $\\mu$.\n\nI dati osservati sono i seguenti:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny <- c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43,\n       24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n       41, 36, 26, 35, 33, 28, 27, 34, 27, 22)\nlength(y)  \n#> [1] 30\n```\n:::\n\n\n**Funzioni a priori, verosimiglianza e posteriori.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Prior: Normal(30, 5^2)\nprior <- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2), sigma stimato dai dati\nlikelihood <- function(mu, data) {\n  sigma <- sd(data)\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzata\nposterior <- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n```\n:::\n\n\n**Algoritmo di Metropolis.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmetropolis_for_normal <- function(nsamp, xinit, data) {\n  samples <- numeric(nsamp)\n  x_prev <- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star <- rnorm(1, mean = x_prev, sd = 0.5)  # proposta\n    if (runif(1) < min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev <- x_star\n    }\n    samples[i] <- x_prev\n  }\n  samples\n}\n```\n:::\n\n\n**Esecuzione dell'algoritmo.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\nsamples <- metropolis_for_normal(100000, mean(y), y)\n\nburnin <- 50000\npost_samples <- samples[-seq_len(burnin)]\n```\n:::\n\n\n**Confronto con la soluzione analitica.**\n\nNel caso prior Normale e likelihood Normale con varianza nota, la posterior è ancora Normale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Prior\nmu_prior <- 30\nstd_prior <- 5\nvar_prior <- std_prior^2\n\n# Likelihood\nn <- length(y)\nsum_y <- sum(y)\nvar_data <- var(y)\n\nmu_post <- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post <- 1 / (1 / var_prior + n / var_data)\nstd_post <- sqrt(var_post)\n\nc(mu_post, std_post)\n#> [1] 30.88  1.17\n```\n:::\n\n\n**Trace Plot.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Trace plot\npost_samples |> \n  tibble(Iteration = 1:length(post_samples), Mu = post_samples) |> \n  ggplot(aes(x = Iteration, y = Mu)) +\n  geom_line() +\n  labs(x = \"Iterazione\", y = expression(mu))\n```\n\n::: {.cell-output-display}\n![](01_metropolis_files/figure-html/unnamed-chunk-35-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Istogramma vs Posterior Analitica.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\ndens_teorica <- dnorm(x, mean = mu_post, sd = std_post)\ncurva_teorica <- tibble(x = x, y = dens_teorica)\n\npost_samples |> \n  tibble(Mu = post_samples) |> \n  ggplot(aes(x = Mu)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.6) +\n  geom_line(data = curva_teorica, aes(x = x, y = y), color = \"red\", linewidth = 1) +\n  labs(x = expression(mu), y = \"Densit\\u00e0\")\n```\n\n::: {.cell-output-display}\n![](01_metropolis_files/figure-html/unnamed-chunk-36-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Cosa significa la distribuzione a posteriori?**\n\nIn termini concreti, la distribuzione a posteriori rappresenta la nostra incertezza residua sul valore di $\\mu$, la media dei punteggi BDI-II nella popolazione, **dopo aver visto i dati**. Per esempio, se calcoliamo che il 94% della distribuzione a posteriori cade tra 27.5 e 32.3, possiamo dire:\n\n> \"Date le nostre ipotesi iniziali e i dati osservati, c'è una probabilità del 94% che il vero valore medio della depressione nella popolazione stia tra 27.5 e 32.3\".\n\nQuesta è una **affermazione probabilistica sul parametro**, che è una caratteristica distintiva dell'inferenza bayesiana.\n\nQuesta distribuzione combina:\n\n- le credenze precedenti (il prior),\n- con l’evidenza osservata (i dati).\n\nIl risultato è una distribuzione che riflette cosa sappiamo del parametro dopo aver osservato i dati, e può essere usata per ottenere medie, intervalli di credibilità, probabilità soggettive, ecc.\n\n::: {.callout-tip title=\"Perché accettare anche campioni con densità più bassa?\"}\n\nNell'algoritmo di Metropolis, a ogni passo si propone un nuovo valore di $\\theta$. Se questo valore ha una densità a posteriori più alta, viene accettato.\n\nMa se ha una densità più bassa, viene comunque accettato con una certa probabilità.\n\n**Perché farlo?**\n\nPer evitare che la catena si \"blocchi\" in un massimo locale.\nPer esplorare anche le aree meno probabili, ma comunque possibili, della distribuzione.\n\nÈ un meccanismo simile a quello con cui gli esseri umani esplorano: ogni tanto vale la pena provare strade meno promettenti, per evitare di restare intrappolati.\nAccettare \"mosse peggiori\" è quindi un meccanismo di esplorazione utile a garantire che la catena possa visitare l’intero spazio dei parametri e convergere correttamente alla distribuzione desiderata. \n:::\n\n::: {.callout-warning title=\"Larghezza della proposta: un equilibrio delicato\"}\nNel Metropolis, il nuovo valore proposto viene scelto spostandosi dal valore corrente secondo una distribuzione normale:\n\n$$\\theta_{new} \\sim \\mathcal{N}(\\theta_{attuale}, \\sigma).$$\n\nIl parametro $\\sigma$ controlla la distanza dei passi.\n\nSe $\\sigma$ è:\n\n- Piccolo → i passi sono molto corti:\n  - Molte proposte vengono accettate (alta accettazione),\n  - Ma la catena esplora lentamente → i campioni sono fortemente autocorrelati.\n- Grande → i passi sono molto lunghi:\n  - Si propongono salti drastici → molte proposte vengono rifiutate,\n  - La catena si muove poco → anche in questo caso, esplorazione inefficiente.\n\nObiettivo: trovare un compromesso ottimale.\n\n- Per un parametro unidimensionale, si consiglia spesso un tasso di accettazione tra 40% e 50%.\n- Negli esercizi puoi provare diversi valori di proposal_sigma e osservare il tasso di accettazione per imparare.\n:::\n\n**Risultati.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(post_samples)\n#> [1] 30.9\nsd(post_samples)\n#> [1] 1.15\nquantile(post_samples, probs = c(0.03, 0.97))\n#>   3%  97% \n#> 28.7 33.1\n```\n:::\n\n\nValori teorici:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmu_post  # media teorica\n#> [1] 30.9\nqnorm(c(0.03, 0.97), mean = mu_post, sd = std_post)\n#> [1] 28.7 33.1\n```\n:::\n\n\n**Spiegazione Didattica.**\n\n- La media $\\mu$ rappresenta il livello medio di depressione nella popolazione.\n- Il prior rappresenta la nostra credenza iniziale (Normale con media 30).\n- L'evidenza fornita dai dati modifica questa credenza.\n- L'algoritmo di Metropolis permette di campionare da una distribuzione posterior anche senza conoscere la forma analitica.\n- Il confronto tra distribuzione teorica e campioni MCMC mostra un ottimo accordo.\n\n**Conclusione.**\n\nIn questo esercizio abbiamo:\n\n- implementato l'algoritmo di Metropolis per un caso con prior e likelihood Normali;\n- stimato la media della distribuzione posterior;\n- confrontato i risultati con la soluzione analitica;\n- verificato la coerenza dei campioni MCMC con la distribuzione teorica.\n\nQuesto mostra la potenza dell'approccio MCMC anche in situazioni dove la soluzione analitica sarebbe disponibile, e pone le basi per affrontare problemi più complessi.\n:::\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] reshape2_1.4.4        cmdstanr_0.9.0        pillar_1.11.0        \n#>  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#>  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#> [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#> [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#> [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#> [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#> [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#> [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#> [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#> [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#> [16] labeling_0.4.3        rmarkdown_2.29        ps_1.9.1             \n#> [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#> [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#> [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#> [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#> [31] knitr_1.50            zoo_1.8-14            R.utils_2.13.0       \n#> [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#> [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#> [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#> [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#> [46] plyr_1.8.9            withr_3.0.2           bridgesampling_1.1-2 \n#> [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#> [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#> [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#> [58] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#> [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#> [64] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#> [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#> [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#> [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#> [76] gtable_0.3.6          R.methodsS3_1.8.2     digest_0.6.37        \n#> [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#> [82] R.oo_1.27.1           memoise_2.0.1         htmltools_0.5.8.1    \n#> [85] lifecycle_1.0.4       MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n",
    "supporting": [
      "01_metropolis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}