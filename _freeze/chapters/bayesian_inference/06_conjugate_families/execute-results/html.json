{
  "hash": "5092c73dc6343df5757962f5454fcf63",
  "result": {
    "engine": "knitr",
    "markdown": "# Distribuzioni coniugate {#sec-bayesian-inference-conjugate-1}\n\n::: {.epigraph}\n> “Conjugate families are not chosen because they are realistic, but because they allow us to see the Bayesian machinery at work in its simplest form.”\n>\n> -- **Morris H. DeGrootx**, Optimal Statistical Decisions (1970)\n:::\n\n\n## Introduzione {.unnumbered .unlisted}\n\nNei capitoli precedenti abbiamo visto in azione l’aggiornamento bayesiano in un caso concreto: la stima della proporzione di successi con il modello *Beta-Binomiale*. Lì abbiamo osservato come la distribuzione *a priori* (Beta) e la verosimiglianza (Binomiale) si combinino attraverso il teorema di Bayes per produrre una distribuzione *a posteriori* che appartiene alla stessa famiglia della prior. Questo ci ha permesso di seguire passo dopo passo l’evoluzione delle nostre credenze in modo intuitivo e matematicamente elegante.\n\nIn questo capitolo generalizziamo questa idea e introduciamo il concetto di *distribuzioni coniugate*. Due distribuzioni sono dette coniugate quando, combinando una prior con la corrispondente verosimiglianza, otteniamo un posterior che appartiene alla stessa famiglia della prior. In altre parole, la forma della distribuzione rimane stabile, e a cambiare sono soltanto i parametri.\n\nQuesta proprietà, apparentemente tecnica, ha in realtà un grande valore didattico e pratico. Dal punto di vista concettuale, ci aiuta a visualizzare con chiarezza come i dati modifichino le nostre credenze: i parametri della distribuzione si aggiornano in modo diretto e cumulativo. Dal punto di vista operativo, rende il calcolo immediato, senza dover ricorrere a metodi di approssimazione numerica.\n\nNaturalmente, sappiamo già dai capitoli precedenti che il mondo reale è spesso più complesso: non sempre abbiamo a disposizione una coppia coniugata, e per modelli più articolati ricorriamo a metodi computazionali come il campionamento MCMC. Ma prima di affrontare quei casi, è utile familiarizzare con le famiglie coniugate, che costituiscono il laboratorio ideale per comprendere a fondo la logica dell’aggiornamento bayesiano.\n\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Introduzione del modello beta-binomiale.\n- Analisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\n- Aescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall'uso di distribuzioni coniugate.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere il capitolo *Conjugate Families* del testo di @Johnson2022bayesrules.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |>\n    source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)\n```\n:::\n\n:::\n\n\n## Il modello Beta-Binomiale \n\nIl *modello beta-binomiale* è un esempio classico per analizzare una proporzione $\\theta$, ossia la probabilità di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare $y$ successi su $n$ prove, dove ogni prova è indipendente e con la stessa probabilità di successo $\\theta$, che appartiene all'intervallo $[0,1]$.\n\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, è espressa come:\n\n$$\n\\mathcal{Binomial}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n$$\ndove $\\binom{n}{y}$ è il coefficiente binomiale che conta il numero di modi in cui $y$ successi possono verificarsi in $n$ prove.\n\nPer modellare la nostra conoscenza preliminare su $\\theta$, scegliamo una distribuzione a priori *Beta*, che rappresenta un'ampia gamma di credenze iniziali con parametri flessibili.\n\n## La distribuzione Beta\n\nLa distribuzione Beta è definita come:\n\n$$\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n$$\ndove:\n\n* $\\alpha > 0$ e $\\beta > 0$ sono i *parametri* che determinano la forma della distribuzione,\n* $B(\\alpha, \\beta)$ è la *funzione Beta di Eulero*, calcolata come:\n\n    $$\n    B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n    $$\n\n    dove $\\Gamma(x)$ è la funzione Gamma, una generalizzazione del fattoriale.\n\nIn termini bayesiani, possiamo pensare a questi parametri nel modo seguente:\n\n* $\\alpha -1$ rappresenta il numero ipotetico di \"successi\" a priori,\n* $\\beta -1$ rappresenta il numero ipotetico di \"fallimenti\" a priori.\n\nAd esempio:\n\n- una distribuzione *Beta(1, 1)* è uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate);\n- una distribuzione *Beta(10, 20)* rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poiché deriva da un totale di 28 osservazioni virtuali che riflettono le nostre credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all'evidenza disponibile o alla fiducia nella stima.\n\nLa distribuzione Beta è estremamente versatile:\n\n- valori diversi di $\\alpha$ e $\\beta$ producono distribuzioni simmetriche, asimmetriche o uniformi;\n- valori elevati di $\\alpha$ e $\\beta$ riducono la varianza, riflettendo credenze più forti.\n\nQuesta flessibilità rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali sulle proporzioni.\n\n\n## Aggiornamento bayesiano\n\nL'aggiornamento bayesiano combina le informazioni iniziali (distribuzione a priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle nostre credenze (distribuzione a posteriori). Nel caso del modello beta-binomiale, questo processo è particolarmente semplice grazie alla \"coniugazione\": il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta. \n\n::: {#thm-beta-binomial}\nSia $Y\\sim\\mathrm{Binomial}(n,\\theta)$ il numero di successi $y$ in $n$ prove indipendenti con probabilità di successo $\\theta$, e sia la nostra distribuzione a priori su $\\theta$ una Beta$\\bigl(\\alpha,\\beta\\bigr).$ Allora la distribuzione a posteriori di $\\theta$ dato l’osservazione $Y=y$ è\n\n$$\n\\theta \\mid Y=y \n\\;\\sim\\;\n\\mathrm{Beta}\\bigl(\\alpha + y,\\;\\beta + (n - y)\\bigr),\n$$ {#eq-beta-binom-post}\novvero i parametri si aggiornano come\n\n$$\n\\alpha' = \\alpha + y,\n\\quad\n\\beta' = \\beta + n - y.\n$$ {#eq-beta-binom-post-params}\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Derivazione.\n\n**Obiettivo.** Mostrare che, con prior $\\theta \\sim \\mathrm{Beta}(\\alpha,\\beta)$ e dati $Y\\sim\\mathrm{Binomiale}(n,\\theta)$, la posteriori è\n\n$$\n\\theta \\mid Y=y \\;\\sim\\; \\mathrm{Beta}\\bigl(\\alpha+y,\\;\\beta+n-y\\bigr).\n$$\n\n**1) Formula di Bayes (forma proporzionale).** Per qualunque $\\theta\\in(0,1)$:\n\n$$\np(\\theta\\mid y)\\;\\propto\\; p(y\\mid\\theta)\\, p(\\theta),\n$$\ndove “$\\propto$” significa “uguale a una costante (che non dipende da $\\theta$) per…”. Quella costante verrà ripristinata alla fine.\n\n**2) Verosimiglianza binomiale (parte che dipende da $\\theta$).**\n\n$$\np(y\\mid\\theta) \\;=\\; \\binom{n}{y}\\,\\theta^{\\,y}\\,(1-\\theta)^{\\,n-y}.\n$$\nPoiché $\\binom{n}{y}$ *non* dipende da $\\theta$, ai fini di “$\\propto$” possiamo scrivere:\n\n$$\np(y\\mid\\theta)\\;\\propto\\; \\theta^{\\,y}\\,(1-\\theta)^{\\,n-y}.\n$$\n\n**3) Prior Beta (parte che dipende da $\\theta$).**\n\n$$\np(\\theta) \\;=\\; \\frac{1}{B(\\alpha,\\beta)}\\,\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1},\n$$\ne dunque, ignorando la costante $B(\\alpha,\\beta)$:\n\n$$\np(\\theta)\\;\\propto\\;\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1}.\n$$\n\n**4) Prodotto “prior × verosimiglianza”.** Moltiplichiamo i soli termini che dipendono da $\\theta$:\n\n$$\n\\begin{aligned}\np(\\theta\\mid y)\n&\\;\\propto\\; \\bigl[\\theta^{\\,y}(1-\\theta)^{\\,n-y}\\bigr]\\;\\bigl[\\theta^{\\,\\alpha-1}(1-\\theta)^{\\,\\beta-1}\\bigr] \\\\\n&\\;=\\; \\theta^{\\,(\\alpha-1)+y}\\; (1-\\theta)^{\\,(\\beta-1)+(n-y)}.\n\\end{aligned}\n$$\n\n**5) Riconoscere la forma Beta (matching degli esponenti).** La *forma non normalizzata* di una $\\mathrm{Beta}(a,b)$ è:\n\n$$\n\\theta^{\\,a-1}\\,(1-\\theta)^{\\,b-1}.\n$$\nConfrontando gli esponenti otteniamo:\n\n$$\na-1 = (\\alpha-1)+y \\;\\;\\Rightarrow\\;\\; a = \\alpha + y,\n$$\n$$\nb-1 = (\\beta-1)+(n-y) \\;\\;\\Rightarrow\\;\\; b = \\beta + (n-y).\n$$\nQuindi la *densità non normalizzata* della distribuzione a posteriori è\n\n$$\np(\\theta\\mid y)\\;\\propto\\;\\theta^{\\,(\\alpha+y)-1}\\,(1-\\theta)^{\\,(\\beta+n-y)-1}.\n$$\n\n**6) Ripristino della costante di normalizzazione.** Per essere una densità, $p(\\theta\\mid y)$ deve integrare a 1 su $\\theta\\in(0,1)$. La costante corretta è l’inverso della funzione Beta con i nuovi parametri:\n\n$$\np(\\theta\\mid y)\n\\;=\\;\n\\frac{1}{B(\\alpha+y,\\;\\beta+n-y)}\\;\n\\theta^{\\,(\\alpha+y)-1}\\,(1-\\theta)^{\\,(\\beta+n-y)-1}.\n$$\n\n**7) Conclusione (forma parametrica della posteriori).** \n\n$$\n\\boxed{\n\\;\\theta\\mid Y=y \\;\\sim\\; \\mathrm{Beta}\\bigl(\\alpha+y,\\;\\beta+n-y\\bigr).\\;\n}\n$$\n\n\n**Intuizione in termini di “pseudocontenuti di informazione”.**\n\n* La Beta$(\\alpha,\\beta)$ può essere interpretata in termini di *pseudoconteggi*: $\\alpha-1$ “successi” e $\\beta-1$ “insuccessi” precedenti ai dati.\n* Dopo aver osservato $y$ successi e $n-y$ insuccessi, *si sommano* i conteggi:\n\n  $$\n  \\alpha \\to \\alpha+y,\\qquad \\beta \\to \\beta+(n-y).\n  $$\n* Questa additività spiega la *conjugatezza*: prior e posterior appartengono alla stessa famiglia.\n\n\n**Controllo rapido della normalizzazione.** Usiamo la definizione di $B(a,b)$:\n\n$$\nB(a,b) \\;=\\; \\int_0^1 \\theta^{a-1}(1-\\theta)^{b-1}\\,d\\theta.\n$$\nCon $a=\\alpha+y$ e $b=\\beta+n-y$, l’integrale della nostra forma non normalizzata è $B(\\alpha+y,\\beta+n-y)$; moltiplicando per $1/B(\\alpha+y,\\beta+n-y)$ otteniamo dunque una densità che integra a 1.\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Alcune quantità riassuntive utili.\n\nPer $\\theta\\mid y \\sim \\mathrm{Beta}(\\alpha+y,\\beta+n-y)$:\n\n* *Media posteriori*:\n\n  $$\n  \\mathbb{E}[\\theta\\mid y] \\;=\\; \\frac{\\alpha+y}{\\alpha+\\beta+n}.\n  $$\n* *Moda* (se parametri $>1$):\n\n  $$\n  \\frac{\\alpha+y-1}{\\alpha+\\beta+n-2}.\n  $$\n* *Varianza*:\n\n  $$\n  \\mathrm{Var}(\\theta\\mid y) \\;=\\; \n  \\frac{(\\alpha+y)(\\beta+n-y)}{(\\alpha+\\beta+n)^2\\,(\\alpha+\\beta+n+1)}.\n  $$\n:::\n\n### Vantaggi del modello Beta-Binomiale\n\n1. *Semplicità analitica*: la coniugatezza della distribuzione Beta-Binomiale semplifica i calcoli, rendendo immediato l'aggiornamento dei parametri.\n2. *Interpretazione intuitiva*: l'aggiornamento dei parametri $\\alpha$ e $\\beta$ mostra in modo trasparente come i dati influenzino le credenze.\n\nIn sintesi, il modello Beta-Binomiale è un esempio didattico fondamentale per comprendere l'inferenza bayesiana e rappresenta un punto di partenza ideale per approcci più avanzati.\n\n\n::: {.callout-note collapse=\"true\"}\n## Esercizio 1.\n\nNel @sec-bayesian-inference-proportion abbiamo utilizzato il metodo basato su griglia per determinare la distribuzione a posteriori nel caso di $y = 6$ successi su $n = 9$ prove [vedi anche @McElreath_rethinking per una discussione dettagliata]. Ora esploriamo un approccio alternativo, sfruttando le proprietà delle famiglie coniugate.\n\nLa verosimiglianza binomiale per questo esperimento è espressa dalla seguente funzione:\n\n$$\n\\mathcal{L}(\\theta) \\propto \\theta^y (1-\\theta)^{n-y},\n$$\ndove $y = 6$ rappresenta il numero di successi e $n = 9$ il numero totale di prove.\n\nScegliendo una distribuzione a priori Beta con parametri $\\alpha = 2$ e $\\beta = 5$, possiamo applicare il teorema di Bayes per calcolare i parametri aggiornati della distribuzione a posteriori. In base alla regola di aggiornamento per distribuzioni coniugate, otteniamo:\n\n$$\n\\alpha' = \\alpha + y = 2 + 6 = 8.\n$$\n$$\n\\beta' = \\beta + n - y = 5 + 9 - 6 = 8.\n$$\nLa distribuzione a posteriori risultante è quindi una distribuzione Beta con parametri $\\mathcal{Beta}(8, 8)$.\n\nProcediamo ora a visualizzare le tre distribuzioni rilevanti:\n\n1. **Distribuzione a priori**: $\\mathcal{Beta}(2, 2)$,\n2. **Verosimiglianza binomiale**: per $y = 6$ e $n = 9$,\n3. **Distribuzione a posteriori**: $\\text{Beta}(8, 5)$.\n\nEcco il codice R per generare il grafico comparativo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione dei parametri\nalpha_prior <- 2\nbeta_prior <- 5\ny <- 6\nn <- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post <- alpha_prior + y\nbeta_post <- beta_prior + n - y\n\n# Sequenza di valori di theta\ntheta <- seq(0, 1, length.out = 1000)\n\n# Calcolo delle PDF\nprior_pdf <- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood <- theta^y * (1 - theta)^(n - y)\n\n# Normalizzazione della verosimiglianza\nlikelihood_integral <- sum(likelihood) * (theta[2] - theta[1])\nnormalized_likelihood <- likelihood / likelihood_integral\n\nposterior_pdf <- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf <- data.frame(\n  theta = rep(theta, 3),\n  densita = c(prior_pdf, normalized_likelihood, posterior_pdf),\n  distribuzione = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(theta))\n)\n\n# Creare il grafico \nggplot(df, aes(x = theta, y = densita, color = distribuzione)) +\n  geom_line(size = 1) +  # Aggiungere le linee per le distribuzioni\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Likelihood\" = \"green\", \"Posterior\" = \"red\")) +  # Assegnare i colori\n  labs(title = \"Distribuzioni Prior, Likelihood e Posterior\",\n       x = expression(theta),\n       y = \"Densità\",\n       color = \"Distribuzione\") +  # Aggiungere titoli e label\n  theme(legend.position = \"top\")  # Posizionare la legenda in alto\n```\n\n::: {.cell-output-display}\n![](06_conjugate_families_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n- *Curva blu*: Prior $\\mathcal{Beta}(2, 5)$, che riflette le credenze iniziali prima dell'osservazione dei dati.  \n- *Curva verde*: Likelihood (normalizzata), rappresenta l'evidenza fornita dai dati osservati.  \n- *Curva rossa*: Posterior $\\mathcal{Beta}(8, 8)$, risultato dell'aggiornamento bayesiano che combina prior e likelihood.  \n\n**Nota sulla normalizzazione della verosimiglianza.** La verosimiglianza binomiale non è una distribuzione di probabilità (il suo integrale non è pari a 1). Per rappresentarla visivamente accanto alla distribuzione a priori e a quella a posteriori, è necessario normalizzarla. Questo è fatto calcolando il suo integrale su $\\theta \\in [0, 1]$ e dividendo la funzione per il risultato. La normalizzazione serve solo per la visualizzazione e non influisce sui calcoli analitici.\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Esercizio 2.\n\nEsaminiamo ora un esempio discuso da @Johnson2022bayesrules. In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorità, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell'articolo, Milgram descrive lo studio come\n\n> consistente nell'ordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che è un complice addestrato dell'esperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un 'esperimento di apprendimento' apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l'esperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre più intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realtà era un attore addestrato) sulla loro capacità di memorizzare una serie di item. Se l'attore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all'attore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l'attore stesse solo fingendo di provare dolore dalla scossa.\n\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello \"Pericolo: Scossa Grave\". Il problema richiede di costruire la distribuzione a posteriori della probabilità $\\theta$ di infliggere una scossa a l livello \"Pericolo: Scossa Grave\", ipotizzando che uno studio precedente aveva stabilito che $\\theta$ segue una distribuzione Beta(1, 10).\n\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Impostazione dei parametri della distribuzione Beta\nalpha <- 1\nbeta_val <- 10\n\n# Creazione di valori x per il plot\nx_values <- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf <- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Creare un dataframe contenente i dati per il grafico\ndf <- data.frame(\n  x = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico\nggplot(df, aes(x = x, y = densita)) +\n  geom_line(color = \"#b97c7c\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(1, 10)\",  # Aggiungere il titolo\n       x = \"x\",  # Label dell'asse x\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  geom_vline(xintercept = 1, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(1, 10)\", color = \"#b97c7c\", size = 5)  # Aggiungere una legenda\n```\n\n::: {.cell-output-display}\n![](06_conjugate_families_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny <- 26\nn <- 40\n\nalpha_prior <- 1\nbeta_prior <- 10\n\nalpha_post <- alpha_prior + y\nbeta_post <- beta_prior + n - y\n\nalpha_post\n#> [1] 27\nbeta_post\n#> [1] 24\n```\n:::\n\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Creazione di valori x per il plot\nx_values <- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf <- dbeta(x_values, alpha_post, beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf <- data.frame(\n  theta = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(27, 24)\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(27, 24)\", color = \"blue\", size = 5)  \n```\n\n::: {.cell-output-display}\n![](06_conjugate_families_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nCalcolo della media a posteriori di $\\theta$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nalpha_post / (alpha_post + beta_post)\n#> [1] 0.529\n```\n:::\n\n\nCalcolo della moda a posteriori:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#> [1] 0.531\n```\n:::\n\n\nCalcolo della probabilità che $\\theta > 0.6$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#> [1] 0.156\n```\n:::\n\n\nOvvero:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n1 - pbeta(0.6, alpha_post, beta_post)\n#> [1] 0.156\n```\n:::\n\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntheta <- seq(0, 1, length.out = 100)\n```\n:::\n\n\nCreiamo la distribuzione a priori:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprior <- dbeta(theta, alpha_prior, beta_prior)\n\n# Normalizzazione della densità per ottenere una somma pari a 1\nprior_normalized <- prior / sum(prior)\n\n# Creare un dataframe contenente i dati per il grafico\ndf <- data.frame(\n  theta = theta,\n  probabilita = prior_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"blue\", size = 1) +  # Linee verticali per rappresentare le probabilità\n  labs(title = \"Distribuzione a priori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n```\n\n::: {.cell-output-display}\n![](06_conjugate_families_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nCreiamo la verosimiglianza:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlk <- dbinom(y, n, theta)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized <- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf <- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"red\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Verosimiglianza\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n```\n\n::: {.cell-output-display}\n![](06_conjugate_families_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nCalcoliamo la distribuzione a posteriori:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npost <- (prior * lk) / sum(prior * lk)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized <- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf <- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"green\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Distribuzione a posteriori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n```\n\n::: {.cell-output-display}\n![](06_conjugate_families_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsamples <- sample(theta, size = 1e6, replace = TRUE, prob = post)\n```\n:::\n\n\nTroviamo la media a posteriori:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(samples)\n#> [1] 0.529\n```\n:::\n\n\nCalcoliamo la probabilità che $\\theta > 0.6$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(samples > 0.6)\n#> [1] 0.152\n```\n:::\n\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Esercizio 3.\n\nConsideriamo un esempio discusso da @nalborczyk2018 nel quale, oltre all'applicazione del teorema beta-binimiale, viene anche introdotto il concetto di posterior-predictive check.\n\nSupponiamo di reclutare partecipanti per uno studio di mezza ora:  \n\n- Possiamo farlo fra le 9:00 e le 18:00, con sessioni ogni 30 minuti.  \n- In una settimana lavorativa (lun–ven) otteniamo $n = 90$ time slot.  \n- Ad ogni slot, il partecipante o si presenta ($1$) o manca ($0$).  \n\nVogliamo stimare la probabilità media di presenza, che chiameremo $\\theta$.  \n\nModello:\n\n$$\n\\begin{cases}\n    Y \\mid \\theta \\;\\sim\\;\\mathrm{Binomial}(n,\\theta),\\\\[6pt]\n    \\theta \\;\\sim\\;\\mathrm{Beta}(\\alpha,\\beta).\n    \\end{cases}\n$$\n\n\nScelta del prior:\n\n- conoscenze pregresse suggeriscono che $\\theta$ sia intorno a 0.5;  \n- scegliamo quindi un **prior** $\\;\\mathrm{Beta}(2,2)$, che ha media $0.5$ e riflette incertezza moderata.  \n\n\nDati osservati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# vettore di 0/1 con n = 90 osservazioni\ny <- c(\n  0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,\n  0,1,0,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,\n  1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,\n  1,0,0,1,1,1,0,1,1,1,1,1,1,0,0,0,0,1,\n  0,1,0,1,1,1,0,0,0,0,0,1,1,1,1,1,1,0\n)\n```\n:::\n\n\nCalcoliamo  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn <- length(y)  # numero di slot = 90\nz <- sum(y)     # numero di presenze = numero di 1\n```\n:::\n\n\n\n**Posterior Beta–Binomiale.**\n\nI parametri aggiornati sono  \n\n$$\n\\alpha_{post} = \\alpha + z,\n\\quad\n\\beta_{post} = \\beta + (n - z).\n$$\n\nIn particolare, con $\\alpha=\\beta=2$:  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\na <- b <- 2\na_post <- a + z\nb_post <- b + (n - z)\n```\n:::\n\n\nIl *posterior* è quindi  \n\n$$\n\\theta\\mid y \\;\\sim\\;\\mathrm{Beta}(a+z,\\;b+n-z).\n$$\n\n\nVisualizzazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# griglia per theta\ngrid <- seq(0, 1, length.out = 1000)\n\n# densità\nprior     <- dbeta(grid, a,      b)\nposterior <- dbeta(grid, a_post, b_post)\n\ndf <- data.frame(theta = grid,\n                 prior = prior,\n                 posterior = posterior)\n\nggplot(df) +\n  geom_area(aes(x = theta, y = prior,\n                fill = \"Prior\", colour = \"Prior\"),\n            alpha = 0.5, size = 1) +\n  geom_area(aes(x = theta, y = posterior,\n                fill = \"Posterior\", colour = \"Posterior\"),\n            alpha = 0.5, size = 1) +\n  scale_fill_grey(name = \"\") +\n  scale_colour_grey(name = \"\") +\n  theme_bw(base_size = 12) +\n  xlab(expression(theta)) +\n  ylab(\"\") +\n  ggtitle(\"Densità Prior e Posterior\\nmodello Beta–Binomiale\")\n```\n\n::: {.cell-output-display}\n![](06_conjugate_families_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Introduzione ai posterior predictive checks.**\n\nIl modello assume *indipendenza* fra i time slot.  Se questa assunzione è violata (ad es. presenza autocorrelata nel tempo), le nostre stime potrebbero essere fuorvianti.\n\n**Idea**:  \n\n1. Simulare $\\theta$ dal posterior.  \n2. Dato ciascun $\\theta$, generare una nuova serie $y^{rep}$ da  \n   $\\mathrm{Binomial}(n,\\theta)$.  \n3. Calcolare su ogni $y^{rep}$ una **test-quantità** $T(y^{rep})$.  \n4. Confrontare la distribuzione di $T(y^{rep})$ con il valore osservato $T(y)$.  \n\nSe $T(y)$ è un outlier rispetto ai $T(y^{rep})$, l’assunzione di indipendenza è sospetta.\n\n\n**Test‐quantità: numero di “switch”.** \n\nDefiniamo una funzione che conta quante volte la serie passa da 0→1 o da 1→0:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncount_switches <- function(x) {\n  sum(abs(diff(x)) == 1)\n}\n\n# valore osservato\nTy <- count_switches(y)\ncat(\"Switch osservati:\", Ty, \"\\n\")\n#> Switch osservati: 28\n```\n:::\n\n\n**Simulazione e istogramma.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)      # per riproducibilità\nnsims <- 10000     # numero di repliche\n\nsim_switches <- replicate(nsims, {\n  # 1) estrai un theta dal posterior\n  theta_sim <- rbeta(1, a_post, b_post)\n  # 2) genera y^rep ~ Bernoulli(theta_sim)\n  y_sim     <- rbinom(n, size = 1, prob = theta_sim)\n  # 3) conta gli switch\n  count_switches(y_sim)\n})\n\n# Istogramma\nhist(sim_switches,\n     breaks = 30,\n     col    = \"lightgrey\",\n     main   = \"Distribuzione Posterior Predictive\\ndel numero di switch\",\n     xlab   = \"Numero di switch\",\n     ylab   = \"Frequenza\")\nabline(v = Ty, col = \"darkgreen\", lty = 2, lwd = 2)\n```\n\n::: {.cell-output-display}\n![](06_conjugate_families_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Bayesian p‐value.**\n\nCalcoliamo la probabilità di ottenere un numero di switch **≤** di quello osservato:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np_value <- mean(sim_switches <= Ty)\ncat(\"Bayesian p-value:\", round(p_value, 4), \"\\n\")\n#> Bayesian p-value: 0.0073\n```\n:::\n\n\n- Un valore molto basso (es. $<0.05$) indica che $T(y)$ è sorprendente rispetto alle predizioni del modello.  \n- Qui: se $p\\approx 0.01$, la bassa variabilità di switch suggerisce **dipendenza** fra le osservazioni.\n\n\n**Interpretazione.**  \n\n- *Un modello non è “giusto” o “sbagliato”*, ma deve descrivere bene il processo che genera i dati.  \n- Il nostro check mostra che il numero di switch osservato è **molto** minore di quanto ci aspetteremmo sotto l'ipotesi di indipendenza.  \n- Con tutta probabilità c’è **autocorrelazione temporale** (le presenze dipendono dall’ora del giorno).  \n- Per tenerne conto, si potrebbero usare modelli più avanzati (es. processi gaussiani).\n\nIn sintesi, il posterior predictive checking ci offre un modo flessibile per diagnosticare *diverse* violazioni del modello, scegliendo test‐quantities adatte (media, varianza, max, autocorrelazione, …). Come scrivono Gelman et al. (2013), “i p-valori posteriori … possono essere calcolati per varie test-quantities per valutare più modi in cui un modello può fallire”.\n:::\n\n\n## Principali distribuzioni coniugate\n\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle più note coniugazioni tra modelli statistici e distribuzioni a priori:\n\n- Nel modello *Normale-Normale* $\\mathcal{N}(\\mu, \\sigma^2_0)$, la distribuzione a priori è $\\mathcal{N}(\\mu_0, \\tau^2)$ e la distribuzione a posteriori è $\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)$.\n\n- Nel modello *Poisson-gamma* $\\text{Po}(\\theta)$, la distribuzione a priori è $\\Gamma(\\lambda, \\delta)$ e la distribuzione a posteriori è $\\Gamma(\\lambda + n \\bar{y}, \\delta +n)$.\n\n- Nel modello *Esponenziale* $\\text{Exp}(\\theta)$, la distribuzione a priori è $\\Gamma(\\lambda, \\delta)$ e la distribuzione a posteriori è $\\Gamma(\\lambda + n, \\delta +n\\bar{y})$.\n\n- Nel modello *Uniforme-Pareto* $\\text{U}(0, \\theta)$, la distribuzione a priori è $\\text{Pa}(\\alpha, \\varepsilon)$ e la distribuzione a posteriori è $\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))$.\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo approfondito l’idea di *famiglia coniugata*, mostrando come, in certi casi, il teorema di Bayes mantenga invariata la forma della distribuzione a priori. L’esempio del modello Beta-Binomiale, già incontrato in precedenza, ci ha offerto l’occasione di vedere con chiarezza come i dati modifichino le nostre credenze in modo semplice e cumulativo: basta aggiornare i parametri della distribuzione, senza cambiare la sua struttura.\n\nQuesta proprietà, apparentemente tecnica, riveste una grande importanza concettuale. Le distribuzioni coniugate costituiscono il *laboratorio ideale* per comprendere a fondo la logica dell’inferenza bayesiana: permettono di seguire con trasparenza il passaggio da prior a posterior, di vedere come ogni nuova osservazione si traduca in un aggiornamento dei parametri e di cogliere in maniera intuitiva la natura dinamica del processo.\n\nNaturalmente, sappiamo che la coniugazione è un caso speciale. Nella maggior parte dei problemi reali, soprattutto quando i modelli diventano complessi e includono più parametri o strutture gerarchiche, non esiste una coppia prior–verosimiglianza coniugata che semplifichi i calcoli. È in questi casi che entrano in gioco metodi computazionali più generali, come il campionamento MCMC, che ci permettono di affrontare situazioni realistiche senza rinunciare alla coerenza dell’approccio bayesiano [@Johnson2022bayesrules].\n\nIn questo senso, le famiglie coniugate non rappresentano un punto di arrivo, ma un passaggio fondamentale: ci insegnano i principi dell’aggiornamento bayesiano in un contesto semplice, che prepara la strada verso strumenti più potenti e flessibili.\n\n\n::: {.callout-important title=\"Problemi 1\" collapse=\"true\"}\nSi consideri lo studio \"*An excess of positive results: Comparing the standard psychology literature with registered reports*\" di @scheel2021excess. In questo lavoro, gli autori confrontano il tasso di risultati positivi $\\theta$ ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro $\\theta$.\n\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per $\\theta$, seguendo il metodo illustrato da @Johnson2022bayesrules.\n\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati:\n(a) Un tasso di successo del 60%\n(b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da @scheel2021excess).\n\nInfine, si commentino i risultati derivanti dall'analisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n:::\n\n::: {.callout-tip title=\"Soluzioni 1\" collapse=\"true\"}\n```r\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Funzione per trovare i parametri della distribuzione beta\nfind_beta_parameters <- function(mean, lower, upper, conf_level = 0.95) {\n  # Funzione obiettivo da minimizzare\n  objective <- function(alpha) {\n    beta <- alpha * (1 - mean) / mean\n    predicted_ci <- qbeta(c((1-conf_level)/2, 1-(1-conf_level)/2), alpha, beta)\n    error <- (predicted_ci[1] - lower)^2 + (predicted_ci[2] - upper)^2\n    return(error)\n  }\n  \n  # Ottimizzazione per trovare alpha\n  result <- optimize(objective, interval = c(0.1, 100))\n  alpha <- result$minimum\n  beta <- alpha * (1 - mean) / mean\n  \n  return(list(alpha = alpha, beta = beta))\n}\n\n# Parametri degli studi preregistrati\nmean_preregistered <- 0.4366\nci_lower <- 0.3191\nci_upper <- 0.5595\n\n# Calcolo dei parametri della distribuzione beta a priori\nprior_params <- find_beta_parameters(mean_preregistered, ci_lower, ci_upper)\nalpha_prior <- prior_params$alpha\nbeta_prior <- prior_params$beta\n\n# Dati osservati\nn <- 152  # numero di studi\nsuccesses_60 <- round(0.60 * n)  # scenario (a)\nsuccesses_96 <- round(0.96 * n)  # scenario (b)\n\n# Calcolo delle distribuzioni a posteriori\nalpha_post_60 <- alpha_prior + successes_60\nbeta_post_60 <- beta_prior + (n - successes_60)\n\nalpha_post_96 <- alpha_prior + successes_96\nbeta_post_96 <- beta_prior + (n - successes_96)\n\n# Creazione del dataframe per il plotting\ntheta <- seq(0, 1, length.out = 1000)\n\ndf <- data.frame(\n  theta = rep(theta, 3),\n  density = c(\n    dbeta(theta, alpha_prior, beta_prior),\n    dbeta(theta, alpha_post_60, beta_post_60),\n    dbeta(theta, alpha_post_96, beta_post_96)\n  ),\n  distribution = rep(c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"), \n                    each = length(theta))\n)\n\n# Creazione del grafico\np <- ggplot(df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    x = expression(theta),\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n# Calcolo degli intervalli di credibilità al 95%\ncredible_intervals <- data.frame(\n  Distribution = c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"),\n  Mean = c(\n    alpha_prior / (alpha_prior + beta_prior),\n    alpha_post_60 / (alpha_post_60 + beta_post_60),\n    alpha_post_96 / (alpha_post_96 + beta_post_96)\n  ),\n  Lower = c(\n    qbeta(0.025, alpha_prior, beta_prior),\n    qbeta(0.025, alpha_post_60, beta_post_60),\n    qbeta(0.025, alpha_post_96, beta_post_96)\n  ),\n  Upper = c(\n    qbeta(0.975, alpha_prior, beta_prior),\n    qbeta(0.975, alpha_post_60, beta_post_60),\n    qbeta(0.975, alpha_post_96, beta_post_96)\n  )\n)\n\n# Visualizzazione dei risultati\nprint(\"Parametri della distribuzione beta a priori:\")\nprint(paste(\"alpha =\", round(alpha_prior, 2)))\nprint(paste(\"beta =\", round(beta_prior, 2)))\n\nprint(\"\\nIntervalli di credibilità al 95%:\")\nprint(credible_intervals)\n\n# Visualizza il grafico\nprint(p)\n```\n:::\n\n\n::: {.callout-important title=\"Problemi 2\" collapse=\"true\"}\nTra i fattori che possono influenzare il rapporto tra i sessi alla nascita c'è la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta è impiantata in basso nell'utero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\n\nQuanta evidenza fornisce questo studio a supporto dell'ipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da @gelman1995bayesian)\n:::\n\n::: {.callout-tip title=\"Soluzioni 2\" collapse=\"true\"}\n```r\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn <- 980        # numero totale di nascite\ny <- 437        # numero di femmine\np0 <- 0.485     # proporzione nella popolazione generale\n\n# Calcolo della proporzione osservata\np_hat <- y/n\nprint(paste(\"Proporzione osservata di femmine:\", round(p_hat, 3)))\n\n# Test dell'ipotesi utilizzando il Bayes Factor\n# H0: p = 0.485 vs H1: p < 0.485\n\n# Funzione per calcolare la verosimiglianza marginale sotto H1\nmarginal_likelihood_h1 <- function(y, n, p_max = 0.485) {\n  # Integrazione numerica sulla distribuzione uniforme tra 0 e p_max\n  p_grid <- seq(0, p_max, length.out = 1000)\n  likelihood <- dbinom(y, n, p_grid)\n  prior <- dunif(p_grid, 0, p_max)\n  mean(likelihood * prior) * p_max\n}\n\n# Verosimiglianza sotto H0\nlikelihood_h0 <- dbinom(y, n, p0)\n\n# Verosimiglianza marginale sotto H1\nmarg_lik_h1 <- marginal_likelihood_h1(y, n)\n\n# Calcolo del Bayes Factor\nbf10 <- marg_lik_h1 / likelihood_h0\nprint(paste(\"Bayes Factor (H1 vs H0):\", round(bf10, 2)))\n\n# Visualizzazione delle distribuzioni a posteriori\np_grid <- seq(0, 1, length.out = 1000)\nlikelihood <- dbinom(y, n, p_grid)\nprior <- dunif(p_grid, 0, 1)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\n\n# Creazione del dataframe per il plotting\ndf <- data.frame(\n  p = p_grid,\n  Posterior = posterior / max(posterior)  # normalizzato per la visualizzazione\n)\n\n# Creazione del grafico\np <- ggplot(df, aes(x = p, y = Posterior)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = p_hat, linetype = \"dashed\", color = \"blue\") +\n  labs(\n    title = \"Distribuzione a Posteriori della Proporzione di Nascite Femminili\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità a Posteriori (normalizzata)\"\n  ) +\n  annotate(\"text\", x = p0, y = 0.1, \n           label = \"Popolazione Generale\", \n           angle = 90, vjust = -0.5, color = \"red\") +\n  annotate(\"text\", x = p_hat, y = 0.1, \n           label = \"Proporzione Osservata\", \n           angle = 90, vjust = -0.5, color = \"blue\")\n\n# Calcolo dell'intervallo di credibilità al 95%\nsorted_p <- sort(p_grid)\ncum_post <- cumsum(posterior)\nlower <- sorted_p[which(cum_post > 0.025)[1]]\nupper <- sorted_p[which(cum_post > 0.975)[1]]\n\nprint(paste(\"Intervallo di credibilità al 95%: [\", \n            round(lower, 3), \",\", round(upper, 3), \"]\"))\n\n# Calcolo della probabilità a posteriori che p < 0.485\nprob_less_than_p0 <- sum(posterior[p_grid < p0])\nprint(paste(\"Probabilità a posteriori che p < 0.485:\", \n            round(prob_less_than_p0, 3)))\n\n# Visualizza il grafico\nprint(p)\n```\n:::\n\n::: {.callout-important title=\"Problemi 3\" collapse=\"true\"}\nPer valutare la sensibilità della soluzione precedente alla scelta della distribuzione a priori, ripetere l'esercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione è centrata su 0.485 e concentra la maggior parte della sua massa nell'intervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n:::\n\n::: {.callout-tip title=\"Soluzioni 3\" collapse=\"true\"}\n```r\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn <- 980        # numero totale di nascite\ny <- 437        # numero di femmine\np0 <- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior <- 48.5\nbeta_prior <- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post <- alpha_prior + y\nbeta_post <- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid <- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density <- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density <- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf <- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np <- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean <- alpha_prior / (alpha_prior + beta_prior)\npost_mean <- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci <- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci <- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p < 0.485\nprob_less_than_p0 <- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p < %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\n```\n```r\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn <- 980        # numero totale di nascite\ny <- 437        # numero di femmine\np0 <- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior <- 48.5\nbeta_prior <- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post <- alpha_prior + y\nbeta_post <- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid <- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density <- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density <- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf <- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np <- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean <- alpha_prior / (alpha_prior + beta_prior)\npost_mean <- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci <- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci <- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p < 0.485\nprob_less_than_p0 <- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p < %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\n\n```\n\nI risultati mostrano che:\n\n1. La proporzione osservata nel campione (0.446) è inferiore al valore di riferimento della popolazione generale (0.485)\n\n2. La distribuzione a priori Beta(48.5, 51.5):\n\n- Ha media 0.485\n- Riflette la nostra conoscenza iniziale sulla proporzione di nascite femminili\n- Fornisce un'incertezza ragionevole attorno al valore di riferimento\n\n3. La distribuzione a posteriori:\n\n- Ha una media di circa 0.447\n- L'intervallo di credibilità al 95% esclude il valore di riferimento 0.485\n- Indica una probabilità elevata che la vera proporzione sia inferiore a 0.485\n\n4. Questa analisi suggerisce che:\n\n- Esiste un'associazione tra placenta previa e una minor proporzione di nascite femminili\n- L'effetto è moderato ma statisticamente rilevante\n- La stima è abbastanza precisa grazie alla dimensione campionaria considerevole\n:::\n\n::: {.callout-important title=\"Problemi 4\" collapse=\"true\"}\nIn uno studio recente, @gori2024italian hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di @papadatou2020human, condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralità manuale. Inoltre, @papadatou2020human mostrano che la prevalenza della lateralità manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di @gori2024italian con le informazioni pregresse fornite da Papadatou-Pastou et al. (2020). Le informazioni di @papadatou2020human possono essere espresse in termini di una distribuzione Beta(8, 60).\n:::\n\n::: {.callout-tip title=\"Soluzioni 4\" collapse=\"true\"}\n```r\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn <- 202       # dimensione del campione\ny <- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior <- 8\nbeta_prior <- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post <- alpha_prior + y\nbeta_post <- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid <- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density <- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density <- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf <- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean <- alpha_prior / (alpha_prior + beta_prior)\npost_mean <- alpha_post / (alpha_post + beta_post)\n\nprior_ci <- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci <- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np <- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\n```\n\n```r\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn <- 202       # dimensione del campione\ny <- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior <- 8\nbeta_prior <- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post <- alpha_prior + y\nbeta_post <- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid <- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density <- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density <- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf <- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean <- alpha_prior / (alpha_prior + beta_prior)\npost_mean <- alpha_post / (alpha_post + beta_post)\n\nprior_ci <- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci <- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np <- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\n\n```\n\nL'analisi bayesiana della prevalenza dei mancini combina le informazioni provenienti dalla meta-analisi di Papadatou-Pastou et al. (2020) con i dati più recenti di Gori et al. (2024). Di seguito sono riportati i principali risultati:\n\n1. **Distribuzione a priori** (basata su Papadatou-Pastou et al., 2020):  \n   - Modellata come una distribuzione Beta(8, 60).  \n   - Presenta una media intorno all'11,8%.  \n   - Riflette la variabilità osservata nella meta-analisi.  \n   - L'intervallo di credibilità al 95% copre approssimativamente il range 9,3%-18,1%, come riportato nello studio.  \n\n2. **Dati osservati** (Gori et al., 2024):  \n   - 202 partecipanti italiani.  \n   - 13 mancini, corrispondenti al 6,4% del campione.  \n   - Questo valore è inferiore alla media stimata dalla meta-analisi globale.  \n\n3. **Distribuzione a posteriori**:  \n   - Combina le informazioni a priori con i nuovi dati osservati.  \n   - La media a posteriori si è spostata verso il basso rispetto alla distribuzione a priori.  \n   - L'intervallo di credibilità si è ristretto, indicando una riduzione dell'incertezza.  \n   - Maggiore peso è stato attribuito ai dati italiani rispetto alla meta-analisi globale.  \n\n4. **Interpretazione**:  \n   - La stima finale suggerisce una prevalenza di mancini nella popolazione italiana inferiore alla media globale.  \n   - Questo risultato potrebbe riflettere specificità culturali o metodologiche dello studio italiano.  \n   - L'incertezza nella stima finale è diminuita rispetto alla meta-analisi, ma rimane significativa.  \n   - I risultati supportano l'ipotesi di una variabilità geografica nella prevalenza della mancinismo.  \n\nLa distribuzione a posteriori fornisce una sintesi equilibrata tra le conoscenze globali precedenti e i dati specifici della popolazione italiana, suggerendo che potrebbero esistere peculiarità culturali o demografiche che influenzano la prevalenza del mancinismo in Italia.\n:::\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#>  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#>  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [25] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#>  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#>  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#> [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#> [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#> [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#> [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#> [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#> [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#> [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#> [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#> [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#> [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#> [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#> [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#> [46] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#> [49] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#> [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#> [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#> [58] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#> [61] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#> [64] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#> [67] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#> [70] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#> [73] lme4_1.1-37           mvtnorm_1.3-3         grid_4.5.1           \n#> [76] rbibutils_2.3         QuickJSR_1.8.0        colorspace_2.1-1     \n#> [79] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#> [82] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#> [85] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#> [88] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#> [91] htmltools_0.5.8.1     lifecycle_1.0.4       mitml_0.4-5          \n#> [94] MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n",
    "supporting": [
      "06_conjugate_families_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}