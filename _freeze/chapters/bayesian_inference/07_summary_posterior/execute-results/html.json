{
  "hash": "7c40d48c85f2e253632950760228380e",
  "result": {
    "engine": "knitr",
    "markdown": "# Sintesi a posteriori {#sec-bayesian-inference-summary-posterior}\n\n::: {.epigraph}\n> “The summary of a posterior distribution is an essential step for its interpretation. Point estimators and credible intervals are the most common Bayesian answers, but they should not make us forget the richness of the entire posterior.”\n>\n> -- **Christian P. Robert**, The Bayesian Choice (2007)\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nNei capitoli precedenti abbiamo imparato a costruire distribuzioni a posteriori combinando la nostra conoscenza preliminare (*prior*) con i dati osservati attraverso la verosimiglianza. Abbiamo visto come questo processo si realizzi in casi semplici, come la stima di una proporzione di successi con il modello Beta–Binomiale, e come possa essere generalizzato grazie al concetto di famiglie coniugate. Ora ci poniamo una domanda fondamentale: una volta che abbiamo ottenuto una distribuzione a posteriori, *come possiamo riassumerla e comunicarla in modo chiaro ed efficace?*\n\nIl *posterior* non è un singolo numero, ma un’intera distribuzione che rappresenta la nostra incertezza sul parametro. Nella pratica della ricerca psicologica, tuttavia, dobbiamo spesso sintetizzare queste informazioni per presentarle nei risultati di un articolo o per confrontarle con altre stime. Questo capitolo è dedicato proprio a questa esigenza: mostreremo come ricavare quantità riassuntive (media, mediana, moda) e come costruire intervalli credibili che esprimano in modo trasparente i valori più plausibili.\n\nL’obiettivo non è ridurre l’inferenza bayesiana alla ricerca di un punto o di un intervallo, ma imparare a *comunicare l’incertezza* in modo comprensibile, senza perdere la ricchezza informativa del posterior. Come vedremo, anche nei contesti più complessi, la capacità di sintetizzare correttamente le distribuzioni a posteriori è ciò che distingue un’analisi meramente tecnica da una presentazione scientifica chiara e convincente.\n\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Distribuzione a posteriori = conoscenza aggiornata.\n- Stime puntuali: MAP, media, mediana.\n- Incertezza: varianza e deviazione standard.\n- Intervalli di credibilità: simmetrici e HPD.\n- Verifica di ipotesi: probabilità a posteriori.\n\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere il capitolo *Posterior Inference & Prediction* del testo di  @Johnson2022bayesrules.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)\n```\n:::\n\n:::\n\n\n## Riepilogo numerico\n\nLa distribuzione a posteriori contiene in sé tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico $p(\\theta \\mid y)$. Tuttavia, quando ci troviamo di fronte a vettori di parametri con più di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori: stima puntuale e intervallo di credibilità.\n\n\n## Stima puntuale  \n\nNel contesto dell’*inferenza bayesiana*, stimare il valore più credibile di un parametro $\\theta$ a partire dalla distribuzione a posteriori può avvenire attraverso tre statistiche principali: *moda, mediana e media*. La scelta tra queste dipende dalla forma della distribuzione a posteriori.  Queste statistiche forniscono una *stima puntuale* della tendenza centrale della distribuzione, ossia il valore a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sia sui dati osservati sia sulle credenze a priori.  \n\n### Moda (*Massimo a Posteriori*, MAP) {.unnumbered}\n\nLa moda della distribuzione a posteriori, nota come stima di *massimo a posteriori (MAP)*, corrisponde al valore del parametro $\\theta$ a cui è associata la massima densità di probabilità. Questo concetto rappresenta l’estensione bayesiana della classica *stima di massima verosimiglianza (MLE)*, definita come:\n\n$$\n\\hat{\\theta}_{\\text{ML}} = \\arg \\max_\\theta L(\\theta \\mid y),\n$$\ndove $L(\\theta \\mid y)$ è la funzione di verosimiglianza. Nell’approccio bayesiano, l’informazione a priori $p(\\theta)$ viene incorporata attraverso il teorema di Bayes, portando alla definizione della stima MAP:\n\n$$\n\\hat{\\theta}_{\\text{MAP}} = \\arg \\max_\\theta \\, L(\\theta \\mid y) \\, p(\\theta).\n$$\nIn altre parole, $\\hat{\\theta}_{\\text{MAP}}$ massimizza la densità a posteriori non normalizzata, combinando in modo esplicito l’evidenza empirica con la conoscenza pregressa.\n\n\n#### Limitazioni della stima MAP\n\nNonostante l’interpretazione intuitiva, la stima MAP presenta alcune limitazioni di cui è importante essere consapevoli. In primo luogo, la sua determinazione può risultare computazionalmente impegnativa, specialmente quando la distribuzione a posteriori viene campionata mediante metodi MCMC: individuare con precisione il massimo in uno spazio di parametri ad alta dimensionalità o con forme complesse richiede tecniche specifiche e può essere instabile.\n\nIn secondo luogo, la bontà della stima MAP dipende fortemente dalla forma della distribuzione a posteriori. In presenza di asimmetrie marcate o di multimodalità, il massimo globale potrebbe non essere rappresentativo della regione di alta probabilità, soprattutto se associato a un picco stretto ma isolato, mentre la maggior parte della massa probabilistica si trova altrove.\n\nInfine, il MAP è intrinsecamente meno robusto di altre statistiche centrali, come la media o la mediana a posteriori, in quanto basato esclusivamente sul valore di massimo densità, ignorando la forma complessiva della distribuzione. Ciò lo rende sensibile a variazioni nella parametrizzazione del modello e poco informativo riguardo all’incertezza complessiva sul parametro.\n\n\n### Media a posteriori {.unnumbered}\n\nLa *media a posteriori* rappresenta il valore atteso del parametro $\\theta$ rispetto alla sua distribuzione a posteriori. Formalmente, essa è definita come:\n\n$$\n\\mathbb{E}[\\theta \\mid y] = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta.\n$$\nQuesta quantità costituisce una stima di $\\theta$ che tiene conto dell'intera distribuzione a posteriori, integrando su tutti i possibili valori del parametro. Una proprietà notevole della media a posteriori è quella di essere lo stimatore che minimizza l’*errore quadratico medio (MSE)* nella previsione di $\\theta$, il che ne giustifica l’ampio utilizzo in contesti di ottimizzazione statistica.\n\nTuttavia, in presenza di distribuzioni a posteriori marcatamente *asimmetriche* o con *code pesanti*, la media potrebbe non rappresentare adeguatamente la regione di massima densità di probabilità. In tali casi, valori estremi possono influenzare eccessivamente la stima, allontanando la media dalla zona in cui è concentrata la maggior parte della massa probabilistica. Per questo motivo, in situazioni di asimmetria pronunciata, altre statistiche come la *mediana* o la *moda* a posteriori possono offrire una rappresentazione più appropriata della tendenza centrale.\n\n\n### Mediana a posteriori {.unnumbered}\n\nLa *mediana a posteriori* è definita come il valore del parametro $\\theta$ che divide la distribuzione a posteriori in due parti di uguale probabilità: il 50% della massa probabilistica si trova al di sotto di tale valore e il restante 50% al di sopra. Formalmente, essa soddisfa la condizione:\n\n$$\nP(\\theta \\leq \\hat{\\theta}_{\\text{med}} \\mid y) = 0.5.\n$$\n\nRispetto alla media e alla moda a posteriori, la mediana offre una misura di tendenza centrale particolarmente *robusta*, in quanto poco sensibile alla presenza di valori estremi o code distributive pesanti. Questa proprietà la rende preferibile in contesti in cui la distribuzione a posteriori presenta marcate *asimmetrie* o è *multimodale*, situazioni in cui la media può essere distortta da valori anomali e la moda può risultare instabile o non unica. Grazie alla sua stabilità, la mediana a posteriori fornisce una rappresentazione più affidabile della posizione centrale del parametro quando la forma della distribuzione è irregolare, garantendo una sintesi inferenziale solida anche in condizioni di elevata variabilità o non normalità.\n\n\n## Misurare l'incertezza: varianza a posteriori {.unnumbered}\n\nOltre a individuare il valore più plausibile del parametro $\\theta$, è fondamentale quantificare l'incertezza residua associata alla nostra stima. A questo scopo, la *varianza a posteriori* fornisce una misura della dispersione dei valori di $\\theta$ attorno alla sua media, condizionatamente ai dati osservati $y$. Formalmente, essa è definita come:\n\n$$\n\\mathbb{V}(\\theta \\mid y) = \\mathbb{E}\\left[(\\theta - \\mathbb{E}[\\theta \\mid y])^2 \\mid y \\right] = \\int (\\theta - \\mathbb{E}[\\theta \\mid y])^2 \\, p(\\theta \\mid y) \\, d\\theta.\n$$\n\nUn modo equivalente per calcolarla è attraverso l'identità:\n\n$$\n\\mathbb{V}(\\theta \\mid y) = \\mathbb{E}[\\theta^2 \\mid y] - \\left(\\mathbb{E}[\\theta \\mid y]\\right)^2.\n$$\n\nPer interpretare più facilmente l’incertezza nella stessa unità di misura del parametro $\\theta$, è utile considerare la *deviazione standard a posteriori*, data semplicemente dalla radice quadrata della varianza.\n\nIn conclusione, mentre la moda (MAP), la media e la mediana a posteriori forniscono diverse misure di tendenza centrale per la stima puntuale di $\\theta$, la varianza (e la deviazione standard) a posteriori ne quantificano l'affidabilità. La scelta tra le diverse statistiche dipende dalla forma della distribuzione a posteriori e dagli obiettivi dell’analisi. Nel loro insieme, questi indicatori consentono di comunicare in modo sintetico non solo la migliore stima del parametro, ma anche il grado di confidenza ad essa associato, elemento cruciale in qualsiasi processo inferenziale.\n\n\n## Intervallo di credibilità\n\nNell'inferenza bayesiana, l'intervallo di credibilità è uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro $\\theta$. Questo intervallo riflette l'incertezza associata alla stima del parametro: un intervallo più ampio suggerisce una maggiore incertezza. Lo scopo principale dell'intervallo di credibilità è fornire una misura quantitativa dell'incertezza riguardante $\\theta$.\n\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilità per un dato livello di confidenza $(1 - \\alpha) \\cdot 100\\%$. In effetti, è possibile costruire un numero infinito di tali intervalli. Per questo motivo, è necessario stabilire criteri aggiuntivi per selezionare l'intervallo di credibilità più appropriato. Tra le opzioni più comuni ci sono l'intervallo di credibilità simmetrico e l'intervallo di massima densità posteriore (HPD).\n\n\n### Intervallo di credibilità simmetrico {.unnumbered}\n\nQuesto tipo di intervallo è centrato rispetto al punto di stima puntuale. Se $\\hat{\\theta}$ rappresenta la stima del parametro, l'intervallo simmetrico avrà la forma $(\\hat{\\theta} - a, \\hat{\\theta} + a)$, dove $a$ è un valore positivo scelto in modo tale che la massa totale inclusa sia pari a $(1 - \\alpha)$. Più formalmente, un intervallo di credibilità simmetrico al livello $\\alpha$ può essere espresso come:\n\n$$ \nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}], \n$$\ndove $q_z$ rappresenta il quantile $z$ della distribuzione a posteriori. Ad esempio, un intervallo di credibilità simmetrico al 94% sarà:\n\n$$ \nI_{0.06} = [q_{0.03}, q_{0.97}], \n$$\ndove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\n\n\n### Intervallo di credibilità più stretto (intervallo di massima densità posteriore, HPD) {.unnumbered}\n\nL'intervallo di massima densità posteriore (HPD) è l'intervallo più stretto possibile che contiene il $(1 - \\alpha) \\cdot 100\\%$ della massa a posteriori. A differenza dell'intervallo simmetrico, l'HPD include tutti i valori di $\\theta$ che hanno la maggiore densità a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l'altezza della linea in modo che l'area sotto la curva corrisponda a $(1 - \\alpha)$. L'HPD risulta essere il più stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l'HPD coincide con l'intervallo di credibilità simmetrico.\n\n\n### Interpretazione\n\nIl calcolo degli *intervalli di credibilità*—in particolare dell’*intervallo di massima densità posteriore* (HPD)—richiede quasi sempre l’utilizzo di software statistici specializzati. Questo perché, nei modelli bayesiani con distribuzioni posteriori articolate o che richiedono simulazioni numeriche (ad esempio tramite Markov Chain Monte Carlo), ricavare a mano i confini dell’intervallo può risultare molto laborioso.\n\n#### Incertezza nel paradigma frequentista  \n\n- *Parametro fisso*: nel contesto frequentista, il parametro di interesse (ad esempio la media di popolazione $\\mu$) è un valore costante ma sconosciuto.  \n- *Ripetizione ipotetica*: immaginiamo di ripetere all’infinito il prelievo di campioni dalla popolazione. Per ciascun campione otteniamo una media $\\bar{x}$ e costruendo un intervallo di confidenza al $100(1-\\alpha)\\%$ avremo che, nel lungo periodo, il $100(1-\\alpha)\\%$ di questi intervalli conterrà il vero $\\mu$.  \n- *Interpretazione del singolo intervallo*: per un singolo intervallo calcolato, la probabilità che contenga effettivamente $\\mu$ è formalmente 0 o 1, perché $\\mu$ non è soggetto a variabilità stocastica—siamo semplicemente ignari del suo valore reale.\n\n#### Incertezza nel paradigma bayesiano  \n\n- *Parametro come variabile aleatoria*: qui $\\mu$ non è più un valore fisso, ma possiede una distribuzione di probabilità che riflette sia l’informazione a priori sia quella fornita dai dati osservati.  \n- *Campionamento dalla distribuzione a posteriori*: grazie a tecniche di simulazione (ad es. MCMC), otteniamo un insieme di possibili valori di $\\mu$ che segue la distribuzione posteriore.  \n- *Costruzione diretta dell’intervallo*: scegliendo i quantili al $2.5\\%$ e al $97.5\\%$ di questa distribuzione, otteniamo un intervallo di credibilità al 95%. In termini intuitivi, possiamo affermare che «c’è una probabilità del 95% che $\\mu$ cada all’interno di questo intervallo, dati i dati e le ipotesi a priori».\n\n#### Confronto e considerazioni  \n\n- *Frequentista*: l’intervallo di confidenza è un costrutto legato alla frequenza di lungo periodo di un procedimento ipotetico di campionamento.  \n- *Bayesiano*: l’intervallo di credibilità fornisce una misura puntuale dell’incertezza sul parametro, direttamente comprensibile come probabilità condizionata sui dati osservati.  \n- *Intuizione*: per molti, l’interpretazione bayesiana risulta più aderente al senso comune, perché traduce immediatamente il grado di fiducia che possiamo riporre nei valori ipotizzati per il parametro.\n\nIn sintesi, mentre la teoria frequentista quantifica l’affidabilità del metodo di stima nel lungo periodo, l’approccio bayesiano esprime senza ambiguità la probabilità attuale che il parametro si trovi in un certo intervallo, alla luce delle evidenze e delle conoscenze pregresse.\n\n\n## Verifica di ipotesi bayesiana\n\nL'inferenza bayesiana può essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come *verifica di ipotesi bayesiana*. In questo tipo di inferenza, l'obiettivo è valutare la plausibilità che un parametro $\\theta$ assuma valori all'interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto è probabile che $\\theta$ sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\n\nIn questo approccio, si calcola la *probabilità a posteriori* che $\\theta$ si trovi all'interno dell'intervallo di interesse. Questa probabilità viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un'ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilità che un parametro rientri in un intervallo specifico, dato l'evidenza osservata e le informazioni a priori.\n\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all'affermazione che $\\theta$ rientri in un certo intervallo, fornendo una probabilità che rappresenta direttamente la plausibilità di quell'ipotesi.\n\n::: {#exm-}\nPer illustrare l'approccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (*Beck Depression Inventory - Second Edition*) di 30 soggetti clinici, come riportato nello studio condotto da @zetsche_2019future. Il BDI-II è uno strumento per valutare la gravità dei sintomi depressivi.\n\nI punteggi del BDI-II per i 30 soggetti sono:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Dati del BDI-II\nbdi <- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#>  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35 33\n#> [26] 28 27 34 27 22\n```\n:::\n\n\nUn punteggio BDI-II $\\geq 30$ indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Conteggio di depressione grave\nsum(bdi >= 30)\n#> [1] 17\n```\n:::\n\n\nStima della distribuzione a posteriori.\n\nSupponiamo di voler stimare la probabilità $\\theta$ di depressione grave nei pazienti clinici utilizzando una distribuzione a priori $Beta(8, 2)$. I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave è un \"successo\". La verosimiglianza è quindi binomiale con parametri $n = 30$ e $y = 17$.\n\nCon una distribuzione a priori $Beta(8, 2)$, la distribuzione a posteriori di $\\theta$ sarà:\n\n$$\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n$$\nTracciamo la distribuzione a posteriori.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Parametri della distribuzione Beta\nalpha <- 25\nbeta <- 15\n\n# Calcolo della densità per valori di theta\ntheta <- seq(0, 1, length.out = 200)\nposterior_density <- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line() +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densità di probabilità\"\n  ) \n```\n\n::: {.cell-output-display}\n![](07_summary_posterior_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Stime puntuali.**\n\n1. **Media a posteriori.**  La media della distribuzione a posteriori è calcolata come:\n\n$$\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n$$\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo della media a posteriori\nposterior_mean <- alpha / (alpha + beta)\nposterior_mean\n#> [1] 0.625\n```\n:::\n\n\n2. **Moda a posteriori (MAP).**  La moda della distribuzione a posteriori è:\n\n$$\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n$$\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo della moda a posteriori\nposterior_mode <- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#> [1] 0.632\n```\n:::\n\n\n3. **Mediana a posteriori.**  La mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo della mediana a posteriori\nposterior_median <- qbeta(0.5, alpha, beta)\nposterior_median\n#> [1] 0.627\n```\n:::\n\n\n**Intervallo di credibilità.**\n\n1. **Intervallo di credibilità simmetrico.** L'intervallo di credibilità simmetrico al 94% è dato dai percentili 3% e 97%:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Intervallo di credibilità simmetrico al 94%\ncred_interval <- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#> [1] 0.478 0.761\n```\n:::\n\n\nPossiamo interpretare questo intervallo come segue: c'è una certezza soggettiva del 94% che $\\theta$ sia compreso tra 0.478 e 0.761.\n\n**Verifica di ipotesi bayesiana.** Infine, calcoliamo la probabilità che $\\theta > 0.5$:\n\n$$\nP(\\theta > 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n$$\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Probabilità P(theta > 0.5)\nprob_theta_greater_0_5 <- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#> [1] 0.946\n```\n:::\n\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di $\\theta$, ottenuto stime puntuali e costruito intervalli di credibilità. Abbiamo inoltre calcolato la probabilità che $\\theta$ superi una soglia specifica, mostrando la flessibilità e l'interpretabilità delle analisi bayesiane.\n:::\n\n\n## Sintesi della distribuzione a posteriori in contesti multivariati\n\nL'estensione dell'analisi bayesiana a modelli con più parametri introduce complessità legate alle interdipendenze tra i parametri stessi. Tali relazioni, se non adeguatamente considerate, possono condurre a sintesi incomplete o fuorvianti della distribuzione a posteriori, con possibili errori interpretativi.\n\n### La sfida delle correlazioni tra parametri\n\nUno degli aspetti critici riguarda la presenza di *correlazioni tra i parametri*. Le distribuzioni marginali a posteriori — spesso utilizzate nei riassunti statistici — possono risultare ingannevoli se esaminate isolatamente. Parametri fortemente correlati possono dar luogo a marginali apparentemente piatte o poco informative, benché la loro struttura congiunta restringa significativamente lo spazio delle combinazioni plausibili. Ciò implica che, nonostante l'incertezza marginale possa sembrare elevata, l'incertezza congiunta su specifiche relazioni parametriche può essere molto ridotta.\n\nUn'ulteriore complicazione sorge quando le relazioni tra parametri sono *non lineari*. In tali casi, il massimo della distribuzione congiunta può non coincidere con i massimi delle distribuzioni marginali. Ad esempio, in presenza di strutture a \"banana\" o altre forme complesse, gli usuali indicatori di tendenza centrale (come la moda o la media) calcolati sui singoli parametri possono non riflettere la regione di massima densità di probabilità nello spazio multivariato.\n\n\n### Approcci per una sintesi efficace\n\nPer una rappresentazione fedele dell’incertezza in contesti multivariati, è essenziale adottare una prospettiva che vada oltre l’analisi delle marginali:\n\n- **Visualizzazione delle relazioni congiunte**: Grafici di dispersione a coppie (*pair plots*) o contour plot bidimensionali consentono di esplorare visivamente le dipendenze tra parametri, rivelando strutture non catturate dalle marginali.\n  \n- **Utilizzo di distribuzioni predittive**: Il confronto tra distribuzioni predittive a priori e a posteriori fornisce una visione complessiva dell’incertezza ridotta dall’evidenza dei dati, tenendo conto di tutte le interazioni parametriche.\n\n- **Misure di dipendenza avanzate**: In casi di relazioni non lineari, misure come la correlazione di Spearman o l’informazione mutua possono integrare la correlazione lineare, offrendo una descrizione più completa delle dipendenze.\n\n- **Analisi di sensibilità**: Valutare come variano le inferenze al variare di gruppi di parametri aiuta a identificare le relazioni più influenti e a comprendere la stabilità delle conclusioni.\n\nIn conclusione, una sintesi appropriata della distribuzione a posteriori in presenza di più parametri richiede un esame congiunto delle relazioni tra di essi. La sola inspezione delle distribuzioni marginali rischia di occultare importanti fonti di informazione circa la struttura parametrica, con possibili conseguenze sulle inferenze tratte. Un approccio integrato — che unisca visualizzazione, misure di dipendenza e analisi di sensibilità — è fondamentale per una comprensione robusta dei risultati bayesiani in contesti multivariati.\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo visto che il cuore dell’approccio bayesiano non è soltanto ottenere una distribuzione a posteriori, ma anche imparare a descriverla in modo utile. Abbiamo distinto tra diversi modi di riassumere un posterior (media, mediana, moda) e tra diverse forme di intervallo credibile, chiarendo come ciascuna offra una prospettiva diversa sull’incertezza.\n\nQueste sintesi non sostituiscono la distribuzione completa, ma la rendono comunicabile. L’intervallo credibile, in particolare, ci permette di dire con chiarezza quali valori del parametro hanno una certa probabilità a posteriori di essere veri, dato il modello e i dati osservati. Questo rappresenta una differenza cruciale rispetto all’approccio frequentista, in cui l’interpretazione degli intervalli di confidenza rimane indiretta e spesso fonte di equivoci.\n\nDal punto di vista della ricerca psicologica, la capacità di sintetizzare il posterior è indispensabile. Molti risultati sperimentali si basano sulla stima di proporzioni, medie o differenze tra gruppi, e il modo in cui presentiamo l’incertezza può fare la differenza tra una conclusione chiara e una affermazione ambigua. Una sintesi ben costruita non solo comunica meglio, ma rafforza la solidità della conoscenza accumulata, perché rende trasparenti i margini di dubbio.\n\nQuesto capitolo chiude così un primo ciclo del nostro percorso: abbiamo imparato a costruire distribuzioni a posteriori e a sintetizzarle. Nei prossimi capitoli vedremo come andare oltre i parametri e usare il posterior per *fare previsioni sui dati futuri* e per *confrontare modelli alternativi*. È qui che il pensiero bayesiano mostrerà tutta la sua forza: non solo descrivere ciò che sappiamo, ma anche guidare ciò che possiamo aspettarci.\n\n\n::: {.callout-important title=\"Problemi\" collapse=\"true\"}\n**1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?**\n\n   - Spiega le differenze tra **moda (MAP)**, **media a posteriori** e **mediana**.\n   - In quali contesti è preferibile utilizzare una di queste statistiche rispetto alle altre?\n\n**2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?**\n\n   - Spiega le differenze concettuali tra i due approcci.\n   - Quale dei due è più intuitivo in termini di incertezza sui parametri?\n\n**3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?**\n\n   - Spiega il concetto di HPD e perché è più informativo in alcuni casi.\n   - In quali situazioni l’HPD è preferibile rispetto all’intervallo di credibilità simmetrico?\n\n**4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?**\n\n   - Perché il **MAP** può essere meno affidabile rispetto ad altre statistiche?\n   - Quali problemi si possono incontrare nei modelli bayesiani complessi?\n\n**5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?**\n\n   - Quali sono le principali difficoltà nell’interpretare la distribuzione congiunta di più parametri?\n   - Come si possono visualizzare e sintetizzare distribuzioni posteriori multivariate?\n\n**Domande applicative in R**\n\nPer queste domande, usa il dataset basato sulla **Satisfaction with Life Scale (SWLS)**, supponendo che i dati seguano una distribuzione normale.\n\n**1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.**\n   - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n\n**2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.**\n\n   - Usa la distribuzione normale a posteriori per calcolare l’intervallo.\n\n\n**3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.**\n\n   - Genera un campione dalla distribuzione a posteriori e rappresentalo con **ggplot2**.\n\n**4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).**\n\n   - Usa la funzione **hdi()** del pacchetto **bayestestR** per calcolare l’HPD.\n\n\n**5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23.**\n\n   - Usa la distribuzione a posteriori per calcolare questa probabilità.\n\n:::\n\n::: {.callout-tip title=\"Soluzioni\" collapse=\"true\"}\n**1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?**\n\n\nLe tre principali statistiche usate per ottenere una **stima puntuale** del parametro $\\theta$ nella distribuzione a posteriori sono:\n\n1. **Moda (Massimo a Posteriori, MAP)**  \n   - È il valore di $\\theta$ che massimizza la distribuzione a posteriori $p(\\theta \\mid y)$.  \n   - Se la distribuzione è unimodale e simmetrica, il MAP coincide con la media a posteriori.  \n   - Il MAP è spesso simile alla stima di massima verosimiglianza (MLE) quando il prior è uniforme.  \n\n2. **Media a Posteriori**  \n   - È il valore atteso della distribuzione a posteriori:  \n     $$\n     E(\\theta \\mid y) = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta\n     $$\n   - È la stima più utile quando si vuole minimizzare l'errore quadratico medio (MSE).  \n   - Risente dell'eventuale asimmetria della distribuzione, spostandosi verso le code.\n\n3. **Mediana a Posteriori**  \n   - È il valore che divide la distribuzione a posteriori in due parti uguali:  \n     $$\n     P(\\theta \\leq \\theta_{\\text{mediana}} \\mid y) = 0.5\n     $$\n   - È più robusta agli outlier rispetto alla media ed è utile quando la distribuzione è fortemente asimmetrica.\n\n💡 **Quando usarle?**\n- Se la distribuzione è **simmetrica**, tutte e tre le statistiche coincidono.\n- Se la distribuzione è **asimmetrica**, la **mediana** è più robusta, la **media** può essere influenzata dalle code e il **MAP** è utile se si vuole un valore più probabile.\n\n**2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?**\n\n\n| Caratteristica                 | Intervallo di Credibilità (Bayesiano) | Intervallo di Confidenza (Frequentista) |\n|--------------------------------|--------------------------------------|----------------------------------------|\n| **Significato** | Esprime la probabilità che il parametro sia nell'intervallo, dati i dati osservati. | È una proprietà di un metodo di campionamento: se si ripetesse l’esperimento infinite volte, il $(1 - \\alpha)100\\%$ degli intervalli conterrebbe il vero valore del parametro. |\n| **Approccio** | Assume che il parametro sia una variabile casuale con una distribuzione di probabilità. | Assume che il parametro sia fisso e sconosciuto, mentre i dati sono casuali. |\n| **Interpretazione** | \"C'è il 95% di probabilità che il parametro sia tra questi valori.\" | \"Se ripetessimo l'esperimento molte volte, il 95% degli intervalli conterrebbe il vero parametro.\" |\n\n💡 **Differenza fondamentale:**  \n\n- L'intervallo di credibilità è **probabilistico** e più intuitivo: si può direttamente dire che il parametro ha il 95% di probabilità di trovarsi nell'intervallo.  \n- L'intervallo di confidenza è **basato sulla ripetizione ipotetica** dell'esperimento e non può essere interpretato in termini probabilistici sul singolo intervallo.\n\n**3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?**\n \nL’**intervallo di massima densità posteriore (HPD)** è l’intervallo più stretto che contiene una percentuale fissata (es. 94%) della distribuzione a posteriori. Si distingue dall'intervallo di credibilità simmetrico perché:\n\n| Caratteristica | Intervallo HPD | Intervallo di Credibilità Simmetrico |\n|--------------|-------------|--------------------------------|\n| **Definizione** | Contiene il  $(1 - \\alpha)100\\%$ della probabilità a posteriori, minimizzando la lunghezza dell’intervallo. | È centrato attorno alla mediana e copre una frazione fissa della distribuzione. |\n| **Forma** | Può essere asimmetrico e discontinuo se la distribuzione è multimodale. | È sempre simmetrico. |\n| **Vantaggio** | È più informativo se la distribuzione è asimmetrica o multimodale. | È più facile da calcolare, specialmente per distribuzioni unimodali. |\n\n💡 **Quando usarli?**  \n\n- Se la distribuzione è **simmetrica**, entrambi gli intervalli danno risultati simili.  \n- Se la distribuzione è **asimmetrica o multimodale**, l’HPD è più informativo.\n\n**4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?**\n \nSebbene il **MAP** sia un concetto intuitivo (il valore più probabile della distribuzione a posteriori), presenta alcune limitazioni:\n\n1. **Difficoltà computazionale con MCMC**  \n   - Con metodi di campionamento come **Markov Chain Monte Carlo (MCMC)**, trovare il massimo della distribuzione a posteriori è difficile perché la funzione viene stimata in modo discreto.\n   - Spesso si preferisce stimare **media** o **mediana**, più facili da calcolare con MCMC.\n\n2. **Sensibilità ai dati e al prior**  \n   - Il MAP dipende fortemente dal **prior** scelto.\n   - Se il prior è informativo, il MAP può spostarsi troppo rispetto ai dati.\n\n3. **Problemi con distribuzioni multimodali**  \n   - Se la distribuzione a posteriori ha più di un massimo (moda), il MAP potrebbe non essere una buona rappresentazione della distribuzione.\n\n💡 **Quando evitarlo?**  \n- Se la distribuzione a posteriori è **asimmetrica o multimodale**.\n- Se si usa un **metodo MCMC**, dove la media o la mediana sono più semplici da stimare.\n\n**5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?**\n \nQuando l'inferenza bayesiana coinvolge più parametri (es. $\\mu$ e $\\sigma$), l'analisi diventa più complessa per diversi motivi:\n\n1. **Interazioni tra parametri**  \n   - I parametri spesso non sono indipendenti: la distribuzione a posteriori congiunta può mostrare **correlazioni** che non emergono dalle distribuzioni marginali.\n\n2. **Difficoltà di visualizzazione**  \n   - Per un parametro si usa un istogramma o una funzione di densità.\n   - Per due parametri si usa un **contour plot** o un **grafico 3D**.\n   - Con più di due parametri, si ricorre a **pair plots** o **matrici di correlazione**.\n\n3. **Stimare margine e congiunta**  \n   - La distribuzione marginale di un parametro si ottiene integrando la distribuzione congiunta rispetto agli altri parametri:\n     $$\n     p(\\theta_1) = \\int p(\\theta_1, \\theta_2) d\\theta_2\n     $$\n   - Se i parametri sono fortemente correlati, le marginali possono **nascondere informazioni importanti**.\n\n4. **Rischio di correlazioni non lineari**  \n   - Le correlazioni non lineari tra i parametri possono portare a distribuzioni con forme complesse (es. a banana), rendendo difficile la sintesi con MAP o media.\n\n💡 **Strategie per affrontare il problema:**  \n- **Visualizzare le correlazioni** tra i parametri con scatter plot o heatmap.  \n- **Usare tecniche di riduzione della dimensionalità** come PCA (Analisi delle Componenti Principali).  \n- **Utilizzare il MCMC** per campionare direttamente dalla distribuzione congiunta.\n\n**Esercizio in R con i dati SWLS**\n\nNell'esercizio, usa i dati della SWLS che sono stati raccolti. Qui useremo i dati seguenti:\n\n```r\nswls_data <- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n```\n\n**1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.**\n\n   - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n\n```r\nlibrary(tibble)\n\n# Dati\nn <- nrow(swls_data)\nmean_x <- mean(swls_data$soddisfazione)\nsigma <- 1  # Deviazione standard nota\n\n# Prior diffuso\nmu_prior <- 4.5    \nsigma_prior <- 10  \n\n# Media a posteriori\nmu_post <- (sigma_prior^2 * mean_x + sigma^2 * n * mu_prior) / (sigma_prior^2 + sigma^2 * n)\n\n# Deviazione standard a posteriori\nsigma_post <- sqrt((sigma_prior^2 * sigma^2) / (sigma_prior^2 + sigma^2 * n))\n\n# Moda (MAP)\nposterior_mode <- mu_post  # Per una distribuzione normale, MAP coincide con la media\n\n# Mediana (simile alla media in una distribuzione normale)\nposterior_median <- mu_post\n\ntibble(\"Media a Posteriori\" = mu_post,\n       \"Moda (MAP)\" = posterior_mode,\n       \"Mediana\" = posterior_median)\n```\n\n**2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.**\n\n   - Usa la distribuzione normale a posteriori per calcolare l’intervallo.\n\n```r\ncred_interval <- qnorm(c(0.03, 0.97), mean = mu_post, sd = sigma_post)\ncred_interval\n```\n\n**3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.**\n\n   - Genera un campione dalla distribuzione a posteriori e rappresentalo con **ggplot2**.\n\n```r\nlibrary(ggplot2)\n\n# Campionamento dalla distribuzione a posteriori\nset.seed(123)\nsamples <- rnorm(1000, mean = mu_post, sd = sigma_post)\n\n# Creazione del dataframe\nsamples_df <- tibble(media_campionata = samples)\n\n# Grafico della distribuzione a posteriori\nggplot(samples_df, aes(x = media_campionata)) +\n  geom_density(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Distribuzione a Posteriori della Media SWLS\",\n       x = \"Media\", y = \"Densità\")\n```\n\n**4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).**\n\n   - Usa la funzione **hdi()** del pacchetto **bayestestR** per calcolare l’HPD.\n\n```r\nlibrary(bayestestR)\n\n# Calcolo intervallo HPD al 94%\nhpd_interval <- hdi(samples, ci = 0.94)\nhpd_interval\n```\n\n**5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23 -- per fare un esempio, qui caloleremo per i dati simulati la probabilità a posteriori per la media SWLS maggiore di 4.7.**\n\n   - Usa la distribuzione a posteriori per calcolare questa probabilità.\n\n```r\nprob_greater_4_7 <- 1 - pnorm(4.7, mean = mu_post, sd = sigma_post)\nprob_greater_4_7\n```\n:::\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#>  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#>  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [25] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#>  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#>  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#> [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#> [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#> [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#> [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#> [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#> [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#> [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#> [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#> [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#> [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#> [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#> [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#> [46] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#> [49] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#> [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#> [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#> [58] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#> [61] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#> [64] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#> [67] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#> [70] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#> [73] lme4_1.1-37           mvtnorm_1.3-3         grid_4.5.1           \n#> [76] rbibutils_2.3         QuickJSR_1.8.0        colorspace_2.1-1     \n#> [79] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#> [82] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#> [85] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#> [88] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#> [91] htmltools_0.5.8.1     lifecycle_1.0.4       mitml_0.4-5          \n#> [94] MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n\n",
    "supporting": [
      "07_summary_posterior_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}