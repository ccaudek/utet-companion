{
  "hash": "7c40d48c85f2e253632950760228380e",
  "result": {
    "engine": "knitr",
    "markdown": "# Sintesi a posteriori {#sec-bayesian-inference-summary-posterior}\n\n::: {.epigraph}\n> ‚ÄúThe summary of a posterior distribution is an essential step for its interpretation. Point estimators and credible intervals are the most common Bayesian answers, but they should not make us forget the richness of the entire posterior.‚Äù\n>\n> -- **Christian P. Robert**, The Bayesian Choice (2007)\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nNei capitoli precedenti abbiamo imparato a costruire distribuzioni a posteriori combinando la nostra conoscenza preliminare (*prior*) con i dati osservati attraverso la verosimiglianza. Abbiamo visto come questo processo si realizzi in casi semplici, come la stima di una proporzione di successi con il modello Beta‚ÄìBinomiale, e come possa essere generalizzato grazie al concetto di famiglie coniugate. Ora ci poniamo una domanda fondamentale: una volta che abbiamo ottenuto una distribuzione a posteriori, *come possiamo riassumerla e comunicarla in modo chiaro ed efficace?*\n\nIl *posterior* non √® un singolo numero, ma un‚Äôintera distribuzione che rappresenta la nostra incertezza sul parametro. Nella pratica della ricerca psicologica, tuttavia, dobbiamo spesso sintetizzare queste informazioni per presentarle nei risultati di un articolo o per confrontarle con altre stime. Questo capitolo √® dedicato proprio a questa esigenza: mostreremo come ricavare quantit√† riassuntive (media, mediana, moda) e come costruire intervalli credibili che esprimano in modo trasparente i valori pi√π plausibili.\n\nL‚Äôobiettivo non √® ridurre l‚Äôinferenza bayesiana alla ricerca di un punto o di un intervallo, ma imparare a *comunicare l‚Äôincertezza* in modo comprensibile, senza perdere la ricchezza informativa del posterior. Come vedremo, anche nei contesti pi√π complessi, la capacit√† di sintetizzare correttamente le distribuzioni a posteriori √® ci√≤ che distingue un‚Äôanalisi meramente tecnica da una presentazione scientifica chiara e convincente.\n\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Distribuzione a posteriori = conoscenza aggiornata.\n- Stime puntuali: MAP, media, mediana.\n- Incertezza: varianza e deviazione standard.\n- Intervalli di credibilit√†: simmetrici e HPD.\n- Verifica di ipotesi: probabilit√† a posteriori.\n\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere il capitolo *Posterior Inference & Prediction* del testo di  @Johnson2022bayesrules.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)\n```\n:::\n\n:::\n\n\n## Riepilogo numerico\n\nLa distribuzione a posteriori contiene in s√© tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico $p(\\theta \\mid y)$. Tuttavia, quando ci troviamo di fronte a vettori di parametri con pi√π di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori: stima puntuale e intervallo di credibilit√†.\n\n\n## Stima puntuale  \n\nNel contesto dell‚Äô*inferenza bayesiana*, stimare il valore pi√π credibile di un parametro $\\theta$ a partire dalla distribuzione a posteriori pu√≤ avvenire attraverso tre statistiche principali: *moda, mediana e media*. La scelta tra queste dipende dalla forma della distribuzione a posteriori.  Queste statistiche forniscono una *stima puntuale* della tendenza centrale della distribuzione, ossia il valore a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sia sui dati osservati sia sulle credenze a priori.  \n\n### Moda (*Massimo a Posteriori*, MAP) {.unnumbered}\n\nLa moda della distribuzione a posteriori, nota come stima di *massimo a posteriori (MAP)*, corrisponde al valore del parametro $\\theta$ a cui √® associata la massima densit√† di probabilit√†. Questo concetto rappresenta l‚Äôestensione bayesiana della classica *stima di massima verosimiglianza (MLE)*, definita come:\n\n$$\n\\hat{\\theta}_{\\text{ML}} = \\arg \\max_\\theta L(\\theta \\mid y),\n$$\ndove $L(\\theta \\mid y)$ √® la funzione di verosimiglianza. Nell‚Äôapproccio bayesiano, l‚Äôinformazione a priori $p(\\theta)$ viene incorporata attraverso il teorema di Bayes, portando alla definizione della stima MAP:\n\n$$\n\\hat{\\theta}_{\\text{MAP}} = \\arg \\max_\\theta \\, L(\\theta \\mid y) \\, p(\\theta).\n$$\nIn altre parole, $\\hat{\\theta}_{\\text{MAP}}$ massimizza la densit√† a posteriori non normalizzata, combinando in modo esplicito l‚Äôevidenza empirica con la conoscenza pregressa.\n\n\n#### Limitazioni della stima MAP\n\nNonostante l‚Äôinterpretazione intuitiva, la stima MAP presenta alcune limitazioni di cui √® importante essere consapevoli. In primo luogo, la sua determinazione pu√≤ risultare computazionalmente impegnativa, specialmente quando la distribuzione a posteriori viene campionata mediante metodi MCMC: individuare con precisione il massimo in uno spazio di parametri ad alta dimensionalit√† o con forme complesse richiede tecniche specifiche e pu√≤ essere instabile.\n\nIn secondo luogo, la bont√† della stima MAP dipende fortemente dalla forma della distribuzione a posteriori. In presenza di asimmetrie marcate o di multimodalit√†, il massimo globale potrebbe non essere rappresentativo della regione di alta probabilit√†, soprattutto se associato a un picco stretto ma isolato, mentre la maggior parte della massa probabilistica si trova altrove.\n\nInfine, il MAP √® intrinsecamente meno robusto di altre statistiche centrali, come la media o la mediana a posteriori, in quanto basato esclusivamente sul valore di massimo densit√†, ignorando la forma complessiva della distribuzione. Ci√≤ lo rende sensibile a variazioni nella parametrizzazione del modello e poco informativo riguardo all‚Äôincertezza complessiva sul parametro.\n\n\n### Media a posteriori {.unnumbered}\n\nLa *media a posteriori* rappresenta il valore atteso del parametro $\\theta$ rispetto alla sua distribuzione a posteriori. Formalmente, essa √® definita come:\n\n$$\n\\mathbb{E}[\\theta \\mid y] = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta.\n$$\nQuesta quantit√† costituisce una stima di $\\theta$ che tiene conto dell'intera distribuzione a posteriori, integrando su tutti i possibili valori del parametro. Una propriet√† notevole della media a posteriori √® quella di essere lo stimatore che minimizza l‚Äô*errore quadratico medio (MSE)* nella previsione di $\\theta$, il che ne giustifica l‚Äôampio utilizzo in contesti di ottimizzazione statistica.\n\nTuttavia, in presenza di distribuzioni a posteriori marcatamente *asimmetriche* o con *code pesanti*, la media potrebbe non rappresentare adeguatamente la regione di massima densit√† di probabilit√†. In tali casi, valori estremi possono influenzare eccessivamente la stima, allontanando la media dalla zona in cui √® concentrata la maggior parte della massa probabilistica. Per questo motivo, in situazioni di asimmetria pronunciata, altre statistiche come la *mediana* o la *moda* a posteriori possono offrire una rappresentazione pi√π appropriata della tendenza centrale.\n\n\n### Mediana a posteriori {.unnumbered}\n\nLa *mediana a posteriori* √® definita come il valore del parametro $\\theta$ che divide la distribuzione a posteriori in due parti di uguale probabilit√†: il 50% della massa probabilistica si trova al di sotto di tale valore e il restante 50% al di sopra. Formalmente, essa soddisfa la condizione:\n\n$$\nP(\\theta \\leq \\hat{\\theta}_{\\text{med}} \\mid y) = 0.5.\n$$\n\nRispetto alla media e alla moda a posteriori, la mediana offre una misura di tendenza centrale particolarmente *robusta*, in quanto poco sensibile alla presenza di valori estremi o code distributive pesanti. Questa propriet√† la rende preferibile in contesti in cui la distribuzione a posteriori presenta marcate *asimmetrie* o √® *multimodale*, situazioni in cui la media pu√≤ essere distortta da valori anomali e la moda pu√≤ risultare instabile o non unica. Grazie alla sua stabilit√†, la mediana a posteriori fornisce una rappresentazione pi√π affidabile della posizione centrale del parametro quando la forma della distribuzione √® irregolare, garantendo una sintesi inferenziale solida anche in condizioni di elevata variabilit√† o non normalit√†.\n\n\n## Misurare l'incertezza: varianza a posteriori {.unnumbered}\n\nOltre a individuare il valore pi√π plausibile del parametro $\\theta$, √® fondamentale quantificare l'incertezza residua associata alla nostra stima. A questo scopo, la *varianza a posteriori* fornisce una misura della dispersione dei valori di $\\theta$ attorno alla sua media, condizionatamente ai dati osservati $y$. Formalmente, essa √® definita come:\n\n$$\n\\mathbb{V}(\\theta \\mid y) = \\mathbb{E}\\left[(\\theta - \\mathbb{E}[\\theta \\mid y])^2 \\mid y \\right] = \\int (\\theta - \\mathbb{E}[\\theta \\mid y])^2 \\, p(\\theta \\mid y) \\, d\\theta.\n$$\n\nUn modo equivalente per calcolarla √® attraverso l'identit√†:\n\n$$\n\\mathbb{V}(\\theta \\mid y) = \\mathbb{E}[\\theta^2 \\mid y] - \\left(\\mathbb{E}[\\theta \\mid y]\\right)^2.\n$$\n\nPer interpretare pi√π facilmente l‚Äôincertezza nella stessa unit√† di misura del parametro $\\theta$, √® utile considerare la *deviazione standard a posteriori*, data semplicemente dalla radice quadrata della varianza.\n\nIn conclusione, mentre la moda (MAP), la media e la mediana a posteriori forniscono diverse misure di tendenza centrale per la stima puntuale di $\\theta$, la varianza (e la deviazione standard) a posteriori ne quantificano l'affidabilit√†. La scelta tra le diverse statistiche dipende dalla forma della distribuzione a posteriori e dagli obiettivi dell‚Äôanalisi. Nel loro insieme, questi indicatori consentono di comunicare in modo sintetico non solo la migliore stima del parametro, ma anche il grado di confidenza ad essa associato, elemento cruciale in qualsiasi processo inferenziale.\n\n\n## Intervallo di credibilit√†\n\nNell'inferenza bayesiana, l'intervallo di credibilit√† √® uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro $\\theta$. Questo intervallo riflette l'incertezza associata alla stima del parametro: un intervallo pi√π ampio suggerisce una maggiore incertezza. Lo scopo principale dell'intervallo di credibilit√† √® fornire una misura quantitativa dell'incertezza riguardante $\\theta$.\n\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilit√† per un dato livello di confidenza $(1 - \\alpha) \\cdot 100\\%$. In effetti, √® possibile costruire un numero infinito di tali intervalli. Per questo motivo, √® necessario stabilire criteri aggiuntivi per selezionare l'intervallo di credibilit√† pi√π appropriato. Tra le opzioni pi√π comuni ci sono l'intervallo di credibilit√† simmetrico e l'intervallo di massima densit√† posteriore (HPD).\n\n\n### Intervallo di credibilit√† simmetrico {.unnumbered}\n\nQuesto tipo di intervallo √® centrato rispetto al punto di stima puntuale. Se $\\hat{\\theta}$ rappresenta la stima del parametro, l'intervallo simmetrico avr√† la forma $(\\hat{\\theta} - a, \\hat{\\theta} + a)$, dove $a$ √® un valore positivo scelto in modo tale che la massa totale inclusa sia pari a $(1 - \\alpha)$. Pi√π formalmente, un intervallo di credibilit√† simmetrico al livello $\\alpha$ pu√≤ essere espresso come:\n\n$$ \nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}], \n$$\ndove $q_z$ rappresenta il quantile $z$ della distribuzione a posteriori. Ad esempio, un intervallo di credibilit√† simmetrico al 94% sar√†:\n\n$$ \nI_{0.06} = [q_{0.03}, q_{0.97}], \n$$\ndove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\n\n\n### Intervallo di credibilit√† pi√π stretto (intervallo di massima densit√† posteriore, HPD) {.unnumbered}\n\nL'intervallo di massima densit√† posteriore (HPD) √® l'intervallo pi√π stretto possibile che contiene il $(1 - \\alpha) \\cdot 100\\%$ della massa a posteriori. A differenza dell'intervallo simmetrico, l'HPD include tutti i valori di $\\theta$ che hanno la maggiore densit√† a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l'altezza della linea in modo che l'area sotto la curva corrisponda a $(1 - \\alpha)$. L'HPD risulta essere il pi√π stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l'HPD coincide con l'intervallo di credibilit√† simmetrico.\n\n\n### Interpretazione\n\nIl calcolo degli *intervalli di credibilit√†*‚Äîin particolare dell‚Äô*intervallo di massima densit√† posteriore* (HPD)‚Äîrichiede quasi sempre l‚Äôutilizzo di software statistici specializzati. Questo perch√©, nei modelli bayesiani con distribuzioni posteriori articolate o che richiedono simulazioni numeriche (ad esempio tramite Markov Chain Monte Carlo), ricavare a mano i confini dell‚Äôintervallo pu√≤ risultare molto laborioso.\n\n#### Incertezza nel paradigma frequentista  \n\n- *Parametro fisso*: nel contesto frequentista, il parametro di interesse (ad esempio la media di popolazione $\\mu$) √® un valore costante ma sconosciuto.  \n- *Ripetizione ipotetica*: immaginiamo di ripetere all‚Äôinfinito il prelievo di campioni dalla popolazione. Per ciascun campione otteniamo una media $\\bar{x}$ e costruendo un intervallo di confidenza al $100(1-\\alpha)\\%$ avremo che, nel lungo periodo, il $100(1-\\alpha)\\%$ di questi intervalli conterr√† il vero $\\mu$.  \n- *Interpretazione del singolo intervallo*: per un singolo intervallo calcolato, la probabilit√† che contenga effettivamente $\\mu$ √® formalmente 0 o 1, perch√© $\\mu$ non √® soggetto a variabilit√† stocastica‚Äîsiamo semplicemente ignari del suo valore reale.\n\n#### Incertezza nel paradigma bayesiano  \n\n- *Parametro come variabile aleatoria*: qui $\\mu$ non √® pi√π un valore fisso, ma possiede una distribuzione di probabilit√† che riflette sia l‚Äôinformazione a priori sia quella fornita dai dati osservati.  \n- *Campionamento dalla distribuzione a posteriori*: grazie a tecniche di simulazione (ad es. MCMC), otteniamo un insieme di possibili valori di $\\mu$ che segue la distribuzione posteriore.  \n- *Costruzione diretta dell‚Äôintervallo*: scegliendo i quantili al $2.5\\%$ e al $97.5\\%$ di questa distribuzione, otteniamo un intervallo di credibilit√† al 95%. In termini intuitivi, possiamo affermare che ¬´c‚Äô√® una probabilit√† del 95% che $\\mu$ cada all‚Äôinterno di questo intervallo, dati i dati e le ipotesi a priori¬ª.\n\n#### Confronto e considerazioni  \n\n- *Frequentista*: l‚Äôintervallo di confidenza √® un costrutto legato alla frequenza di lungo periodo di un procedimento ipotetico di campionamento.  \n- *Bayesiano*: l‚Äôintervallo di credibilit√† fornisce una misura puntuale dell‚Äôincertezza sul parametro, direttamente comprensibile come probabilit√† condizionata sui dati osservati.  \n- *Intuizione*: per molti, l‚Äôinterpretazione bayesiana risulta pi√π aderente al senso comune, perch√© traduce immediatamente il grado di fiducia che possiamo riporre nei valori ipotizzati per il parametro.\n\nIn sintesi, mentre la teoria frequentista quantifica l‚Äôaffidabilit√† del metodo di stima nel lungo periodo, l‚Äôapproccio bayesiano esprime senza ambiguit√† la probabilit√† attuale che il parametro si trovi in un certo intervallo, alla luce delle evidenze e delle conoscenze pregresse.\n\n\n## Verifica di ipotesi bayesiana\n\nL'inferenza bayesiana pu√≤ essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come *verifica di ipotesi bayesiana*. In questo tipo di inferenza, l'obiettivo √® valutare la plausibilit√† che un parametro $\\theta$ assuma valori all'interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto √® probabile che $\\theta$ sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\n\nIn questo approccio, si calcola la *probabilit√† a posteriori* che $\\theta$ si trovi all'interno dell'intervallo di interesse. Questa probabilit√† viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un'ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilit√† che un parametro rientri in un intervallo specifico, dato l'evidenza osservata e le informazioni a priori.\n\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all'affermazione che $\\theta$ rientri in un certo intervallo, fornendo una probabilit√† che rappresenta direttamente la plausibilit√† di quell'ipotesi.\n\n::: {#exm-}\nPer illustrare l'approccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (*Beck Depression Inventory - Second Edition*) di 30 soggetti clinici, come riportato nello studio condotto da @zetsche_2019future. Il BDI-II √® uno strumento per valutare la gravit√† dei sintomi depressivi.\n\nI punteggi del BDI-II per i 30 soggetti sono:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Dati del BDI-II\nbdi <- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#>  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35 33\n#> [26] 28 27 34 27 22\n```\n:::\n\n\nUn punteggio BDI-II $\\geq 30$ indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Conteggio di depressione grave\nsum(bdi >= 30)\n#> [1] 17\n```\n:::\n\n\nStima della distribuzione a posteriori.\n\nSupponiamo di voler stimare la probabilit√† $\\theta$ di depressione grave nei pazienti clinici utilizzando una distribuzione a priori $Beta(8, 2)$. I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave √® un \"successo\". La verosimiglianza √® quindi binomiale con parametri $n = 30$ e $y = 17$.\n\nCon una distribuzione a priori $Beta(8, 2)$, la distribuzione a posteriori di $\\theta$ sar√†:\n\n$$\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n$$\nTracciamo la distribuzione a posteriori.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Parametri della distribuzione Beta\nalpha <- 25\nbeta <- 15\n\n# Calcolo della densit√† per valori di theta\ntheta <- seq(0, 1, length.out = 200)\nposterior_density <- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line() +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densit√† di probabilit√†\"\n  ) \n```\n\n::: {.cell-output-display}\n![](07_summary_posterior_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Stime puntuali.**\n\n1. **Media a posteriori.**  La media della distribuzione a posteriori √® calcolata come:\n\n$$\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n$$\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo della media a posteriori\nposterior_mean <- alpha / (alpha + beta)\nposterior_mean\n#> [1] 0.625\n```\n:::\n\n\n2. **Moda a posteriori (MAP).**  La moda della distribuzione a posteriori √®:\n\n$$\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n$$\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo della moda a posteriori\nposterior_mode <- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#> [1] 0.632\n```\n:::\n\n\n3. **Mediana a posteriori.**  La mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo della mediana a posteriori\nposterior_median <- qbeta(0.5, alpha, beta)\nposterior_median\n#> [1] 0.627\n```\n:::\n\n\n**Intervallo di credibilit√†.**\n\n1. **Intervallo di credibilit√† simmetrico.** L'intervallo di credibilit√† simmetrico al 94% √® dato dai percentili 3% e 97%:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Intervallo di credibilit√† simmetrico al 94%\ncred_interval <- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#> [1] 0.478 0.761\n```\n:::\n\n\nPossiamo interpretare questo intervallo come segue: c'√® una certezza soggettiva del 94% che $\\theta$ sia compreso tra 0.478 e 0.761.\n\n**Verifica di ipotesi bayesiana.** Infine, calcoliamo la probabilit√† che $\\theta > 0.5$:\n\n$$\nP(\\theta > 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n$$\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Probabilit√† P(theta > 0.5)\nprob_theta_greater_0_5 <- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#> [1] 0.946\n```\n:::\n\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di $\\theta$, ottenuto stime puntuali e costruito intervalli di credibilit√†. Abbiamo inoltre calcolato la probabilit√† che $\\theta$ superi una soglia specifica, mostrando la flessibilit√† e l'interpretabilit√† delle analisi bayesiane.\n:::\n\n\n## Sintesi della distribuzione a posteriori in contesti multivariati\n\nL'estensione dell'analisi bayesiana a modelli con pi√π parametri introduce complessit√† legate alle interdipendenze tra i parametri stessi. Tali relazioni, se non adeguatamente considerate, possono condurre a sintesi incomplete o fuorvianti della distribuzione a posteriori, con possibili errori interpretativi.\n\n### La sfida delle correlazioni tra parametri\n\nUno degli aspetti critici riguarda la presenza di *correlazioni tra i parametri*. Le distribuzioni marginali a posteriori ‚Äî spesso utilizzate nei riassunti statistici ‚Äî possono risultare ingannevoli se esaminate isolatamente. Parametri fortemente correlati possono dar luogo a marginali apparentemente piatte o poco informative, bench√© la loro struttura congiunta restringa significativamente lo spazio delle combinazioni plausibili. Ci√≤ implica che, nonostante l'incertezza marginale possa sembrare elevata, l'incertezza congiunta su specifiche relazioni parametriche pu√≤ essere molto ridotta.\n\nUn'ulteriore complicazione sorge quando le relazioni tra parametri sono *non lineari*. In tali casi, il massimo della distribuzione congiunta pu√≤ non coincidere con i massimi delle distribuzioni marginali. Ad esempio, in presenza di strutture a \"banana\" o altre forme complesse, gli usuali indicatori di tendenza centrale (come la moda o la media) calcolati sui singoli parametri possono non riflettere la regione di massima densit√† di probabilit√† nello spazio multivariato.\n\n\n### Approcci per una sintesi efficace\n\nPer una rappresentazione fedele dell‚Äôincertezza in contesti multivariati, √® essenziale adottare una prospettiva che vada oltre l‚Äôanalisi delle marginali:\n\n- **Visualizzazione delle relazioni congiunte**: Grafici di dispersione a coppie (*pair plots*) o contour plot bidimensionali consentono di esplorare visivamente le dipendenze tra parametri, rivelando strutture non catturate dalle marginali.\n  \n- **Utilizzo di distribuzioni predittive**: Il confronto tra distribuzioni predittive a priori e a posteriori fornisce una visione complessiva dell‚Äôincertezza ridotta dall‚Äôevidenza dei dati, tenendo conto di tutte le interazioni parametriche.\n\n- **Misure di dipendenza avanzate**: In casi di relazioni non lineari, misure come la correlazione di Spearman o l‚Äôinformazione mutua possono integrare la correlazione lineare, offrendo una descrizione pi√π completa delle dipendenze.\n\n- **Analisi di sensibilit√†**: Valutare come variano le inferenze al variare di gruppi di parametri aiuta a identificare le relazioni pi√π influenti e a comprendere la stabilit√† delle conclusioni.\n\nIn conclusione, una sintesi appropriata della distribuzione a posteriori in presenza di pi√π parametri richiede un esame congiunto delle relazioni tra di essi. La sola inspezione delle distribuzioni marginali rischia di occultare importanti fonti di informazione circa la struttura parametrica, con possibili conseguenze sulle inferenze tratte. Un approccio integrato ‚Äî che unisca visualizzazione, misure di dipendenza e analisi di sensibilit√† ‚Äî √® fondamentale per una comprensione robusta dei risultati bayesiani in contesti multivariati.\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo visto che il cuore dell‚Äôapproccio bayesiano non √® soltanto ottenere una distribuzione a posteriori, ma anche imparare a descriverla in modo utile. Abbiamo distinto tra diversi modi di riassumere un posterior (media, mediana, moda) e tra diverse forme di intervallo credibile, chiarendo come ciascuna offra una prospettiva diversa sull‚Äôincertezza.\n\nQueste sintesi non sostituiscono la distribuzione completa, ma la rendono comunicabile. L‚Äôintervallo credibile, in particolare, ci permette di dire con chiarezza quali valori del parametro hanno una certa probabilit√† a posteriori di essere veri, dato il modello e i dati osservati. Questo rappresenta una differenza cruciale rispetto all‚Äôapproccio frequentista, in cui l‚Äôinterpretazione degli intervalli di confidenza rimane indiretta e spesso fonte di equivoci.\n\nDal punto di vista della ricerca psicologica, la capacit√† di sintetizzare il posterior √® indispensabile. Molti risultati sperimentali si basano sulla stima di proporzioni, medie o differenze tra gruppi, e il modo in cui presentiamo l‚Äôincertezza pu√≤ fare la differenza tra una conclusione chiara e una affermazione ambigua. Una sintesi ben costruita non solo comunica meglio, ma rafforza la solidit√† della conoscenza accumulata, perch√© rende trasparenti i margini di dubbio.\n\nQuesto capitolo chiude cos√¨ un primo ciclo del nostro percorso: abbiamo imparato a costruire distribuzioni a posteriori e a sintetizzarle. Nei prossimi capitoli vedremo come andare oltre i parametri e usare il posterior per *fare previsioni sui dati futuri* e per *confrontare modelli alternativi*. √à qui che il pensiero bayesiano mostrer√† tutta la sua forza: non solo descrivere ci√≤ che sappiamo, ma anche guidare ci√≤ che possiamo aspettarci.\n\n\n::: {.callout-important title=\"Problemi\" collapse=\"true\"}\n**1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?**\n\n   - Spiega le differenze tra **moda (MAP)**, **media a posteriori** e **mediana**.\n   - In quali contesti √® preferibile utilizzare una di queste statistiche rispetto alle altre?\n\n**2. Qual √® la differenza tra un intervallo di credibilit√† bayesiano e un intervallo di confidenza frequentista?**\n\n   - Spiega le differenze concettuali tra i due approcci.\n   - Quale dei due √® pi√π intuitivo in termini di incertezza sui parametri?\n\n**3. Cos‚Äô√® un intervallo di massima densit√† posteriore (HPD) e in cosa si differenzia dall‚Äôintervallo di credibilit√† simmetrico?**\n\n   - Spiega il concetto di HPD e perch√© √® pi√π informativo in alcuni casi.\n   - In quali situazioni l‚ÄôHPD √® preferibile rispetto all‚Äôintervallo di credibilit√† simmetrico?\n\n**4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?**\n\n   - Perch√© il **MAP** pu√≤ essere meno affidabile rispetto ad altre statistiche?\n   - Quali problemi si possono incontrare nei modelli bayesiani complessi?\n\n**5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di pi√π parametri incogniti?**\n\n   - Quali sono le principali difficolt√† nell‚Äôinterpretare la distribuzione congiunta di pi√π parametri?\n   - Come si possono visualizzare e sintetizzare distribuzioni posteriori multivariate?\n\n**Domande applicative in R**\n\nPer queste domande, usa il dataset basato sulla **Satisfaction with Life Scale (SWLS)**, supponendo che i dati seguano una distribuzione normale.\n\n**1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.**\n   - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n\n**2. Costruisci un intervallo di credibilit√† simmetrico al 94% per la media SWLS.**\n\n   - Usa la distribuzione normale a posteriori per calcolare l‚Äôintervallo.\n\n\n**3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densit√†.**\n\n   - Genera un campione dalla distribuzione a posteriori e rappresentalo con **ggplot2**.\n\n**4. Confronta l‚Äôintervallo di credibilit√† simmetrico con l‚Äôintervallo di massima densit√† posteriore (HPD).**\n\n   - Usa la funzione **hdi()** del pacchetto **bayestestR** per calcolare l‚ÄôHPD.\n\n\n**5. Calcola la probabilit√† a posteriori che la media SWLS sia minore di 23.**\n\n   - Usa la distribuzione a posteriori per calcolare questa probabilit√†.\n\n:::\n\n::: {.callout-tip title=\"Soluzioni\" collapse=\"true\"}\n**1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?**\n\n\nLe tre principali statistiche usate per ottenere una **stima puntuale** del parametro $\\theta$ nella distribuzione a posteriori sono:\n\n1. **Moda (Massimo a Posteriori, MAP)**  \n   - √à il valore di $\\theta$ che massimizza la distribuzione a posteriori $p(\\theta \\mid y)$.  \n   - Se la distribuzione √® unimodale e simmetrica, il MAP coincide con la media a posteriori.  \n   - Il MAP √® spesso simile alla stima di massima verosimiglianza (MLE) quando il prior √® uniforme.  \n\n2. **Media a Posteriori**  \n   - √à il valore atteso della distribuzione a posteriori:  \n     $$\n     E(\\theta \\mid y) = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta\n     $$\n   - √à la stima pi√π utile quando si vuole minimizzare l'errore quadratico medio (MSE).  \n   - Risente dell'eventuale asimmetria della distribuzione, spostandosi verso le code.\n\n3. **Mediana a Posteriori**  \n   - √à il valore che divide la distribuzione a posteriori in due parti uguali:  \n     $$\n     P(\\theta \\leq \\theta_{\\text{mediana}} \\mid y) = 0.5\n     $$\n   - √à pi√π robusta agli outlier rispetto alla media ed √® utile quando la distribuzione √® fortemente asimmetrica.\n\nüí° **Quando usarle?**\n- Se la distribuzione √® **simmetrica**, tutte e tre le statistiche coincidono.\n- Se la distribuzione √® **asimmetrica**, la **mediana** √® pi√π robusta, la **media** pu√≤ essere influenzata dalle code e il **MAP** √® utile se si vuole un valore pi√π probabile.\n\n**2. Qual √® la differenza tra un intervallo di credibilit√† bayesiano e un intervallo di confidenza frequentista?**\n\n\n| Caratteristica                 | Intervallo di Credibilit√† (Bayesiano) | Intervallo di Confidenza (Frequentista) |\n|--------------------------------|--------------------------------------|----------------------------------------|\n| **Significato** | Esprime la probabilit√† che il parametro sia nell'intervallo, dati i dati osservati. | √à una propriet√† di un metodo di campionamento: se si ripetesse l‚Äôesperimento infinite volte, il $(1 - \\alpha)100\\%$ degli intervalli conterrebbe il vero valore del parametro. |\n| **Approccio** | Assume che il parametro sia una variabile casuale con una distribuzione di probabilit√†. | Assume che il parametro sia fisso e sconosciuto, mentre i dati sono casuali. |\n| **Interpretazione** | \"C'√® il 95% di probabilit√† che il parametro sia tra questi valori.\" | \"Se ripetessimo l'esperimento molte volte, il 95% degli intervalli conterrebbe il vero parametro.\" |\n\nüí° **Differenza fondamentale:**  \n\n- L'intervallo di credibilit√† √® **probabilistico** e pi√π intuitivo: si pu√≤ direttamente dire che il parametro ha il 95% di probabilit√† di trovarsi nell'intervallo.  \n- L'intervallo di confidenza √® **basato sulla ripetizione ipotetica** dell'esperimento e non pu√≤ essere interpretato in termini probabilistici sul singolo intervallo.\n\n**3. Cos‚Äô√® un intervallo di massima densit√† posteriore (HPD) e in cosa si differenzia dall‚Äôintervallo di credibilit√† simmetrico?**\n \nL‚Äô**intervallo di massima densit√† posteriore (HPD)** √® l‚Äôintervallo pi√π stretto che contiene una percentuale fissata (es. 94%) della distribuzione a posteriori. Si distingue dall'intervallo di credibilit√† simmetrico perch√©:\n\n| Caratteristica | Intervallo HPD | Intervallo di Credibilit√† Simmetrico |\n|--------------|-------------|--------------------------------|\n| **Definizione** | Contiene il  $(1 - \\alpha)100\\%$ della probabilit√† a posteriori, minimizzando la lunghezza dell‚Äôintervallo. | √à centrato attorno alla mediana e copre una frazione fissa della distribuzione. |\n| **Forma** | Pu√≤ essere asimmetrico e discontinuo se la distribuzione √® multimodale. | √à sempre simmetrico. |\n| **Vantaggio** | √à pi√π informativo se la distribuzione √® asimmetrica o multimodale. | √à pi√π facile da calcolare, specialmente per distribuzioni unimodali. |\n\nüí° **Quando usarli?**  \n\n- Se la distribuzione √® **simmetrica**, entrambi gli intervalli danno risultati simili.  \n- Se la distribuzione √® **asimmetrica o multimodale**, l‚ÄôHPD √® pi√π informativo.\n\n**4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?**\n \nSebbene il **MAP** sia un concetto intuitivo (il valore pi√π probabile della distribuzione a posteriori), presenta alcune limitazioni:\n\n1. **Difficolt√† computazionale con MCMC**  \n   - Con metodi di campionamento come **Markov Chain Monte Carlo (MCMC)**, trovare il massimo della distribuzione a posteriori √® difficile perch√© la funzione viene stimata in modo discreto.\n   - Spesso si preferisce stimare **media** o **mediana**, pi√π facili da calcolare con MCMC.\n\n2. **Sensibilit√† ai dati e al prior**  \n   - Il MAP dipende fortemente dal **prior** scelto.\n   - Se il prior √® informativo, il MAP pu√≤ spostarsi troppo rispetto ai dati.\n\n3. **Problemi con distribuzioni multimodali**  \n   - Se la distribuzione a posteriori ha pi√π di un massimo (moda), il MAP potrebbe non essere una buona rappresentazione della distribuzione.\n\nüí° **Quando evitarlo?**  \n- Se la distribuzione a posteriori √® **asimmetrica o multimodale**.\n- Se si usa un **metodo MCMC**, dove la media o la mediana sono pi√π semplici da stimare.\n\n**5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di pi√π parametri incogniti?**\n \nQuando l'inferenza bayesiana coinvolge pi√π parametri (es. $\\mu$ e $\\sigma$), l'analisi diventa pi√π complessa per diversi motivi:\n\n1. **Interazioni tra parametri**  \n   - I parametri spesso non sono indipendenti: la distribuzione a posteriori congiunta pu√≤ mostrare **correlazioni** che non emergono dalle distribuzioni marginali.\n\n2. **Difficolt√† di visualizzazione**  \n   - Per un parametro si usa un istogramma o una funzione di densit√†.\n   - Per due parametri si usa un **contour plot** o un **grafico 3D**.\n   - Con pi√π di due parametri, si ricorre a **pair plots** o **matrici di correlazione**.\n\n3. **Stimare margine e congiunta**  \n   - La distribuzione marginale di un parametro si ottiene integrando la distribuzione congiunta rispetto agli altri parametri:\n     $$\n     p(\\theta_1) = \\int p(\\theta_1, \\theta_2) d\\theta_2\n     $$\n   - Se i parametri sono fortemente correlati, le marginali possono **nascondere informazioni importanti**.\n\n4. **Rischio di correlazioni non lineari**  \n   - Le correlazioni non lineari tra i parametri possono portare a distribuzioni con forme complesse (es. a banana), rendendo difficile la sintesi con MAP o media.\n\nüí° **Strategie per affrontare il problema:**  \n- **Visualizzare le correlazioni** tra i parametri con scatter plot o heatmap.  \n- **Usare tecniche di riduzione della dimensionalit√†** come PCA (Analisi delle Componenti Principali).  \n- **Utilizzare il MCMC** per campionare direttamente dalla distribuzione congiunta.\n\n**Esercizio in R con i dati SWLS**\n\nNell'esercizio, usa i dati della SWLS che sono stati raccolti. Qui useremo i dati seguenti:\n\n```r\nswls_data <- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n```\n\n**1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.**\n\n   - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n\n```r\nlibrary(tibble)\n\n# Dati\nn <- nrow(swls_data)\nmean_x <- mean(swls_data$soddisfazione)\nsigma <- 1  # Deviazione standard nota\n\n# Prior diffuso\nmu_prior <- 4.5    \nsigma_prior <- 10  \n\n# Media a posteriori\nmu_post <- (sigma_prior^2 * mean_x + sigma^2 * n * mu_prior) / (sigma_prior^2 + sigma^2 * n)\n\n# Deviazione standard a posteriori\nsigma_post <- sqrt((sigma_prior^2 * sigma^2) / (sigma_prior^2 + sigma^2 * n))\n\n# Moda (MAP)\nposterior_mode <- mu_post  # Per una distribuzione normale, MAP coincide con la media\n\n# Mediana (simile alla media in una distribuzione normale)\nposterior_median <- mu_post\n\ntibble(\"Media a Posteriori\" = mu_post,\n       \"Moda (MAP)\" = posterior_mode,\n       \"Mediana\" = posterior_median)\n```\n\n**2. Costruisci un intervallo di credibilit√† simmetrico al 94% per la media SWLS.**\n\n   - Usa la distribuzione normale a posteriori per calcolare l‚Äôintervallo.\n\n```r\ncred_interval <- qnorm(c(0.03, 0.97), mean = mu_post, sd = sigma_post)\ncred_interval\n```\n\n**3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densit√†.**\n\n   - Genera un campione dalla distribuzione a posteriori e rappresentalo con **ggplot2**.\n\n```r\nlibrary(ggplot2)\n\n# Campionamento dalla distribuzione a posteriori\nset.seed(123)\nsamples <- rnorm(1000, mean = mu_post, sd = sigma_post)\n\n# Creazione del dataframe\nsamples_df <- tibble(media_campionata = samples)\n\n# Grafico della distribuzione a posteriori\nggplot(samples_df, aes(x = media_campionata)) +\n  geom_density(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Distribuzione a Posteriori della Media SWLS\",\n       x = \"Media\", y = \"Densit√†\")\n```\n\n**4. Confronta l‚Äôintervallo di credibilit√† simmetrico con l‚Äôintervallo di massima densit√† posteriore (HPD).**\n\n   - Usa la funzione **hdi()** del pacchetto **bayestestR** per calcolare l‚ÄôHPD.\n\n```r\nlibrary(bayestestR)\n\n# Calcolo intervallo HPD al 94%\nhpd_interval <- hdi(samples, ci = 0.94)\nhpd_interval\n```\n\n**5. Calcola la probabilit√† a posteriori che la media SWLS sia minore di 23 -- per fare un esempio, qui caloleremo per i dati simulati la probabilit√† a posteriori per la media SWLS maggiore di 4.7.**\n\n   - Usa la distribuzione a posteriori per calcolare questa probabilit√†.\n\n```r\nprob_greater_4_7 <- 1 - pnorm(4.7, mean = mu_post, sd = sigma_post)\nprob_greater_4_7\n```\n:::\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#>  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#>  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [25] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#>  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#>  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#> [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#> [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#> [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#> [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#> [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#> [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#> [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#> [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#> [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#> [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#> [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#> [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#> [46] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#> [49] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#> [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#> [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#> [58] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#> [61] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#> [64] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#> [67] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#> [70] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#> [73] lme4_1.1-37           mvtnorm_1.3-3         grid_4.5.1           \n#> [76] rbibutils_2.3         QuickJSR_1.8.0        colorspace_2.1-1     \n#> [79] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#> [82] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#> [85] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#> [88] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#> [91] htmltools_0.5.8.1     lifecycle_1.0.4       mitml_0.4-5          \n#> [94] MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n\n",
    "supporting": [
      "07_summary_posterior_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}