{
  "hash": "f26cf7301d23a2dd6fabd0934775016f",
  "result": {
    "engine": "knitr",
    "markdown": "# Aggiornare le credenze su un parametro: dal prior alla posterior {#sec-bayesian-inference-proportion}\n\n::: {.epigraph}\n> “The probability of any event is the ratio between the value at which an expectation depending on the happening of the event ought to be computed, and the value of the thing expected upon its happening.”\n>\n> — **Thomas Bayes**, An Essay towards Solving a Problem in the Doctrine of Chances\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nNei capitoli precedenti abbiamo esaminato il ruolo fondamentale dell'incertezza nella ricerca psicologica e abbiamo visto come l'approccio bayesiano fornisca un linguaggio particolarmente adatto per rappresentarla. Abbiamo inoltre distinto tra modelli puramente fenomenologici, che si limitano a descrivere associazioni tra variabili, e modelli meccanicistici, che cercano invece di formalizzare i processi psicologici sottostanti.\n\nIn questo capitolo ci concentreremo su un caso di studio particolarmente comune e rilevante: l'inferenza sulla proporzione di successi in un compito sperimentale o in un campione di soggetti.\n\n### Perché partire dalle proporzioni?\n\nUna parte significativa della ricerca psicologica si basa su dati di natura binaria: un soggetto che ricorda o non ricorda uno stimolo, un paziente che risponde o non risponde a una terapia, uno studente che sceglie o non sceglie l'opzione corretta in un compito cognitivo.\n\nIn tutti questi scenari, i dati si riducono essenzialmente a un conteggio di successi e insuccessi, e la quantità di interesse principale diventa la proporzione di successi nella popolazione o nel campione studiato.\n\nL'analisi di questo caso apparentemente semplice ci offre tre vantaggi fondamentali: in primo luogo, ci permette di stabilire un collegamento chiaro tra dati osservati e modelli probabilistici; in secondo luogo, ci aiuta a comprendere come i priori e i posteriori operano concretamente nel contesto di un modello Beta-Binomiale; infine, getta le basi per modelli più complessi che in seguito potranno descrivere non solo proporzioni statiche, ma veri e propri processi psicologici dinamici che generano le osservazioni.\n\n### Collegamento con la crisi di replicazione\n\nMolti dei risultati controversi emersi in psicologia derivano da studi che confrontavano proporzioni tra diversi gruppi sperimentali - si pensi ad esempio alla percentuale di partecipanti che mostrano un certo effetto. Una delle criticità principali di questi studi è stata la tendenza a presentare queste proporzioni come stime puntuali, tralasciando una adeguata rappresentazione dell'incertezza associata.\n\nL'approccio bayesiano supera questa limitazione consentendo di comunicare non solo quale sia la proporzione più plausibile, ma anche quanto dubbio residuo permanga attorno a questa stima. Questa trasparenza favorisce interpretazioni più equilibrate e cumulative dei risultati, contribuendo così ad affrontare uno dei fattori che hanno alimentato la crisi di replicabilità nel campo.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Applicare l'aggiornamento bayesiano per affinare credenze.\n- Rappresentare distribuzioni a priori (discrete e continue).\n- Calcolare la verosimiglianza e aggiornare la distribuzione a priori.\n- Derivare e interpretare la distribuzione a posteriori.\n- Usare il metodo a griglia per approssimare la distribuzione a posteriori.\n- Applicare il modello binomiale per stimare probabilità e incertezze.\n- Calcolare medie, mode e intervalli di credibilità.\n- Utilizzare la distribuzione Beta come prior continuo.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere il settimo capitolo del testo di @albert_2019prob.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(HDInterval)\n```\n:::\n\n:::\n\n\n## Verosimiglianza binomiale \n\nNei capitoli precedenti abbiamo visto che l’approccio bayesiano rappresenta l’incertezza con distribuzioni di probabilità. Ora possiamo tradurre questa idea in un caso concreto molto comune nella ricerca psicologica: quando osserviamo una sequenza di successi e insuccessi.\nQuesto tipo di dati non è raro: pensiamo a uno studente che risponde a una serie di domande (corretto/errato), a un paziente che mostra o non mostra un miglioramento, a un partecipante che sceglie o non sceglie un certo stimolo. In questi casi, la distribuzione che descrive le probabilità dei possibili conteggi di successi si chiama distribuzione binomiale. Essa rappresenta il cuore del modello fenomenologico più semplice per i dati binari: il modello binomiale.\n\nLa distribuzione binomiale descrive il numero di successi $y$ in $n$ prove indipendenti, ciascuna con probabilità di successo $\\theta$:\n\n$$ \np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y}, \n$$\n\ndove $\\theta$ rappresenta la probabilità di successo per singola prova, $y$ è il numero osservato di successi e $n$ è il numero totale di prove (fissato a priori).\n\n## Esempio psicologico: giudizio morale in un dilemma\n\nI dilemmi morali, come il classico *problema del treno* [@foot1967problem; @greene2001fmri], sono strumenti usati in psicologia per indagare come le persone prendono decisioni etiche [per es., @bucciarelli2008psychology]. Supponiamo che un ricercatore voglia stimare la *proporzione di adulti* che considerano accettabile compiere un’azione moralmente controversa (ad es. deviare un treno per salvare cinque persone, causando però la morte di una persona).\n\nOgni partecipante legge *un singolo scenario morale* e deve dare una risposta binaria:\n\n- 1 = giudica l’azione come moralmente accettabile (successo),\n- 0 = giudica l’azione come non accettabile (fallimento).\n\nIn un campione di *30 soggetti indipendenti*, *22 hanno giudicato l’azione accettabile*.\n\nIn questo scenario:\n\n- ciascun soggetto fornisce un unico giudizio (unità di osservazione indipendente),\n- ogni risposta è una variabile di Bernoulli con probabilità di successo $\\theta$,\n- il numero totale di giudizi favorevoli segue una distribuzione binomiale:\n\n$$\nY \\sim \\text{Binomiale}(n = 30, \\theta),\n$$\n\ndove $Y = 22$ rappresenta il numero di successi osservati.\n\n\n### Obiettivo inferenziale\n\nIl nostro scopo è stimare $\\theta$: la probabilità che un adulto, scelto a caso dalla popolazione, giudichi moralmente accettabile l’azione descritta nel dilemma. Nel quadro bayesiano combiniamo:\n\n- la verosimiglianza (dati osservati: 22 su 30),\n- una distribuzione a priori (credenze iniziali su $\\theta$),\n\nottenendo la distribuzione a posteriori, che rappresenta la nostra conoscenza aggiornata.\n\n\n## Metodo basato su griglia \n\nIl metodo basato su griglia è un approccio intuitivo e didatticamente efficace per approssimare una distribuzione a posteriori. La sua semplicità lo rende ideale per comprendere il meccanismo di aggiornamento delle credenze. L'idea fondamentale è di discretizzare lo spazio dei parametri e calcolare la distribuzione a posteriori in punti isolati, evitando il ricorso a metodi analitici complessi.\n\nI passaggi operativi sono i seguenti:\n\n1.  **Definizione della griglia:** Si suddivide l'intervallo dei valori plausibili per il parametro di interesse (ad esempio, $\\theta$, compreso tra 0 e 1) in una sequenza finita di punti equidistanti.\n2.  **Calcolo della verosimiglianza:** Per ogni punto $\\theta_i$ sulla griglia, si calcola la funzione di verosimiglianza $P(D \\mid \\theta_i)$, che rappresenta la probabilità di osservare i dati $D$ dato quel specifico valore del parametro.\n3.  **Prodotto priori-verosimiglianze:** Per ogni punto della griglia, si moltiplica il valore della verosimiglianza per il valore della distribuzione a priori $P(\\theta_i)$. Questo prodotto è proporzionale alla distribuzione a posteriori non normalizzata.\n4.  **Normalizzazione:** I valori ottenuti nel passo precedente vengono sommati e ciascuno di essi è diviso per questa somma totale. Il risultato è una distribuzione di probabilità discreta a posteriori valida, i cui valori per ogni $\\theta_i$ sommano a 1.\n\nIl risultato finale è un'approssimazione della vera distribuzione a posteriori continua, che mostra in modo chiaro come l'evidenza fornita dai dati ($D$) abbia aggiornato e modificato le credenze iniziali (la distribuzione a priori) sul parametro $\\theta$.\n\n## Aggiornamento bayesiano con una distribuzione a priori discreta  \n\n### Costruzione della distribuzione a priori  \n\nIn assenza di informazioni specifiche, possiamo assumere che tutti i valori di $\\theta$ siano ugualmente plausibili. Per implementare concretamente questo approccio:  \n\n- definiamo un insieme discreto di valori possibili per $\\theta$: {0, 0.1, 0.2, ..., 1},  \n- assegniamo a ciascun valore la stessa probabilità a priori: $p(\\theta) = 1/11 \\approx 0.09$.  \n\nQuesta scelta rappresenta uno stato di massima incertezza iniziale, dove nessun valore di $\\theta$ risulta a priori più plausibile di altri.  \n\n\n### Aggiornamento con i dati\n\nAbbiamo osservato $y = 22$ giudizi di *accettabilità* su $n = 30$ partecipanti. Per ogni valore $\\theta$ nella griglia:\n\n1. calcoliamo la verosimiglianza binomiale:\n\n   $$\n   p(y \\mid \\theta) = \\theta^{22}(1-\\theta)^8 ,\n   $$\n\n   dove $\\theta$ rappresenta la probabilità che un adulto giudichi l’azione come moralmente accettabile,  \n2. moltiplichiamo per la probabilità a priori,  \n3. normalizziamo dividendo per la somma totale di tutti i prodotti ottenuti.  \n\nIl risultato è una distribuzione a posteriori discreta che mostra come l’osservazione aggiorna le nostre credenze iniziali. I valori di $\\theta$ vicini a $22/30 \\approx 0.7$ ricevono una maggiore probabilità a posteriori.\n\n### Interpretazione  \n\n- Prima dei dati, ogni valore di $\\theta$ era ugualmente plausibile.  \n- Dopo i dati, valori come $\\theta = 0.7$ o $0.75$ hanno alta probabilità a posteriori.  \n- Valori estremi ($0.2$, $0.9$) diventano poco plausibili.  \n\nIn altre parole, la distribuzione a posteriori concentra la massa di probabilità attorno ai valori che rendono i dati osservati più plausibili.\n\n\n### Implementazione in R\n\nDefinizione della griglia:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntheta <- seq(0, 1, by = 0.1)  # Griglia di valori da 0 a 1 con passo 0.1\n```\n:::\n\n\nQuando non abbiamo informazioni preliminari, usiamo una distribuzione uniforme:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npriori_unif <- rep(1 / length(theta), length(theta))  # Probabilità uniformi\n```\n:::\n\n\nVisualizziamo questa distribuzione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data.frame(theta, prob = priori_unif), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"Densità di probabilità\")\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nSe invece riteniamo più probabili valori centrali di $\\theta$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npriori_inf <- c(\n  0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05\n)\n```\n:::\n\n\nVisualizzazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data.frame(theta, prob = priori_inf), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"Densità di probabilità\")\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nVerosimiglianza:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nverosimiglianza <- dbinom(22, size = 30, prob = theta)\n```\n:::\n\n\nVisualizzazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data.frame(theta, prob = verosimiglianza), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"L(θ|dati)\")\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nCalcolo della distribuzione a posteriori:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposteriori_non_norm <- priori_inf * verosimiglianza\nposteriori <- posteriori_non_norm / sum(posteriori_non_norm)  # Normalizzazione\n```\n:::\n\n\nVisualizzazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data.frame(theta, prob = posteriori), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"P(θ|dati)\")\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nStatistiche descrittive:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmedia_post <- sum(theta * posteriori)\nvar_post <- sum(theta^2 * posteriori) - media_post^2\nmoda_post <- theta[which.max(posteriori)]\n\ncat(\"Media a posteriori:\", round(media_post, 3),\n    \"\\nVarianza a posteriori:\", round(var_post, 3),\n    \"\\nModa a posteriori:\", moda_post)\n#> Media a posteriori: 0.689 \n#> Varianza a posteriori: 0.005 \n#> Moda a posteriori: 0.7\n```\n:::\n\n\n**Interpretazione grafici.**\nIl grafico della verosimiglianza mostra un picco tra 0.6 e 0.8: significa che questi valori di $\\theta$ rendono i dati osservati particolarmente plausibili. La combinazione con il prior porta la curva a posteriori ad accentuare o attenuare questa evidenza, a seconda della distribuzione iniziale.\n\n\n## Aggiornamento bayesiano con una distribuzione a priori continua\n\nUn’estensione naturale è usare una distribuzione continua come priori. La più adatta nel caso di proporzioni è la Beta:\n\n* supporto: $\\[0,1]$ (come $\\theta$),\n* coniugata della Binomiale (la posteriori è ancora una Beta),\n* parametri: $\\text{Beta}(\\alpha, \\beta)$.\n\nEsempi:\n\n* $\\text{Beta}(2,2)$: priori simmetrica e non troppo informativa,\n* $\\text{Beta}(2,5)$: priori che privilegia valori bassi di $\\theta$.\n\n### Implementazione in R\n\nCalcoliamo la densità della distribuzione $\\text{Beta}(2, 2)$ su una griglia fine di valori di $\\theta$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntheta <- seq(0, 1, length.out = 1000)\nprior_beta_2_2 <- dbeta(theta, 2, 2)\n```\n:::\n\n\nVisualizzazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data.frame(theta, prior = prior_beta_2_2), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2, color = \"#5d5349\") +\n  labs(x = expression(theta), y = \"Densità\")\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nContinuiamo con l’esempio precedente, in cui 22 partecipanti su 30 hanno giudicato l’azione come moralmente accettabile. La verosimiglianza associata a ciascun valore di $\\theta$ è calcolata come:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlikelihood <- dbinom(22, size = 30, prob = theta)\n```\n:::\n\n\nPoiché il prior è continuo, otteniamo la distribuzione a posteriori moltiplicando punto a punto la densità a priori per la verosimiglianza, e normalizzando:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposterior_unnorm <- prior_beta_2_2 * likelihood\nposterior <- posterior_unnorm / sum(posterior_unnorm)\n```\n:::\n\n\nVisualizziamo le tre curve (per gli scopi della visualizzazione, standardizziamo ciascuna distribuzione):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- data.frame(\n  theta, \n  prior = prior_beta_2_2 / sum(prior_beta_2_2), \n  likelihood = likelihood / sum(likelihood), \n  posterior\n  )\n\ndf_long <- df |>\n  pivot_longer(cols = c(\"prior\", \"likelihood\", \"posterior\"),\n               names_to = \"Distribuzione\", values_to = \"Densità\")\n\nggplot(df_long, aes(x = theta, y = Densità, color = Distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(x = expression(theta), y = \"Densità\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nOra consideriamo una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di $\\theta$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprior_2_5 <- dbeta(theta, 2, 5)\nposterior <- (prior_2_5 * likelihood) / sum(prior_2_5 * likelihood)\n```\n:::\n\nVisualizziamo le tre distribuzioni:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- data.frame(\n  theta, \n  prior = prior_2_5 / sum(prior_2_5), \n  likelihood = likelihood / sum(likelihood), \n  posterior\n  )\n\ndf_long <- df |>\n  pivot_longer(cols = c(\"prior\", \"likelihood\", \"posterior\"),\n               names_to = \"Distribuzione\", values_to = \"Densità\")\n\nggplot(df_long, aes(x = theta, y = Densità, color = Distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(x = expression(theta), y = \"Densità\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Interpretazione.**\nL’aggiornamento bayesiano con una distribuzione a priori continua fornisce una stima aggiornata di $\\theta$, la probabilità che un adulto giudichi moralmente accettabile l’azione proposta nel dilemma. Questa stima tiene conto sia delle credenze iniziali (prior) sia dell’evidenza empirica (verosimiglianza).\n\nNel nostro esempio, la distribuzione a posteriori risulta spostata verso valori alti rispetto al prior simmetrico $\\text{Beta}(2,2)$, riflettendo l’evidenza che *22 partecipanti su 30* hanno espresso un giudizio di accettabilità. In alternativa, utilizzando un prior asimmetrico come $\\text{Beta}(2,5)$, la distribuzione a posteriori mostra un compromesso: da un lato la tendenza iniziale a ritenere poco probabile l’accettazione morale, dall’altro i dati osservati che indicano una proporzione maggiore di giudizi favorevoli.\n\n**Sintesi didattica.**\nQuesto esempio illustra il cuore dell’inferenza bayesiana: la conoscenza non è mai statica, ma si aggiorna continuamente integrando dati empirici e credenze iniziali in modo trasparente e quantitativo.\n\n\n::: {.callout-note collapse = \"true\"}\n## Approfondimento — Metodo su griglia con la Normale (media ignota, $\\sigma$ nota)\n\nIl metodo su griglia non vale solo per la Binomiale: si applica anche al caso Normale quando vogliamo stimare la media $\\mu$ assumendo la deviazione standard nota. L’idea è la stessa: scegliamo una griglia di valori plausibili per $\\mu$, calcoliamo la verosimiglianza per ciascun valore, la combiniamo con il prior e normalizziamo per ottenere la posterior.\n\n**Scenario.** Studiamo i punteggi di QI di bambini ad alto potenziale. Supponiamo che i punteggi seguano una Normale con deviazione standard nota $\\sigma = 5$, mentre la media $\\mu$ è ignota. Usiamo un prior informativo $\\mu \\sim \\mathcal{N}(140, 3^2)$.\n\n### Dati ed elementi del modello\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\ncampione <- round(rnorm(10, mean = 130, sd = 5))  # 10 osservazioni simulate\ncampione\n#>  [1] 127 129 138 130 131 139 132 124 127 128\nsigma <- 5\n```\n:::\n\n\nLa verosimiglianza congiunta per un dato $\\mu$ è il prodotto delle densità Normali:\n\n$$\nL(\\mu) \\;=\\; \\prod_{i=1}^n \\text{Normal}\\bigl(y_i \\mid \\mu, \\sigma\\bigr).\n$$\n\nNel calcolo numerico conviene usare i logaritmi (stabilità): il prodotto diventa somma.\n\n### Metodo su griglia (versione stabile)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Griglia di valori plausibili per mu: centrata tra prior e dati\nmu_griglia <- seq(120, 150, length.out = 400)\n\n# Log-verosimiglianza: somma delle densità log-normali\nlog_lik <- sapply(mu_griglia, function(mu)\n  sum(dnorm(campione, mean = mu, sd = sigma, log = TRUE))\n)\n\n# Prior (log-densità normale): mu ~ N(140, 3^2)\nlog_prior <- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\n\n# Log-posterior non normalizzata\nlog_post_unnorm <- log_lik + log_prior\n\n# Normalizzazione numericamente stabile (log-sum-exp)\nlog_post_stab <- log_post_unnorm - max(log_post_unnorm)\npost <- exp(log_post_stab)\npost <- post / sum(post)  # posterior discreta sulla griglia (somma = 1)\n\n# Sommari deterministici (somme pesate sulla griglia)\npost_mean <- sum(mu_griglia * post)\npost_var  <- sum((mu_griglia - post_mean)^2 * post)\npost_sd   <- sqrt(post_var)\n\nc(media_post = post_mean, sd_post = post_sd)\n#> media_post    sd_post \n#>      132.6        1.4\n```\n:::\n\n\n### Visualizzare prior, verosimiglianza e posterior\n\nPer confrontare *forme* diverse (prior, verosimiglianza, posterior) portiamo verosimiglianza e prior “in scala comparabile” (solo a fini grafici).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Rescaling per confronto visivo (non usato nei calcoli)\nprior_vis <- dnorm(mu_griglia, mean = 140, sd = 3)\nprior_vis <- prior_vis / max(prior_vis)\n\nlik_vis   <- exp(log_lik - max(log_lik))  # anche qui versione stabile\n\ndf <- tibble(\n  mu = mu_griglia,\n  Prior = prior_vis,\n  Verosimiglianza = lik_vis,\n  Posterior = post / max(post)\n)\n\ndf |>\n  pivot_longer(-mu, names_to = \"Distribuzione\", values_to = \"Densita\") |>\n  ggplot(ggplot2::aes(x = mu, y = Densita, color = Distribuzione)) +\n  geom_line(linewidth = 1.1) +\n  geom_vline(xintercept = mean(campione), linetype = \"dashed\") +\n  geom_vline(xintercept = 140, linetype = \"dotted\") +\n  geom_vline(xintercept = post_mean, linetype = \"dotdash\") +\n  labs(\n    x = expression(mu), y = \"Scala comparabile\\n(solo per confronto visivo)\"\n  ) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Come leggere il grafico.**\nLa verosimiglianza (linea centrata sulla media campionaria) riflette dove i dati sono più plausibili; il prior rappresenta la conoscenza iniziale (centrata a 140); la posterior è il compromesso bayesiano tra i due. Con più dati, la posterior tende ad avvicinarsi e a stringersi attorno alla media empirica.\n\n### Collegamento con la soluzione analitica (conjugacy)\n\nNel caso Normale con $\\sigma$ nota e prior Normale per $\\mu$, la posterior è ancora Normale:\n\n$$\n\\mu \\mid y \\;\\sim\\; \\mathcal{N}\\!\\Bigl(\\,\\mu_\\text{post},\\, \\tau_\\text{post}^2\\Bigr),\n$$\n\ndove\n\n$$\n\\tau_\\text{post}^2\n= \\left(\\frac{n}{\\sigma^2} + \\frac{1}{\\tau_0^2}\\right)^{-1},\n\\qquad\n\\mu_\\text{post}\n= \\tau_\\text{post}^2\\left(\\frac{n\\,\\bar y}{\\sigma^2} + \\frac{\\mu_0}{\\tau_0^2}\\right).\n$$\n\nQui $\\mu\\_0=140$ e $\\tau\\_0=3$ sono media e deviazione standard del prior; $\\bar y$ è la media campionaria.\n\nVerifichiamo numericamente l’accordo con la griglia:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn      <- length(campione)\nybar   <- mean(campione)\nmu0    <- 140\ntau0   <- 3\n\ntau2_post <- 1 / (n / sigma^2 + 1 / tau0^2)\nmu_post   <- tau2_post * (n * ybar / sigma^2 + mu0 / tau0^2)\nsd_post   <- sqrt(tau2_post)\n\nc(analitico_media = mu_post, analitico_sd = sd_post,\n  griglia_media   = post_mean, griglia_sd   = post_sd)\n#> analitico_media    analitico_sd   griglia_media      griglia_sd \n#>           132.6             1.4           132.6             1.4\n```\n:::\n\n\nI risultati coincidono (entro il passo di griglia), mostrando che il metodo su griglia “ricostruisce” la soluzione coniugata. Questo è didatticamente utile: gli studenti vedono *sia* la meccanica computazionale (griglia + normalizzazione) *sia* la struttura teorica (conjugacy).\n\n### Nota numerica: perché i logaritmi\n\nLa verosimiglianza congiunta è il prodotto di molte densità, quindi può diventare numericamente piccolissima. Usare le somme dei logaritmi evita l’underflow e rende stabile la normalizzazione finale (tramite il trucco “log-sum-exp”). È una buona pratica anche con campioni moderati.\n:::\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo affrontato uno dei casi più fondamentali dell’inferenza statistica: la stima della proporzione di successi. Attraverso la combinazione della verosimiglianza binomiale con un prior Beta, abbiamo visto come il teorema di Bayes ci consenta di ottenere una distribuzione a posteriori che rappresenta in maniera trasparente la nostra incertezza riguardo al parametro di interesse. Questo esempio, per quanto elementare, ci permette di osservare in azione la logica dell’aggiornamento bayesiano presentata nei capitoli precedenti: ciò che sapevamo prima viene modificato dalla nuova evidenza empirica, producendo credenze aggiornate che incorporano tanto le informazioni pregresse quanto i dati osservati.\n\nQuesta applicazione mette in luce un punto centrale che ha accompagnato tutta la nostra discussione fino a qui: l’incertezza non è un ostacolo da eliminare, ma una componente intrinseca e inevitabile dell’inferenza scientifica. Al contrario di quanto avviene in molti approcci tradizionali, dove il risultato viene spesso ridotto a un singolo numero o a un verdetto dicotomico, il metodo bayesiano ci offre una rappresentazione più onesta e informativa, in cui diversi valori rimangono plausibili con gradi di sostegno differenti. La distinzione tra conoscenza preliminare (*prior*), evidenza empirica (dati) e credenze aggiornate (*posterior*) fornisce così un quadro concettuale coerente e cumulativo, che si integra con le riflessioni sviluppate nei capitoli precedenti sulla crisi di replicabilità e sulla necessità di modelli trasparenti e confrontabili.\n\nDal punto di vista computazionale, l’approccio basato su griglia che abbiamo utilizzato si è rivelato particolarmente utile come strumento didattico. La sua logica è semplice e intuitiva: si discretizza lo spazio dei parametri, si calcolano prior e verosimiglianza in ciascun punto e si normalizza per ottenere una distribuzione coerente di probabilità. Questa procedura esplicita, anche se rudimentale, permette di visualizzare con chiarezza i passaggi fondamentali dell’inferenza bayesiana e di comprenderne la natura dinamica. Tuttavia, sappiamo che la sua utilità pratica diminuisce rapidamente con l’aumentare della complessità dei modelli: la cosiddetta *maledizione della dimensionalità*[^1] rende presto insostenibile il calcolo.\n\n[^1]: La *maledizione della dimensionalità* si riferisce al fatto che lo spazio dei parametri cresce in modo esponenziale con il numero delle dimensioni. Se, ad esempio, dividiamo ogni parametro in 100 possibili valori e vogliamo esplorare un modello con 10 parametri, dovremmo valutare $100^{10} = 10^{20}$ combinazioni: un numero astronomico, impossibile da gestire con un approccio esaustivo a griglia. Questo rende necessarie tecniche di campionamento più efficienti, come i metodi Monte Carlo che introdurremo nei capitoli successivi.\n\nQuesta consapevolezza ci prepara ad affrontare, nei prossimi capitoli, strumenti più sofisticati come i metodi di campionamento MCMC. Essi sono concettualmente più complessi, ma offrono la potenza computazionale necessaria per affrontare modelli realistici e a più alta dimensionalità, mantenendo però intatta la logica di fondo che abbiamo visto emergere anche nel caso semplice del modello binomiale. In questo senso, il metodo a griglia conserva il suo valore formativo: è un punto di accesso privilegiato al pensiero bayesiano, un laboratorio concettuale in cui gli studenti possono osservare direttamente come si realizza l’aggiornamento delle credenze, prima di cimentarsi con strumenti più potenti e astratti.\n\n\n::: {.callout-note}\n\n#### Messaggio chiave\n\nPartire da casi semplici come la proporzione di successi ci aiuta a capire in profondità l’idea centrale: l’inferenza bayesiana non fornisce un numero definitivo, ma una distribuzione che rappresenta i valori plausibili e il grado di incertezza associato. Nei prossimi capitoli vedremo come questa logica si estenda a modelli più articolati, inclusi quelli che cercano di rappresentare i **processi psicologici** che generano i dati.\n:::\n\n\n\n::: {.callout-important title=\"Esercizio\" collapse=\"true\"}\n\nIn uno studio sulla percezione delle emozioni, un partecipante osserva 10 fotografie di volti arrabbiati. Deve indicare se il volto esprime **rabbia** o no. Ogni risposta può essere **corretta (1)** o **errata (0)**.\n\nI dati osservati del partecipante sono:\n\n```\n1, 0, 1, 1, 1, 0, 0, 1, 1, 1\n```\n\n→ Totale: **7 successi** su **10 prove** → $y = 7$, $n = 10$.\n\n**Obiettivo:** stimare la probabilità $\\theta$ che il partecipante riconosca correttamente un volto arrabbiato, tenendo conto sia dei **dati osservati** sia di **conoscenze pregresse**.\n\n**Prior Informativo.**\n\nSupponiamo di voler adottare un approccio cautamente *pessimistico* sulle capacità iniziali del partecipante, basandoci su studi precedenti che indicano un riconoscimento della rabbia **non sempre accurato**, ad esempio mediamente intorno al **40%** con moderata incertezza.\n\nPer rappresentare questa convinzione, scegliamo come **distribuzione a priori** una **Beta(4, 6)**:\n\n- **Media**: $\\mu = \\frac{4}{4+6} = 0.4$\n- **Varianza**: $\\frac{4 \\cdot 6}{(10)^2 \\cdot 11} = 0.0218$\n\nQuesta prior concentra la massa di probabilità su valori inferiori a 0.5, ma lascia spazio anche a livelli di competenza superiori.\n\n\n**Calcolo della Distribuzione a Posteriori con il Metodo Basato su Griglia.**\n\n**1. Griglia di valori per $\\theta$.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntheta <- seq(0, 1, length.out = 1000)\nhead(theta)\n#> [1] 0.00000 0.00100 0.00200 0.00300 0.00400 0.00501\ntail(theta)\n#> [1] 0.995 0.996 0.997 0.998 0.999 1.000\n```\n:::\n\n\n**2. Calcolo della distribuzione a priori Beta(4, 6).**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprior <- dbeta(theta, shape1 = 4, shape2 = 6)\nprior <- prior / sum(prior)  # normalizzazione\n```\n:::\n\n\nVisualizzazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data.frame(theta, prior), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-25-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**3. Calcolo della verosimiglianza per 7 successi su 10.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlikelihood <- dbinom(7, size = 10, prob = theta)\nlikelihood <- likelihood / sum(likelihood)  # normalizzazione\n```\n:::\n\n\nVisualizzazione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data.frame(theta, likelihood), aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-27-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**4. Calcolo della distribuzione a posteriori.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunnormalized_posterior <- prior * likelihood\nposterior <- unnormalized_posterior / sum(unnormalized_posterior)\n```\n:::\n\n\n**5. Visualizzazione congiunta: prior, likelihood e posteriori.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata <- data.frame(theta, prior, likelihood, posterior)\n\n# Imposta i livelli desiderati con nomi leggibili\nlong_data <- pivot_longer(\n  data,\n  cols = c(\"prior\", \"likelihood\", \"posterior\"),\n  names_to = \"distribution\",\n  values_to = \"density\"\n) |>\n  mutate(distribution = factor(\n    distribution,\n    levels = c(\"prior\", \"likelihood\", \"posterior\"),\n    labels = c(\"A Priori\", \"Verosimiglianza\", \"A Posteriori\")\n    )\n  )\n\nggplot(\n  long_data, \n  aes(x = theta, y = density, color = distribution)\n  ) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Densità (normalizzata)\",\n    color = NULL\n  ) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](05_subj_prop_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Riepilogo:**\n\n- la **prior** (Beta(4,6)) riflette una convinzione iniziale più scettica;\n- la **verosimiglianza** è centrata su $\\theta = 0.7$, corrispondente a 7 successi su 10;\n- la **posteriori** media tra prior e dati, ma si sposta chiaramente verso destra, evidenziando l’**effetto aggiornamento bayesiano**.\n\nQuesto esempio mostra come l’approccio bayesiano:\n\n- **integra in modo trasparente** dati individuali e credenze pregresse;\n- **produce una stima personalizzata** della capacità del partecipante;\n- permette di **quantificare l’incertezza** in modo completo, tramite la distribuzione a posteriori.\n\n**Quantità a Posteriori.**\n\nMedia:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposterior_mean <- sum(theta * posterior)\nposterior_mean\n#> [1] 0.55\n```\n:::\n\n\nDeviazione standard:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposterior_sd <- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#> [1] 0.109\n```\n:::\n\n\nModa:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposterior_mode <- theta[which.max(posterior)]\nposterior_mode\n#> [1] 0.556\n```\n:::\n\n\nIntervallo di credibilità al 94%:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsamples <- sample(theta, size = 10000, replace = TRUE, prob = posterior)\nquantile(samples, probs = c(0.03, 0.97))\n#>    3%   97% \n#> 0.342 0.750\n```\n:::\n\n\nQuesto esercizio mostra come:\n\n- l’informazione pregressa può essere incorporata in modo trasparente in un modello bayesiano;\n- la posteriori riflette **una combinazione tra dati osservati e conoscenze precedenti**.\n\n:::\n\n::: {.callout-important title=\"Problemi 1\" collapse=\"true\"}\nIn uno studio sull'analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, @hardwicke2022estimating hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.\n\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità $\\theta$ che uno studio condivida i materiali di ricerca. Per semplicità, discretizza $\\theta$ in 10 livelli equispaziati: $0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95$.\n\nAttribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull'informazione che la condivisione dei materiali è un evento raro ma non trascurabile: $0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02$.\n\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l'intervallo di credibilità al 89%.\n:::\n\n::: {.callout-tip title=\"Soluzioni 1\" collapse=\"true\"}\n```r\n# Definizione dei possibili valori di theta (probabilità discreta)\ntheta <- seq(0.05, 0.95, by = 0.10)\n\n# Definizione della distribuzione a priori\nprior <- c(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02)\n\n# Normalizzazione della prior (se necessario, ma in questo caso già normalizzata)\nprior <- prior / sum(prior)\n\n# Dati osservati\nsuccessi <- 20  # studi che hanno condiviso materiali\nn <- 100        # studi totali\n\n# Calcolo della verosimiglianza usando la distribuzione binomiale\nlikelihood <- dbinom(successi, size = n, prob = theta)\n\n# Calcolo della distribuzione a posteriori (applicazione del teorema di Bayes)\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)  # Normalizzazione\n\n# Calcolo della media della distribuzione a posteriori\nposterior_mean <- sum(theta * posterior)\n\n# Calcolo dell'intervallo di credibilità al 89%\ncdf <- cumsum(posterior)  # Distribuzione cumulativa\nlower_bound <- theta[which.min(abs(cdf - 0.055))]  # 5.5% quantile\nupper_bound <- theta[which.min(abs(cdf - 0.945))]  # 94.5% quantile\n\n# Output dei risultati\nlist(\n  posterior_mean = posterior_mean,\n  credibility_interval_89 = c(lower_bound, upper_bound)\n)\n```\n:::\n\n::: {.callout-important title=\"Problemi 2\" collapse=\"true\"}\n\nL'obiettivo di questo esercizio è applicare il metodo basato su griglia per stimare la distribuzione a posteriori di una proporzione, utilizzando dati dalla Scala della Rete Sociale di Lubben (LSNS-6). Si assume che un punteggio LSNS-6 superiore a una soglia prefissata indichi isolamento sociale. Il compito è:\n\n1. Scegliere una soglia per classificare i partecipanti in due gruppi (isolati vs. non isolati), garantendo che la proporzione osservata non sia inferiore a 0.1 o superiore a 0.9.\n2. Calcolare la distribuzione a posteriori della proporzione usando un'approssimazione discreta su una griglia di valori.\n3. Determinare l'intervallo di credibilità all'89%.\n4. Interpretare i risultati.\n\n**Consegna:**\ncaricare su Moodle il file .qmd compilato in pdf.\n:::\n\n::: {.callout-tip title=\"Soluzioni 2\" collapse=\"true\"}\n**Dati e Modellizzazione**\n\nSi assume che i dati siano rappresentati da una variabile binaria $y$, con $y = 1$ per individui classificati come isolati e $y = 0$ altrimenti. Supponiamo che su un campione di $n$ individui, $s$ siano isolati.\n\nDefiniamo il modello statistico:\n\n$$ y_i \\sim \\text{Bernoulli}(\\theta) $$\n\ncon:\n\n- $y_i \\in \\{0,1\\}$ per $i=1,\\dots,n$,\n- $\\theta$ proporzione di individui isolati nella popolazione.\n\nLa distribuzione a priori su $\\theta$ è scelta come $\\text{Beta}(2,2)$, che rappresenta una conoscenza iniziale moderata e non estrema.\n\n**Metodo basato su griglia**\n\nIl metodo a griglia approssima la distribuzione a posteriori calcolando la probabilità per una serie di valori discreti di $\\theta$.\n\n1. **Definire una griglia di valori per $\\theta$**:\n\n    ```r\n    theta <- seq(0, 1, length.out = 100)\n    ```\n2. **Calcolare la distribuzione a priori**:\n\n    ```r\n    prior <- dbeta(theta, 2, 2)\n    prior <- prior / sum(prior)  # Normalizzazione\n    ```\n3. **Calcolare la verosimiglianza**:\n\n    ```r\n    likelihood <- dbinom(s, size = n, prob = theta)\n    likelihood <- likelihood / sum(likelihood)  # Normalizzazione\n    ```\n4. **Calcolare la distribuzione a posteriori**:\n\n    ```r\n    posterior <- prior * likelihood\n    posterior <- posterior / sum(posterior)  # Normalizzazione\n    ```\n\n** Calcolo dell'intervallo di credibilità all'89%**\n\nL'intervallo di credibilità è calcolato come l'intervallo che contiene il 89% della probabilità a posteriori.\n\n```r\nci_89 <- quantile(sample(theta, size = 10000, prob = posterior, replace = TRUE), probs = c(0.055, 0.945))\nci_89\n```\n\n**Interpretazione dei risultati**\n\n1. **Valore atteso e moda a posteriori**:\n\n    ```r\n    mean_theta <- sum(theta * posterior)\n    mode_theta <- theta[which.max(posterior)]\n    ```\n    \n    - Il valore atteso fornisce una stima puntuale di $\\theta$.\n    - La moda indica il valore più probabile della proporzione di isolamento sociale.\n\n2. **Intervallo di credibilità**:\n\n    - L'89% della probabilità a posteriori cade tra i valori dell'intervallo di credibilità.\n    - Se l'intervallo è stretto, c'è maggiore certezza sulla proporzione stimata.\n    - Se l'intervallo è ampio, vi è maggiore incertezza sulla proporzione.\n:::\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] HDInterval_0.2.4      pillar_1.11.0         tinytable_0.13.0     \n#>  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#>  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [25] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#>  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#>  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#> [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#> [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#> [16] tools_4.5.1           yaml_2.3.10           knitr_1.50           \n#> [19] labeling_0.4.3        bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#> [22] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#> [25] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#> [28] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#> [31] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#> [34] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#> [37] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#> [40] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#> [43] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#> [46] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#> [49] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#> [52] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#> [55] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#> [58] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#> [61] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#> [64] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#> [67] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#> [70] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#> [73] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#> [76] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#> [79] pkgconfig_2.0.3\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n\n\n",
    "supporting": [
      "05_subj_prop_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}