{
  "hash": "75e7a2156959aa7ae64d5aec6cdfe0d6",
  "result": {
    "engine": "knitr",
    "markdown": "# Modelli statistici {#sec-bayes-stat-models}\n\n::: {.epigraph}\n\n> “Statistical models are not about the data, they are about how the data are generated.”\n>\n> — **David A. Freedman**, Statistical Models and Causal Inference\n:::\n\n## Introduzione  {.unnumbered .unlisted}\n\nNegli ultimi anni, la psicologia ha vissuto un profondo ripensamento metodologico, sollecitato dalla cosiddetta *crisi della replicabilità*. Una delle critiche principali emerse in questo dibattito riguarda la tendenza della ricerca tradizionale a concentrarsi prevalentemente sull'identificazione di *associazioni statistiche* tra variabili, trascurando spesso la modellazione dei *processi psicologici* sottostanti che potrebbero aver generato i dati osservati.\n\nSebbene questo approccio descrittivo possa rivelarsi utile in determinate circostanze, esso presenta due limiti fondamentali. In primo luogo, tende a produrre risultati fragili e di difficile replicazione, poiché le relazioni identificate non sono ancorate a una teoria solida riguardante i meccanismi causali che le generano. In secondo luogo, contribuisce a mantenere un divario tra la psicologia e altre discipline scientifiche – come la fisica, la biologia o l'economia – che da tempo fondano il proprio progresso sulla costruzione di modelli formali in grado di rappresentare esplicitamente i processi sottostanti ai fenomeni osservati.\n\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Cosa significa descrivere i dati rispetto a spiegare i processi che li generano.  \n- I limiti dei modelli fenomenologici e perché possono indurre in errore.  \n- Il ruolo delle distribuzioni di probabilità per rappresentare l’incertezza.  \n- Come confrontare modelli alternativi e scegliere quelli che meglio descrivono i dati e generalizzano a nuovi contesti.  \n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere il capitolo *Common Statistical Models* del testo di @kroese2025statistical.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n## Preparazione del Notebook\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n```\n:::\n\n:::\n\n### Dalla correlazione alla spiegazione\n\nUn modello che si limita a stimare una correlazione o una regressione lineare può dirci se due variabili si muovono insieme, ma non ci dice *perché* accade. Per esempio: osservare un’associazione tra stress e rendimento accademico è informativo, ma non basta per capire il processo attraverso cui lo stress influisce (o non influisce) sulla performance.\n\nIl passo avanti consiste nel cercare di rappresentare *come* i dati emergono da processi psicologici sottostanti. In altre parole, spostiamo l’attenzione dalle semplici relazioni osservate ai meccanismi generativi che le producono.\n\n#### Perché questo cambiamento è cruciale?\n\nQuesto cambiamento è cruciale perché permette di costruire modelli più vicini alla realtà dei fenomeni psicologici, rende le teorie più precise e testabili, e fornisce risultati più robusti e potenzialmente più replicabili, poiché radicati in una rappresentazione del processo e non solo in un dato campione.\n\n### Anticipazione\n\nNei prossimi paragrafi vedremo come questo approccio si traduca in pratica: non ci limiteremo a presentare i modelli di regressione nelle loro diverse varianti, ma esploreremo anche modelli che cercano di descrivere processi psicologici espliciti, come ad esempio il modello di Rescorla-Wagner per l’apprendimento associativo.\n\nL’obiettivo non è sostituire l’analisi statistica classica, ma integrarla con strumenti che ci aiutino a rispondere a una domanda più ambiziosa: quali processi mentali plausibili possono aver generato i dati che osserviamo?\n\n\n## Campionamento indipendente da una distribuzione fissa\n\nMolti modelli statistici tradizionali si basano sull'assunzione fondamentale che i dati osservati rappresentino un *processo di campionamento indipendente* da una distribuzione fissa. Prendiamo ad esempio il caso dei punteggi di ansia misurati in un campione di studenti: si assume che questi punteggi seguano una distribuzione normale caratterizzata da una media $\\mu$ e una deviazione standard $\\sigma$.\n\nIn questo quadro concettuale:\n\n* ogni singola osservazione viene considerata come un'estrazione indipendente dalla stessa distribuzione di probabilità sottostante;\n* l'obiettivo principale del modello statistico diventa quindi la stima dei parametri che definiscono questa distribuzione ($\\mu$ e $\\sigma$).\n\nQuesto approccio presenta indubbi vantaggi per la descrizione sintetica dei dati e l'identificazione delle loro caratteristiche distributive fondamentali. Tuttavia, è importante riconoscere i suoi limiti concettuali: questa prospettiva rimane essenzialmente muta riguardo ai meccanismi attraverso i quali i livelli di ansia effettivamente emergono o si modificano nel tempo. In altre parole, descrive i dati nella loro manifestazione osservabile (\"così come sono\"), ma non offre alcuna insight sui processi psicologici dinamici che li hanno generati. \n\n## Modelli fenomenologici: descrivere le associazioni\n\nUn passo in più è rappresentato dai modelli che analizzano *relazioni tra variabili*, come la regressione lineare o logistica. Questi approcci ci permettono di andare oltre la semplice descrizione di una distribuzione, consentendoci di studiare sistematicamente come una variabile dipendente cambia in funzione di una o più variabili indipendenti.\n\nPer esempio, possiamo modellare la relazione tra stress e rendimento accademico, verificando empiricamente se un aumento dei livelli di stress corrisponde effettivamente a un calo delle performance scolastiche.\n\nQuesti modelli statistici sono estremamente diffusi e costituiscono il fondamento metodologico di gran parte della ricerca psicologica contemporanea. Tuttavia, è importante riconoscere che rimangono essenzialmente modelli *fenomenologici*: descrivono efficacemente *che cosa* accade (documentando ad esempio l'esistenza di una correlazione tra stress e rendimento), ma non sono in grado di spiegare *perché* tale relazione esista.\n\nUn modello di regressione, infatti, non può dirci se lo stress riduce direttamente il rendimento, se entrambe le variabili sono influenzate da un fattore terzo (come il supporto sociale), o se la relazione evolve nel tempo attraverso complesse dinamiche di adattamento psicologico. Questa fragilità metodologica ha contribuito direttamente alla *crisi di replicazione*: modelli che descrivono soltanto associazioni spesso sembrano solidi in uno studio, ma non riescono a replicarsi in altri contesti, proprio perché non si appoggiano a un processo generativo condiviso.\n\n\n## Modelli meccanicistici: spiegare i processi\n\nI modelli meccanicistici, detti anche processuali, rappresentano un passo ulteriore rispetto ai modelli puramente statistici. Questi modelli non si limitano a descrivere associazioni tra variabili, ma cercano di formalizzare i meccanismi psicologici che generano i dati osservati.\n\nQuesti modelli sono costruiti a partire da ipotesi specifiche su come le persone percepiscono, apprendono, decidono o reagiscono a stimoli. Ogni parametro del modello possiede un significato psicologico interpretabile, come ad esempio la velocità di apprendimento, una soglia decisionale, o la sensibilità a ricompense e punizioni. In questa prospettiva, i dati non sono più considerati come semplici estrazioni indipendenti da una distribuzione fissa, ma come l'esito dinamico di un processo psicologico sottostante.\n\nUn esempio particolarmente illustrativo è il modello di Rescorla-Wagner per l'apprendimento associativo. Questo modello descrive come la forza di un'associazione tra stimoli viene aggiornata a ogni prova in base all'errore di previsione commesso dall'individuo. In questo caso, non ci limitiamo a stimare se \"esiste un effetto\" di uno stimolo, ma modelliamo esplicitamente il processo di apprendimento che produce le risposte osservate, offrendo così una comprensione più profonda e meccanicistica del fenomeno psicologico in esame. Modelli di questo tipo, radicati in un processo psicologico esplicito, hanno il potenziale di produrre risultati più robusti e *replicabili*: se il modello cattura davvero il meccanismo sottostante, allora la sua applicazione a nuovi dati dovrebbe confermare le stesse dinamiche di base, anche se le osservazioni specifiche cambiano.\n\n\n### Confronto tra i due approcci\n\nI modelli fenomenologici offrono il vantaggio della semplicità e sono spesso sufficienti per una descrizione iniziale dei dati. Tuttavia, questa semplicità comporta un rischio significativo: tendono a produrre spiegazioni fragili e poco replicabili, in quanto catturano relazioni superficiali senza indagare i meccanismi sottostanti.\n\nAl contrario, i modelli meccanicistici richiedono un maggior numero di ipotesi iniziali e presentano una complessità analitica superiore. Questo investimento aggiuntivo viene ricompensato da un fondamentale vantaggio epistemologico: ci avvicinano alla logica metodologica delle scienze naturali, permettendoci di spiegare i dati osservati attraverso la formalizzazione di processi generativi sottostanti. In questo modo, non ci limitiamo a descrivere le relazioni tra variabili, ma cerchiamo di comprendere i meccanismi causali che le producono.\n\n::: callout-note\n## Differenza intuitiva\n\nUn modello fenomenologico si limita a descrivere una relazione osservabile, affermando ad esempio che \"più ore di studio corrispondono a voti più alti\". Al contrario, un modello meccanicistico cerca di spiegare il processo sottostante questa relazione, proponendo ad esempio che \"ogni sessione di studio incrementa la forza della traccia mnestica con un determinato tasso di apprendimento, il quale a sua volta influenza direttamente la probabilità di rispondere correttamente durante l'esame\". \n\nMentre il primo si concentra sul *cosa* accade, il secondo cerca di spiegare *come* e *perché* accade.\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](04_statistical_models_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nModello fenomenologico: il focus è sulla forma della distribuzione e sui suoi parametri riassuntivi (media, varianza).\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](04_statistical_models_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nModello meccanicistico: il focus è sul *meccanismo nel tempo* (apprendimento): $V_t$ evolve in base all’errore di previsione e le osservazioni $Y_t$ sono rumore attorno a $V_t$.\n\n**Messaggio chiave:* descrivere *associazioni* vs spiegare *processi generativi*.\n\n## Valutazione e confronto dei modelli\n\nOgni modello psicologico, che sia descrittivo o meccanicistico, costituisce una *rappresentazione semplificata* della realtà. Nessun modello può catturare interamente la complessità dei fenomeni psicologici: il suo valore scientifico dipende fondamentalmente dalla capacità di aiutarci a comprendere e prevedere i dati osservati.\n\n### Due prospettive complementari\n\nLa valutazione dei modelli si articola su due dimensioni distinte ma complementari. Da un lato l'*adeguatezza esplicativa*, che misura quanto bene un modello riesce a descrivere i dati già osservati. Dall'altro la *capacità predittiva*, che valuta invece l'abilità del modello di generalizzare a nuovi dati non ancora raccolti.\n\nÈ importante notare come queste due dimensioni non sempre coincidano: un modello eccessivamente complesso può adattarsi perfettamente ai dati esistenti, mostrando un'eccellente adeguatezza esplicativa, ma rivelarsi al contempo incapace di fare previsioni accurate su dati nuovi, manifestando così una scarsa capacità predittiva.\n\n### Confrontare i modelli\n\nLa *crisi di replicazione* ci ricorda che non basta adattare bene un modello ai dati disponibili: ciò che conta è la capacità di prevedere dati nuovi. È proprio qui che la valutazione e il confronto dei modelli diventano strumenti centrali per una psicologia più solida. \n\nIl confronto tra modelli rappresenta un aspetto cruciale della ricerca scientifica, poiché riconosce che per uno stesso fenomeno possono esistere multiple spiegazioni plausibili. Il compito del ricercatore consiste nell'identificare il modello che produce le rappresentazioni più *utili* e *coerenti* con la realtà osservata.\n\nQuesto confronto può avvenire sia tra approcci diversi che all'interno dello stesso paradigma. I modelli *fenomenologici* e *meccanicistici*, ad esempio, possono essere messi a confronto: mentre il primo si limita a descrivere le associazioni tra variabili, il secondo avanza ipotesi specifiche sui processi generatori dei dati. Allo stesso modo, due modelli meccanicistici alternativi – come diverse teorie dell'apprendimento – possono essere confrontati per determinare quale meglio spieghi il comportamento osservato.\n\n### Anticipazione\n\nNei prossimi capitoli esploreremo le metodologie concrete per condurre questi confronti, introducendo strumenti statistici che quantificano oggettivamente la bontà predittiva dei modelli. In particolare:\n\n* approfondiremo criteri statistici come la *log-verosimiglianza*, il *WAIC* e il *LOO-CV*, che permettono un confronto formale delle capacità predittive dei modelli;\n\n* esamineremo casi di studio psicologici in cui modelli alternativi – come diversi modelli di apprendimento o processi decisionali – vengono sottoposti a verifica empirica sugli stessi dati.\n\nQuesto approccio ci permetterà di passare da valutazioni qualitative a giudizi quantitativi e rigorosi sulla bontà dei nostri modelli teorici.\n\n\n::: {.callout-note}\n\n#### Messaggio chiave\n\nUn modello non è mai “vero” in senso assoluto: è più o meno utile.\nLa valutazione e il confronto dei modelli sono strumenti fondamentali per rendere la psicologia una scienza **cumulativa**, in cui teorie diverse possono essere messe a confronto sulla base dei dati.\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](04_statistical_models_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](04_statistical_models_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nI modelli possono essere valutati secondo due prospettive fondamentali: quella esplicativa e quella predittiva. \n\nLa *valutazione esplicativa* (o _fit del modello_) misura quanto bene un modello riesce a descrivere i dati già osservati, ovvero quanto sia in grado di adattarsi alle informazioni in nostro possesso.\n\nLa *valutazione predittiva* (o _validazione del modello_) misura invece la capacità del modello di generalizzare, ovvero di fare previsioni accurate su dati nuovi, non ancora osservati e provenienti da outside del campione originario.\n\nIl messaggio chiave è che un modello statisticamente valido non è solo quello che spiega bene il passato, ma soprattutto quello che dimostra di saper prevedere in modo affidabile il futuro. La vera prova della bontà di un modello risiede nella sua capacità predittiva, non solo in quella descrittiva.\n\n\n### Un esempio psicologico: scelte alimentari negli adolescenti\n\nImmaginiamo di voler studiare le scelte alimentari di un gruppo di adolescenti, osservando se scelgono uno snack *salutare* o *non salutare* in una serie di decisioni.\n\n* **Approccio fenomenologico**\n  Possiamo costruire una *regressione logistica* che predice la probabilità di scegliere lo snack salutare in funzione di alcune variabili, ad esempio il livello di stress e la disponibilità economica. Questo modello ci direbbe se lo stress è associato a una minore probabilità di fare scelte salutari, senza però chiarire *perché* avvenga.\n\n* **Approccio meccanicistico**\n  Possiamo invece ipotizzare un *modello di apprendimento associativo* (ad esempio il modello di Rescorla–Wagner): ad ogni prova, l’adolescente aggiorna le proprie aspettative di ricompensa per ciascuna opzione sulla base dell’esperienza precedente. In questo quadro, i dati delle scelte non sono solo correlati a variabili esterne, ma sono l’esito di un processo dinamico di apprendimento governato da parametri interpretabili (tasso di apprendimento, sensibilità alla ricompensa, variabilità decisionale).\n\n#### Confronto dei due modelli\n\nEntrambi i modelli possono adattarsi agli stessi dati, ma offrono spiegazioni molto diverse: la regressione descrive un’associazione “statica” tra stress e scelta, mentre il modello di apprendimento descrive un meccanismo dinamico, cioè *come* gli adolescenti aggiornano le loro preferenze. Valutare e confrontare i modelli significa allora chiedersi quale delle due rappresentazioni sia *più utile*: quella che ci dice solo quali variabili sono correlate, o quella che propone un processo psicologico plausibile alla base delle decisioni?\n\n\n::: {.callout-note}\n\n#### Messaggio chiave\n\nGli stessi dati possono essere interpretati con modelli diversi. Il confronto tra modelli non è un lusso, ma una necessità: ci permette di capire quale rappresentazione dei dati sia più informativa e più vicina ai processi psicologici reali.\n:::\n\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo distinto tra due modi di intendere i modelli in psicologia:\n\n* i **modelli fenomenologici**, che descrivono le relazioni osservabili tra variabili;\n* i **modelli meccanicistici**, che cercano invece di rappresentare i processi psicologici che generano i dati.\n\nI primi hanno il vantaggio della semplicità e forniscono un punto di partenza utile per descrivere i fenomeni. I secondi, più complessi, ci permettono però di avvicinarci a una spiegazione: ci dicono non solo *che cosa* accade, ma anche *come* e *perché* accade.\n\nAbbiamo visto che la psicologia, per rafforzare la propria solidità scientifica, non può limitarsi all’analisi delle associazioni. È necessario un salto verso modelli che mettano al centro i *meccanismi generativi*. Solo così possiamo rendere le nostre teorie più precise, più testabili e più replicabili.\n\nUn altro punto fondamentale riguarda la *valutazione dei modelli*: non esiste un modello “vero” in senso assoluto, ma modelli più o meno utili. Per questo dobbiamo sempre confrontare alternative, verificare la loro capacità di spiegare i dati raccolti e soprattutto la loro forza nel prevedere dati nuovi.\n\nNei prossimi capitoli passeremo dal livello concettuale a quello operativo, vedendo come l’approccio bayesiano ci consenta di costruire e confrontare concretamente modelli fenomenologici e meccanicistici.\n\n::: {.callout-note}\n\n#### Messaggio chiave\n\nL’uso dei modelli meccanicistici, insieme a strumenti di confronto basati sulla capacità predittiva, rappresenta una via promettente per affrontare la crisi di replicabilità in psicologia. Nei capitoli successivi vedremo come tradurre questi principi in pratiche concrete di analisi statistica e di modellazione.\n:::\n\n\n::: {.callout-important title=\"Problemi\" collapse=\"true\"}\n1. Qual è il processo concettuale alla base della modellizzazione e dell'analisi statistica?  \n\n2. Cosa significa che un campione è indipendente e identicamente distribuito (iid) e perché questa assunzione è importante nei modelli statistici?\n\n3. Come si differenziano i modelli di campionamento da una singola distribuzione rispetto ai modelli di campioni multipli indipendenti?  \n\n4. Qual è la differenza tra regressione lineare semplice e regressione lineare multipla? \n\n5. In che modo i modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, si differenziano dai modelli statistici tradizionali?\n\n*Consegna:* Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n:::\n\n::: {.callout-tip title=\"Soluzioni\" collapse=\"true\"}\n\n1. Il processo concettuale della modellizzazione e analisi statistica inizia con un problema reale e i dati raccolti su tale problema. Si costruisce quindi un modello probabilistico che rappresenta le conoscenze disponibili e il modo in cui i dati sono stati ottenuti. L’analisi viene condotta all’interno del modello, producendo conclusioni sui suoi parametri. Infine, i risultati vengono tradotti in inferenze sulla realtà, con lo scopo di migliorare la comprensione del fenomeno studiato.\n\n2. Un campione è detto indipendente e identicamente distribuito (iid) se le osservazioni sono indipendenti tra loro e seguono la stessa distribuzione di probabilità. Questa assunzione è fondamentale perché semplifica le analisi statistiche e permette di applicare risultati teorici importanti, come la legge dei grandi numeri e il teorema del limite centrale.  \n\n3. Nei modelli di campionamento da una singola distribuzione, si assume che tutte le osservazioni provengano da una stessa popolazione e seguano la stessa distribuzione. Nei modelli di campioni multipli indipendenti, invece, si confrontano più gruppi distinti, ciascuno con la propria distribuzione, per studiare differenze tra le popolazioni. Un esempio è il confronto tra altezze di individui con madri fumatrici e non fumatrici. \n\n4. La regressione lineare semplice analizza la relazione tra una variabile dipendente e una sola variabile indipendente attraverso una relazione lineare. La regressione lineare multipla, invece, estende questo concetto a più variabili indipendenti, permettendo di modellare fenomeni più complessi e controllare l’effetto di più fattori simultaneamente.  \n\n5. I modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, differiscono dai modelli statistici tradizionali perché mirano a simulare i processi mentali e decisionali sottostanti il comportamento umano. I modelli statistici descrivono principalmente relazioni tra variabili nei dati osservati, mentre i modelli computazionali cercano di rappresentare dinamicamente i meccanismi cognitivi e comportamentali che generano tali dati.\n:::\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#> [8] base     \n#> \n#> other attached packages:\n#>  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#>  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [25] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#>  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#>  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#> [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#> [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#> [16] yaml_2.3.10           knitr_1.50            labeling_0.4.3       \n#> [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#> [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#> [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#> [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#> [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#> [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#> [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#> [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#> [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#> [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#> [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#> [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#> [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#> [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#> [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#> [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#> [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#> [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#> [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#> [76] zoo_1.8-14            pkgconfig_2.0.3\n```\n:::\n\n:::\n\n## Bibliografia  {.unnumbered .unlisted}\n\n",
    "supporting": [
      "04_statistical_models_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}