{
  "hash": "319883144fc9eac6890f3aac2263c8e6",
  "result": {
    "engine": "knitr",
    "markdown": "# ANOVA ad una via {#sec-anova1via}\n\n::: {.epigraph}\n> “The agricultural analogy is for [ANOVA] what the barnyard is to the city child—a romantic but inefficient source of fundamental concepts.”\n>\n> -- **David Bakan**, The Test of Significance in Psychological Research (1966)\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nNei capitoli precedenti abbiamo affrontato l’inferenza su una media, il confronto tra due gruppi e la valutazione della grandezza dell’effetto. Abbiamo visto come questi problemi possano essere formulati in modo elegante all’interno del modello lineare e affrontati sia con l’approccio frequentista sia con quello bayesiano.\n\nUn passo ulteriore, molto frequente nella ricerca psicologica, è il confronto tra *più di due gruppi o condizioni*. Pensiamo, ad esempio, a uno studio in cui vogliamo confrontare il livello medio di ansia in tre diversi contesti sperimentali, o a una ricerca educativa che mette a confronto più metodi di insegnamento. In questi casi, la domanda non è più soltanto se due medie differiscono, ma se esistono *differenze sistematiche* tra più gruppi.\n\nLo strumento tradizionalmente utilizzato in ambito frequentista è l’*ANOVA a una via* (*Analysis of Variance*), che permette di testare l’ipotesi nulla di uguaglianza tra tutte le medie di popolazione. Tuttavia, come per i casi precedenti, anche qui la prospettiva bayesiana offre un quadro più ricco: non ci limita a un verdetto dicotomico, ma ci restituisce la distribuzione a posteriori dei parametri, consentendo di quantificare la plausibilità di scenari diversi e di valutare l’ampiezza delle differenze.\n\nIn questo capitolo vedremo come l’ANOVA a una via possa essere interpretata come un caso particolare del modello di regressione lineare con variabile indicatrice, e come possa essere affrontata in chiave bayesiana per ottenere inferenze più trasparenti e direttamente interpretabili. In questo modo, l’ANOVA non appare come uno strumento separato, ma come parte integrante di un impianto metodologico unificato, fondato sul modello lineare.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Fare inferenza sulla media di un campione.\n- Trovare le distribuzioni a posteriori usando `brms`.\n- Verificare il modello usando i pp-check plots.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere il capitolo *Geocentric models* di Statistical rethinking [@McElreath_rethinking].\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)\n```\n:::\n\n:::\n\n\n## Codifica del modello con variabili dummy\n\nSupponiamo un esperimento con tre gruppi. Per rappresentare questo fattore all’interno di un modello lineare, usiamo due variabili dummy e consideriamo il terzo gruppo come riferimento implicito. Il modello assume la forma:\n\n$$\nY_i = \\alpha + \\gamma_1 D_{i1} + \\gamma_2 D_{i2} + \\varepsilon_i\n$$ {#eq-anova1}\n\ndove:\n\n* $\\alpha$ è l’intercetta del modello,\n* $\\gamma_1$ e $\\gamma_2$ sono i coefficienti associati alle variabili dummy,\n* $D_{i1}$ e $D_{i2}$ indicano l’appartenenza dell’osservazione $i$ ai gruppi 1 e 2, rispettivamente,\n* $\\varepsilon_i$ è l’errore aleatorio.\n\nLa codifica delle dummy è la seguente:\n\n$$\n\\begin{array}{c|cc}\n\\text{Gruppo} & D_{1} & D_{2} \\\\\n\\hline\n1 & 1 & 0 \\\\\n2 & 0 & 1 \\\\\n3 & 0 & 0\n\\end{array}\n$$ {#eq-anova1a}\n\n\n### Interpretazione dei parametri\n\nCon questa codifica, possiamo esprimere le medie di ciascun gruppo come:\n  \n$$\n\\begin{aligned}\n\\mu_1 &= \\alpha + \\gamma_1 \\\\\n\\mu_2 &= \\alpha + \\gamma_2 \\\\\n\\mu_3 &= \\alpha\n\\end{aligned}\n$$\n  \nDa cui otteniamo:\n  \n$$\n\\alpha = \\mu_3, \\quad \\gamma_1 = \\mu_1 - \\mu_3, \\quad \\gamma_2 = \\mu_2 - \\mu_3.\n$$\n  \nQuindi:\n  \n* $\\alpha$: media del gruppo 3 (riferimento),\n* $\\gamma_1$: quanto il gruppo 1 si discosta da $\\mu_3$,\n* $\\gamma_2$: quanto il gruppo 2 si discosta da $\\mu_3$.\n\nIn un'ottica bayesiana, questi coefficienti possono essere pensati come distribuzioni: esprimono *quanto crediamo che ciascuna differenza sia plausibile*, date le osservazioni. Passiamo ora a una simulazione.\n\n\n## Simulazione\n\nSimuliamo un esperimento con tre condizioni: `controllo`, `psicoterapia1` e `psicoterapia2`. Ogni gruppo ha una media diversa ma la stessa deviazione standard. Ci interessa modellare la variabilità tra le condizioni e interpretare le differenze in modo probabilistico.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\n\nn <- 30  # numero di osservazioni per gruppo\n# Medie di ciascun gruppo\nmean_control <- 30\nmean_psico1  <- 25\nmean_psico2  <- 20\n# Deviazione standard comune\nsd_value <- 5\n\n# Generazione dei dati\ncontrollo     <- rnorm(n, mean_control, sd_value)\npsicoterapia1 <- rnorm(n, mean_psico1,  sd_value)\npsicoterapia2 <- rnorm(n, mean_psico2,  sd_value)\n\n# Creazione del data frame\ndf <- data.frame(\n  condizione = rep(c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\"), each = n),\n  punteggio  = c(controllo, psicoterapia1, psicoterapia2)\n)\n\ndf |> head()\n#>   condizione punteggio\n#> 1  controllo      27.2\n#> 2  controllo      28.8\n#> 3  controllo      37.8\n#> 4  controllo      30.4\n#> 5  controllo      30.6\n#> 6  controllo      38.6\n```\n:::\n\n\n\n### Esplorazione iniziale\n\nVisualizziamo le distribuzioni dei punteggi:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +\n  geom_violin(trim = FALSE, color = css_palette$text_primary, linewidth = 0.3) +\n  geom_boxplot(width = 0.22, outlier.shape = NA,\n               color = css_palette$text_primary, fill = scales::alpha(\"white\", 0.55)) +\n  labs(x = \"Condizione sperimentale\", y = \"Punteggio di depressione\") +\n  scale_fill_manuscript(limits = levels(df$condizione), drop = FALSE) +  \n  theme_manuscript() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](11_anova_1via_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nCalcoliamo media e deviazione standard per ogni gruppo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf |> \n  group_by(condizione) |> \n  summarize(\n    media = mean(punteggio),\n    sd = sd(punteggio)\n  )\n#> # A tibble: 3 × 3\n#>   condizione    media    sd\n#>   <chr>         <dbl> <dbl>\n#> 1 controllo      29.8  4.91\n#> 2 psicoterapia1  25.9  4.18\n#> 3 psicoterapia2  20.1  4.35\n```\n:::\n\n\n\n## Modello lineare con variabili dummy\n\nConvertiamo `condizione` in fattore e definiamo `controllo` come categoria di riferimento:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf$condizione <- factor(df$condizione)\ndf$condizione <- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#>               psicoterapia1 psicoterapia2\n#> controllo                 0             0\n#> psicoterapia1             1             0\n#> psicoterapia2             0             1\n```\n:::\n\n\nIl modello di regressione con le variabili dummy sarà:\n\n$$\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{psicoterapia1}_i + \\beta_2 \\cdot \\text{psicoterapia2}_i + \\varepsilon_i,\n$$\n\ndove:\n\n* $\\beta_0$ è la media del gruppo di **controllo**;\n* $\\beta_1$ e $\\beta_2$ sono le differenze tra le rispettive psicoterapie e il gruppo di controllo.\n\n\n### Stima del modello\n\nEseguiamo una prima analisi usando il metodo di massima verosimiglianza:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfm1 <- lm(punteggio ~ condizione, data = df)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fm1)\n#> \n#> Call:\n#> lm(formula = punteggio ~ condizione, data = df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -11.668  -2.620  -0.183   2.681  10.128 \n#> \n#> Coefficients:\n#>                         Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)               29.764      0.819   36.33  < 2e-16\n#> condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#> condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#> \n#> Residual standard error: 4.49 on 87 degrees of freedom\n#> Multiple R-squared:  0.446,\tAdjusted R-squared:  0.434 \n#> F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n```\n:::\n\n\nVerifica delle medie e differenze tra i gruppi:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nout <- tapply(df$punteggio, df$condizione, mean)\nout[2] - out[1]  # psicoterapia1 - controllo\n#> psicoterapia1 \n#>         -3.87\nout[3] - out[1]  # psicoterapia2 - controllo\n#> psicoterapia2 \n#>         -9.64\n```\n:::\n\n\n\n## Contrasti personalizzati\n\nI contrasti ci permettono di andare oltre il test globale e formulare ipotesi teoriche mirate. Ad esempio:\n\n- la media del gruppo controllo è diversa dalla media delle due psicoterapie?\n- le due psicoterapie differiscono tra loro?\n\nA questo fine, specifichiamo la seguente matrice dei contrasti:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmy_contrasts <- matrix(c(\n  0.6667,  0,     # controllo\n -0.3333,  0.5,   # psicoterapia1\n -0.3333, -0.5    # psicoterapia2\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts) <- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts) <- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\ncontrasts(df$condizione) <- my_contrasts\n```\n:::\n\n\nAdattiamo il modello:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod_custom <- lm(punteggio ~ condizione, data = df)\n```\n:::\n\n\nEsaminiamo i coefficienti:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(mod_custom)\n#> \n#> Call:\n#> lm(formula = punteggio ~ condizione, data = df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -11.668  -2.620  -0.183   2.681  10.128 \n#> \n#> Coefficients:\n#>                             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)                   25.259      0.473   53.40  < 2e-16\n#> condizioneCtrl_vs_PsicoMean    6.758      1.003    6.73  1.7e-09\n#> condizioneP1_vs_P2             5.770      1.159    4.98  3.2e-06\n#> \n#> Residual standard error: 4.49 on 87 degrees of freedom\n#> Multiple R-squared:  0.446,\tAdjusted R-squared:  0.434 \n#> F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n```\n:::\n\n\nInterpretazione dei coefficienti:\n\n* **Intercetta**: non rappresenta più una singola media, ma una combinazione lineare dei gruppi.\n* **Ctrl\\_vs\\_PsicoMean**: confronta la media di `controllo` con la media combinata delle due psicoterapie.\n* **P1\\_vs\\_P2**: differenza tra le due psicoterapie.\n\nVerifica manuale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Controllo - media delle psicoterapie\nout[1] - (out[2] + out[3]) / 2\n#> controllo \n#>      6.76\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Psicoterapia1 - Psicoterapia2\nout[2] - out[3]\n#> psicoterapia1 \n#>          5.77\n```\n:::\n\n\n\n## Estensione bayesiana con `brms` e `emmeans`\n\nUsiamo ora il modello bayesiano:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod <- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(mod)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: punteggio ~ condizione \n#>    Data: df (Number of observations: 90) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Regression Coefficients:\n#>                             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n#> Intercept                      25.26      0.48    24.33    26.15 1.00     4321\n#> condizioneCtrl_vs_PsicoMean     6.78      1.04     4.73     8.85 1.00     4260\n#> condizioneP1_vs_P2              5.76      1.16     3.49     8.08 1.00     4598\n#>                             Tail_ESS\n#> Intercept                       2937\n#> condizioneCtrl_vs_PsicoMean     2964\n#> condizioneP1_vs_P2              2785\n#> \n#> Further Distributional Parameters:\n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     4.54      0.34     3.93     5.26 1.00     4287     3279\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nLe medie marginali e i confronti possono essere ottenuti con il pacchetto `emmeans`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nem <- emmeans(mod, specs = \"condizione\")\nem\n#>  condizione    emmean lower.HPD upper.HPD\n#>  controllo       29.8      28.1      31.4\n#>  psicoterapia1   25.9      24.3      27.5\n#>  psicoterapia2   20.1      18.4      21.7\n#> \n#> Point estimate displayed: median \n#> HPD interval probability: 0.95\n```\n:::\n\n\nConfronti tra gruppi:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npairs(em)  # confronti a coppie\n#>  contrast                      estimate lower.HPD upper.HPD\n#>  controllo - psicoterapia1         3.90      1.70      6.21\n#>  controllo - psicoterapia2         9.65      7.31     12.03\n#>  psicoterapia1 - psicoterapia2     5.76      3.57      8.14\n#> \n#> Point estimate displayed: median \n#> HPD interval probability: 0.95\n```\n:::\n\n\nContrasti personalizzati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmy_list <- list(\n  \"Ctrl_vs_PsicoMean\" = c(\n    \"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5\n  ),\n  \"P1_vs_P2\" = c(\n    \"controllo\" = 0, \"psicoterapia1\" = 1, \"psicoterapia2\" = -1\n  )\n)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncontrast(em, method = my_list)\n#>  contrast          estimate lower.HPD upper.HPD\n#>  Ctrl_vs_PsicoMean     6.77      4.77      8.88\n#>  P1_vs_P2              5.76      3.57      8.14\n#> \n#> Point estimate displayed: median \n#> HPD interval probability: 0.95\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizzazione\nplot(em)\n```\n\n::: {.cell-output-display}\n![](11_anova_1via_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo visto come l’*ANOVA a una via* non sia un metodo a sé stante, ma un caso particolare del modello lineare. Attraverso l’uso di variabili indicatrici, infatti, il confronto tra più gruppi può essere formulato come un’estensione naturale della regressione, in cui ciascuna media di gruppo è rappresentata da un parametro del modello.\n\nL’approccio frequentista tradizionale all’ANOVA si concentra sul test dell’ipotesi nulla di uguaglianza tra le medie, producendo un singolo indice sintetico (la statistica $F$). L’approccio bayesiano, invece, ci permette di andare oltre: possiamo stimare la distribuzione a posteriori delle differenze tra gruppi, valutare la probabilità che certe medie siano più alte o più basse di altre, e soprattutto ragionare sulla rilevanza pratica delle differenze osservate.\n\nL’insegnamento più importante è che regressione e ANOVA non sono strumenti separati, ma due volti dello stesso impianto metodologico. Il modello lineare costituisce il quadro unificante che ci consente di descrivere, stimare e interpretare relazioni tra variabili, sia quantitative sia categoriali, con la stessa logica di base.\n\nCon questo capitolo si chiude la sezione dedicata alla regressione. Abbiamo percorso un itinerario che ci ha portato dalla regressione bivariata alla regressione verso la media, dal confronto tra due gruppi all’ANOVA, passando per l’interpretazione bayesiana dei modelli e per la loro implementazione in Stan. Il filo conduttore è stato duplice: da un lato, la consapevolezza che i modelli lineari sono strumenti *fenomenologici*, utili per descrivere le associazioni ma non per spiegare i meccanismi sottostanti; dall’altro, la convinzione che l’approccio *bayesiano* renda queste descrizioni più trasparenti, interpretabili e coerenti con il modo in cui la psicologia scientifica dovrebbe affrontare l’incertezza.\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] emmeans_1.11.2-8      bayestestR_0.17.0     cmdstanr_0.9.0       \n#>  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#> [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [28] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#> [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#> [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#> [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#> [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#> [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#> [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#> [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#> [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#> [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#> [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#> [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#> [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#> [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#> [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#> [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#> [55] checkmate_2.3.3       stats4_4.5.1          insight_1.4.2        \n#> [58] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#> [61] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#> [64] glue_1.8.0            tools_4.5.1           data.table_1.17.8    \n#> [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#> [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#> [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#> [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#> [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#> [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#> [85] MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n",
    "supporting": [
      "11_anova_1via_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}