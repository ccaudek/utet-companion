{
  "hash": "38eb6ef7ca6ff9df1b2730b664c793d4",
  "result": {
    "engine": "knitr",
    "markdown": "# Errore di specificazione e bias da variabile omessa {#sec-omitted-variable}\n\n::: {.epigraph}\n\n> “The coefficients may be useful for descriptive purposes, but not for causal inference or even prediction.”\n>\n> — **David A. Freedman**, From Association to Causation via Regression\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nFinora abbiamo presentato la regressione lineare come uno strumento potente e flessibile per descrivere relazioni tra variabili. Abbiamo visto come stimarne i parametri, come interpretarli e come implementarli sia in R che in Stan. Ma in tutte queste applicazioni abbiamo dato per scontato un punto cruciale: che il modello fosse *specificato correttamente*.\n\nNella pratica, questa condizione è raramente soddisfatta. Può accadere che una variabile rilevante non sia stata inclusa nel modello, oppure che la forma funzionale ipotizzata non descriva adeguatamente la relazione reale. In questi casi parliamo di *errore di specificazione del modello*.\n\nUna delle conseguenze più importanti è il cosiddetto *bias da variabile omessa*: quando trascuriamo un predittore correlato sia con la variabile dipendente sia con altri predittori inclusi, le stime dei coefficienti risultano distorte. Questo non è un dettaglio tecnico, ma un problema sostanziale: potremmo attribuire a un predittore un effetto che in realtà appartiene a un altro, fraintendendo così i meccanismi che hanno generato i dati.\n\nIn questo capitolo analizzeremo cosa significa errore di specificazione, mostreremo matematicamente come nasce il bias da variabile omessa e discuteremo le sue implicazioni nella ricerca psicologica. Comprendere questi limiti è fondamentale non solo per interpretare in modo corretto i risultati della regressione, ma anche per formulare modelli più adeguati e consapevoli.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n* Bias da variabile omessa: escludere una variabile rilevante altera sistematicamente i coefficienti.\n* Condizioni del bias.\n* Implicazioni: i coefficienti OLS non sono interpretabili in chiave causale; la regressione è *fenomenologica*.\n* Prospettiva: privilegiare modelli meccanicistici (es., Rescorla–Wagner, DDM, dinamici EMA).\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\nPer seguire al meglio questo capitolo è utile avere:\n\n- una conoscenza di base della *regressione lineare semplice* e del concetto di coefficiente di regressione.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, cmdstanr, tidybayes, loo, patchwork)\n```\n:::\n\n:::\n\n\n## Errore di specificazione e bias da variabile omessa {#sec-ovb}\n\n### Idea chiave\n\nSe il *vero* modello è\n\n$$\nY=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\varepsilon,\\qquad \\mathbb{E}[\\varepsilon\\mid X_1,X_2]=0,\n$$\nma stimiamo erroneamente il modello che *omette* $X_2$,\n\n$$\nY=\\alpha_0+\\alpha_1X_1+u,\n$$\nallora il coefficiente su $X_1$ risulta distorto quando:\n\n1. $X_2$ ha *effetto diretto* su $Y$ ($\\beta_2\\neq 0$);\n2. $X_2$ è *correlata* con $X_1$ ($\\mathrm{Corr}(X_1,X_2)\\neq 0$).\n\n\n### Dimostrazione (via standardizzazione)\n\n#### Passo 1 — Standardizza le variabili\n\nDefiniamo medie $\\mu_1,\\mu_2,\\mu_Y$ e deviazioni standard $\\sigma_1,\\sigma_2,\\sigma_Y$. Poniamo\n\n$$\nZ_1=\\frac{X_1-\\mu_1}{\\sigma_1},\\qquad \nZ_2=\\frac{X_2-\\mu_2}{\\sigma_2},\\qquad\nZ_Y=\\frac{Y-\\mu_Y}{\\sigma_Y}.\n$$\n\nPer costruzione: \n\n- $\\mathrm{Var}(Z_1)=\\mathrm{Var}(Z_2)=1$, \n- $\\mathrm{Cov}(Z_1,Z_2)=\\rho_{12}=\\mathrm{Corr}(X_1,X_2)$.\n\nIl *modello vero standardizzato* è\n\n$$\nZ_Y=\\gamma_1 Z_1+\\gamma_2 Z_2+\\varepsilon_z,\\qquad \\mathbb{E}[\\varepsilon_z\\mid Z_1,Z_2]=0,\n$$\ncon *beta standardizzati*\n\n$$\n\\gamma_1=\\beta_1\\,\\frac{\\sigma_1}{\\sigma_Y},\\qquad\n\\gamma_2=\\beta_2\\,\\frac{\\sigma_2}{\\sigma_Y}.\n$$\n\n#### Passo 2 — Stima (erronea) che omette $Z_2$\n\nStimiamo la regressione univariata\n\n$$\nZ_Y=\\delta_1 Z_1 + \\text{errore}.\n$$\n\nPer OLS,\n\n$$\n\\hat\\delta_1=\\frac{\\mathrm{Cov}(Z_1,Z_Y)}{\\mathrm{Var}(Z_1)}=\\mathrm{Cov}(Z_1,Z_Y),\n$$\ndato che $\\mathrm{Var}(Z_1)=1$.\n\nUsiamo il modello vero standardizzato:\n\n$$\n\\begin{align}\n\\mathrm{Cov}(Z_1,Z_Y)\n&=\\mathrm{Cov}\\big(Z_1,\\gamma_1Z_1+\\gamma_2Z_2+\\varepsilon_z\\big)\\notag\\\\\n&=\\gamma_1\\underbrace{\\mathrm{Var}(Z_1)}_{=1}\n+\\gamma_2\\,\\mathrm{Cov}(Z_1,Z_2)\n+\\underbrace{\\mathrm{Cov}(Z_1,\\varepsilon_z)}_{=0}.\n\\end{align} \n$$\n\nQuindi\n\n$$\n\\boxed{\\;\\hat\\delta_1=\\gamma_1+\\gamma_2\\,\\rho_{12}\\;}.\n$$\n\n**Lettura immediata:** il coefficiente stimato univariato mescola l’effetto diretto standardizzato di $X_1$ ($\\gamma_1$) con un termine spurio $\\gamma_2\\rho_{12}$ dovuto all’omissione di $X_2$.\n\n\n### Ritraduzione ai coefficienti non standardizzati\n\nTra i coefficienti vale\n\n$$\n\\hat\\delta_1=\\frac{\\sigma_1}{\\sigma_Y}\\,\\hat\\alpha_1,\\qquad\n\\gamma_1=\\beta_1\\,\\frac{\\sigma_1}{\\sigma_Y},\\qquad\n\\gamma_2=\\beta_2\\,\\frac{\\sigma_2}{\\sigma_Y}.\n$$\n\nDalla formula standardizzata\n\n$$\n\\hat\\delta_1=\\gamma_1+\\gamma_2\\rho_{12}\n$$\nsegue\n\n$$\n\\frac{\\sigma_1}{\\sigma_Y}\\,\\hat\\alpha_1\n=\\beta_1\\frac{\\sigma_1}{\\sigma_Y}\n+\\beta_2\\frac{\\sigma_2}{\\sigma_Y}\\rho_{12}.\n$$\n\nMoltiplicando per $\\sigma_Y/\\sigma_1$ e ricordando che\n$\\rho_{12}=\\dfrac{\\mathrm{Cov}(X_1,X_2)}{\\sigma_1\\sigma_2}$,\nottieniamo la forma non standardizzata:\n\n$$\n\\boxed{\\;\\hat\\alpha_1=\\beta_1+\\beta_2\\,\\frac{\\mathrm{Cov}(X_1,X_2)}{\\mathrm{Var}(X_1)}\\;}.\n$$\n\n**Bias (in media):**\n\n$$\n\\boxed{\\;\\mathbb{E}[\\hat\\alpha_1]-\\beta_1\n=\\beta_2\\,\\frac{\\mathrm{Cov}(X_1,X_2)}{\\mathrm{Var}(X_1)}\\;}\n\\quad\\Longleftrightarrow\\quad\n\\boxed{\\;\\mathbb{E}[\\hat\\delta_1]-\\gamma_1=\\gamma_2\\rho_{12}\\;}.\n$$\n\n\n\n### Interpretazione didattica\n\n* **Condizioni per il bias:** serve *sia* $\\beta_2\\neq 0$ (l’omessa $X_2$ conta davvero su $Y$) *sia* $\\rho_{12}\\neq 0$ (l’omessa $X_2$ è correlata con $X_1$). Se una condizione manca, il bias svanisce.\n* **Segno del bias (scala standardizzata):** $\\mathrm{Bias}(\\hat\\delta_1)=\\gamma_2\\rho_{12}$.\n  - $\\gamma_2>0$ e $\\rho_{12}>0$ ⇒ *sovrastima*; \n  - $\\gamma_2>0$ e $\\rho_{12}<0$ ⇒ *sottostima*.\n\n\n### Perché conta in psicologia\n\nLa regressione multipla è un modello *fenomenologico*: fotografa *associazioni* tra variabili, non i *meccanismi* che le generano. In contesti psicologici, l’*omissione di variabili rilevanti* è spesso inevitabile: non conosciamo o non misuriamo tutti i determinanti di $Y$. Ne segue che i coefficienti parziali possono essere *sistematicamente distorti* e, dunque, fuorvianti.\n\n\n### Oltre la regressione: modelli formali dei processi\n\nPer queste ragioni, i modelli di regressione multipla dovrebbero avere un ruolo limitato in psicologia. Molto più promettente è l’uso di *modelli formali* che cercano di rappresentare i meccanismi psicologici sottostanti. Esempi discussi in questa dispensa sono:\n\n- il *modello di apprendimento di Rescorla–Wagner*, che spiega come gli individui aggiornano le loro aspettative sulla base del feedback;  \n- il *Drift Diffusion Model (DDM)*, che descrive i processi decisionali come un accumulo di evidenza nel tempo;  \n- i *modelli dinamici per dati EMA*, che mostrano come l’umore e altre variabili psicologiche cambiano nel tempo.  \n\nQuesti modelli non si limitano a descrivere correlazioni, ma cercano di catturare i *processi causali* che generano i dati osservati.\n\n\n::: {.callout-tip collapse=true title=\"1) Mappa del bias: variazione di $\\rho_{12}$ e $\\beta_2$\"}\nEsaminiamo come **segno** e **magnitudo** del bias cambino al variare della correlazione tra regressori ($\\rho_{12}$) e dell’effetto dell’omessa ($\\beta_2$). La heatmap visualizza $\\hat\\alpha_1-\\beta_1$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(1)\nn <- 3000; beta1 <- 1; sig <- 1\nrho_seq <- seq(-.9,.9,length=19); b2_seq <- seq(-1.5,1.5,length=19)\n\ngrid <- expand.grid(rho=rho_seq, b2=b2_seq)\n\nsim_once <- function(rho, beta2){\n  X1 <- rnorm(n)\n  X2 <- rho*X1 + sqrt(1-rho^2)*rnorm(n)   # Corr(X1,X2)=rho\n  Y  <- beta1*X1 + beta2*X2 + rnorm(n,0,sig)\n  coef(lm(Y ~ X1))[2] - beta1             # ritorna uno scalare, senza nome\n}\n\ngrid$bias <- mapply(sim_once, grid$rho, grid$b2)  # <-- niente t(), niente [, \"bias\"]\n\nggplot(grid, aes(x=rho, y=b2, fill=bias)) +\n  geom_tile() + scale_fill_gradient2() +\n  labs(x=expression(rho[12]), y=expression(beta[2]), fill=\"Bias\",\n       title=\"Bias da variabile omessa al variare di ρ12 e β2\")\n```\n\n::: {.cell-output-display}\n![](06_specification_error_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Commento e interpretazione.**\nL’asse orizzontale riporta la correlazione tra i regressori $\\rho_{12}=\\mathrm{Corr}(X_1,X_2)$; l’asse verticale l’effetto dell’omessa $X_2$ su $Y$ ($\\beta_2$). Il riempimento (“Bias”) è $\\hat\\alpha_1-\\beta_1$, cioè di quanto il coefficiente sul regressore incluso $X_1$ *sovrastima* (valori > 0) o *sottostima* (valori < 0) il suo valore vero.\n\n* **Segno del bias.** Il bias è (in media) $\\beta_2\\,\\rho_{12}$.\n  Quadranti:\n  \n  - $\\beta_2>0,\\ \\rho_{12}>0$ → **positivo** (sovrastima);\n  - $\\beta_2>0,\\ \\rho_{12}<0$ → **negativo** (sottostima);\n  - $\\beta_2<0,\\ \\rho_{12}>0$ → **negativo**;\n  - $\\beta_2<0,\\ \\rho_{12}<0$ → **positivo**.\n  \n  Le bande di colore cambiano segno attraversando le linee $\\rho_{12}=0$ o $\\beta_2=0$, dove il bias si annulla (zona chiara).\n\n* **Magnitudo.** Aumenta con $|\\beta_2|$ e $|\\rho_{12}|$: gli angoli (|ρ|≈0.9, |β₂|≈1.5) mostrano i *bias maggiori*. La diagonale basso-sinistra → alto-destra evidenzia bias *positivo*; l’altra diagonale bias *negativo*.\n\n* **Simmetria e teoria.** La mappa è sostanzialmente simmetrica perché il bias teorico è $\\beta_2\\rho_{12}$. Le piccole irregolarità dipendono dal rumore Monte Carlo della simulazione (con $n$ finito). \n\n* **Lettura pratica.** Se *anche solo una* tra correlazione tra regressori ($\\rho_{12}$) o effetto dell’omessa ($\\beta_2$) è prossima a zero, il bias è trascurabile (aree chiare lungo gli assi). Quando *entrambi* sono lontani da zero, l’OLS nel modello omesso è *fuorviante*.\n\n:::\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo visto come la validità delle stime di regressione dipenda in modo cruciale dalla corretta specificazione del modello. Abbiamo discusso in particolare il *bias da variabile omessa*, mostrando che trascurare un predittore rilevante può distorcere i coefficienti degli altri, inducendo interpretazioni fuorvianti.\n\nQuesto non è un problema marginale: nella ricerca psicologica capita spesso di lavorare con costrutti complessi, difficili da misurare, e di non poter includere tutte le variabili rilevanti. In queste condizioni, le stime di regressione rischiano di riflettere relazioni spurie piuttosto che effetti reali. Essere consapevoli di questi limiti è quindi essenziale per interpretare i risultati con cautela e per progettare studi che riducano al minimo il rischio di specificare modelli inadeguati.\n\nLa lezione più importante è che la regressione, come ogni modello fenomenologico, non deve essere scambiata per una spiegazione causale: è un modo per descrivere associazioni nei dati, che può però facilmente indurre in errore se non viene accompagnato da una riflessione critica sulla struttura del modello.\n\nNel prossimi capitolo vedremo come l’ANOVA a una via possa essere interpretata come un caso particolare del modello lineare. Sarà l’occasione per consolidare ulteriormente la visione unificata che guida questa sezione: regressione e confronto tra gruppi non sono strumenti separati, ma facce diverse dello stesso impianto metodologico.\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#>  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#>  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [25] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#> [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#> [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#> [16] labeling_0.4.3        rmarkdown_2.29        ps_1.9.1             \n#> [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#> [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#> [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#> [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#> [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#> [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#> [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#> [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#> [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#> [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#> [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#> [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#> [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#> [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#> [61] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#> [64] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#> [67] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#> [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#> [73] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#> [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#> [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65\n```\n:::\n\n:::\n\n\n## Bibliografia {.unnumbered .unlisted}\n",
    "supporting": [
      "06_specification_error_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}