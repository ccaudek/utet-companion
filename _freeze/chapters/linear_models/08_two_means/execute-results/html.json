{
  "hash": "3a168b97091f43d8b6b62f8c94183a4d",
  "result": {
    "engine": "knitr",
    "markdown": "# Confronto tra le medie di due gruppi {#sec-linear-models-two-groups}\n\n::: {.epigraph}\n> “La domanda non è \"è la differenza reale?\", ma piuttosto \"quanto è grande la differenza, e di quanto siamo certi?”\n>\n> -- **Jeffrey Rouder**, Psicologo e Statistico, esperto di statistica bayesiana\n:::\n\n## Introduzione {.unnumbered .unlisted}\n\nUno dei problemi di ricerca più frequenti in psicologia riguarda il *confronto tra due gruppi o condizioni*. Ci chiediamo, ad esempio, se un gruppo di trattamento ottenga risultati migliori di un gruppo di controllo, o se un campione clinico differisca da un campione non clinico in una certa misura psicologica. In questi casi, la questione cruciale non è soltanto *se* esista una differenza, ma anche *quanto grande* essa sia e con quale grado di *incertezza* possiamo descriverla.\n\nIn questo capitolo affrontiamo il problema con un approccio *bayesiano*. Immaginiamo di avere una variabile continua di esito, indicata con $y_{ig}$, che misura l’osservazione $i$ nel gruppo $g$ (dove $g$ può assumere valore 0 oppure 1). Un modello semplice e naturale assume che i punteggi in ciascun gruppo seguano una distribuzione normale con la propria media:\n\n$$\ny_{ig}\\sim\\mathcal N(\\mu_g,\\ \\sigma), \n\\qquad \\Delta=\\mu_1-\\mu_0 .\n$$\n\nLa quantità di interesse centrale è $\\Delta$, la **differenza tra le due medie**.\n\nQuesto stesso modello può essere scritto in forma equivalente come un *modello di regressione lineare* semplice, utilizzando una variabile indicatrice $x_i$ che codifica l’appartenenza al gruppo (0 = gruppo di riferimento, 1 = gruppo sperimentale):\n\n$$\ny_i \\sim \\mathcal N(\\alpha+\\beta x_i,\\ \\sigma).\n$$\n\nIn questa formulazione, l’intercetta $\\alpha$ rappresenta la media del gruppo di riferimento ($\\mu_0$), mentre il coefficiente $\\beta$ coincide con la differenza tra le due medie ($\\Delta$). Quando necessario, considereremo anche la versione *standardizzata* di questo effetto, definita come $d = \\Delta / \\sigma$, che fornisce una misura della *dimensione dell’effetto* indipendente dalla scala di misura utilizzata.\n\nRispetto all’approccio frequentista tradizionale, che si concentra principalmente sul calcolo di un *p*-value per l’ipotesi nulla di uguaglianza delle medie, l’inferenza bayesiana offre una prospettiva più ricca e informativa. Essa fornisce una *distribuzione a posteriori* completa per $\\Delta$, che quantifica direttamente la nostra incertezza sulla differenza dopo aver osservato i dati. Da questa distribuzione possiamo calcolare probabilità con un significato immediato, come:\n\n* la probabilità che la differenza sia positiva, $\\Pr(\\Delta>0 \\mid \\text{dati})$;\n* la probabilità che l’effetto superi una soglia di rilevanza pratica predefinita, $\\Pr(|\\Delta|>\\text{SESOI}\\mid\\text{dati})$.\n\nInoltre, il quadro bayesiano rende trasparente l’integrazione di conoscenze pregresse tramite le distribuzioni a priori e obbliga a esplicitare tutte le assunzioni su cui il modello si basa. Questo rende il processo inferenziale non solo più flessibile, ma anche più rigoroso e interpretabile dal punto di vista scientifico.\n\n::: {.callout-note}\n### Le assunzioni del modello base\n\nCome ogni modello statistico, anche questo semplice confronto tra medie si basa su alcune assunzioni fondamentali che è importante tenere a mente. Le osservazioni sono assumed to be indipendenti tra loro, una volta tenuto conto dell'effetto del gruppo. I residui del modello, cioè la parte di variabilità non spiegata dalla gruppo appartenenza, dovrebbero seguire una distribuzione approssimativamente normale. Il modello presentato qui assume anche che la variabilità dei dati (la $\\sigma$) sia la stessa nei due gruppi; si tratta di un'ipotesi semplificatrice, ma il modello può essere esteso per accomodare il caso più generale in cui le varianze siano diverse (eteroscedasticità).\n:::\n\n::: {.callout-tip}\n### L'importanza di una Soglia di Rilevanza (SESOI)\n\nPer evitare di sovrainterpretare differenze statisticamente significative ma trivialmente piccole, è una buona pratica metodologica definire *a priori* una Soglia di Rilevanza Scientificamente Significativa (SESOI). Stabilire, ad esempio, che una differenza di almeno 5 punti in un test cognitivo abbia un reale significato pratico, permette di ancorare le conclusioni alla sostanza del fenomeno studiato, andando oltre la semplice significatività statistica. È quindi utile riportare non solo la probabilità che l'effetto sia diverso da zero, ma anche la probabilità che superi questa soglia di rilevanza.\n:::\n\nIl percorso che seguiremo in questo capitolo è semplice e strutturato. Inizieremo specificando il modello bayesiano per il confronto tra due medie, esplorandone anche varianti più robuste nel caso in cui l'assunzione di normalità risulti troppo restrittiva. Sceglieremo poi delle *prior debolmente informative*, che siano coerenti con la scala di misura della nostra variabile risultato e che permettano ai dati di \"parlare\" in modo predominante. Una volta stimato il modello, il focus sarà sul riportare le quantità di interesse—la differenza $\\Delta$ e l'eventuale dimensione dell'effetto standardizzata $d$—accompagnate dalle loro distribuzioni a posteriori e dalle probabilità rilevanti. Infine, valuteremo l'adeguatezza del nostro modello attraverso *verifiche predittive*, per assicurarci che sia in grado di generare dati simili a quelli osservati, e, se necessario, confronteremo modelli con assunzioni diverse per scegliere quello che meglio cattura la struttura dei nostri dati.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Le basi concettuali e statistiche che sottendono la modellazione della differenza tra medie nell'ambito del modello di regressione lineare bayesiana.\n- Le diverse strategie di codifica del predittore categoriale (dummy, centrata, a medie di cella).\n- Le strategie più efficaci per comunicare i risultati attraverso intervalli credibili e previsioni probabilistiche.\n\n\n::: {.callout-tip collapse=true title=\"Prerequisiti\"}\n- Consultare l'articolo \"Bayesian estimation supersedes the t test\" [@kruschke2013bayesian]. \n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, brms, bayestestR, insight)\nconflicts_prefer(loo::loo)\n```\n:::\n\n:::\n\n## Il modello a indicatore e le quantità di interesse\n\nPer confrontare due gruppi in modo rigoroso, utilizziamo un modello statistico che incorpora un predittore binario, $x_i$, il cui valore (0 o 1) indica l'appartenenza a uno dei due gruppi. Il modello lineare che proponiamo è il seguente:\n\n$$\ny_i = \\alpha + \\beta x_i + \\varepsilon_i, \\qquad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma),\n$$\n\ndove il termine $\\varepsilon_i$ rappresenta l'errore residuo, la parte di variabilità del punteggio $y_i$ che il modello non riesce a spiegare. Un'assunzione fondamentale di questo modello base è che la dispersione di questi residui, misurata dalla deviazione standard $\\sigma$, sia la stessa per entrambi i gruppi. Questa condizione è nota come ipotesi di *omoschedasticità*.\n\nLe quantità centrali che vogliamo stimare—le medie dei due gruppi—sono ricavabili direttamente dai parametri del modello. Sostituendo i valori dell'indicatore, otteniamo:\n\n*   L'attesa per il *gruppo di riferimento* (quando $x_i = 0$) è: $\\mathbb{E}[y \\mid x=0] = \\alpha$. Chiamiamo questo valore $\\mu_0$.\n*   L'attesa per il *gruppo di confronto* (quando $x_i = 1$) è: $\\mathbb{E}[y \\mid x=1] = \\alpha + \\beta$. Chiamiamo questo valore $\\mu_1$.\n\nLa differenza tra le due medie, che è la quantità di interesse primaria, risulta quindi essere esattamente il coefficiente $\\beta$:\n\n$$\n\\Delta = \\mu_1 - \\mu_0 = (\\alpha + \\beta) - \\alpha = \\beta.\n$$\n\n*In sintesi, l'interpretazione dei parametri è molto intuitiva:*\n\n*   Il parametro $\\alpha$ (l'*intercetta*) rappresenta la *media del gruppo di riferimento*.\n*   Il parametro $\\beta$ (la *pendenza*) rappresenta la *differenza media* tra il gruppo di confronto e il gruppo di riferimento.\n*   Il parametro $\\sigma$ rappresenta la *variabilità residua comune* all'interno di ciascun gruppo, assumendo che sia omogenea.\n\n**Una prospettiva alternativa: il modello a medie di cella**\n\nLo stesso modello può essere formulato in un modo che rende ancora più esplicite le medie di gruppo. Invece di esprimerlo come una funzione lineare, possiamo scriverlo direttamente specificando la media per ogni cella:\n\n$$\ny_i \\sim \\mathcal{N}(\\mu_{x_i},\\, \\sigma),\n$$\n\ndove $\\mu_{x_i}$ è semplicemente la media del gruppo a cui l'osservazione $i$-esima appartiene. In pratica, questo significa che se $x_i = 0$, allora $y_i \\sim \\mathcal{N}(\\mu_0, \\sigma)$, e se $x_i = 1$, allora $y_i \\sim \\mathcal{N}(\\mu_1, \\sigma)$.\n\nQuesta parametrizzazione è del tutto equivalente a quella con $\\alpha$ e $\\beta$, con la semplice corrispondenza $\\mu_0 = \\alpha$ e $\\mu_1 = \\alpha + \\beta$. La sua utilità risiede nel fatto che rende immediatamente visibili i parametri di interesse diretto ($\\mu_0$ e $\\mu_1$) ed è spesso più semplice da comprendere concettualmente.\n\n\n## La codifica centrata dell'indicatore\n\nUn'accortezza tecnica ma molto utile nella modellazione consiste nel *centrare* la variabile indicatrice. Invece di usare i valori 0 e 1, possiamo ridefinirla sottraendo 0.5, ottenendo così:\n\n$$\nx_c = x - \\tfrac12 \\in \\left\\{-\\tfrac12,\\ +\\tfrac12\\right\\}.\n$$\n\nIl modello di regressione viene quindi riscritto utilizzando questo predittore centrato:\n\n$$\ny_i = \\alpha_c + \\beta_c \\, x_{c,i} + \\varepsilon_i.\n$$\n\nQuesta piccola modifica altera in modo vantaggioso l'interpretazione dei coefficienti:\n\n*   Il parametro *$\\alpha_c$ (l'intercetta)* non è più la media del gruppo di riferimento, bensì la *media generale* (o *grand mean*) dei due gruppi, calcolata come $(\\mu_0 + \\mu_1)/2$.\n*   Il parametro *$\\beta_c$ (la pendenza)* rimane invece *esattamente la differenza tra le due medie* ($\\mu_1 - \\mu_0$), proprio come nel caso della codifica non centrata.\n\n\n### Vantaggi pratici della codifica centrata\n\nQuesta parametrizzazione alternativa offre diversi vantaggi pratici:\n\n1. *Interpretazione immediata dell'intercetta*: L'intercetta $\\alpha_c$ rappresenta direttamente la media complessiva del campione, una quantità spesso utile da riportare.\n2. *Semplicità nella specifica delle prior*: Risulta più intuitivo e diretto specificare distribuzioni a priori per i parametri. Possiamo scegliere una prior per $\\alpha_c$ basata sulla nostra conoscenza del livello medio generale della variabile $y$ nella popolazione, e una prior separata per $\\beta_c$ basata sull'ampiezza dell'effetto che ci aspettiamo o che riteniamo rilevante.\n3. *Stima più efficiente in modelli complessi*: Nei modelli gerarchici più avanzati, la centratura può spesso ridurre la correlazione tra le stime dei parametri, migliorando l'efficienza del campionatore MCMC e facilitando la convergenza.\n\n**Suggerimento operativo:** La scelta tra la codifica standard (0/1) e quella centrata dipende dagli obiettivi dell'analisi.\n\n*   Utilizza la *codifica centrata* quando l'attenzione è primariamente sulla *differenza* $\\beta$ e quando vuoi riportare in modo trasparente la media complessiva.\n*   Utilizza la forma a *\"medie di cella\"* (o la codifica 0/1) quando è più conveniente o interpretabile stimare direttamente i livelli medi $\\mu_0$ e $\\mu_1$ per ciascun gruppo.\n\n## Stima con `brms`\n\nDi seguito mostriamo *tre modi equivalenti* per stimare la differenza tra due gruppi con `brms`. Per ogni blocco indichiamo: *cosa fa il modello*, *come leggere i coefficienti*, *quali quantità riportare*.\n\n### 1) Codifica dummy $x\\in\\{0,1\\}$ (modello “standard”)\n\n**Idea.** Stimiamo $\\alpha$ (media del gruppo $x=0$) e $\\beta$ (differenza $\\mu_1-\\mu_0$). Le *prior* `student_t(3, 0, 10)` sono *debolmente informative*: centrano i parametri a 0 e consentono ampia variabilità (code più pesanti della normale).\n\n```r\n#| message: false\n# install.packages(c(\"brms\",\"posterior\",\"tidyverse\",\"bayestestR\",\"loo\",\"cmdstanr\"))\nlibrary(brms); library(posterior); library(tidyverse); library(bayestestR); library(loo)\n\nfit <- brm(\n  y ~ 1 + x,                 # Intercetta + indicatrice (0/1)\n  data = df,\n  family = gaussian(),\n  prior = c(\n    prior(student_t(3, 0, 10), class = \"Intercept\"),  # prior su α (media gruppo 0)\n    prior(student_t(3, 0, 10), class = \"b\"),          # prior su β (differenza)\n    prior(student_t(3, 0, 10), class = \"sigma\")       # prior su σ (half-t implicita)\n  ),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\n```\n\n**Come leggere i risultati.**\n\n* `b_Intercept` stima $\\mu_0$.\n* `b_x` stima $\\Delta=\\mu_1-\\mu_0$.\n* `sigma` è la deviazione standard comune.\n  Calcoliamo anche $d=\\Delta/\\sigma$ e due probabilità a posteriori utili: $\\Pr(\\Delta>0)$ e $\\Pr(|\\Delta|>\\text{SESOI})$.\n\n```r\ndraws <- as_draws_df(fit)\npost <- draws %>%\n  transmute(\n    mu0   = b_Intercept,          # = α\n    mu1   = b_Intercept + b_x,    # = α + β\n    delta = b_x,                  # = β\n    sigma = sigma,\n    d     = delta / sigma         # effetto standardizzato (pooled)\n  )\n\nposterior::summarise_draws(post[, c(\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\n\nSESOI <- 5  # definita a priori in base al contesto applicativo\nc(\n  P_delta_gt0  = mean(post$delta > 0),\n  P_delta_gtS  = mean(abs(post$delta) > SESOI)\n)\n```\n\n**Cosa riportare nel testo:** media e intervallo credibile per $\\mu_0,\\mu_1,\\Delta,d$; $\\Pr(\\Delta>0)$; $\\Pr(|\\Delta|>\\text{SESOI})$.\n\n\n### 2) Codifica *centrata* $x_c=x-\\tfrac12$\n\n**Idea.** L’intercetta diventa la *grand mean* $(\\mu_0+\\mu_1)/2$; il coefficiente su $x_c$ è *direttamente* $\\Delta$. Le *prior* sono normali (comode quando interpretiamo $\\alpha$ come media complessiva).\n\n```r\ndf <- df %>% mutate(xc = x - 0.5)  # xc ∈ {-0.5, +0.5}\n\nfit_c <- brm(\n  y ~ 1 + xc,\n  data = df,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 10), class = \"Intercept\"),   # prior su grand mean\n    prior(normal(0, 10), class = \"b\"),           # prior sulla differenza\n    prior(student_t(3, 0, 10), class = \"sigma\")\n  ),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\n\ndraws_c <- as_draws_df(fit_c)\npost_c <- draws_c %>%\n  transmute(\n    grand_mean = b_Intercept,            # = (μ0+μ1)/2\n    delta      = b_xc,                   # = μ1 - μ0\n    mu0        = b_Intercept - 0.5*b_xc, # ricostruzione\n    mu1        = b_Intercept + 0.5*b_xc,\n    sigma      = sigma,\n    d          = delta / sigma\n  )\nposterior::summarise_draws(post_c[, c(\"grand_mean\",\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\n```\n\n**Quando usarla:** quando vuoi dare *prior* separate e intuitive su *media complessiva* e *differenza*.\n\n\n### 3) *Medie di cella* (senza intercetta)\n\n**Idea.** Stimiamo *direttamente* $\\mu_0$ e $\\mu_1$. Vantaggio: puoi assegnare *prior* *indipendenti* sulle due medie.\n\n```r\ndf <- df %>% mutate(group = factor(x, levels = c(0,1), labels = c(\"G0\",\"G1\")))\n\nfit_cells <- brm(\n  y ~ 0 + group,              # niente intercetta: i coefficienti SONO le medie\n  data = df, family = gaussian(),\n  prior = c(\n    prior(normal(0, 10), class = \"b\", coef = \"groupG0\"),  # prior su μ0\n    prior(normal(0, 10), class = \"b\", coef = \"groupG1\"),  # prior su μ1\n    prior(student_t(3, 0, 10), class = \"sigma\")\n  ),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\n\ndraws_cells <- as_draws_df(fit_cells)\npost_cells <- draws_cells %>%\n  transmute(\n    mu0   = b_groupG0,\n    mu1   = b_groupG1,\n    delta = b_groupG1 - b_groupG0,\n    sigma = sigma,\n    d     = delta / sigma\n  )\nposterior::summarise_draws(post_cells[, c(\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\n```\n\n**Quando usarla:** quando vuoi controllare in modo esplicito le *prior* sulle due medie (e.g., vincoli diversi per ciascun gruppo).\n\n\n::: {.callout-important}\n#### Nota sulle *prior* indotte\n\nCon la forma “intercetta + differenza”, *prior* indipendenti su $\\alpha$ e $\\beta$ *inducono* correlazione tra $\\mu_0$ e $\\mu_1$ ($\\mu_0=\\alpha,\\ \\mu_1=\\alpha+\\beta$).\nSe desideri *indipendenza a priori* tra $\\mu_0$ e $\\mu_1$, usa la parametrizzazione *a medie di cella*.\n:::\n\n::: {.callout-tip}\n#### Nomi dei coefficienti: attenzione alla codifica\n\n* Se `x` è *numerica* (0/1): il coefficiente si chiama tipicamente `b_x`.\n* Se `x` è *fattore* (due livelli): il coefficiente sarà `b_x1` o `b_x<nomeLivello>`.\n* Con `0 + group`: i coefficienti si chiamano `b_groupG0`, `b_groupG1` (le etichette dipendono dai livelli della variabile).\n  Controlla sempre i *nomi esatti* in `names(as_draws_df(fit))` prima di costruire le trasformazioni.\n:::\n\n::: {.callout-warning}\n#### Diagnostica minima da riportare\n\nVerifica `Rhat` (\\~1.00), `ESS`, assenza di *divergenze* e PPC coerenti. Se necessario aumenta `adapt_delta` (0.95–0.99) e `max_treedepth` (es. 15).\n:::\n\n> *Riassunto operativo.* Qualunque parametrizzazione tu scelga, riporta sempre: $\\mu_0,\\mu_1,\\Delta,d$ con intervalli credibili e le probabilità $\\Pr(\\Delta>0)$ e $\\Pr(|\\Delta|>\\text{SESOI})$.\n\n\n### Interpretazione operativa (cosa leggere nelle posteriori)\n\nDi seguito come *leggere e riportare* i risultati a seconda della codifica usata per il predittore binario.\n\n*1) Codifica dummy $D\\in\\{0,1\\}$*\n\n* `Intercept` $\\Rightarrow$ *$\\mu_0$* (media del gruppo $D=0$).\n* Coefficiente su `D` $\\Rightarrow$ *$\\Delta=\\mu_1-\\mu_0$* (differenza tra medie).\n* Da riportare sempre: $\\mu_1=\\mu_0+\\Delta$, $\\sigma$, $d=\\Delta/\\sigma$, $\\Pr(\\Delta>0)$, $\\Pr(|\\Delta|>\\text{SESOI})$.\n\n*2) Codifica centrata $D_c=D-\\tfrac12\\in\\{-\\tfrac12,+\\tfrac12\\}$*\n\n* `Intercept` $\\Rightarrow$ *grand mean* $\\displaystyle \\alpha=\\tfrac{\\mu_0+\\mu_1}{2}$.\n* Coefficiente su `D_c` $\\Rightarrow$ *$\\Delta=\\mu_1-\\mu_0$*.\n* Ricostruzioni utili: $\\mu_0=\\alpha-\\tfrac12\\Delta$, $\\mu_1=\\alpha+\\tfrac12\\Delta$.\n* Da riportare come sopra: $\\Delta$, $d$, $\\Pr(\\Delta>0)$, $\\Pr(|\\Delta|>\\text{SESOI})$.\n\n*3) Parametrizzazione a “medie di cella” (senza intercetta)*\n\n* I coefficienti *sono direttamente* $\\mu_0$ e $\\mu_1$.\n* La differenza si ottiene come *combinazione lineare a posteriori*: $\\Delta=\\mu_1-\\mu_0$.\n* Da riportare: $\\mu_0,\\mu_1,\\Delta,\\sigma,d,\\Pr(\\Delta>0),\\Pr(|\\Delta|>\\text{SESOI})$.\n\n::: {.callout-tip}\n*Promemoria pratico.*\nIndipendentemente dalla codifica, l’*oggetto sostantivo* è sempre $\\Delta$ (e, quando serve, $d=\\Delta/\\sigma$). Per la discussione applicativa affianca sempre:\n\n* un *intervallo credibile* per $\\Delta$;\n* $\\Pr(\\Delta>0\\mid\\text{dati})$;\n* $\\Pr(|\\Delta|>\\text{SESOI}\\mid\\text{dati})$ con una SESOI definita *prima* dell’analisi.\n:::\n\n*Esempio di lettura sintetica.*\nSe la posteriore di $\\Delta$ ha media 4.8, intervallo credibile 95% $[2.1,\\ 7.4]$, $\\Pr(\\Delta>0)=0.99$ e $\\Pr(|\\Delta|>5)=0.46$ (SESOI = 5), allora: la differenza media è plausibilmente positiva, ma la probabilità di superare la soglia di rilevanza scelta è circa *46%* (informazione utile per l’interpretazione sostantiva).\n\n\n## Confronto tra approcci: frequentista e bayesiano\n\n| Aspetto                 | Frequentista                                                                 | Bayesiano                                                                                               |\n| ----------------------- | ----------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |\n| Rappresentazione        | Intervallo di confidenza                                                      | Intervallo di credibilità                                                                                |\n| Unità di analisi        | Compatibilità dei dati con $H_0$                                             | Distribuzione a posteriori su $\\Delta$ e probabilità su regioni di interesse (SESOI/ROPE)               |\n| Ipotesi di partenza     | Ipotesi nulla puntuale come riferimento                                       | Modello + prior; non richiede un $H_0$ puntuale, ma consente ipotesi su regioni parametriche            |\n| Uso di informazione pregressa | Non previsto                                                           | Integrabile tramite prior                                                                                |\n| Domanda tipica          | “Quanto sono rari i dati se $\\Delta=0$?”                                     | “Quanto è plausibile che $\\Delta$ superi una soglia definita (SESOI)?”                                  |\n\n\n## Esempio: istruzione materna e QI\n\nUsiamo il dataset `kidiq` (sviluppo cognitivo): per ogni bambino abbiamo il *QI* (`kid_score`) e se la *madre ha il diploma* (`mom_hs`: 0 = non diplomata; 1 = diplomata).\n\n**Domanda:** *i figli di madri diplomate hanno, in media, un QI diverso?* Inoltre, fissiamo a titolo esemplificativo una *SESOI = 5 punti* di QI (soglia di rilevanza pratica da motivare nel contesto).\n\n### Esplorazione iniziale dei dati\n\n**1) Import, pulizia minima e etichette chiare.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nkidiq <- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\n# Ricodifica esplicita per leggibilità nei grafici e nelle tabelle\nkidiq <- kidiq |>\n  mutate(\n    mom_hs = factor(mom_hs, levels = c(0, 1),\n                    labels = c(\"Non diplomata\", \"Diplomata\"))\n  )\n\n# Controllo veloce: struttura e eventuali missing\nglimpse(kidiq)\n#> Rows: 434\n#> Columns: 5\n#> $ kid_score <dbl> 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78, 1…\n#> $ mom_hs    <fct> Diplomata, Diplomata, Diplomata, Diplomata, Diplomata, Non d…\n#> $ mom_iq    <dbl> 121.1, 89.4, 115.4, 99.4, 92.7, 107.9, 138.9, 125.1, 81.6, 9…\n#> $ mom_work  <dbl> 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, 3, …\n#> $ mom_age   <dbl> 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 24, …\ncolSums(is.na(kidiq[, c(\"kid_score\", \"mom_hs\")]))\n#> kid_score    mom_hs \n#>         0         0\n```\n:::\n\n\n**2) Statistiche descrittive per gruppo.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nkidiq |>\n  group_by(mom_hs) |>\n  summarise(\n    n        = n(),\n    media_QI = mean(kid_score, na.rm = TRUE),\n    sd_QI    = sd(kid_score, na.rm = TRUE),\n    mediana  = median(kid_score, na.rm = TRUE),\n    IQR      = IQR(kid_score, na.rm = TRUE)\n  ) |>\n  ungroup()\n#> # A tibble: 2 × 6\n#>   mom_hs            n media_QI sd_QI mediana   IQR\n#>   <fct>         <int>    <dbl> <dbl>   <dbl> <dbl>\n#> 1 Non diplomata    93     77.5  22.6      80    37\n#> 2 Diplomata       341     89.3  19.0      92    26\n```\n:::\n\n\n> Lettura rapida: riportiamo numerosità, media e deviazione standard (oltre a mediana e IQR per un controllo di robustezza). Nel nostro campione tipicamente i gruppi sono *sbilanciati* (ad es., \\~93 vs \\~341): è un’informazione utile per interpretare precisione e incertezza delle stime.\n\n**3) Visualizzazione della distribuzione nei due gruppi.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(kidiq, aes(x = mom_hs, y = kid_score)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.12, outlier.shape = NA) +\n  geom_jitter(width = 0.08, alpha = 0.25, size = 1) +\n  labs(\n    x = \"Istruzione materna\",\n    y = \"QI del bambino\"\n  ) \n```\n\n::: {.cell-output-display}\n![](08_two_means_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n> Cosa mostra il grafico: le *medie* sembrano diverse, ma le *distribuzioni* si sovrappongono in modo consistente. È un pattern tipico in psicologia: la differenza media non esaurisce l’informazione: servono *stima dell’ampiezza*, *incertezza* e, se possibile, *rilevanza pratica* (SESOI).\n\n**Domanda guida per l’analisi inferenziale**\n\nLa differenza osservata è compatibile con la sola variabilità campionaria oppure suggerisce *una tendenza nella popolazione*?\n\nPer rispondere, nel seguito stimiamo la *differenza tra le medie* con approccio *frequentista* (t-test) e con approccio *bayesiano* (modello gaussiano con `brms`), riportando anche le *probabilità a posteriori* rispetto alla SESOI.\n\n\n#### Approccio frequentista\n\nPer verificare se la *differenza media* osservata può essere attribuita alla sola variabilità campionaria, applichiamo un *t-test per campioni indipendenti* (versione con *varianze uguali*):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt.test(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  var.equal = TRUE\n)\n#> \n#> \tTwo Sample t-test\n#> \n#> data:  kid_score by mom_hs\n#> t = -5, df = 432, p-value = 0.0000006\n#> alternative hypothesis: true difference in means between group Non diplomata and group Diplomata is not equal to 0\n#> 95 percent confidence interval:\n#>  -16.34  -7.21\n#> sample estimates:\n#> mean in group Non diplomata     mean in group Diplomata \n#>                        77.5                        89.3\n```\n:::\n\n\n**Interpretazione.**\n\n* Le *medie campionarie* sono circa 77.6 (madri non diplomate) e 89.3 (madri diplomate).\n* La *differenza* (gruppo 1 − gruppo 0) è \\~ *+11.8 punti QI*.\n* L’IC al 95% stampato da R si riferisce a (gruppo 0 − gruppo 1) ed è $[-16.34,\\ -7.21]$; quindi, per (gruppo 1 − gruppo 0) l’IC corrispondente è *\\[+7.21, +16.34]*.\n* Il *p*-value $= 6\\times 10^{-7}$ indica che, *se* nella popolazione non ci fosse differenza ($\\mu_1=\\mu_0$), sarebbe molto raro osservare una differenza almeno così grande. *(Non è la probabilità che $H_0$ sia vera.)*\n\n**Assunzioni e note pratiche.**\n\n* Il test qui usa *varianze uguali* (`var.equal=TRUE`). In pratica è spesso preferibile la versione *di Welch* (default di `t.test`, cioè senza `var.equal=TRUE`), più robusta a varianze diverse e sbilanciamento tra gruppi.\n* L’inferenza frequentista fornisce una decisione rispetto a $H_0$ e un IC; *non* restituisce la probabilità che l’effetto superi una soglia di interesse applicativo.\n\nNel paragrafo successivo stimiamo la stessa differenza con l’*approccio bayesiano*, ottenendo una *distribuzione a posteriori* per $\\Delta$ e quantità direttamente interpretabili come $\\Pr(\\Delta>0)$ e $\\Pr(|\\Delta|>\\text{SESOI})$.\n\n\n#### Approccio bayesiano\n\nCon `mom_hs` codificata come *0 = non diplomata* e *1 = diplomata*, il modello\n\n$$\ny_i \\sim \\mathcal N(\\alpha+\\beta\\,\\text{mom\\_hs}_i,\\ \\sigma)\n$$\n\nsi interpreta così:\n\n* $\\alpha$ = media del gruppo *mom\\_hs = 0*;\n* $\\beta = \\Delta$ = *differenza tra medie* (gruppo 1 − gruppo 0);\n* $\\sigma$ = deviazione standard residua (assunta uguale nei due gruppi).\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Assicuriamoci che la referenza sia \"Non diplomata\"\nkidiq$mom_hs <- relevel(kidiq$mom_hs, ref = \"Non diplomata\")\n\nfit_1 <- brm(\n  kid_score ~ mom_hs,\n  data   = kidiq,\n  family = gaussian(),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\n```\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ===== Ponte sicuro tra nomi \"umani\" e nomi dei draw =====\n# Termini dei coefficienti a livello fissato (esclude l'intercetta)\nterm_names <- setdiff(rownames(fixef(fit_1)), \"Intercept\")\nstopifnot(length(term_names) == 1)         # qui ci aspettiamo un solo coefficiente: \"mom_hsDiplomata\"\n\nb_name <- paste0(\"b_\", term_names)         # es. \"b_mom_hsDiplomata\"\n\ndr <- as_draws_df(fit_1)\n\n# Quantità di interesse\npost <- dr %>%\n  transmute(\n    mu0   = b_Intercept,         # media del gruppo di riferimento (Non diplomata)\n    delta = .data[[b_name]],     # differenza vs referenza: (Diplomata - Non diplomata)\n    mu1   = b_Intercept + delta, # media del gruppo \"Diplomata\"\n    sigma = sigma,\n    d     = delta / sigma\n  )\n\nSESOI <- 5\nposterior::summarise_draws(post[, c(\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\n#> # A tibble: 5 × 10\n#>   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu0      77.570 77.559 2.030 2.016 74.205 80.885 1.000 3811.388 2972.604\n#> 2 mu1      89.308 89.307 1.063 1.066 87.602 91.079 1.000 3931.890 2780.415\n#> 3 delta    11.737 11.787 2.309 2.309  7.911 15.506 1.000 4154.701 3119.643\n#> 4 d         0.591  0.593 0.118 0.120  0.395  0.783 1.000 4130.593 3034.413\n#> 5 sigma    19.894 19.868 0.702 0.709 18.780 21.073 1.000 3713.284 3095.218\n\nc(\n  P_delta_gt0    = mean(post$delta > 0),          # Pr(Δ > 0 | dati)\n  P_absDelta_gtS = mean(abs(post$delta) > SESOI)  # Pr(|Δ| > 5 | dati)\n)\n#>    P_delta_gt0 P_absDelta_gtS \n#>          1.000          0.999\n```\n:::\n\n\n**Come leggere i risultati:**\n\n* `mu0` e `mu1` sono le medie di gruppo stimate (con incertezza).\n* `delta` è la differenza media $(\\mu_1-\\mu_0)$; `d` è la versione standardizzata.\n* Le due probabilità a posteriori rispondono a domande pratiche:\n\n  * $\\Pr(\\Delta>0\\mid\\text{dati})$: quanto è plausibile che i figli di madri diplomate abbiano un QI medio *maggiore*?\n  * $\\Pr(|\\Delta|>\\text{SESOI}\\mid\\text{dati})$: quanto è plausibile che la differenza *superi 5 punti* (soglia di rilevanza scelta)?\n\n\n## Approfondimenti bayesiani\n\nFinora abbiamo stimato la differenza tra i gruppi e le relative probabilità a posteriori. Qui vediamo come *controllare l’adeguatezza del modello* e, se serve, *raffinarlo*. Usiamo tre strumenti: (1) verifiche predittive a posteriori (*PPC*), (2) verifiche a priori, (3) confronto predittivo tra modelli.\n\n\n### 1) Posterior predictive checks (PPC)\n\nL’idea è semplice: il modello dovrebbe essere in grado di *rigenerare* dati simili a quelli osservati.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Verifica globale (densità osservata vs replicata dal modello)\npp_check(fit_1)   # default: dens_overlay\n```\n\n::: {.cell-output-display}\n![](08_two_means_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n**Cosa guardare.**\n\n* *Forma*: la distribuzione simulata copre quella osservata? Ci sono code o asimmetrie non riprodotte?\n\n\n### 2) Verifica predittiva *a priori*\n\nServe a controllare se le *prior* producono dati *plausibili* prima di vedere i dati.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npri <- c(\n  prior(normal(90, 20), class = \"Intercept\"),  # scala QI\n  prior(normal(0, 15),  class = \"b\"),          # differenza attesa moderata\n  prior(student_t(3, 0, 20), class = \"sigma\")\n)\n\nfit_prior <- brm(\n  kid_score ~ mom_hs,\n  data = kidiq,\n  family = gaussian(),\n  prior = pri,\n  sample_prior = \"only\",       # ignora i dati: simula dai prior\n  backend = \"cmdstanr\",\n  chains = 2, iter = 1000, seed = 123\n)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npp_check(fit_prior, ndraws = 100)\n```\n\n::: {.cell-output-display}\n![](08_two_means_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n**Interpretazione**: se i dati simulati *a priori* cadono in range irrealistici (es. molti QI < 30 o > 180), le prior vanno *allineate* alla conoscenza di dominio.\n\n\n### 3) Varianti del modello (quando i PPC suggeriscono limiti)\n\n*Code pesanti / outlier* → *t di Student*:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_t <- brm(kid_score ~ mom_hs, family = student(), data = kidiq,\n               backend = \"cmdstanr\", chains = 4, iter = 2000, seed = 123)\n```\n:::\n\n\n*Varianze diverse per gruppo* → eteroscedastico:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_het <- brm(bf(kid_score ~ mom_hs, sigma ~ mom_hs),\n                 family = gaussian(),  data = kidiq,\n                 backend = \"cmdstanr\", chains = 4, iter = 2000, seed = 123)\n```\n:::\n\n\n*Asimmetria* → skew-normal:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_sn <- brm(kid_score ~ mom_hs, family = skew_normal(), data = kidiq,\n              backend = \"cmdstanr\", chains = 4, iter = 2000, seed = 123)\n```\n:::\n\n\nDopo l’eventuale rifit, ripeti i *PPC* (globali e per gruppo).\n\n\n### 4) Confronto predittivo tra modelli (LOO/ELPD)\n\nScegliamo il modello che *predice meglio* nuovi dati simili a quelli osservati.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nloo_fit1  <- loo(fit_1)\nloo_fit_t <- loo(fit_t)\nloo_fit_het <- loo(fit_het)\nloo_fit_sn  <- loo(fit_sn)\n\nloo_compare(loo_fit1, loo_fit_t, loo_fit_het, loo_fit_sn)\n#>         elpd_diff se_diff\n#> fit_sn   0.0       0.0   \n#> fit_het -6.0       5.9   \n#> fit_1   -7.4       5.3   \n#> fit_t   -8.8       5.5\n```\n:::\n\n\nNel confronto tra modelli, un modello migliore è caratterizzato da un valore di ELPD più elevato. Quando la differenza nell’ELPD è paragonabile al suo errore standard (se_diff), il vantaggio predittivo può considerarsi modesto; in tali circostanze, è preferibile adottare il modello più semplice che superi le posterior predictive checks. È inoltre opportuno verificare i parametri di forma Pareto $k$: qualora numerosi valori superino la soglia di 0.7, si raccomanda di impiegare la procedura di reloo o di ricorrere alla validazione incrociata k-fold.\n\nNel caso in esame, il confronto mediante LOO indica un lieve vantaggio predittivo del modello basato sulla distribuzione skew-normal rispetto alle alternative gaussiane, sia omoscedastiche che eteroscedastiche, nonché rispetto al modello con distribuzione t di Student. Tuttavia, le differenze nell’ELPD sono dell’ordine di grandezza dell’errore standard, pertanto l’evidenza a favore della skew-normal risulta moderata. Le posterior predictive checks mostrano un migliore allineamento delle code e della struttura di asimmetria nel caso della skew-normal; per questo motivo, tale modello viene adottato come specificazione principale, affiancandolo da un’analisi di sensibilità delle stime di $\\Delta$ rispetto alle diverse assunzioni di likelihood. Il modesto vantaggio del modello eteroscedastico rispetto all’omoscedastico suggerisce la presenza di differenze nella variabilità tra gruppi, sebbene l’impatto predittivo di tale eterogeneità sia contenuto.\n\nIn sintesi, il criterio dell’ELPD favorisce il modello skew-normal, sebbene con differenze esigue rispetto alle alternative. La scelta del modello deve essere giustificata congiuntamente in base a: (i) compatibilità predittiva mediante LOO, (ii) esito delle posterior predictive checks, e (iii) robustezza delle quantità sostantive di interesse, quali $\\Delta$, $\\Pr(\\Delta > 0)$ e $\\Pr(|\\Delta| > \\text{SESOI})$. Quando le differenze predittive sono esigue, la stabilità di $\\Delta$ tra diverse specificazioni diventa un elemento cruciale per l’interpretazione sostantiva dei risultati.\n\nQuesto approccio consente di mantenere l’analisi trasparente e riproducibile, collegando le stime ottenute a domande di ricerca concrete—attraverso l’uso di smallest effect sizes of interest (SESOI)—senza introdurre soglie arbitrarie di significatività.\n\n::: {.callout-warning}\n### Diagnostica MCMC (workflow minimo)\nControllare sistematicamente: `Rhat` ≈ 1.00, ESS adeguati, assenza di divergenze e *E-BFMI* bassi; ispezionare `pairs()` per funnel. Se necessario, aumentare `adapt_delta` (es. 0.95–0.99) e `max_treedepth` (es. 15).\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Approfondimento statistico (opzionale)\n\nConsideriamo ora le basi statistiche su cui si basa l'approccio frequentista. Nel paradigma frequentista, l’inferenza sulla differenza tra due gruppi si basa sulla *distribuzione campionaria* della differenza tra le medie. L’idea di fondo è che, se ripetessimo il campionamento molte volte, otterremmo valori diversi per la differenza tra le medie campionarie, e questa variabilità può essere descritta attraverso una distribuzione probabilistica.\n\nSupponiamo di avere due popolazioni normali e indipendenti:\n\n$$\nY_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2) \\quad \\text{e} \\quad Y_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)\n$$\n\ne di osservare due campioni indipendenti, rispettivamente di dimensione $n_1$ e $n_2$.\n\nSe assumiamo inoltre che le varianze siano uguali ($\\sigma_1^2 = \\sigma_2^2 = \\sigma^2$), possiamo utilizzare una versione semplificata del modello.\n\n**Statistica di interesse.** Il nostro obiettivo è stimare la *differenza tra le medie* delle due popolazioni, ovvero:\n\n$$\n\\mu_1 - \\mu_2.\n$$\n\nLa stima di questa quantità è data dalla *differenza tra le medie campionarie*:\n\n$$\n\\bar{Y}_1 - \\bar{Y}_2.\n$$\n\n**Proprietà della statistica campionaria.**\n\n**Valore atteso.** Nel caso di due campioni indipendenti:\n\n$$\nE(\\bar{Y}_1 - \\bar{Y}_2) = \\mu_1 - \\mu_2.\n$$\n\n::: {.callout-important title=\"Dimostrazione\" collapse=\"true\"}\n\nSi parte dalla definizione di media campionaria per ciascun gruppo e si applica la linearità dell’operatore valore atteso:\n\n$$\nE(\\bar{Y}_1 - \\bar{Y}_2) = E(\\bar{Y}_1) - E(\\bar{Y}_2) = \\mu_1 - \\mu_2.\n$$\n\n:::\n\n**Varianza.** La varianza della differenza tra le medie campionarie è:\n\n$$\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}.\n$$\n\n::: {.callout-important title=\"Dimostrazione\" collapse=\"true\"}\n\nPoiché i due campioni sono indipendenti, la varianza della differenza si ottiene sommando le varianze delle due medie:\n\n$$\n\\operatorname{Var}(\\bar{Y}_1) = \\frac{\\sigma_1^2}{n_1}, \\quad \\operatorname{Var}(\\bar{Y}_2) = \\frac{\\sigma_2^2}{n_2}\n$$\n\nquindi:\n\n$$\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}.\n$$\n\n:::\n\nSe assumiamo varianze uguali ($\\sigma_1 = \\sigma_2 = \\sigma$), possiamo scrivere:\n\n$$\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\sigma^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right).\n$$\n\nPoiché $\\sigma^2$ è sconosciuta, la si stima tramite la *varianza pooled*:\n\n$$\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2},\n$$\n\ndove $s_1^2$ e $s_2^2$ sono le varianze campionarie:\n\n$$\ns_j^2 = \\frac{1}{n_j - 1} \\sum_{i=1}^{n_j} (y_{j,i} - \\bar{y}_j)^2, \\quad j = 1,2.\n$$\n\n**Distribuzione della statistica.** Sotto l’ipotesi di normalità e indipendenza, e assumendo varianze uguali, la statistica $\\bar{Y}_1 - \\bar{Y}_2$ segue (almeno approssimativamente) una distribuzione normale:\n\n$$\n\\bar{Y}_1 - \\bar{Y}_2 \\sim \\mathcal{N} \\left( \\mu_1 - \\mu_2,\\ \\sigma \\sqrt{ \\frac{1}{n_1} + \\frac{1}{n_2} } \\right).\n$$\n\nQuesta proprietà permette di costruire un *intervallo di confidenza al 95%* per la differenza tra le medie, oppure di effettuare un *test t di Student per due campioni indipendenti*, basato sulla seguente statistica:\n\n$$\nt = \\frac{(\\bar{Y}_1 - \\bar{Y}_2) - (\\mu_1 - \\mu_2)}{s_p \\sqrt{ \\frac{1}{n_1} + \\frac{1}{n_2} }}.\n$$\n\nQuesta statistica segue, sotto l’ipotesi nulla $\\mu_1 = \\mu_2$, una distribuzione t di Student con $n_1 + n_2 - 2$ gradi di libertà.\n:::\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo riformulato il classico problema del confronto tra due medie in chiave bayesiana. Abbiamo visto come il modello possa essere espresso sia come differenza diretta tra le medie di due distribuzioni normali ($\\Delta = \\mu_1 - \\mu_0$), sia come un semplice modello di regressione con variabile indicatrice. Entrambe le formulazioni portano alla stessa conclusione: ciò che ci interessa non è un verdetto dicotomico sull’esistenza o meno di una differenza, ma la **distribuzione delle nostre credenze** sulla sua ampiezza.\n\nL’approccio bayesiano ci fornisce esattamente questo: una distribuzione a posteriori per $\\Delta$, da cui possiamo derivare probabilità direttamente interpretabili, come la probabilità che la differenza sia positiva o che superi una soglia di rilevanza pratica. Questo rappresenta un cambiamento radicale rispetto al frequentismo, dove la risposta si riduce a un *p*-value, senza informazioni sulla magnitudine dell’effetto né sulla sua plausibilità relativa.\n\nIl confronto tra due gruppi è un esempio paradigmatico perché mostra con chiarezza i punti di forza dell’inferenza bayesiana: trasparenza, flessibilità e possibilità di collegare l’analisi statistica a domande scientifiche sostantive. Ma rappresenta anche un punto di partenza. Nella ricerca psicologica, infatti, non basta sapere che due medie differiscono: dobbiamo anche chiederci *quanto* questa differenza sia grande e se abbia una reale rilevanza pratica.\n\nPer questo, nel capitolo successivo introdurremo il tema della *grandezza dell’effetto*, collegando la differenza tra medie alla variabilità dei dati e discutendo strumenti per valutare non solo la presenza di un effetto, ma anche la sua importanza scientifica.\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#>  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#> [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [28] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#> [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#> [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#> [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#> [19] rmarkdown_2.29        tzdb_0.5.0            haven_2.5.5          \n#> [22] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#> [25] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#> [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#> [31] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#> [34] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#> [37] R.utils_2.13.0        pacman_0.5.1          readr_2.1.5          \n#> [40] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#> [43] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#> [46] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#> [49] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#> [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#> [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#> [58] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#> [61] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#> [64] hms_1.1.3             rstantools_2.5.0      scales_1.4.0         \n#> [67] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#> [70] tools_4.5.1           data.table_1.17.8     forcats_1.0.0        \n#> [73] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#> [76] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#> [79] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#> [82] V8_7.0.0              gtable_0.3.6          R.methodsS3_1.8.2    \n#> [85] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#> [88] farver_2.1.2          R.oo_1.27.1           memoise_2.0.1        \n#> [91] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted} \n\n",
    "supporting": [
      "08_two_means_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}