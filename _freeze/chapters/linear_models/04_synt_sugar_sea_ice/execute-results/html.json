{
  "hash": "12b8e9fc7ca2b603a7eb2faf7167ad56",
  "result": {
    "engine": "knitr",
    "markdown": "# Zucchero sintattico {#sec-linar-models-brms}\n\n## Introduzione {.unnumbered .unlisted}\n\nNel capitolo precedente abbiamo visto come formulare e stimare un modello bayesiano di regressione lineare bivariata utilizzando distribuzioni a priori semplici. Questo esercizio ci ha permesso di cogliere l’essenza dell’approccio: i parametri della retta di regressione non sono valori fissi, ma quantità descritte da distribuzioni di probabilità aggiornate alla luce dei dati.\n\nTuttavia, la scrittura esplicita di ogni dettaglio del modello può diventare rapidamente ingombrante, soprattutto quando si lavora con più predittori o con modelli più complessi. Per rendere l’analisi più agevole, possiamo introdurre alcune notazioni e funzioni che alleggeriscono il codice senza modificarne il significato statistico.\n\nIn questo capitolo presenteremo quindi quello che potremmo chiamare *“zucchero sintattico”*: strumenti che rendono la specificazione dei modelli in R più compatta e leggibile, pur mantenendo intatta la logica bayesiana sottostante. Sarà un passaggio intermedio utile, che ci permetterà di concentrarci sugli aspetti concettuali della modellazione senza appesantirci con dettagli tecnici ripetitivi. Nei capitoli successivi, quando introdurremo Stan, vedremo come questa stessa esigenza di sintesi e chiarezza diventi ancora più cruciale.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Costruire e adattare modelli lineari con la funzione `brm()`.\n- Interpretare i risultati e confrontarli con quelli ottenuti da un approccio frequentista.\n- Visualizzare le relazioni stimate e distinguere tra intervalli di credibilità e di predizione.\n- Specificare priors personalizzati e valutare l’impatto sui risultati.\n- Eseguire verifiche predittive a posteriori (*posterior predictive checks*).\n- Gestire la presenza di outlier tramite la regressione robusta.\n- Calcolare e interpretare l’indice di determinazione bayesiano (*Bayes R²*).\n- Accedere e manipolare la distribuzione a posteriori dei parametri.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere *Navigating the Bayes maze: The psychologist's guide to Bayesian statistics, a hands-on tutorial with R code* [@alter2025navigating].\n- Consultare [The brms Book: Applied Bayesian Regression Modelling Using R and Stan](https://paulbuerkner.com/software/brms-book/brms-book.pdf).\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, cmdstanr, tidybayes)\n```\n:::\n\n:::\n\n## Interfaccia `brms`\n\nCome esempio, utilizzeremo un dataset che ci consente di stimare un modello lineare molto semplice. Il [National Snow and Ice Data Center](https://nsidc.org/home) mette a disposizione numerosi dati pubblici, scaricabili ed esplorabili liberamente. Uno degli effetti più evidenti del cambiamento climatico riguarda la progressiva riduzione dell’estensione dei ghiacci marini nell’emisfero settentrionale. Qui analizzeremo come questa estensione è variata nel tempo.\n\nLa progressiva scomparsa di un elemento così iconico del nostro pianeta non è solo un dato fisico; agisce come un potente *segnale psicologico*. La percezione di perdite ambientali tangibili e su larga scala è un fattore chiave nel fenomeno dell'*ansia climatica* (*climate anxiety*), quella preoccupazione cronica e angoscia per gli impatti presenti e futuri del cambiamento climatico [@clayton2020climate].\n\nVisualizzare un trend discendente così chiaro, come quello che emergerà dalla nostra analisi, fornisce un contesto cruciale. Non si tratta di un'astratta previsione futura, ma della documentazione di una trasformazione in atto che sta già alterando ecosistemi, economie e, non da ultimo, il nostro benessere psicologico collettivo ([APA, 2017](https://www.apa.org/news/press/releases/2017/03/mental-health-climate.pdf)). L'analisi dei dati diventa così uno strumento per comprendere e comunicare una delle fonti dello stress ambientale contemporaneo.\n\nI dati contenuti nel file `N_08_extent_v4.0.csv` riguardano le osservazioni del mese di agosto dal 1979 al 2024 e riportano i valori di `extent`. Con questo termine si indica la superficie marina totale in cui la concentrazione di ghiaccio è almeno del 15%. L’*extent* è considerato l’indicatore più robusto per monitorare le tendenze climatiche di lungo periodo, poiché risente meno delle fluttuazioni giornaliere dovute al vento (che può comprimere o disperdere il ghiaccio, modificandone la concentrazione ma non la sua estensione complessiva). Per questo motivo, quando si parla di “minimo storico dei ghiacci artici”, il riferimento è quasi sempre al valore di *extent*. La variabile `extent` è espressa in milioni di chilometri quadrati (ad esempio, 8.04 = 8.040.000 km²).\n\nCarichiamo i dati e diamo un’occhiata alle prime righe:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- rio::import(here::here(\"data\", \"N_08_extent_v4.0.csv\"))\ndf |> \n  head()\n#>   year mo source_dataset region extent area\n#> 1 1979  8     NSIDC-0051      N   8.04 5.06\n#> 2 1980  8     NSIDC-0051      N   7.98 4.94\n#> 3 1981  8     NSIDC-0051      N   7.84 4.48\n#> 4 1982  8     NSIDC-0051      N   8.14 5.00\n#> 5 1983  8     NSIDC-0051      N   8.19 4.97\n#> 6 1984  8     NSIDC-0051      N   7.77 4.68\n```\n:::\n\n\nVisualizziamo ora la relazione tra `extent` e `year` con un diagramma a dispersione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = year, y = extent)) +\n  geom_point() +  \n  labs(x = \"Anno\", y = \"Estensione (milioni km²)\") \n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl pacchetto `brms` si concentra sui *modelli di regressione*. Questa specializzazione consente di adottare una sintassi semplice e compatta, detta *sintassi di Wilkinson* [@wilkinson1973symbolic].\n\nPer esempio, il modello lineare\n\n$$\ny = \\alpha + \\beta x + \\varepsilon\n$$\npuò essere scritto in `brms` nel modo seguente:\n\n```r\na_model <- brm(extent ∼ 1 + year, data = df)\n```\n\nNella sintassi di Wilkinson:\n\n* il simbolo `~` separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra);\n* `1` rappresenta l’intercetta, che in realtà è inclusa di default.\n\nQuindi il modello precedente può essere scritto in maniera equivalente come:\n\n```r\na_model <- brm(extent ∼ year, data = df)\n```\nSe desideriamo *escludere l’intercetta* dal modello, possiamo farlo così:\n\n```r\nno_intercept_model <- brm(extent ∼ 0 + year, data = df)\n```\noppure:\n\n```r\nno_intercept_model <- brm(extent ∼ -1 + year, data = df)\n```\nPer aggiungere altre variabili indipendenti, basta estendere la formula:\n\n```r\nmodel_2 <- brm(extent ∼ year + z, data = df)\n```\n\n`brms` permette anche di stimare *modelli gerarchici (a effetti misti)*. Ad esempio, se avessimo osservazioni raggruppate per area geografica `g` e volessimo stimare un effetto di `year` che varia da un gruppo all’altro, potremmo scrivere:\n\n```r\nmodel_h <- brm(extent ∼ year + z + (year | g), data = df)\n```\n\nÈ importante sottolineare che la sintassi di Wilkinson *non specifica le distribuzioni a priori*, ma soltanto come le variabili sono collegate tra loro. In assenza di istruzioni esplicite, `brms` assegna automaticamente delle *prior debolmente informative*, che permettono di stimare comunque il modello senza ulteriori interventi. Tuttavia, se desideriamo avere un controllo più preciso, possiamo definire manualmente le prior, come vedremo nelle sezioni successive.\n\n\n### Centrare le variabili\n\nPer interpretare più facilmente *l’intercetta*, centriamo la variabile `year` rispetto alla sua media nel campione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf$year_c <- df$year - mean(df$year)\n```\n:::\n\nIn questo modo, *l’intercetta* ($\\alpha$) del modello rappresenterà l’*estensione media prevista* (*extent*, in milioni di km²) *nell’anno medio del campione* (cioè l’anno medio tra 1979 e 2024).\n\nAdattiamo un modello lineare con `year` centrata ed esaminiamo i risultati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_1 <- brm(\n  bf(extent ~ 1 + year_c, center = FALSE),\n  data = df,\n  backend = \"cmdstanr\",\n  silent = 0\n)\n```\n:::\n\n\n* `center = FALSE` nel *bf(...)* assicura che *brms non applichi un centraggio automatico* ai predittori numerici: così evitiamo il “doppio centraggio”, dato che abbiamo già centrato `year` a mano.\n* `backend = \"cmdstanr\"` indica a `brms` di usare *CmdStan tramite l’interfaccia `cmdstanr`* (anziché l’interfaccia `rstan`). In questo corso useremo `cmdstanr`, quindi è utile specificarlo esplicitamente.\n* `silent = 0` lascia visibili alcuni messaggi informativi durante la compilazione e il campionamento (opzionale).\n\nLe *tracce MCMC* dei parametri si ottengono così:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmcmc_trace(\n  fit_1,\n  pars = c(\"b_Intercept\", \"b_year_c\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nRiepilogo del modello:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fit_1)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: extent ~ 1 + year_c \n#>    Data: df (Number of observations: 46) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     6.71      0.07     6.58     6.83 1.00     3383     2942\n#> year_c       -0.07      0.01    -0.08    -0.06 1.00     4432     2887\n#> \n#> Further Distributional Parameters:\n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.45      0.05     0.37     0.56 1.00     3341     2803\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\n#### Interpretazione\n\n* L’*intercetta* $\\alpha$ = `b_Intercept` è l’*extent previsto* (milioni di km²) *nell’anno medio* del campione (circa $\\text{mean(df\\$year)}$).\n* La *pendenza* $\\beta$ = `b_year_c` quantifica la *variazione media annua* dell’extent: un valore negativo indica una *diminuzione* dell’estensione dei ghiacci nel tempo (trend atteso in questi dati).\n\nPer confronto, stimiamo lo *stesso modello* con l’approccio frequentista:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_2 <- lm(extent ~ 1 + year_c, data = df)\nsummary(fit_2)\n#> \n#> Call:\n#> lm(formula = extent ~ 1 + year_c, data = df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -1.2394 -0.2755  0.0204  0.3081  1.0768 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)  6.71000    0.06537   102.6   <2e-16\n#> year_c      -0.07148    0.00492   -14.5   <2e-16\n#> \n#> Residual standard error: 0.443 on 44 degrees of freedom\n#> Multiple R-squared:  0.827,\tAdjusted R-squared:  0.823 \n#> F-statistic:  211 on 1 and 44 DF,  p-value: <2e-16\n```\n:::\n\n\nCon *prior debolmente informativi*, i risultati bayesiani e frequentisti tendono a essere molto simili (stesse quantità stimate, ma nel caso bayesiano abbiamo l’intera *distribuzione a posteriori* dei parametri, utile per inferenze e previsione).\n\n\n### Visualizzazione dei risultati\n\nPer comprendere visivamente la relazione stimata tra *anno* ed *estensione dei ghiacci artici* nel nostro modello bayesiano, possiamo utilizzare la funzione `conditional_effects`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconditional_effects(fit_1, effects = \"year_c\")\n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl grafico generato fornisce una rappresentazione intuitiva della stima:\n\n* **Linea centrale (media posteriore):** rappresenta il valore medio previsto di *extent* per ciascun valore di `year_c`.\n* **Area colorata (intervallo di credibilità):** mostra l’*intervallo di credibilità* al 95% (Highest Density Interval, HDI), cioè l’intervallo in cui cade il 95% della distribuzione a posteriori delle previsioni.\n\nPossiamo modificare il livello di incertezza visualizzato regolando l’argomento `prob`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizzazione con intervallo di credibilità all'89%\nconditional_effects(fit_1, effects = \"year_c\", prob = 0.89)\n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n* Riducendo `prob` (ad esempio a 0.80 o 0.50) otteniamo intervalli più stretti, che mostrano solo la parte più densa della distribuzione posteriore.\n* Aumentando `prob` (ad esempio a 0.99) otteniamo intervalli più ampi, che riflettono una maggiore incertezza.\n\n#### Interpretazione pratica del grafico\n\nNel grafico:\n\n* il punto in cui la linea attraversa `year_c = 0` corrisponde all’*estensione prevista dei ghiacci* nell’anno medio del campione (circa il 2001, dato che abbiamo centrato la variabile `year`);\n* la *pendenza della linea* indica la variazione media di estensione dei ghiacci (in milioni di km²) per ogni anno in più: un valore negativo segnala una riduzione progressiva;\n* la *larghezza dell’intervallo di credibilità* riflette il grado di incertezza delle stime: intervalli più stretti indicano maggiore precisione, intervalli più larghi indicano più incertezza.\n\n\n## Due tipi di incertezza nei modelli bayesiani\n\nImmaginiamo di voler capire come l’*anno* (*X*) sia collegato all’*estensione dei ghiacci artici* (*Y*). Con un modello bayesiano otteniamo due tipi distinti di incertezza, che corrispondono a due domande diverse:\n\n| Che cosa stiamo stimando?                                                                                         | Come si chiama l’incertezza?                      | Che intervallo disegniamo?                       |\n| ----------------------------------------------------------------------------------------------------------------- | ------------------------------------------------- | ------------------------------------------------ |\n| *La media “vera”* dell’estensione dei ghiacci per un dato anno                                                    | *Incertezza del parametro* (o dell’effetto medio) | *Intervallo di credibilità* (credible interval)  |\n| *Il valore futuro di una nuova osservazione* (quale sarà l’estensione dei ghiacci in un singolo anno come quello) | *Incertezza predittiva*                           | *Intervallo di predizione* (prediction interval) |\n\n\n### Incertezza del parametro – «Quanto stiamo sbagliando la linea media?»\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconditional_effects(fit_1, effects = \"year_c\")\n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n* Disegna la *linea di regressione* (la media stimata dell’estensione per ogni anno centrato).\n* Aggiunge intorno una *fascia stretta*: l’intervallo di credibilità al 95%.\n\n* *Come leggerla:*\n  Se la fascia, per l’anno medio del campione, va ad esempio da 7.5 a 7.7 milioni di km², significa che “con il 95% di probabilità la vera media dell’estensione in quell’anno sta lì dentro”.\n  Non dice nulla sulle singole osservazioni, che possono discostarsi anche molto dalla media.\n\n\n**Metafora veloce.** *Pensa a tirare freccette: la media cade vicino al centro, ma ogni singola freccia può atterrare in punti diversi. L’intervallo di credibilità descrive solo *dove cade il centro*.*\n\n\n### Incertezza predittiva – «Quanto potrebbe variare la prossima osservazione?»\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconditional_effects(fit_1, effects = \"year_c\", method = \"predict\")\n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n* Ripropone la stessa linea media.\n* Disegna però una *fascia molto più larga*: l’intervallo di predizione.\n\nL’intervallo predittivo include due fonti di variabilità:\n\n1. *Incertezza sulla linea media* (come sopra).\n2. *Variabilità residua*: le differenze naturali tra osservazioni nello stesso anno (fluttuazioni dovute a vento, condizioni meteorologiche, ecc.).\n\n**Metafora veloce.** *Ora guardi non solo il centro del bersaglio, ma l’intero disco dove ogni freccia potrebbe cadere. L’area è molto più grande.*\n\n\n### Quando usare l’una o l’altra fascia?\n\n| Obiettivo della tua domanda                                                                     | Funzione da usare                              | Quale fascia guardare       |\n| ----------------------------------------------------------------------------------------------- | ---------------------------------------------- | --------------------------- |\n| Capire *l’effetto medio* (es. “quanto si riduce in media l’estensione ogni anno?”)              | `conditional_effects(...)`                     | *Intervallo di credibilità* |\n| Fare *previsioni su un caso futuro* (es. “quale sarà l’estensione osservata nell’agosto 2025?”) | `conditional_effects(..., method = \"predict\")` | *Intervallo di predizione*  |\n\n\n#### In sintesi\n\n1. *Credibilità* = incertezza sul *parametro medio* → fascia stretta (stima della retta).\n2. *Predizione* = incertezza su *osservazioni future* → fascia larga (linea + variabilità residua).\n3. La scelta dipende dalla domanda: “qual è la media?” (credibilità) oppure “dove cadrà il prossimo dato?” (predizione).\n\nIn breve, la visualizzazione predittiva è più onesta quando vogliamo fare previsioni concrete su nuove osservazioni, mentre quella con l’intervallo di credibilità è più utile per capire la relazione generale tra anno ed estensione dei ghiacci.\n\n\n\n## Distribuzione a posteriori dei parametri\n\nPer esaminare la *distribuzione a posteriori dei parametri* del modello, possiamo utilizzare la funzione `mcmc_plot()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmcmc_plot(fit_1, type = \"dens\")\n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nQuesta funzione disegna la *densità a posteriori* dei parametri, mostrando graficamente quali valori sono più plausibili dato il modello, i dati e le scelte a priori.\n\nPer un’analisi numerica più dettagliata, trasformiamo l’oggetto `fit_1` in un formato compatibile con il pacchetto `posterior` e poi calcoliamo le statistiche di sintesi:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws <- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#> # A tibble: 2 × 5\n#>   variable      mean    sd mcse_mean mcse_sd\n#>   <chr>        <dbl> <dbl>     <dbl>   <dbl>\n#> 1 b_Intercept  6.709 0.066     0.001   0.001\n#> 2 b_year_c    -0.071 0.005     0.000   0.000\n```\n:::\n\n\n* La funzione `as_draws()` converte l’oggetto in una struttura che rappresenta i campioni MCMC.\n* Gli argomenti `variable = \"^b_\"` e `regex = TRUE` selezionano solo i parametri che iniziano con `b_`, cioè i coefficienti del modello: l’intercetta e la pendenza.\n* La funzione `summarise_draws()` calcola statistiche riassuntive per la distribuzione a posteriori di questi parametri.\n\n\n### Spiegazione di `mcse_mean` e `mcse_sd`\n\nOltre a media (`mean`) e deviazione standard (`sd`), `summarise_draws()` riporta anche due indici utili:\n\n* **`mcse_mean`** = *Monte Carlo Standard Error* della media.\n\n  * Indica quanto la stima della media potrebbe variare semplicemente perché abbiamo un numero finito di campioni MCMC.\n  * Se è molto piccolo rispetto a `sd`, possiamo fidarci che la media stimata rappresenta bene la distribuzione a posteriori.\n\n* **`mcse_sd`** = *Monte Carlo Standard Error* della deviazione standard.\n\n  * Indica quanto la stima della deviazione standard della distribuzione a posteriori potrebbe variare per lo stesso motivo.\n  * Anche qui, un valore molto piccolo rispetto alla `sd` è segno che il campionamento è stato sufficiente.\n\n\n### Come interpretarli in pratica?\n\n* **Rapporto rispetto a `sd`**\n\n  * `mcse_mean` e `mcse_sd` dovrebbero essere almeno un ordine di grandezza più piccoli delle corrispondenti stime (`mean` e `sd`).\n  * Ad esempio: se per `b_Intercept` abbiamo `mcse_mean = 0.0044` e `sd = 0.2695`, il valore è più di 60 volte più piccolo → la stima è robusta.\n\n* **Qualità del campionamento**\n\n  * Se `mcse_mean` o `mcse_sd` fossero troppo grandi, questo indicherebbe che:\n\n    * il numero di iterazioni MCMC è insufficiente,\n    * le catene non hanno mescolato bene,\n    * o ci sono problemi di convergenza.\n\n\n#### In sintesi\n\n* `mcse_mean` e `mcse_sd` non descrivono l’incertezza statistica sui dati, ma *la qualità del campionamento Monte Carlo*.\n* Se sono piccoli, significa che il numero di campioni è sufficiente e la distribuzione a posteriori è rappresentata in modo accurato.\n* In altre parole: ci dicono se possiamo fidarci che la “fotografia” ottenuta con l’MCMC rispecchi bene la vera distribuzione a posteriori.\n\n\n## Specificare i priors\n\nNei modelli bayesiani i *priors* rappresentano le nostre aspettative sui parametri *prima* di osservare i dati. Se non li specifichiamo, `brms` assegna dei prior debolmente informativi di default.\n\nPossiamo ispezionarli con la funzione `get_prior`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nget_prior(extent ~ 1 + year_c, data = df)\n#>                   prior     class   coef group resp dpar nlpar lb ub\n#>  student_t(3, 6.8, 2.5) Intercept                                   \n#>                  (flat)         b                                   \n#>                  (flat)         b year_c                            \n#>    student_t(3, 0, 2.5)     sigma                               0   \n#>        source\n#>       default\n#>       default\n#>  (vectorized)\n#>       default\n```\n:::\n\n\nL’output mostra quali prior vengono assegnati a ciascun parametro del modello. Per esempio:\n\n1. **`prior`** – indica il prior utilizzato.\n\n   * `student_t(3, 6.8, 2.5)`: prior t di Student per l’intercetta, con 3 gradi di libertà, media 6.8 e scala 2.5.\n   * `(flat)`: prior piatto (non informativo) per i coefficienti delle variabili predittive, come il coefficiente di `year_c`.\n   * `student_t(3, 0, 2.5)`: prior t di Student per la deviazione standard residua ($\\sigma$), centrato su 0 con scala 2.5.\n\n2. **`class`** – indica a quale tipo di parametro il prior si riferisce:\n\n   * `Intercept`: prior sull’intercetta ($\\alpha$);\n   * `b`: prior sui coefficienti dei predittori ($\\beta$);\n   * `sigma`: prior sulla deviazione standard residua ($\\sigma$).\n\n3. **`coef`** – specifica a quale predittore si riferisce il prior.\n\n   * Vuoto per l’intercetta (perché non dipende da un predittore specifico).\n   * `year_c` per il coefficiente associato al predittore `year_c`.\n\n4. **`lb` e `ub`** – rappresentano i limiti inferiore (*lower bound*) e superiore (*upper bound*) del prior, se esistono.\n\n   * Per `sigma`, il limite inferiore è 0, poiché una deviazione standard non può essere negativa.\n\n5. **`source`** – indica se il prior è stato impostato dall’utente o se è il valore predefinito (`default`).\n\n\n### Specificare priors manualmente\n\nSe vogliamo rendere esplicite le nostre ipotesi, possiamo definire dei priors diversi da quelli di default. Ad esempio:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprior_gaussian <- \n  brms::prior(normal(7, 2), class = \"b\", coef = \"Intercept\") +    # Intercetta attorno a 7 (milioni km²)\n  brms::prior(normal(0, 0.5), class = \"b\", coef = \"year_c\") +  # Coefficiente di year_c\n  brms::prior(cauchy(0, 2), class = \"sigma\")          # Deviazione standard residua\n```\n:::\n\n\n> Nota: usiamo `brms::prior()` per essere sicuri di richiamare la funzione del pacchetto `brms` ed evitare conflitti con funzioni omonime di altri pacchetti.\n\nAdattiamo ora il modello con i priors specificati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_2 <- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n```\n:::\n\n\nE otteniamo un sommario numerico delle distribuzioni a posteriori:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws <- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#> # A tibble: 2 × 5\n#>   variable      mean    sd mcse_mean mcse_sd\n#>   <chr>        <dbl> <dbl>     <dbl>   <dbl>\n#> 1 b_Intercept  6.711 0.068     0.001   0.001\n#> 2 b_year_c    -0.072 0.005     0.000   0.000\n```\n:::\n\n\n### Confronto con i priors di default\n\nNel nostro caso, i priors esplicitamente definiti *non cambiano in modo rilevante* le distribuzioni a posteriori. Questo accade perché i dati disponibili sono numerosi e forniscono già informazioni molto forti: in pratica, le osservazioni “dominano” sulle ipotesi iniziali.\n\nDal punto di vista didattico è un aspetto cruciale da sottolineare:\n\n* **Con molti dati e alta informatività**, i priors hanno un ruolo marginale: le stime finali saranno simili indipendentemente dalle ipotesi iniziali.\n* **Con pochi dati o dati molto rumorosi**, invece, i priors diventano determinanti: le scelte iniziali possono influenzare in maniera sostanziale i risultati finali.\n\nIn altre parole, la forza relativa tra *dati* e *priors* dipende dalla quantità e dalla qualità dell’informazione empirica disponibile.\n\n\n## Predizioni a posteriori (*Posterior Predictive Checks*)\n\nUn aspetto fondamentale nella valutazione di un modello statistico, sia frequentista che bayesiano, è verificare *quanto bene le predizioni del modello rappresentino i dati osservati*. La logica di fondo è simile nei due paradigmi, ma l’approccio e l’interpretazione sono diversi.\n\n\n### Confronto frequentista\n\nNel caso frequentista, il confronto si basa sui valori stimati dal modello:\n\n$$\n\\hat{y} = \\hat{\\alpha} + \\hat{\\beta}x\n$$\n\nSi analizzano principalmente:\n\n* la vicinanza della retta di regressione ai dati osservati;\n* la presenza di eventuali pattern non lineari nei residui;\n* la variazione della dispersione di $y$ rispetto a $x$ (per verificare l’ipotesi di omoschedasticità).\n\n\n### Approccio bayesiano\n\nNell’approccio bayesiano eseguiamo *le stesse verifiche di base*, ma disponiamo di uno strumento in più: le *Predizioni a Posteriori* (*Posterior Predictive Checks, PPCs*).\n\nL’idea è semplice ma potente:\n\n* invece di confrontare i dati osservati solo con una linea di regressione “fissa”,\n* li confrontiamo con *dati simulati dal modello*, generati utilizzando i campioni dalle distribuzioni a posteriori dei parametri.\n\nIn questo modo, nelle predizioni è incorporata anche l’*incertezza sui parametri* stimata dal modello.\n\n\n### Come si costruiscono le predizioni a posteriori\n\nNel caso di un modello lineare semplice, il procedimento è:\n\n1. **Dati osservati:** partiamo dalla distribuzione empirica della variabile risposta ($y$).\n2. **Estrazione dei parametri:** prendiamo un campione casuale $\\alpha'$, $\\beta'$, $\\sigma'$ dalle distribuzioni a posteriori dei parametri.\n3. **Simulazione dei dati:** generiamo valori simulati da una normale:\n\n   $$\n   y_{\\text{sim}} \\sim \\mathcal{N}(\\alpha' + \\beta' x, \\sigma')\n   $$\n\n   dove $x$ sono i predittori osservati.\n4. **Ripetizione:** il processo viene ripetuto molte volte, producendo numerosi dataset simulati.\n5. **Confronto:** i dati simulati vengono confrontati con i dati reali (istogrammi, densità o residui).\n\n\n### Interpretazione\n\n* **Buona corrispondenza:** se la distribuzione dei dati simulati si sovrappone bene a quella osservata, il modello rappresenta adeguatamente i dati.\n* **Discrepanze:** differenze sistematiche (picchi mancanti, code sottostimate, ecc.) indicano che il modello non cattura tutti gli aspetti dei dati.\n\nIl vantaggio dei PPC è che:\n\n* integrano l’incertezza sui parametri;\n* permettono di valutare non solo la bontà di adattamento media, ma anche dettagli della distribuzione;\n* sono molto intuitivi e visivi, facilitando la diagnosi di problemi.\n\n\n#### Esempi con R\n\nVerifichiamo le predizioni del modello confrontandole con i dati osservati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npp_check(fit_2)\n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIn questo caso, il grafico mostra una buona corrispondenza tra i dati simulati e quelli reali.\n\nPossiamo poi analizzare i *residui bayesiani* con un grafico più specifico:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npp_check(fit_1, type = \"error_scatter_avg\")\n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nQuesto grafico rappresenta i residui (differenze tra osservato e predetto) rispetto ai valori predetti:\n\n* se i residui appaiono distribuiti in modo uniforme, il modello descrive correttamente la relazione;\n* se emergono pattern sistematici (ad esempio curvature o variazioni di dispersione), il modello potrebbe essere inadeguato.\n\n\n### Commento sui residui\n\nNel grafico dei residui ($y$ in funzione di $y - y_{\\text{rep}}$) si osserva un *trend crescente*: i residui non sono distribuiti in modo uniforme, ma mostrano una struttura sistematica. Questo pattern indica che il modello lineare bivariato *non cattura pienamente le proprietà dei dati*. In particolare, trattandosi di una serie temporale, è probabile che vi siano *dipendenze tra osservazioni successive nel tempo*: l’estensione dei ghiacci in un anno dipende anche dai valori degli anni immediatamente precedenti. Il modello lineare semplice, invece, assume che gli errori siano *indipendenti e identicamente distribuiti*, e non è quindi in grado di rappresentare questa dinamica temporale.\n\nQuesto esempio è didatticamente importante perché mostra che:\n\n* anche un modello molto semplice può aiutare a evidenziare *strutture nascoste nei dati* (qui la dipendenza temporale);\n* tuttavia, se compaiono *incongruenze nei residui*, significa che il modello non è adeguato e va *migliorato o reso più complesso* (ad esempio con modelli di regressione per serie temporali o modelli gerarchici dinamici).\n\nLa verifica dei residui è dunque un passaggio cruciale: non solo permette di valutare l’adattamento del modello, ma può suggerire *nuove direzioni di modellizzazione* per rappresentare meglio la complessità del fenomeno.\n\n\n\n#### In sintesi\n\nLe *Predizioni a Posteriori* forniscono un modo robusto per valutare l’adeguatezza di un modello bayesiano:\n\n* se i dati simulati somigliano ai dati reali, il modello è plausibile per il campione analizzato;\n* in caso contrario, è opportuno rivedere la struttura del modello (es. includendo effetti non lineari, variabili aggiuntive o priors più adeguati).\n\nIl PPC è una “prova del nove” del modello, che traduce la teoria in un confronto diretto e visivo con i dati osservati.\n\n\n## Regressione robusta\n\nIn questa sezione introduciamo la *regressione robusta*.\nL’obiettivo è mostrare quanto sia semplice modificare, in `brm()`, la distribuzione degli errori per rendere il modello meno sensibile agli *outlier*.\n\nQuesta flessibilità è un punto di forza dell’approccio bayesiano: nei modelli frequentisti standard, la distribuzione degli errori è quasi sempre fissata a priori (ad esempio normale/gaussiana) e non può essere facilmente modificata.\n\n\n### Perché servono modelli robusti?\n\nGli outlier — valori molto distanti dal resto delle osservazioni — possono influenzare in modo marcato le stime di regressione.\nAd esempio, aggiungiamo artificialmente un outlier nel dataset:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_outlier <- df\ndf_outlier$extent[1] <- 20     # valore anomalo molto alto\ndf_outlier$year_c[1] <- -25    # anno centrato \"estremo\"\n```\n:::\n\n\nVisualizziamo i dati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_outlier |> \n  ggplot(aes(x = year_c, y = extent)) +\n    geom_point() +  \n    labs(x = \"Anno centrato\", y = \"Estensione (milioni km²)\") \n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n### Effetto dell’outlier su un modello gaussiano\n\nStimiamo un modello lineare gaussiano:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_3 <- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n```\n:::\n\n\nEsaminiamo i parametri stimati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws <- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#> # A tibble: 2 × 5\n#>   variable      mean    sd mcse_mean mcse_sd\n#>   <chr>        <dbl> <dbl>     <dbl>   <dbl>\n#> 1 b_Intercept  6.961 0.252     0.004   0.004\n#> 2 b_year_c    -0.107 0.019     0.000   0.000\n```\n:::\n\n\nRispetto al modello stimato senza outlier (dove la pendenza $\\beta$ era intorno a –0.07), qui la stima è fortemente distorta. Un singolo punto anomalo può dunque trascinare la retta di regressione.\n\n\n### Un modello robusto con distribuzione *t*\n\nPer ridurre la sensibilità agli outlier, possiamo sostituire la distribuzione gaussiana degli errori con una distribuzione *t* di Student, che ha *code più pesanti*:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_4 <- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  family = student(),   # distribuzione t di Student\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n```\n:::\n\n\nI risultati mostrano che il modello *t* è *meno influenzato dall’outlier* rispetto al modello gaussiano:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws <- posterior::as_draws(fit_4, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#> # A tibble: 2 × 5\n#>   variable      mean    sd mcse_mean mcse_sd\n#>   <chr>        <dbl> <dbl>     <dbl>   <dbl>\n#> 1 b_Intercept  6.740 0.068     0.001   0.001\n#> 2 b_year_c    -0.072 0.005     0.000   0.000\n```\n:::\n\n\n\n### Il parametro $\\nu$: quanto sono pesanti le code?\n\nIl modello con distribuzione *t* stima anche il parametro $\\nu$, che controlla la pesantezza delle code:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws <- posterior::as_draws(fit_4, variable = \"nu\")\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#> # A tibble: 1 × 5\n#>   variable  mean    sd mcse_mean mcse_sd\n#>   <chr>    <dbl> <dbl>     <dbl>   <dbl>\n#> 1 nu       2.527 0.840     0.014   0.016\n```\n:::\n\n\n* Con valori *alti* di $\\nu$ (es. > 30), la distribuzione *t* si avvicina a una normale.\n* Con valori *bassi* (es. $\\nu \\approx 4$), le code sono molto più pesanti: la distribuzione “accetta” più facilmente valori estremi, senza permettere che influenzino eccessivamente le stime.\n\nNel nostro caso, $\\nu \\approx 4$ indica una distribuzione ben più robusta della normale, e il modello riesce a ignorare in buona parte l’effetto dell’outlier.\n\n\n### In sintesi\n\nLa regressione robusta con distribuzione *t* è uno strumento essenziale quando sospettiamo che i dati possano contenere valori anomali. A differenza del modello gaussiano, non lascia che pochi outlier distorcano in modo significativo le stime dei parametri.\n\n\n\n## Indice di determinazione bayesiano\n\nCon il pacchetto `brms` possiamo calcolare il *Bayes $R^2$*, l’equivalente bayesiano del classico indice di determinazione $R^2$.\nQuesto indice misura la *proporzione di varianza spiegata dal modello*, ma a differenza dell’approccio frequentista, tiene conto dell’*incertezza associata* alle stime dei parametri.\n\nIl comando per calcolarlo è:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbayes_R2(fit_2)\n#>    Estimate Est.Error  Q2.5 Q97.5\n#> R2    0.822     0.023 0.764 0.851\n```\n:::\n\n\n\n### Interpretazione dell’output\n\nIl risultato è un *tibble* (una tabella ordinata) che riporta:\n\n* **Estimate**: la media della distribuzione a posteriori del Bayes $R^2$, cioè la proporzione di varianza spiegata dal modello;\n* **Est.Error**: l’errore standard associato alla stima;\n* **Q2.5** e **Q97.5**: i limiti inferiore e superiore dell’intervallo di credibilità al 95% per il Bayes $R^2$.\n\nEsempio (con valori ipotetici coerenti col nostro modello):\n\n* **Stima media**: il modello spiega circa il 57% della varianza osservata;\n* **Errore standard**: l’incertezza sulla stima è bassa (± 0.02);\n* **Intervallo di credibilità**: con il 95% di probabilità, il vero valore del Bayes $R^2$ si trova tra 0.52 e 0.61.\n\n### Differenze rispetto al $R^2$ frequentista\n\n1. **Incertezza esplicita**\n\n   * Il Bayes $R^2$ non è una stima puntuale, ma una distribuzione a posteriori: possiamo quindi rappresentare l’incertezza con intervalli di credibilità.\n   * Nel caso frequentista, invece, il $R^2$ è un singolo numero senza misura diretta di incertezza.\n\n2. **Influenza dei priors**\n\n   * Nel Bayes $R^2$, i priors scelti per i parametri influiscono sulla stima finale.\n   * Questo consente di incorporare conoscenze precedenti e rende la misura più flessibile e adattabile al contesto di ricerca.\n\n\n### Distribuzione a posteriori del Bayes $R^2$\n\nPossiamo anche visualizzare la distribuzione completa dei valori simulati di $R^2$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2_draws <- bayes_R2(fit_2, summary = FALSE)\nr2_df <- data.frame(R2 = as.numeric(r2_draws))\n\nggplot(r2_df, aes(x = R2)) +\n  geom_density() +\n  geom_rug(alpha = 0.4) +\n  labs(\n    x = expression(R^2),\n    y = \"Densità\"\n  ) \n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nCalcoliamo anche i quantili:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nround(quantile(r2_df$R2, probs = c(.025, .5, .975)), 3)\n#>  2.5%   50% 97.5% \n#> 0.764 0.827 0.851\n```\n:::\n\n\nIn alternativa, con `bayesplot` possiamo ottenere una visualizzazione immediata e compatta:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmcmc_areas(r2_draws, prob = 0.95) \n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-31-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n#### In sintesi\n\nIl Bayes $R^2$ è uno strumento potente perché combina l’intuitività del $R^2$ classico con la ricchezza informativa dell’approccio bayesiano, permettendo di valutare non solo quanta varianza il modello spiega, ma anche quanto siamo sicuri di questa stima.\n\n\n## Approfondimento: manipolare la distribuzione a posteriori con `brms`\n\nVediamo ora come accedere e manipolare i *campioni della distribuzione a posteriori* generati da un modello stimato con `brms`.\n\nSupponiamo di aver costruito un modello lineare semplice, in cui vogliamo predire l’estensione dei ghiacci (`extent`) a partire dall’anno centrato (`year_c`):\n\n```r\nfit_2 <- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n```\n\n\n### Estrarre i campioni\n\nUna volta stimato il modello, possiamo ottenere i *campioni MCMC* della distribuzione a posteriori con `as_draws()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposterior_2 <- as_draws(fit_2)\n```\n:::\n\n\nL’oggetto `posterior_2` è di tipo *draws*, definito dal pacchetto *posterior*.\nAl suo interno troviamo i campioni prodotti dall’algoritmo MCMC, organizzati come un array o una lista:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstr(posterior_2)\n#> List of 4\n#>  $ 1:List of 5\n#>   ..$ b_Intercept: num [1:1000] 6.74 6.72 6.75 6.65 6.79 ...\n#>   ..$ b_year_c   : num [1:1000] -0.075 -0.0721 -0.0757 -0.0717 -0.0745 ...\n#>   ..$ sigma      : num [1:1000] 0.43 0.427 0.494 0.493 0.413 ...\n#>   ..$ lprior     : num [1:1000] -3.05 -3.05 -3.06 -3.07 -3.04 ...\n#>   ..$ lp__       : num [1:1000] -31.1 -30.8 -31.8 -31.7 -31.9 ...\n#>  $ 2:List of 5\n#>   ..$ b_Intercept: num [1:1000] 6.75 6.75 6.69 6.73 6.53 ...\n#>   ..$ b_year_c   : num [1:1000] -0.0714 -0.0711 -0.0695 -0.0789 -0.0687 ...\n#>   ..$ sigma      : num [1:1000] 0.458 0.473 0.388 0.515 0.468 ...\n#>   ..$ lprior     : num [1:1000] -3.05 -3.05 -3.04 -3.07 -3.07 ...\n#>   ..$ lp__       : num [1:1000] -31 -31.1 -31.6 -32.6 -34.3 ...\n#>  $ 3:List of 5\n#>   ..$ b_Intercept: num [1:1000] 6.65 6.83 6.65 6.76 6.63 ...\n#>   ..$ b_year_c   : num [1:1000] -0.0703 -0.0642 -0.0752 -0.0688 -0.077 ...\n#>   ..$ sigma      : num [1:1000] 0.399 0.424 0.428 0.403 0.41 ...\n#>   ..$ lprior     : num [1:1000] -3.05 -3.04 -3.05 -3.04 -3.05 ...\n#>   ..$ lp__       : num [1:1000] -31.7 -33.8 -31.5 -31.5 -32.4 ...\n#>  $ 4:List of 5\n#>   ..$ b_Intercept: num [1:1000] 6.68 6.66 6.76 6.73 6.78 ...\n#>   ..$ b_year_c   : num [1:1000] -0.0625 -0.0729 -0.0661 -0.0708 -0.0711 ...\n#>   ..$ sigma      : num [1:1000] 0.44 0.423 0.465 0.451 0.414 ...\n#>   ..$ lprior     : num [1:1000] -3.05 -3.05 -3.05 -3.05 -3.04 ...\n#>   ..$ lp__       : num [1:1000] -32.5 -31.2 -31.7 -30.8 -31.5 ...\n#>  - attr(*, \"class\")= chr [1:3] \"draws_list\" \"draws\" \"list\"\n```\n:::\n\n\n\n### Parametri del modello\n\nPer vedere i nomi dei parametri campionati (intercetta, slope, deviazione standard, ecc.) usiamo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvariables(fit_2)\n#> [1] \"b_Intercept\" \"b_year_c\"    \"sigma\"       \"lprior\"      \"lp__\"\n```\n:::\n\n\nNel nostro caso, siamo interessati al coefficiente di regressione associato a `year_c`, che in `brms` è etichettato come `b_year_c`.\n\n\n### Estrarre e riorganizzare i campioni\n\nPer lavorare più comodamente con i campioni, possiamo usare *tidybayes*, che fornisce funzioni per trasformare gli output bayesiani in formato *tidy*.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nb_slope_draws <- posterior_2 |> \n  spread_draws(b_year_c)\n```\n:::\n\n\nLa funzione `spread_draws()` “srotola” i campioni in un tibble:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(b_slope_draws)\n#> # A tibble: 6 × 4\n#>   .chain .iteration .draw b_year_c\n#>    <int>      <int> <int>    <dbl>\n#> 1      1          1     1  -0.0750\n#> 2      1          2     2  -0.0721\n#> 3      1          3     3  -0.0757\n#> 4      1          4     4  -0.0717\n#> 5      1          5     5  -0.0745\n#> 6      1          6     6  -0.0682\n```\n:::\n\n\nOgni riga rappresenta un singolo campione della catena MCMC per quel parametro.\n\n\n### Calcolare statistiche di sintesi\n\nUna volta estratti i campioni di `b_year_c`, possiamo calcolare facilmente mediana, media e quantili:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nquantile(b_slope_draws$b_year_c, probs = c(0.03, 0.50, 0.97))\n#>      3%     50%     97% \n#> -0.0814 -0.0714 -0.0621\nmean(b_slope_draws$b_year_c)\n#> [1] -0.0715\n```\n:::\n\n\n* I quantili a 0.03 e 0.97 definiscono un intervallo di credibilità al 94%.\n* Il quantile a 0.50 corrisponde alla *mediana a posteriori*.\n* La media a posteriori fornisce un’altra stima puntuale utile.\n\n\n### Visualizzare la distribuzione a posteriori\n\nPer capire meglio la forma della distribuzione a posteriori, possiamo tracciarne la densità. Con *tidyverse* e *tidybayes* bastano poche righe:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntibble(beta = b_slope_draws$b_year_c) %>%\n  ggplot(aes(x = beta)) +\n  stat_halfeye() +\n  labs(\n    x = \"Valore di β\",\n    y = \"Densità a posteriori\"\n  )\n```\n\n::: {.cell-output-display}\n![](04_synt_sugar_sea_ice_files/figure-html/unnamed-chunk-38-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n* `stat_halfeye()` mostra la densità stimata e mette in evidenza i valori più probabili.\n* La banda orizzontale rappresenta un intervallo di credibilità centrale.\n\n\n#### In sintesi\n\nGrazie a `as_draws()` di *posterior* e alle funzioni di *tidybayes*, possiamo:\n\n* estrarre i campioni MCMC della distribuzione a posteriori,\n* calcolare statistiche di sintesi (media, mediana, quantili),\n* visualizzare in modo intuitivo la forma e l’incertezza della distribuzione di un parametro.\n\nLa combinazione di *posterior*, *tidybayes* e *tidyverse* rende il flusso di lavoro con i modelli stimati da `brms` semplice, potente e flessibile.\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo visto come la scrittura di un modello possa essere resa più chiara e compatta attraverso l’uso di scorciatoie sintattiche. Lo scopo non è cambiare la sostanza del modello, ma alleggerire la sua formulazione, così da concentrare l’attenzione sugli aspetti concettuali e interpretativi piuttosto che sui dettagli tecnici ripetitivi.\n\nQuesta operazione di “pulizia” del codice ha un valore didattico importante: permette di visualizzare con maggiore immediatezza la struttura del modello e di cogliere più facilmente il legame tra le formule statistiche e la loro implementazione. Inoltre, anticipa una sfida che incontreremo sempre più spesso man mano che i modelli diventeranno complessi: la necessità di strumenti che automatizzino i calcoli senza oscurare la logica sottostante.\n\nNei prossimi capitoli vedremo come **Stan** risponda a questa esigenza su scala molto più ampia, fornendo un linguaggio di programmazione che combina rigore statistico e potenza computazionale. In questo senso, lo “zucchero sintattico” non è solo una comodità, ma un passo preparatorio per abituarci a pensare ai modelli in modo modulare, leggibile e scalabile.\n\n::: {.callout-important title=\"Problemi\" collapse=\"true\"}\n\n1. *Modello base*  \n   Importa il dataset `Howell_18.csv`, filtra gli individui di età ≥ 18 anni e adatta un modello bayesiano lineare `height ∼ weight` usando `brm()`. Visualizza il sommario.\n\n2. *Centraggio del predittore*  \n   Calcola la variabile centrata `weight_c` e adatta il modello `height ∼ weight_c`. Confronta l’intercetta (`b_Intercept`) con quella del modello non centrato. Spiega la differenza.\n\n3. *Specificazione dei prior*  \n   Usa `get_prior()` per recuperare i prior di default, poi definisci manualmente prior debolmente informativi:\n   \n   - `Intercept ∼ Normal(150, 20)`\n   - `weight_c ∼ Normal(0, 10)`\n   - `sigma ∼ Cauchy(0, 5)`\n   \n   Adatta il modello con questi prior e confronta le stime a posteriori con quelle del modello con prior di default.\n\n4. *Predizioni predittive a posteriori*  \n   Per il modello con prior personalizzati:\n   \n   - Esegui `pp_check()` per la densità e per l’errore medio (`type = \"error_scatter_avg\"`).\n   - Descrivi brevemente cosa mostrano i due grafici.\n\n5. *Modello robusto*  \n   Introduci un outlier modificando il primo record: imposta `height = 400`.  \n   \n   - Adatta prima un modello gaussiano e poi uno robusto con `family = student()`.\n   - Confronta le stime di `b_weight_c` nei due modelli e discuti l’impatto dell’outlier.\n\n:::\n\n::: {.callout-tip title=\"Soluzioni\" collapse=\"true\"}\n\n1. *Modello base*  \n\n   ```r\n   library(brms)\n   df <- rio::import(\"data/Howell_18.csv\")\n   df_adults <- subset(df, age >= 18)\n   fit_base <- brm(height ~ weight, data = df_adults, backend = \"cmdstanr\")\n   summary(fit_base)\n   ```\n\n2. *Centraggio del predittore*  \n\n   ```r\n   df_adults$weight_c <- df_adults$weight - mean(df_adults$weight)\n   fit_centered <- brm(height ~ weight_c, data = df_adults, backend = \"cmdstanr\")\n   summary(fit_centered)\n   ```\n   - Il `b_Intercept` nel modello non centrato è l’altezza prevista per peso = 0 (non interpretabile realisticamente).  \n   - Nel modello centrato, l’intercetta rappresenta l’altezza media alla media del peso del campione.\n\n3. *Specificazione dei prior*  \n\n   ```r\n   get_prior(height ~ weight_c, data = df_adults)\n   \n   priors_custom <- c(\n     prior(normal(150, 20), class = \"b\", coef = \"Intercept\"),\n     prior(normal(0, 10), class = \"b\", coef = \"weight_c\"),\n     prior(cauchy(0, 5), class = \"sigma\")\n   )\n   fit_priors <- brm(\n     height ~ weight_c,\n     data = df_adults,\n     prior = priors_custom,\n     backend = \"cmdstanr\"\n   )\n   summary(fit_priors)\n   ```\n   - Le stime a posteriori rimangono simili, ma i prior personalizzati influenzano leggermente l’incertezza.\n\n4. *Predizioni predittive a posteriori*  \n\n   ```r\n   pp_check(fit_priors)\n   pp_check(fit_priors, type = \"error_scatter_avg\")\n   ```\n   - Il grafico di densità mostra se la distribuzione simulata riproduce quella osservata.  \n   - Il grafico degli errori media evidenzia eventuali pattern sistematici nei residui.\n\n5. *Modello robusto*  \n\n   ```r\n   df_out <- df_adults\n   df_out$height[1] <- 400\n   fit_gauss <- brm(height ~ weight_c, data = df_out, backend = \"cmdstanr\")\n   fit_student <- brm(height ~ weight_c, family = student(),\n                      data = df_out, backend = \"cmdstanr\")\n   summary(fit_gauss)$fixed[\"weight_c\", ]\n   summary(fit_student)$fixed[\"weight_c\", ]\n   ```\n   - Il modello gaussiano vede una variazione marcata di `b_weight_c` a causa dell’outlier.  \n   - Il modello Student stima un coefficiente più vicino al valore senza outlier, dimostrando robustezza.\n:::\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#>  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#>  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [25] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#> [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#> [13] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#> [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#> [19] utf8_1.2.6            rmarkdown_2.29        ps_1.9.1             \n#> [22] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#> [25] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#> [28] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#> [31] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#> [34] knitr_1.50            zoo_1.8-14            R.utils_2.13.0       \n#> [37] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#> [40] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#> [43] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#> [46] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#> [49] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#> [52] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#> [55] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#> [58] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#> [61] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#> [64] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#> [67] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#> [70] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#> [73] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#> [76] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#> [79] gtable_0.3.6          R.methodsS3_1.8.2     digest_0.6.37        \n#> [82] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#> [85] R.oo_1.27.1           memoise_2.0.1         htmltools_0.5.8.1    \n#> [88] lifecycle_1.0.4       MASS_7.3-65\n```\n:::\n\n:::\n\n\n## Bibliografia {.unnumbered .unlisted}\n",
    "supporting": [
      "04_synt_sugar_sea_ice_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}