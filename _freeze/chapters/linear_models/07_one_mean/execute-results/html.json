{
  "hash": "837a6457a0899c8ff98b9d4731192ff3",
  "result": {
    "engine": "knitr",
    "markdown": "# Inferenza bayesiana su una media {#sec-mcmc-one-mean}\n\n::: {.epigraph}\n\n> “Il problema statistico non è stimare una media come se fosse un’entità assoluta, ma descrivere la distribuzione delle nostre credenze su di essa.”\n>\n> — ispirato a **Harold Jeffreys**\n:::\n\n\n## Introduzione {.unnumbered .unlisted}\n\nIn questo capitolo affrontiamo uno dei problemi più elementari — e al tempo stesso fondamentali — della statistica: stimare la **media di una popolazione** a partire da un campione di osservazioni. È una situazione ricorrente nella ricerca psicologica: possiamo chiederci qual è l’altezza media in un gruppo di adolescenti, il livello medio di ansia in un campione clinico, oppure la soddisfazione media di studenti che hanno seguito un determinato corso.\n\nTradizionalmente, questo problema è stato affrontato nell’ottica frequentista, che porta a costruire intervalli di confidenza o a testare ipotesi sulla media. In questa prospettiva, la media della popolazione è un valore fisso ma sconosciuto, e il ragionamento si concentra sul comportamento dei campioni che avremmo potuto osservare “se ripetessimo l’esperimento molte volte”.\n\nL’approccio *bayesiano* rovescia la prospettiva: la media non è un’entità misteriosa e fissa, ma una quantità sulla quale formuliamo delle *credenze incerte*, che possiamo aggiornare alla luce dei dati raccolti. Non stimiamo quindi “la media” in senso assoluto, ma descriviamo la *distribuzione delle nostre convinzioni* plausibili su di essa.\n\nQuesto cambiamento concettuale ha conseguenze profonde. Significa che l’analisi non si riduce a un verdetto dicotomico, ma diventa una rappresentazione sfumata dell’incertezza. Significa anche che possiamo integrare conoscenze pregresse tramite distribuzioni a priori, e che ogni inferenza riguarda direttamente i valori del parametro, non campioni ipotetici mai osservati.\n\nIn questo capitolo vedremo come costruire e interpretare una distribuzione a posteriori per la media di una popolazione, utilizzando esempi psicologici concreti. Sarà il primo passo per estendere il ragionamento bayesiano a situazioni più articolate, come il confronto tra due gruppi o la valutazione della grandezza di un effetto.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n- Come fare inferenza sulla media di un campione.\n- Come trovare le distribuzioni a posteriori usando `brms`.\n- Verificare il modello usando i pp-check plots.\n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere il capitolo *Geocentric models* di Statistical rethinking [@McElreath_rethinking].\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, ggdist)\n\nconflicts_prefer(stats::sd)\n```\n:::\n\n:::\n\n\n## La variabilità come punto di partenza\n\nOgni volta che raccogliamo dati psicologici, ci confrontiamo inevitabilmente con la variabilità. Alcune differenze sono *tra individui*:\n\n*Variabilità inter-individuale*: ad esempio, quanto differiscono tra loro le altezze, i tempi di reazione o i livelli di benessere soggettivo?\n\nAltre differenze sono *all’interno dello stesso individuo*, anche se meno visibili in un singolo rilevamento:\n\n*Variabilità intra-individuale*: quanto potrebbe variare la risposta della stessa persona se la misurassimo in momenti diversi della giornata, o in giorni diversi? Anche quando non la osserviamo direttamente, la variabilità intra-individuale è sempre una componente latente del dato psicologico, e ci invita a riflettere sulle fonti di instabilità e fluttuazione nei comportamenti e negli stati mentali.\n\n\n### L'incertezza come oggetto dell'inferenza\n\nA partire da questa variabilità, vogliamo formulare inferenze sul valore medio di un certo parametro (come l’altezza media in una popolazione). Ma ogni inferenza è anche un atto di *stima incerta*: nessun campione ci dà la verità, ma solo una gamma di possibilità più o meno plausibili.\n\nIn questo capitolo affronteremo quindi il problema dell’inferenza sulla media da due prospettive complementari:\n\n* *Approccio frequentista*: basato sull’idea di ripetizione del campionamento e sul calcolo di un intervallo di confidenza;\n* *Approccio bayesiano*: che assume esplicitamente l’incertezza e la rappresenta attraverso una distribuzione di probabilità (la *distribuzione a posteriori*).\n\n\n### Perché usare `brms`?\n\nInvece di derivare la distribuzione a posteriori della media in modo analitico (come nei modelli con prior coniugati), useremo il pacchetto `brms`, che si basa su un potente algoritmo di campionamento chiamato *NUTS* (No-U-Turn Sampler). Questo ci permetterà di stimare numericamente l’intera distribuzione a posteriori della media e della variabilità, anche in casi in cui il calcolo analitico sarebbe difficile o impossibile. In questo modo, potremo:\n\n* quantificare l’incertezza su ciò che ci interessa (ad esempio: qual è l’altezza media? con quanta certezza lo possiamo dire?);\n* visualizzare in modo intuitivo l’effetto dei dati e dei priori sulle nostre stime;\n* avvicinarci a un modo di pensare statistico più adatto alla complessità della psicologia, dove ogni dato è il risultato di molte fonti di variabilità.\n\n\n## Il modello Normale: un primo passo nella descrizione della variabilità\n\nQuando parliamo di altezza, ansia, tempo di reazione o qualsiasi altra variabile psicologica continua, un punto di partenza comune è il modello Normale. Questo modello assume che le osservazioni siano distribuite attorno a un valore medio, con una certa dispersione. In termini formali, diciamo che ogni osservazione $y_n$ è generata da una distribuzione Normale con media $\\mu$ e deviazione standard $\\sigma$:\n\n$$\ny_n \\;\\sim\\; \\mathcal N\\bigl(\\mu, \\sigma\\bigr).\n$$\n\nNel linguaggio dell’inferenza, $\\mu$ rappresenta il valore centrale che vogliamo stimare, mentre $\\sigma$ quantifica la variabilità delle osservazioni rispetto a quel centro. Entrambi i parametri sono ignoti, e l’obiettivo dell’inferenza è proprio descrivere l’incertezza che abbiamo su di essi.\n\nNel capitolo precedente abbiamo visto come calcolare la distribuzione a posteriori di questi parametri in modo analitico, quando si utilizzano prior coniugati. In questo capitolo, invece, riprendiamo lo stesso problema, ma adottiamo un approccio più generale e flessibile: stimiamo il modello usando il pacchetto `brms`, che utilizza metodi MCMC per approssimare la distribuzione a posteriori, anche quando non esistono soluzioni chiuse.\n\n\n## Un esempio concreto: la variabilità dell’altezza nei !Kung San\n\nPer rendere più concreto il problema, useremo un dataset storico: i dati raccolti da Nancy Howell tra la fine degli anni ’60 presso i !Kung San, una popolazione del deserto del Kalahari con uno stile di vita basato su caccia e raccolta.\n\nI dati che utilizzeremo riportano le altezze di individui adulti (con età superiore ai 18 anni). Questo esempio è tratto da @McElreath_rethinking, ed è ideale per iniziare a riflettere sulla *variabilità inter-individuale*.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- rio::import(here::here(\"data\", \"Howell_18.csv\"))\ndf |> head()\n#>   height weight age male\n#> 1    152   47.8  63    1\n#> 2    140   36.5  63    0\n#> 3    137   31.9  65    0\n#> 4    157   53.0  41    1\n#> 5    145   41.3  51    0\n#> 6    164   63.0  35    1\n```\n:::\n\n\nIl campione è composto da 352 osservazioni:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlength(df$height)\n#> [1] 352\n```\n:::\n\n\n\n### Distribuzione osservata dell’altezza\n\nUna prima esplorazione visiva ci aiuta a capire la forma della distribuzione osservata. L’istogramma seguente mostra come si distribuiscono le altezze nel campione:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(df, aes(x = height)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"Altezza\", y = \"Frequenza\") \n```\n\n::: {.cell-output-display}\n![](07_one_mean_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nLa forma appare compatibile con una distribuzione Normale. Ma quanto bene si adatta?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf |>\n  ggplot(aes(sample = height)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  labs(x = \"Quantili teorici\", y = \"Valori osservati\") \n```\n\n::: {.cell-output-display}\n![](07_one_mean_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nIl Q-Q plot mostra un leggero scostamento: la curva empirica è un po’ più piatta rispetto alla linea teorica, segno che la variabilità osservata è leggermente inferiore a quella attesa da una Normale standard (code meno pesanti). Tuttavia, la discrepanza è modesta, e possiamo comunque usare il modello gaussiano come prima approssimazione della distribuzione dei dati.\n\n\n## Specifica del modello: una distribuzione per descrivere l’incertezza\n\nNel modello bayesiano, ipotizziamo che ogni osservazione $y_n$ sia indipendente e identicamente distribuita (iid):\n\n$$\ny_n \\sim \\mathcal N(\\mu, \\sigma),\n$$\n\n* $\\mu$: la media vera (ignota) della popolazione.\n* $\\sigma$: la deviazione standard vera, che misura *quanta variabilità c’è tra gli individui*.\n\n> L'assunzione di indipendenza implica che conoscere l'errore commesso su un individuo non ci dice nulla sull'errore commesso su un altro.\n> L'assunzione di identica distribuzione implica che tutti gli individui provengano dalla stessa popolazione.\n\nScrivere $y_n \\sim \\mathcal N(\\mu, \\sigma)$ è quindi un modo compatto per dire che *ogni osservazione è un'espressione della variabilità inter-individuale*, distribuita attorno a un valore centrale.\n\n\n## Stime preliminari: una fotografia della variabilità\n\nPrima di definire i priori o stimare la distribuzione a posteriori, è utile esplorare alcune statistiche descrittive:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmean(df$height)   # media campionaria\n#> [1] 155\nsd(df$height)     # deviazione standard campionaria\n#> [1] 7.74\n```\n:::\n\n\nQueste due quantità ci offrono una prima “fotografia” della variabilità nel campione:\n\n* La *media campionaria* è una stima iniziale di $\\mu$, che potrà guidarci nella scelta di una prior realistica.\n* La *deviazione standard campionaria* è una misura iniziale di $\\sigma$, e descrive quanto le osservazioni si discostano, in media, dalla media.\n\nAnche se queste statistiche non riflettono ancora in modo completo l’incertezza che abbiamo, sono molto utili per:\n\n1. *Guidare la scelta dei priors* in un’ottica informata;\n2. *Individuare possibili outlier o anomalie*, che potrebbero influenzare sia l’inferenza frequentista sia quella bayesiana.\n\n\n## Il modello frequentista: stimare la media come punto fisso\n\nNel contesto dell’inferenza classica, uno dei modi più semplici per stimare la *media di una popolazione* consiste nell’adottare un modello lineare senza predittori: un modello che si limita a stimare un’unica quantità, chiamata *intercetta*. In pratica, questo corrisponde a stimare la *media campionaria* dei dati osservati.\n\nIn R, questo modello si specifica in modo molto compatto:\n\n```r\nheight ~ 1\n```\n\nIl simbolo `1` indica che vogliamo stimare solo l’intercetta, senza nessuna variabile esplicativa. In termini pratici, l’intercetta rappresenta qui la *media dell’altezza* nel campione.\n\n\n### Specifica e stima del modello\n\nPossiamo stimare il modello con la funzione `lm()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfm1 <- lm(\n  formula = height ~ 1, \n  data = df\n)\n```\n:::\n\n\nQuesto comando applica il metodo della *minima somma dei quadrati*, producendo una stima puntuale della media, assieme a una misura della sua variabilità.\n\n\n### Interpretare i risultati\n\nL’output del modello si ottiene con:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fm1)\n#> \n#> Call:\n#> lm(formula = height ~ 1, data = df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -18.072  -6.007  -0.292   6.058  24.473 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)\n#> (Intercept)  154.597      0.413     375   <2e-16\n#> \n#> Residual standard error: 7.74 on 351 degrees of freedom\n```\n:::\n\n\nIl riassunto mostra diverse informazioni, ma le più rilevanti in questo contesto sono:\n\n* *La stima dell’intercetta* $\\hat{\\alpha}$: coincide con la media campionaria delle altezze.\n* *L’errore standard*: misura la variabilità attesa della stima $\\hat{\\alpha}$ se ripetessimo il campionamento molte volte.\n* *Il p-value*: quantifica la probabilità di osservare un valore della statistica test così estremo (o più) se la media vera fosse 0. In questo caso ha scarso interesse pratico, perché il valore di riferimento (0 cm) non è plausibile.\n* *Il R²*: che in assenza di predittori non è interpretabile in modo utile.\n\n\n### Intervallo di confidenza al 95%: una misura indiretta dell’incertezza\n\nIl modello frequentista non descrive la nostra incertezza come una distribuzione su $\\mu$, ma fornisce invece un *intervallo di confidenza*, che ha un’interpretazione indiretta: se ripetessimo l’esperimento un numero molto elevato di volte, in circa il 95% dei casi l’intervallo conterrebbe il vero valore della media.\n\nPossiamo calcolarlo con:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nconfint(fm1, level = 0.95)\n#>             2.5 % 97.5 %\n#> (Intercept)   154    155\n```\n:::\n\n\nQuesto intervallo si basa sulla formula classica:\n\n$$\n\\hat{\\alpha} \\pm t_{\\text{df}} \\cdot \\text{SE}(\\hat{\\alpha})\n$$\n\ndove:\n\n* $\\hat{\\alpha}$ è la stima puntuale della media,\n* $t_{\\text{df}}$ è il quantile della distribuzione t di Student (con $n - 1$ gradi di libertà),\n* $\\text{SE}(\\hat{\\alpha})$ è l’errore standard della stima.\n\n### Calcolo manuale (opzionale)\n\nSe vogliamo calcolare l’intervallo “a mano”, possiamo scrivere:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncoef(fm1) + c(-1, 1) * qt(0.975, df.residual(fm1)) * 0.413\n#> [1] 154 155\n```\n:::\n\n\n* `coef(fm1)` restituisce la stima dell’intercetta,\n* `qt(0.975, df.residual(fm1))` fornisce il valore critico t,\n* `0.413` è l’errore standard (da sostituire con quello esatto, se disponibile).\n\n\n### Riflessione: cos’è l’incertezza, per davvero?\n\nNel modello frequentista, l’incertezza sulla media è descritta in termini di *variabilità potenziale tra campioni*, non come incertezza su un valore specifico. Il parametro $\\mu$ è trattato come *fisso ma ignoto*, e tutta l’incertezza risiede nella stima che otteniamo da un singolo campione.\n\nIn questo senso, l’approccio frequentista *non fornisce una distribuzione sul parametro*: non possiamo dire “la probabilità che la media sia tra 153 e 155 cm è del 95%”, ma solo che “se ripetessimo l’esperimento molte volte, l’intervallo conterrebbe la media vera nel 95% dei casi”.\n\nNel prossimo paragrafo vedremo come un modello bayesiano offra un’alternativa: trattare $\\mu$ come una *variabile aleatoria* su cui esprimere direttamente l’incertezza, permettendoci di formulare affermazioni probabilistiche esplicite sui valori possibili del parametro.\n\n\n## Il modello Bayesiano: descrivere l’incertezza con distribuzioni\n\nDopo aver stimato la media dell’altezza con il modello frequentista, possiamo affrontare lo stesso problema con un approccio bayesiano, usando il pacchetto `brms`. Questo ci consente di rappresentare in modo più diretto l’incertezza che abbiamo sui parametri del modello.\n\nNel framework bayesiano, tutti i parametri sono trattati come *variabili aleatorie*: invece di stimare un singolo valore per la media, stimiamo una *distribuzione a posteriori*, che riflette l’incertezza residua dopo aver osservato i dati.\n\n### Priori debolmente informativi: quando “non sappiamo molto” \n\nOgni modello bayesiano richiede la specifica di *distribuzioni a priori*. Tuttavia, quando non abbiamo conoscenze forti da inserire, possiamo affidarci ai *priori debolmente informativi*: distribuzioni ampie, generiche e poco vincolanti, che permettono ai dati di “parlare da soli”.\n\nSe non specifichiamo nulla, `brms` userà questi prior di default. È un buon punto di partenza, soprattutto per modelli semplici e dataset abbastanza ricchi.\n\n\n### Specifica del modello in `brms`\n\nIl codice è simile a quello usato con `lm()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfm2 <- brm(\n  formula = height ~ 1,       # stima solo l'intercetta (media dell’altezza)\n  family = gaussian(),        # assunzione di distribuzione normale\n  data = df,                  # dataset\n  chains = 4,                 # numero di catene MCMC\n  iter = 2000,                # iterazioni per catena\n  warmup = 1000,              # periodo di adattamento\n  backend = \"cmdstanr\"        # motore di calcolo efficiente\n)\n```\n:::\n\n\nQui stiamo stimando due parametri:\n\n* $\\mu$ → media dell’altezza nella popolazione;\n* $\\sigma$ → deviazione standard, che rappresenta *quanta variabilità inter-individuale* osserviamo.\n\nIn termini formali, il modello è scritto come:\n\n$$\ny_i = \\alpha + \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma).\n$$\n\n### Interpretare l’output: incertezza esplicitata\n\nUna volta che il modello è stato stimato, possiamo esaminarne l’output:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fm2)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 \n#>    Data: df (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   154.60      0.40   153.79   155.38 1.00     3342     2620\n#> \n#> Further Distributional Parameters:\n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     7.76      0.29     7.23     8.35 1.00     3158     2486\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nNel risultato troveremo:\n\n* *Media della distribuzione a posteriori* per $\\alpha$, che è la stima centrale di $\\mu$;\n* *Errore standard a posteriori*, cioè quanto fluttua $\\mu$ nei campioni simulati;\n* *Intervallo di credibilità* al 95%: l’intervallo in cui cade il 95% della distribuzione a posteriori di $\\mu$.\n\nA differenza dell’intervallo di confidenza frequentista, qui possiamo davvero dire:\n\n> C’è il 95% di probabilità che la media dell’altezza si trovi in questo intervallo, dati il modello e i dati osservati.\n\n\n### Riportare i risultati: due linguaggi per lo stesso fenomeno\n\n| Approccio    | Risultato                                                                                           |\n| ------------ | --------------------------------------------------------------------------------------------------- |\n| Frequentista | “La media stimata è 154.6, con un intervallo di confidenza al 95% tra 153.8 e 155.4.”               |\n| Bayesiano    | “La media stimata a posteriori è 154.6, con un intervallo di credibilità al 95% tra 153.8 e 155.4.” |\n\nNumericamente possono coincidere, ma la *logica inferenziale è diversa*: nel caso bayesiano, l’intervallo descrive ciò che crediamo plausibile; nel frequentista, ciò che la procedura catturerebbe nella maggior parte dei campioni ripetuti.\n\n\n### Esplorare i campioni a posteriori: guardare l’incertezza in faccia\n\nDopo aver stimato il modello, possiamo accedere direttamente ai campioni generati dall’algoritmo NUTS:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nas_draws_df(fm2) %>% head(3)\n#> # A draws_df: 3 iterations, 1 chains, and 5 variables\n#>   b_Intercept sigma Intercept lprior  lp__\n#> 1         155   7.6       155   -6.1 -1224\n#> 2         155   7.6       155   -6.1 -1224\n#> 3         155   7.6       155   -6.1 -1224\n#> # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n```\n:::\n\n\nOgni riga della colonna `b_Intercept` rappresenta un valore plausibile per $\\mu$, estratto dalla sua distribuzione a posteriori. Questi campioni sono il cuore dell’inferenza bayesiana: ci permettono di costruire grafici, intervalli e ragionamenti probabilistici.\n\n\n### Calcoli riassuntivi sui campioni\n\nPossiamo usare i campioni per calcolare:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Media a posteriori\nmean(as_draws_df(fm2)$b_Intercept)\n#> [1] 155\n\n# Deviazione standard a posteriori\nsd(as_draws_df(fm2)$b_Intercept)\n#> [1] 0.4\n\n# Intervallo di credibilità al 95%\nquantile(as_draws_df(fm2)$b_Intercept, probs = c(0.025, 0.975))\n#>  2.5% 97.5% \n#>   154   155\n```\n:::\n\n\n> Questi valori sintetizzano l’incertezza associata alla nostra stima della media: non un singolo punto, ma una nuvola di possibilità, tutte compatibili con i dati osservati.\n\n\n### Conclusioni intermedie\n\nAbbiamo visto come:\n\n* L’approccio frequentista fornisca una *stima puntuale* e un *intervallo ipotetico* di copertura.\n* L’approccio bayesiano fornisca una *distribuzione completa a posteriori*, da cui possiamo derivare medie, intervalli, probabilità e visualizzazioni.\n\nEntrambi gli approcci descrivono la *variabilità tra individui*, ma il metodo bayesiano offre strumenti più trasparenti per rappresentare l’*incertezza sui parametri*.\n\n> Questo è particolarmente utile in psicologia, dove campioni ridotti, contesti variabili e differenze individuali richiedono modelli che sappiano dire “quanto (non) sappiamo”.\n\nNel prossimo paragrafo vedremo come possiamo *personalizzare i priori*, incorporando informazioni pregresse (da studi precedenti, teoria, esperienza clinica…), e come questo possa influenzare l’inferenza nei casi in cui i dati da soli non siano sufficientemente informativi.\n\n\n## Uso dei Prior nel Modello Bayesiano: rendere esplicite le ipotesi sull’incertezza\n\nFinora abbiamo visto che è possibile stimare un modello bayesiano anche senza specificare esplicitamente i prior: in tal caso, `brms` utilizza prior debolmente informativi, lasciando che siano i dati a guidare l’inferenza.\n\nMa il cuore dell’approccio bayesiano sta proprio qui: nella possibilità di incorporare conoscenze precedenti, aspettative, risultati di studi precedenti — insomma, di modellare in modo *esplicito e trasparente* l’incertezza che abbiamo prima di vedere i dati.\n\n### Tre domande chiave prima di stimare\n\nPrima di usare un modello bayesiano, è utile porsi alcune domande fondamentali:\n\n* Cosa sappiamo già del fenomeno?\n* Come possiamo esprimere questa conoscenza sotto forma di distribuzioni?\n* Quanto vogliamo che questa conoscenza influenzi l’inferenza?\n\nLa risposta a queste domande guida la scelta dei prior. Nei passaggi che seguono, vedremo come un modello informato da prior realistici possa non solo migliorare la stima, ma anche *aumentare la coerenza tra teoria e dati*.\n\n\n### Specificare i prior: un esempio concreto\n\nRiprendiamo il nostro esempio sull’altezza nella popolazione dei !Kung San. Supponiamo di avere un’idea ragionevole su quanto potrebbe essere la media e la variabilità delle altezze.\n\nPossiamo tradurre questa conoscenza nel linguaggio delle distribuzioni:\n\n* Per $\\mu$ (la media), ipotizziamo:\n  $\\mu \\sim \\mathcal{N}(181, 30)$ — una media attesa intorno a 181 cm, con ampio margine di incertezza.\n\n* Per $\\sigma$ (la deviazione standard), ipotizziamo:\n  $\\sigma \\sim \\mathcal{N}^+(0, 20)$ — una normale troncata a destra, che garantisce valori positivi.\n\nQuesti prior sono *informativi ma ampi*: riflettono aspettative plausibili, senza imporre vincoli troppo rigidi.\n\n> McElreath scherza dicendo di usare come prior la propria altezza. L’ironia nasconde un principio importante: *ogni ipotesi è valida, purché dichiarata*. Un buon modello bayesiano non finge oggettività, ma esplicita l’incertezza iniziale.\n\n\n### Forma del modello con prior espliciti\n\nIl modello completo si scrive così:\n\n$$\n\\begin{aligned}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\\\\\\\\n\\mu &\\sim \\mathcal{N}(181,\\ 30) \\\\\\\\\n\\sigma &\\sim \\mathcal{N}^+(0,\\ 20)\n\\end{aligned}\n$$\n\nQui, sia la media sia la variabilità della popolazione sono trattate come *quantità soggette a incertezza*. La stima diventa un aggiornamento: partiamo da un’opinione iniziale e la modifichiamo alla luce dei dati.\n\n\n### Implementazione in `brms`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfm3 <- brm(\n  formula = height ~ 1,\n  data    = df,\n  family  = gaussian(),\n  prior   = c(\n    prior(normal(181, 30), class = \"Intercept\"),\n    prior(normal(0, 20), class = \"sigma\")\n  ),\n  chains  = 4, iter = 2000,\n  seed    = 1234,\n  backend = \"cmdstanr\"\n)\n```\n:::\n\n\n\n### Analisi dell’output\n\nUna volta stimato il modello, possiamo esaminarlo come sempre con:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fm3)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 \n#>    Data: df (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   154.60      0.41   153.80   155.41 1.00     3156     2659\n#> \n#> Further Distributional Parameters:\n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     7.77      0.29     7.20     8.38 1.00     3256     2596\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nSe i dati sono informativi (come in questo caso), l’effetto dei prior sarà contenuto: la distribuzione a posteriori sarà molto simile a quella ottenuta con prior deboli. Questo è un comportamento desiderabile: il prior *non deve forzare i risultati*, ma integrarsi con essi.\n\n\n### Scegliere il livello dell’intervallo di credibilità\n\nPossiamo modificare la probabilità coperta dall’intervallo credibile, ad esempio scegliendo un *intervallo all’89%* anziché al 95%:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fm3, prob = 0.89)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 \n#>    Data: df (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   154.60      0.41   153.94   155.27 1.00     3156     2659\n#> \n#> Further Distributional Parameters:\n#>       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     7.77      0.29     7.32     8.25 1.00     3256     2596\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nQuesta scelta è proposta da McElreath come default per motivi pedagogici: evitare che l’intervallo venga interpretato come test di significatività.\n\n> “Why 89%? Because it’s prime.” — è un invito a *pensare criticamente* alle convenzioni statistiche, e a riflettere su cosa stiamo cercando davvero di comunicare quando riportiamo un intervallo.\n\n\n### Cosa otteniamo con prior espliciti?\n\nUsare prior informativi consente di:\n\n- Incorporare conoscenze teoriche, esperienze passate, dati precedenti.\n- Rendere il modello più robusto quando i dati sono scarsi o rumorosi.\n- Evitare stime irrealistiche in contesti con alta incertezza.\n- Esplicitare le nostre ipotesi, invece di nasconderle dietro un’apparente neutralità.\n\n\n### Conclusione\n\nIn un modello bayesiano, ogni assunzione è chiara e trattabile. I risultati non sono semplici numeri, ma *distribuzioni di credibilità* che raccontano ciò che è plausibile, dato ciò che sapevamo prima e ciò che abbiamo osservato ora.\n\n> Questo rende l’approccio bayesiano particolarmente adatto alla psicologia: un campo dove l’incertezza è la norma, la variabilità è parte del fenomeno da spiegare, e la trasparenza delle assunzioni è fondamentale.\n\nNel prossimo paragrafo, ci concentreremo su come visualizzare e valutare queste distribuzioni a posteriori, usando strumenti diagnostici e grafici che ci aiutano a comprendere — e comunicare — la variabilità residua stimata dal modello.\n\n\n## Visualizzare l’incertezza con `bayesplot`\n\nIl pacchetto `bayesplot` è uno strumento prezioso per ogni analisi bayesiana: permette di esplorare visivamente la variabilità delle stime a posteriori, di diagnosticare l’efficienza del campionamento MCMC e di verificare se il modello riesce a riprodurre i dati osservati.\n\nIn un contesto psicologico, dove spesso i dati sono rumorosi e le inferenze complesse, poter visualizzare *dove e quanto il modello è incerto* è fondamentale.\n\n\n### Traceplot: osservare le catene in azione\n\nIl traceplot mostra l’evoluzione dei campioni per ogni parametro nel corso delle iterazioni MCMC. Serve a controllare:\n\n* che le catene siano *stazionarie* (nessuna deriva sistematica),\n* che si *mescolino bene* (assenza di autocorrelazione),\n* che ci sia *convergenza* (tutte le catene esplorano la stessa distribuzione).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmcmc_trace(fm3, pars = c(\"Intercept\", \"sigma\"), facet_args = list(nrow = 2))\n```\n\n::: {.cell-output-display}\n![](07_one_mean_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nUn buon traceplot mostra bande dense, senza tendenze crescenti o oscillazioni lente: questo suggerisce che il campionamento stia catturando in modo affidabile la distribuzione a posteriori.\n\n\n### Densità a posteriori: cosa crediamo dopo aver visto i dati\n\nPer visualizzare la distribuzione di probabilità di un parametro stimato, possiamo usare:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmcmc_areas(fm3, regex_pars = \"b_Intercept\", prob = 0.89)\n```\n\n::: {.cell-output-display}\n![](07_one_mean_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nQuesta funzione evidenzia l’*intervallo credibile* in cui cade, ad esempio, l’89% della densità a posteriori per la media dell’altezza.\n\n> A differenza dell’intervallo di confidenza, qui possiamo davvero dire che *c’è l’89% di probabilità che la media vera sia compresa in quell’intervallo*.\n\n\n### Distribuzione congiunta di due parametri: incrociare incertezze\n\nQuando vogliamo esplorare la relazione tra due parametri (ad esempio, media e deviazione standard), possiamo usare:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmcmc_scatter(fm3, pars = c(\"Intercept\", \"sigma\"))\n```\n\n::: {.cell-output-display}\n![](07_one_mean_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nQuesto tipo di visualizzazione è utile per valutare *dipendenze tra parametri*: ad esempio, se i campioni sono inclinati lungo una diagonale, significa che c’è correlazione a posteriori tra i due.\n\n\n### Posterior Predictive Check: il modello spiega davvero i dati?\n\nUna delle forze dell’approccio bayesiano è che i modelli sono *generativi*: possiamo simulare nuovi dati partendo dalle distribuzioni a posteriori e confrontarli con quelli osservati.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npp_check(fm3)\n```\n\n::: {.cell-output-display}\n![](07_one_mean_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nLa funzione `pp_check()` mostra:\n\n* in nero: la distribuzione dei dati osservati,\n* in colore: più repliche simulate dal modello.\n\nSe le simulazioni coprono bene i dati reali, il modello è coerente con le osservazioni. Se invece ci sono *scostamenti sistematici*, questo può indicare che:\n\n* la distribuzione scelta non è adatta,\n* ci sono outlier non gestiti,\n* mancano variabili esplicative nel modello.\n\n\n## L’approccio tradizionale: il test t di Student\n\nPrima dell’adozione diffusa dei metodi bayesiani, l’inferenza sulla media veniva solitamente effettuata con il *test t*. Questo approccio assume che la variabilità osservata nel campione (stimata con la deviazione standard campionaria) sia sufficiente a rappresentare l’incertezza sul parametro d’interesse.\n\nIl calcolo si basa sulla statistica:\n\n$$\nT = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}.\n$$\n\nIl test permette di costruire un intervallo di confidenza, ma non di fare affermazioni probabilistiche sui parametri. Il valore $\\mu$ è considerato fisso ma sconosciuto, e l’incertezza è attribuita unicamente al *campionamento*.\n\n\n## Confronto tra approcci: stesso dato, epistemologie diverse\n\n| Elemento                       | Frequentista                         | Bayesiano                           |\n| ------------------------------ | ------------------------------------ | ----------------------------------- |\n| Concetto di parametro          | Fisso ma ignoto                      | Variabile aleatoria                 |\n| Incertezza                     | Tra campioni                         | Nei parametri                       |\n| Intervallo (95%)               | Procedura che copre nel 95% dei casi | Credibilità del 95% sul valore vero |\n| Estensione a modelli complessi | Limitata                             | Flessibile                          |\n| Trasparenza delle assunzioni   | Implicita                            | Esplicita                           |\n\n\n## Replicare l’analisi con `cmdstanr`\n\nOra replichiamo con *cmdstanr* (Stan esplicito) l'analisi ottenuta con `brm` e salvata nell'oggetto `fm3`.\n\nIl modello è:\n\n$$\ny_i \\sim \\mathrm{Normal}(\\mu,\\sigma), \\qquad\n\\mu \\sim \\mathcal{N}(181, 30), \\qquad\n\\sigma \\sim \\mathcal{N}^+(0, 20),\n$$\n\ndove $\\mathcal{N}^+$ indica la normale troncata ai valori positivi.\n\nIl modello Stan equivalente è\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstancode <- \"\ndata {\n  int<lower=1> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  // Priors equivalenti a brms:\n  mu    ~ normal(181, 30);\n  sigma ~ normal(0, 20); // con <lower=0> diventa automaticamente Half-Normal(0,20)\n\n  // Likelihood\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (n in 1:N) y_rep[n] = normal_rng(mu, sigma);\n}\n\"\n```\n:::\n\n\nCompiliamo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_file <- write_stan_file(stancode, dir = \"stan\", basename = \"one_mean_fm3.stan\")\nmod       <- cmdstan_model(stan_file)\n```\n:::\n\n\nPrepariamo i dati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_data <- list(N = nrow(df), y = as.numeric(df$height))\nglimpse(stan_data)\n#> List of 2\n#>  $ N: int 352\n#>  $ y: num [1:352] 152 140 137 157 145 ...\n```\n:::\n\n\nEseguiamo il campionamento:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_stan <- mod$sample(\n  data = stan_data,\n  seed = 1234,\n  chains = 4, \n  iter_warmup = 1000, \n  iter_sampling = 4000, \n  parallel_chains = 4,\n  adapt_delta = 0.95\n)\n```\n:::\n\n\nEsaminiamo i risultati:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_stan$summary(variables = c(\"mu\",\"sigma\"))\n#> # A tibble: 2 × 10\n#>   variable    mean  median    sd   mad      q5     q95  rhat  ess_bulk ess_tail\n#>   <chr>      <dbl>   <dbl> <dbl> <dbl>   <dbl>   <dbl> <dbl>     <dbl>    <dbl>\n#> 1 mu       154.601 154.602 0.413 0.406 153.918 155.285 1.000 10185.459 8086.662\n#> 2 sigma      7.767   7.757 0.290 0.288   7.303   8.259 1.000 10043.384 8612.693\n```\n:::\n\n\n\n### Confronto delle posterior (*brms* vs *Stan*)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws_brm  <- as_draws_df(fm3) |>\n  transmute(mu = b_Intercept, sigma = sigma)\ndraws_stan <- as_draws_df(fit_stan$draws(variables = c(\"mu\",\"sigma\")))\n\nsumm_brm  <- posterior::summarise_draws(draws_brm)  |> mutate(modello = \"brms\")\nsumm_stan <- posterior::summarise_draws(draws_stan) |> mutate(modello = \"stan\")\n\ndplyr::bind_rows(summ_brm, summ_stan) |>\n  dplyr::select(modello, variable, mean, sd, q5, q95, rhat, ess_bulk) |>\n  dplyr::arrange(variable, modello)\n#> # A tibble: 4 × 8\n#>   modello variable    mean    sd      q5     q95  rhat  ess_bulk\n#>   <chr>   <chr>      <dbl> <dbl>   <dbl>   <dbl> <dbl>     <dbl>\n#> 1 brms    mu       154.603 0.414 153.924 155.281 1.000  3150.751\n#> 2 stan    mu       154.601 0.413 153.918 155.285 1.000 10185.459\n#> 3 brms    sigma      7.771 0.294   7.305   8.264 1.000  3220.370\n#> 4 stan    sigma      7.767 0.290   7.303   8.259 1.000 10043.384\n```\n:::\n\n\n\n### Visualizzazione delle densità posteriori\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](07_one_mean_files/figure-html/plot-fm3-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nSe le aree colorate e le linee dei due modelli si sovrappongono quasi perfettamente in ciascun pannello, le *posterior* coincidono entro il rumore Monte Carlo.\n\n### Posterior predictive check\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws_yrep <- fit_stan$draws(\"y_rep\")\narr <- posterior::as_draws_array(draws_yrep)\nM <- dim(arr)[1] * dim(arr)[2]\nN <- dim(arr)[3]\n\nyrep_df  <- as.data.frame(matrix(arr, nrow = M, ncol = N))\nobs_mean <- mean(df$height)\nyrep_mean <- rowMeans(as.matrix(yrep_df))\n\nppc_df <- data.frame(stat = yrep_mean)\n\nbase_col  <- \"#56B4E9\"\nline_col  <- \"#D55E00\"\n\nggplot(ppc_df, aes(x = stat)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, color = \"white\", fill = base_col) +\n  geom_vline(xintercept = obs_mean, color = line_col, linewidth = 1) +\n  labs(x = \"Media(y_rep)\", y = \"Densità\")\n```\n\n::: {.cell-output-display}\n![](07_one_mean_files/figure-html/ppc-fm3-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n### Nota sulle prior\n\nCon il vincolo $\\sigma>0$ in Stan, la specifica `sigma ~ normal(0, 20);` implementa automaticamente una *Half-Normal* con scala 20, coerente con `prior(normal(0, 20), class = \"sigma\")` in `brms`. Questa equivalenza assicura che i risultati dei due approcci coincidano entro l’errore Monte Carlo, a parità di dati e impostazioni MCMC.\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo riformulato un problema classico — la stima della media di una popolazione — nella prospettiva bayesiana. Abbiamo visto che ciò che otteniamo non è un singolo numero, ma una *distribuzione a posteriori* che descrive in modo esplicito le nostre credenze aggiornate sul parametro. Questa distribuzione ci dice quanto sono plausibili diversi valori della media, integrando insieme l’informazione a priori e i dati osservati.\n\nIl passaggio dall’approccio frequentista a quello bayesiano segna un cambiamento concettuale profondo. Non ci limitiamo più a calcolare un intervallo di confidenza o a verificare un’ipotesi nulla, ma costruiamo una rappresentazione diretta dell’incertezza sui parametri che ci interessano. In questo modo, l’inferenza diventa non solo più intuitiva, ma anche più trasparente e coerente con il modo in cui gli psicologi ragionano sui fenomeni: sempre con un certo margine di dubbio, ma anche con la possibilità di pesare scenari alternativi.\n\nNaturalmente, la stima di una media è solo il punto di partenza. Nella ricerca psicologica siamo spesso interessati a *confrontare due gruppi*, per capire se una popolazione differisce da un’altra, e se sì di quanto. Nei prossimi capitoli vedremo come estendere il ragionamento bayesiano a questi casi, collegando la stima della media al confronto tra condizioni sperimentali e alla valutazione della *grandezza dell’effetto*.\n\n::: {.callout-important title=\"Problemi\" collapse=\"true\"}\n\n*Obiettivo:* Utilizzare i dati dello studio di @tarrats2025efficacy per replicare i risultati riportati nella Figura 2 , applicando sia l’approccio frequentista che il framework bayesiano. Calcolare inoltre la grandezza dell’effetto nel contesto bayesiano (Cohen’s $d$) e generare un grafico che visualizzi la distribuzione a posteriori della grandezza dell’effetto ottenuta. \n\n:::\n\n::: {.callout-tip title=\"Soluzioni\" collapse=\"true\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(brms)\nlibrary(posterior)\nlibrary(bayestestR)\n\ndf <- read_excel(\n  here::here(\n    \"data\",\n    \"Tarrats-Pons.xlsx\"\n  ),\n  sheet = 3\n)\n\ndf |>\n  group_by(Sample) |>\n  summarize(\n    avg = mean(`CESS-D`),\n    n = n()\n  )\n\ndf_wide <- df %>%\n  select(IdentificationNumber, Sample, CESS_D = `CESS-D`) %>%\n  pivot_wider(\n    names_from = Sample, # da POST/PRE\n    values_from = CESS_D, # i valori da mettere nelle colonne\n    names_prefix = \"CESSD_\" # opzionale, per nominare CESSD_POST, CESSD_PRE\n  )\n\n# Controlla il risultato\nhead(df_wide)\n\ndf_wide$diff <- df_wide$CESSD_PRE - df_wide$CESSD_POST\n\nhist(df_wide$diff)\n\nt.test(df_wide$diff)\n\n# t-test sulle differenze\nres <- t.test(df_wide$diff)\n\n# Numero di soggetti\nn <- length(df_wide$diff)\n\n# Calcolo di Cohen's d\nd_t <- as.numeric(res$statistic) / sqrt(n)\n\n# Mostro risultato\nd_t\n\nfm1 <- brm(\n  formula = diff ~ 1, # Modello con sola intercetta (mu)\n  data = df_wide,\n  family = gaussian(), # Distribuzione Normale\n  prior = c(\n    brms::prior(normal(0, 10), class = \"Intercept\"), # Prior su mu\n    brms::prior(normal(0, 10), class = \"sigma\") # Prior su sigma\n  ),\n  chains = 4,\n  iter = 2000,\n  seed = 1234,\n  backend = \"cmdstanr\"\n)\nsummary(fm1)\npp_check(fm1)\n\nfm2 <- brm(\n  formula = diff ~ 1, # Modello con sola intercetta (mu)\n  data = df_wide,\n  family = student(), # Distribuzione Normale\n  prior = c(\n    brms::prior(normal(0, 10), class = \"Intercept\"), # Prior su mu\n    brms::prior(normal(0, 10), class = \"sigma\") # Prior su sigma\n  ),\n  chains = 4,\n  iter = 2000,\n  seed = 1234,\n  backend = \"cmdstanr\"\n)\nsummary(fm2)\npp_check(fm2)\n\npost_samples <- posterior::as_draws_df(fm1)\nhead(post_samples)\n\npost_samples$effect_size <- post_samples$b_Intercept / post_samples$sigma\n\n# Calcolo diretto delle statistiche dell'effect size\nmean_effect_size <- mean(post_samples$effect_size)\nsd_effect_size <- sd(post_samples$effect_size)\nci_effect_size <- quantile(post_samples$effect_size, probs = c(0.025, 0.975))\n\n# Stampa dei risultati\ncat(\"=== Statistiche dell'Effect Size Bayesiano ===\\n\")\ncat(\"Effect size medio:\", round(mean_effect_size, 2), \"\\n\")\ncat(\"SD dell'effect size:\", round(sd_effect_size, 2), \"\\n\")\ncat(\n  \"Intervallo di credibilità al 95%:\",\n  round(ci_effect_size[1], 2),\n  \"-\",\n  round(ci_effect_size[2], 2),\n  \"\\n\\n\"\n)\n\n# Interpretazione dell'effect size secondo le convenzioni di Cohen\nif (abs(mean_effect_size) < 0.2) {\n  interpretation <- \"piccolo\"\n} else if (abs(mean_effect_size) < 0.5) {\n  interpretation <- \"medio-piccolo\"\n} else if (abs(mean_effect_size) < 0.8) {\n  interpretation <- \"medio\"\n} else {\n  interpretation <- \"grande\"\n}\ncat(\"Interpretazione (Cohen):\", interpretation, \"\\n\")\n\n# Calcola la probabilità che l'effect size sia maggiore di zero\nprob_positive <- mean(post_samples$effect_size > 0)\ncat(\n  \"Probabilità che l'effect size sia positivo:\",\n  round(prob_positive * 100, 2),\n  \"%\\n\"\n)\n\n# Se necessario, calcola probabilità per altre soglie\nprob_medium <- mean(post_samples$effect_size > 0.5)\ncat(\n  \"Probabilità che l'effect size sia > 0.5 (medio):\",\n  round(prob_medium * 100, 2),\n  \"%\\n\"\n)\nprob_large <- mean(post_samples$effect_size > 0.8)\ncat(\n  \"Probabilità che l'effect size sia > 0.8 (grande):\",\n  round(prob_large * 100, 2),\n  \"%\\n\"\n)\n\n# Visualizzazione della distribuzione posteriore dell'effect size\n# (Per eseguire questo blocco, devi avere ggplot2 installato e caricato)\n# library(ggplot2)\nggplot(post_samples, aes(x = effect_size)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  geom_vline(\n    xintercept = mean_effect_size,\n    color = \"red\",\n    linetype = \"dashed\"\n  ) +\n  geom_vline(\n    xintercept = ci_effect_size[1],\n    color = \"darkblue\",\n    linetype = \"dotted\"\n  ) +\n  geom_vline(\n    xintercept = ci_effect_size[2],\n    color = \"darkblue\",\n    linetype = \"dotted\"\n  ) +\n  labs(\n    x = \"Effect Size (Cohen's d)\",\n    y = \"Densità\"\n  ) \n```\n:::\n\n:::\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] readxl_1.4.5          lubridate_1.9.4       forcats_1.0.0        \n#>  [4] stringr_1.5.1         purrr_1.1.0           readr_2.1.5          \n#>  [7] tidyverse_2.0.0       bayestestR_0.17.0     cmdstanr_0.9.0       \n#> [10] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#> [13] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#> [16] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [19] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [22] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [25] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [28] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [31] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [34] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] RColorBrewer_1.1-3    tensorA_0.36.2.1      jsonlite_2.0.0       \n#>  [4] magrittr_2.0.3        TH.data_1.1-4         estimability_1.5.1   \n#>  [7] farver_2.1.2          rmarkdown_2.29        ragg_1.5.0           \n#> [10] vctrs_0.6.5           memoise_2.0.1         htmltools_0.5.8.1    \n#> [13] distributional_0.5.0  curl_7.0.0            broom_1.0.9          \n#> [16] cellranger_1.1.0      htmlwidgets_1.6.4     plyr_1.8.9           \n#> [19] sandwich_3.1-1        emmeans_1.11.2-8      zoo_1.8-14           \n#> [22] cachem_1.1.0          lifecycle_1.0.4       pkgconfig_2.0.3      \n#> [25] Matrix_1.7-4          R6_2.6.1              fastmap_1.2.0        \n#> [28] snakecase_0.11.1      digest_0.6.37         colorspace_2.1-1     \n#> [31] ps_1.9.1              rprojroot_2.1.1       textshaping_1.0.3    \n#> [34] labeling_0.4.3        timechange_0.3.0      abind_1.4-8          \n#> [37] compiler_4.5.1        withr_3.0.2           backports_1.5.0      \n#> [40] inline_0.3.21         QuickJSR_1.8.0        pkgbuild_1.4.8       \n#> [43] R.utils_2.13.0        MASS_7.3-65           tools_4.5.1          \n#> [46] R.oo_1.27.1           glue_1.8.0            nlme_3.1-168         \n#> [49] grid_4.5.1            checkmate_2.3.3       reshape2_1.4.4       \n#> [52] generics_0.1.4        gtable_0.3.6          tzdb_0.5.0           \n#> [55] R.methodsS3_1.8.2     data.table_1.17.8     hms_1.1.3            \n#> [58] utf8_1.2.6            splines_4.5.1         lattice_0.22-7       \n#> [61] survival_3.8-3        tidyselect_1.2.1      knitr_1.50           \n#> [64] arrayhelpers_1.1-0    gridExtra_2.3         V8_7.0.0             \n#> [67] stats4_4.5.1          xfun_0.53             bridgesampling_1.1-2 \n#> [70] stringi_1.8.7         yaml_2.3.10           pacman_0.5.1         \n#> [73] evaluate_1.0.5        codetools_0.2-20      cli_3.6.5            \n#> [76] RcppParallel_5.1.11-1 xtable_1.8-4          systemfonts_1.2.3    \n#> [79] processx_3.8.6        coda_0.19-4.1         svUnit_1.0.8         \n#> [82] parallel_4.5.1        rstantools_2.5.0      Brobdingnag_1.2-9    \n#> [85] mvtnorm_1.3-3         scales_1.4.0          ggridges_0.5.7       \n#> [88] insight_1.4.2         rlang_1.1.6           multcomp_1.4-28\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n",
    "supporting": [
      "07_one_mean_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}