{
  "hash": "459b693068b298b563c14e75624aebbb",
  "result": {
    "engine": "knitr",
    "markdown": "# Estensioni {#sec-formal-models-developments}\n\n::: {.epigraph}\n> “People change over time. ... describing and explaining change over time must focus on dynamics in response to environmental cues and competing internal states. That is, we must include time and change over time in our models.”\n>\n> -- **Wilt, J.**, It's about time: Emphasizing temporal dynamics in [personality] (2003)\n:::\n\n## Introduzione {.unnumbered .unlisted} \n\nSulla scia di @knight2023tutorial, in questo capitolo estendiamo il modello presentato in precedenza lungo tre direzioni complementari. Partiamo dal *livello individuale* (*person-level*), in cui stimiamo per ciascun partecipante i propri parametri $(\\alpha_i, \\beta_i)$. Questo passaggio consente di mappare l’eterogeneità interindividuale (sensibilità al feedback e deriva motivazionale), ma lascia le stime dei singoli *isolate* le une dalle altre.\n\nPer superare questo limite introduciamo la versione *gerarchica (multilevel)*: i parametri dei singoli sono considerati *estratti* da distribuzioni di popolazione (es. normali) descritte da iper-parametri. In questo modo le informazioni vengono condivise tra individui, con il tipico effetto di *shrinkage* che stabilizza le stime, soprattutto quando i dati per soggetto sono pochi o rumorosi.\n\nInfine, consideriamo il caso dei *gruppi noti* (es. *approach* vs *avoidance*), stimando iper-parametri separati per ciascuna condizione. Questo permette di quantificare differenze sistematiche *a livello di popolazione* tra condizioni sperimentali, oltre alle differenze tra individui. Valuteremo i modelli con criteri *predittivi* (ELPD tramite *LOO-CV*), così da bilanciare in modo esplicito *complessità* e *capacità di generalizzazione*.\n\n### Panoramica del capitolo {.unnumbered .unlisted}\n\n* *Modello a livello individuale*: stima di $\\alpha_i$ e $\\beta_i$ per ogni soggetto.\n* *Modello gerarchico*: parametri individuali estratti da distribuzioni di popolazione → *shrinkage* e maggiore robustezza.\n* *Gruppi noti*: iper-parametri specifici per condizione (*approach* vs *avoidance*).\n* *Confronto predittivo*: ELPD e *LOO-CV* per scegliere il modello.\n* *Implicazioni psicologiche*: quando e perché la gerarchia migliora l’inferenza.\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n\nsuppressPackageStartupMessages({\n  library(cmdstanr)\n  library(bayesplot)\n  library(tidybayes)\n  library(posterior)\n  library(loo)\n  library(patchwork)\n  library(conflicted)\n})\n\nconflicts_prefer(loo::loo)\nconflicts_prefer(dplyr::count)\n```\n:::\n\n:::\n\n\n### Modello a livello individuale \n\nIl modello *sample-level* stima un unico insieme di parametri $(\\alpha, \\beta)$ per l'intero campione, ignorando le differenze individuali. Per cogliere questa eterogeneità, è possibile introdurre il *modello a livello individuale* (*person-level*), che stima parametri distinti $(\\alpha_i, \\beta_i)$ per ogni partecipante $i$.\n\nIn questa formulazione:\n\n- ogni individuo possiede il proprio tasso di apprendimento $\\alpha_i$ e la propria deriva motivazionale $\\beta_i$;\n- il parametro $\\sigma$, che cattura la variabilità residua (rumore decisionale), rimane comune a tutti i soggetti.\n\nQuesto approccio consente di:\n\n- mappare la variabilità interindividuale nei processi di aggiornamento degli obiettivi;\n- identificare profili comportamentali distinti (es. soggetti molto reattivi al feedback vs. poco adattivi);\n- evitare l'assunzione – spesso irrealistica – che tutti i partecipanti rispondano allo stesso modo.\n\nTuttavia, il modello a livello individuale non incorpora alcun meccanismo di \"condivisione dell'informazione\" tra i soggettii, ma ogni partecipante viene modellato in modo indipendente dagli altri. Questa caratteristica lo distingue dal modello gerarchico (o multilevel), in cui i parametri individuali sono considerati provenienti da una distribuzione di gruppo, il che migliora la robustezza delle stime, soprattutto quando i dati sono limitati o rumorosi.\n\n\n### Preparazione dei dati\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Caricamento del dataset\ndat <- rio::import(\"data/goal_data.csv\")\n\n# Ordina i dati per soggetto e per trial\ndat <- dat |> \n  arrange(subject, trial)\n\n# (Opzionale) Verifica che l'ordinamento sia corretto\nstr(dat)\n#> 'data.frame':\t600 obs. of  5 variables:\n#>  $ subject    : int  1 1 1 1 1 1 1 1 1 1 ...\n#>  $ condition  : chr  \"approach\" \"approach\" \"approach\" \"approach\" ...\n#>  $ goal       : int  2 2 2 4 4 2 2 4 2 4 ...\n#>  $ performance: int  0 2 2 4 2 0 4 2 4 4 ...\n#>  $ trial      : int  1 2 3 4 5 6 7 8 9 10 ...\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(dat$subject)  # restituisce il numero di trial per soggetto\n#> \n#>  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n#> 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 \n#> 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 \n#> 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 \n#> 53 54 55 56 57 58 59 60 \n#> 10 10 10 10 10 10 10 10\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1) Ordina per soggetto e trial\ndat <- dat %>% arrange(subject, trial)\n\n# 2) Salva scale originali (per eventuale back-transform)\ngoal_mean <- mean(dat$goal, na.rm = TRUE); goal_sd <- sd(dat$goal, na.rm = TRUE)\nperf_mean <- mean(dat$performance, na.rm = TRUE); perf_sd <- sd(dat$performance, na.rm = TRUE)\n\n# 3) Standardizza\ndat <- dat %>%\n  mutate(\n    goal_z = (goal - goal_mean) / goal_sd,\n    perf_z = (performance - perf_mean) / perf_sd\n  )\n\n# 4) Lista per Stan (condition è opzionale qui: non usata nel baseline)\nstan_data <- list(\n  subject       = dat$subject,\n  trial         = dat$trial,\n  observed_goal = dat$goal_z,\n  performance   = dat$perf_z,\n  Nsubj         = dplyr::n_distinct(dat$subject),\n  Ntotal        = nrow(dat)\n)\n\nstr(stan_data)\n#> List of 6\n#>  $ subject      : int [1:600] 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ trial        : int [1:600] 1 2 3 4 5 6 7 8 9 10 ...\n#>  $ observed_goal: num [1:600] -2 -2 -2 -1.07 -1.07 ...\n#>  $ performance  : num [1:600] -2.89 -1.99 -1.99 -1.1 -1.99 ...\n#>  $ Nsubj        : int 60\n#>  $ Ntotal       : int 600\n```\n:::\n\n\n\n### Definizione del modello Stan\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstancode <- \"\ndata {\n  int<lower=1> Ntotal;                 // es. 600\n  int<lower=1> Nsubj;                  // es. 60\n  array[Ntotal] int<lower=1> subject;  // indice soggetto (1..Nsubj)\n  array[Ntotal] int<lower=1> trial;    // 1..T per ciascun soggetto (ordinati)\n  vector[Ntotal] observed_goal;        // Z-score\n  vector[Ntotal] performance;          // Z-score\n}\n\nparameters {\n  vector[Nsubj] alpha;                 // guadagno per soggetto\n  vector[Nsubj] beta;                  // drift per soggetto\n  real<lower=1e-6> sigma;              // dev. std residua (comune)\n}\n\ntransformed parameters {\n  vector[Ntotal] ghat;                 // traiettoria predetta\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      // reset a inizio soggetto: primo stato = prima osservazione\n      ghat[i] = observed_goal[i];\n    } else {\n      int s = subject[i];\n      // ricorsione: usa predizione e performance del trial precedente (stesso soggetto se i dati sono ordinati)\n      ghat[i] = ghat[i - 1]\n                + alpha[s] * (performance[i - 1] - ghat[i - 1])\n                + beta[s];\n    }\n  }\n}\n\nmodel {\n  // Priors semplici coerenti con z-score\n  alpha ~ normal(0, 1);\n  beta  ~ normal(0, 1);\n  sigma ~ normal(0, 1);   // half-normal(1) per via del lower bound\n\n  // Likelihood\n  observed_goal ~ normal(ghat, sigma);\n}\n\ngenerated quantities {\n  vector[Ntotal] yrep;\n  vector[Ntotal] log_lik;\n\n  for (i in 1:Ntotal) {\n    yrep[i]   = normal_rng(ghat[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);\n  }\n}\n\"\n```\n:::\n\n\nQuesto modello presuppone che i dati siano *ordinati per soggetto e per trial*, altrimenti la dinamica `i - 1` non corrisponde al trial precedente dello stesso soggetto. \n\nEsaminiamo in dettaglio cosa significano `alpha[subject[i]]` e `beta[subject[i]]`. Nel modello Stan, ogni trial `i` è associato a un certo soggetto. Questa informazione è contenuta nel vettore:\n\n```stan\narray[Ntotal] int<lower=1> subject;\n```\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstan_data$subject\n#>   [1]  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  3  3  3  3  3\n#>  [26]  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5\n#>  [51]  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8\n#>  [76]  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10\n#> [101] 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13\n#> [126] 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15\n#> [151] 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18\n#> [176] 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20\n#> [201] 21 21 21 21 21 21 21 21 21 21 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23\n#> [226] 23 23 23 23 23 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25\n#> [251] 26 26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 28 28 28 28 28\n#> [276] 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30\n#> [301] 31 31 31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 32 32 33 33 33 33 33\n#> [326] 33 33 33 33 33 34 34 34 34 34 34 34 34 34 34 35 35 35 35 35 35 35 35 35 35\n#> [351] 36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37 37 37 38 38 38 38 38\n#> [376] 38 38 38 38 38 39 39 39 39 39 39 39 39 39 39 40 40 40 40 40 40 40 40 40 40\n#> [401] 41 41 41 41 41 41 41 41 41 41 42 42 42 42 42 42 42 42 42 42 43 43 43 43 43\n#> [426] 43 43 43 43 43 44 44 44 44 44 44 44 44 44 44 45 45 45 45 45 45 45 45 45 45\n#> [451] 46 46 46 46 46 46 46 46 46 46 47 47 47 47 47 47 47 47 47 47 48 48 48 48 48\n#> [476] 48 48 48 48 48 49 49 49 49 49 49 49 49 49 49 50 50 50 50 50 50 50 50 50 50\n#> [501] 51 51 51 51 51 51 51 51 51 51 52 52 52 52 52 52 52 52 52 52 53 53 53 53 53\n#> [526] 53 53 53 53 53 54 54 54 54 54 54 54 54 54 54 55 55 55 55 55 55 55 55 55 55\n#> [551] 56 56 56 56 56 56 56 56 56 56 57 57 57 57 57 57 57 57 57 57 58 58 58 58 58\n#> [576] 58 58 58 58 58 59 59 59 59 59 59 59 59 59 59 60 60 60 60 60 60 60 60 60 60\n```\n:::\n\n\nOgni elemento `subject[i]` ci dice *a quale soggetto appartiene il trial `i`*, usando un numero intero da `1` a `Nsubj`. Quindi se `subject[137] == 24`, significa che il 137-esimo trial è del soggetto 24.\n\nOra, se abbiamo un vettore di parametri specifici per ogni soggetto\n\n```stan\nvector[Nsubj] alpha;\nvector[Nsubj] beta;\n```\n\nallora\n\n* `alpha[subject[i]]` significa: prendi il valore del parametro `alpha` associato al soggetto a cui appartiene il trial `i`;\n* lo stesso vale per `beta[subject[i]]`.\n\nPer esempio, supponiamo\n\n```stan\nsubject = [1, 1, 1, 2, 2, 3, 3]\nalpha = [0.5, 0.8, 1.1]  // Tre soggetti: 1, 2, 3\n```\n\nallora\n\n* `alpha[subject[4]] = alpha[2] = 0.8`, perché il 4° trial è del soggetto 2.\n* `beta[subject[6]] = beta[3] = ...`, perché il 6° trial è del soggetto 3.\n\nIn sintesi, la sintassi `alpha[subject[i]]` (e `beta[subject[i]]`) indica: “Nel trial `i`, usa il valore del parametro `alpha` (o `beta`) del soggetto indicato da `subject[i]`”. È un modo compatto per associare ogni osservazione ai parametri della persona corrispondente.\n\n\n### Compilazione ed esecuzione del modello  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstanmod <- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit1 <- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 5000,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  seed = 4790\n)\n```\n:::\n\n\n\n### Analisi dei risultati\n\nQuesto modello genera un insieme di campioni posteriori per i parametri $\\alpha$ e $\\beta$, uno per ciascun partecipante. \n\nEstrazione dei campioni in formato \"draws_matrix\" (per summary tabellari):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstandraws <- fit1$draws(format = \"draws_matrix\")\n```\n:::\n\n\nStatistiche descrittive compatte per $\\alpha_i$, $\\beta_i$ e $\\sigma$: media, mediana e intervalli credibili al 95% (2.5% - 97.5%):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstandraws |> \n  subset_draws(variable = c(\"alpha\", \"beta\", \"sigma\")) |> \n  summarise_draws(\n    mean,\n    ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n  ) |> \n  print()\n#> # A tibble: 121 × 5\n#>    variable   mean `2.5%` `50%` `97.5%`\n#>    <chr>     <dbl>  <dbl> <dbl>   <dbl>\n#>  1 alpha[1]  0.662  0.161 0.683   1.022\n#>  2 alpha[2]  0.181 -0.265 0.178   0.595\n#>  3 alpha[3]  0.167 -0.251 0.186   0.507\n#>  4 alpha[4]  0.300 -0.515 0.303   0.950\n#>  5 alpha[5]  0.400  0.056 0.399   0.744\n#>  6 alpha[6]  0.586 -0.001 0.613   1.043\n#>  7 alpha[7]  0.408  0.121 0.406   0.750\n#>  8 alpha[8]  0.119 -0.077 0.109   0.343\n#>  9 alpha[9]  0.487  0.009 0.487   0.927\n#> 10 alpha[10] 0.811  0.440 0.811   1.109\n#> # ℹ 111 more rows\n```\n:::\n\n\nDiagnostica rapida (Rhat ed ESS): \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Se qualche Rhat > 1.01 o ESS basso, considerare run più lunghi o reparametrizzazioni\nfit1$summary(variables = c(\"alpha\", \"beta\", \"sigma\")) |>\n  dplyr::select(variable, rhat, ess_bulk, ess_tail) |>\n  dplyr::arrange(dplyr::desc(rhat)) |>\n  print(n = 10)\n#> # A tibble: 121 × 4\n#>    variable   rhat ess_bulk ess_tail\n#>    <chr>     <dbl>    <dbl>    <dbl>\n#>  1 alpha[34] 1.177   14.956   10.927\n#>  2 beta[47]  1.168   15.789   17.071\n#>  3 beta[34]  1.168   15.618   11.197\n#>  4 alpha[47] 1.163   16.778   17.192\n#>  5 beta[46]  1.157   17.028   18.453\n#>  6 beta[56]  1.141   19.034   26.829\n#>  7 alpha[56] 1.141   19.378   43.006\n#>  8 beta[40]  1.124   21.218   71.730\n#>  9 beta[32]  1.122   20.397   22.425\n#> 10 beta[26]  1.120   20.658   27.604\n#> # ℹ 111 more rows\n```\n:::\n\n\nEstrazione \"tidy\" dei parametri livello-persona con `tidybayes::spread_draws`. Questo produce le colonne: `.draw, subject, alpha, beta`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nposteriors_person = spread_draws(fit1, alpha[subject], beta[subject])\n```\n:::\n\n\nCalcolo della media e dell'intervallo credibile al 95% per ciascun soggetto: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo media e intervallo credibile al 95% per ciascun soggetto\nCIs_person <- posteriors_person %>%\n  group_by(subject) %>%\n  summarise(\n    across(c(alpha, beta), list(\n      lower = ~quantile(.x, 0.025),\n      mean  = ~mean(.x),\n      upper = ~quantile(.x, 0.975)\n    ), .names = \"{.col}_{.fn}\")\n  ) %>%\n  arrange(alpha_mean) %>%\n  mutate(alpha_order = row_number()) %>%\n  arrange(beta_mean) %>%\n  mutate(beta_order = row_number())\n```\n:::\n\n\nGrafico 1: CI al 95% per $\\alpha_i$, ordinati per `alpha_mean`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_person_alpha = ggplot(data=CIs_person) +\n  geom_point(aes(y=alpha_order,x=alpha_mean)) +\n  geom_errorbarh(aes(y=alpha_order,xmin=alpha_lower,xmax=alpha_upper),color=\"red\") +\n  labs(x= expression(alpha) ,y=\"Subject\") \n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02_dynamic_models_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nGrafico 2: CI al 95% per $\\beta_i$, ordinati per `beta_mean`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_person_beta <- ggplot(data = CIs_person) +\n  geom_point(aes(y = beta_order, x = beta_mean)) +\n  geom_errorbarh(aes(y = beta_order, xmin = beta_lower, xmax = beta_upper), color = \"red\") +\n  labs(x = expression(beta), y = \"Subject\") \n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02_dynamic_models_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nGrafico 3: Dispersione bivariata (`alpha_mean` vs `beta_mean`) + croci di CI 95%.  Le barre (verticali e orizzontali) danno il colpo d'occhio sulla (co)variabilità individuale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_person_alphabeta = ggplot(data=CIs_person) +\n  geom_point(aes(x=alpha_mean,y=beta_mean)) +\n  geom_errorbar(aes(x=alpha_mean,ymin=beta_lower,ymax=beta_upper),color=\"red\",alpha=0.25) +\n  geom_errorbarh(aes(y=beta_mean,xmin=alpha_lower,xmax=alpha_upper),color=\"red\",alpha=0.25) +\n  labs(x= expression(alpha) ,y=expression(beta)) \n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02_dynamic_models_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nI grafici mostrano una marcata eterogeneità tra i partecipanti nei parametri $\\alpha$ (tasso di apprendimento) e $\\beta$ (drift motivazionale), con intervalli credibili al 95% calcolati per ciascun $\\alpha_i$ e $\\beta_i$.\n\n* **Per $\\alpha$**: i partecipanti mostrano valori distribuiti lungo quasi tutto l’intervallo [0,1]. Alcuni soggetti hanno $\\alpha$ molto vicino a 0 (poca sensibilità al feedback), mentre altri si avvicinano a 1 (forte aggiornamento in risposta all’errore). L’ampiezza degli intervalli credibili varia, ma nella maggior parte dei casi suggerisce stime sufficientemente informative.\n\n**Per $\\beta$**: i valori si distribuiscono attorno a 0, ma con differenze individuali marcate: alcuni soggetti mostrano un drift positivo (tendenza ad aumentare sistematicamente gli obiettivi), altri un drift negativo (tendenza a ridurli). Gli intervalli credibili confermano questa eterogeneità.\n\nIl punto chiave è che questa variabilità *non può essere colta dal modello sample-level*. Quest’ultimo, stimando un unico $\\alpha$ e un unico $\\beta$ comuni a tutti, restituisce una sorta di “media” del comportamento dei partecipanti. In pratica:\n\n* un soggetto con $\\alpha \\approx 0$ e uno con $\\alpha \\approx 0.9$ verrebbero descritti dallo stesso parametro $\\alpha$, che potrebbe cadere a metà strada ma non rappresenta bene né l’uno né l’altro;\n* analogamente, le derive motivazionali individuali $\\beta$ (positive, negative o vicine a zero) verrebbero tutte appiattite su un valore medio.\n\nI grafici dimostrano quindi l’utilità del modello a livello individuale: esso permette di mappare differenze sostanziali tra soggetti, che nel modello a livello di campione vengono perse.\n\nIn sintesi:\n\n* il modello *sample-level* offre una descrizione parsimoniosa, ma rischia di mascherare differenze psicologicamente importanti;\n* il modello *person-level* mostra che i partecipanti non solo differiscono nel grado di apprendimento dal feedback ($\\alpha$), ma anche nella direzione e nell’intensità della deriva motivazionale ($\\beta$);\n* questa eterogeneità costituisce un’informazione preziosa per comprendere i profili comportamentali individuali, impossibile da cogliere con un modello che assume parametri omogenei per tutto il campione.\n\n\n## Modello gerarchico\n\nStimare i parametri per ogni partecipante separatamente (come nel modello a livello individuale) permette di rappresentare le differenze individuali, ma presenta un limite cruciale: le stime rimangono isolate. Analizzare i dati \"persona per persona\" equivale a condurre un'analisi indipendente per ciascun soggetto, senza \"riutilizzare\" le informazioni presenti negli altri individui. Ciò riduce il potere statistico, aumenta la variabilità delle stime quando i dati per soggetto sono pochi e rende più difficile trarre conclusioni a livello di popolazione.\n\nIn molti contesti, però, l'interesse del ricercatore non è solo quello di descrivere le differenze tra gli individui, ma anche di cogliere le regolarità comuni alla popolazione. Per questo motivo, i modelli gerarchici bayesiani (o multilevel) offrono una soluzione particolarmente efficace (Turner et al., 2013; Vincent, 2016; Kruschke & Vanpaemel, 2015).\n\nL’idea di fondo è semplice:\n\n* i parametri individuali (es. $\\alpha_s, \\beta_s$) sono trattati come *variabili casuali*, non come quantità del tutto indipendenti;\n* ciascuno di essi è estratto da una distribuzione a livello di popolazione, descritta da iper-parametri ($\\alpha_{\\text{mean}}, \\alpha_{\\text{sd}}$, ecc.);\n* in questo modo, le stime individuali sono “informate” sia dai dati del singolo soggetto sia dalla tendenza generale osservata nel campione (Lewandowsky & Farrell, 2011).\n\nIl risultato è una *regolarizzazione*: i valori estremi vengono attenuati verso la media di popolazione (*shrinkage*), riducendo il rischio che stime instabili o rumorose abbiano troppo peso. Si ottengono così inferenze più robuste e interpretabili, specialmente in campioni piccoli o con dati per soggetto limitati (Boehm et al., 2018; Rouder & Lu, 2005).\n\n\n### Definizione del modello Stan\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstancode <- \"\ndata {\n  int<lower=1> Ntotal;\n  int<lower=1> Nsubj;\n  array[Ntotal] int<lower=1> subject;\n  array[Ntotal] int<lower=1> trial;\n  vector[Ntotal] observed_goal;   // z-score\n  vector[Ntotal] performance;     // z-score\n}\n\nparameters {\n  // Iper-parametri di popolazione\n  real alpha_mean;\n  real<lower=0> alpha_sd;\n  real beta_mean;\n  real<lower=0> beta_sd;\n\n  // Non-centrato: fattori standard per i soggetti\n  vector[Nsubj] alpha_raw;\n  vector[Nsubj] beta_raw;\n\n  real<lower=1e-6> sigma;\n}\n\ntransformed parameters {\n  // Ricostruzione parametri individuali\n  vector[Nsubj] alpha_unconstrained = alpha_mean + alpha_sd * alpha_raw;\n  vector[Nsubj] beta  = beta_mean  + beta_sd  * beta_raw;\n\n  // Vincolo morbido su alpha per stabilità\n  vector[Nsubj] alpha = 0.95 * tanh(alpha_unconstrained);\n\n  vector[Ntotal] ghat;\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      ghat[i] = observed_goal[i];\n    } else {\n      int s = subject[i];\n      ghat[i] = ghat[i - 1]\n                + alpha[s] * (performance[i - 1] - ghat[i - 1])\n                + beta[s];\n    }\n  }\n}\n\nmodel {\n  // Iper-priori debolmente informativi (coerenti con z-score)\n  alpha_mean ~ normal(0, 0.5);\n  alpha_sd   ~ exponential(1);\n  beta_mean  ~ normal(0, 0.5);\n  beta_sd    ~ exponential(1);\n\n  alpha_raw  ~ normal(0, 1);\n  beta_raw   ~ normal(0, 1);\n\n  sigma ~ student_t(3, 0, 0.5);\n\n  // Likelihood\n  observed_goal ~ normal(ghat, sigma);\n}\n\ngenerated quantities {\n  vector[Ntotal] yrep;\n  vector[Ntotal] log_lik;\n  for (i in 1:Ntotal) {\n    yrep[i]    = normal_rng(ghat[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);\n  }\n}\n\"\n```\n:::\n\n\n\n### Differenza chiave rispetto al modello precedente\n\nNel *Person-Level Model* i parametri individuali sono stimati in modo indipendente; qui, invece, valgono relazioni del tipo:\n\n$$\n\\alpha_s \\sim \\mathcal{N}(\\alpha_{\\text{mean}}, \\alpha_{\\text{sd}}), \\quad\n\\beta_s \\sim \\mathcal{N}(\\beta_{\\text{mean}}, \\beta_{\\text{sd}})\n$$\n\nQuesta struttura gerarchica introduce un livello di vincolo che collega i soggetti tra loro. Il vantaggio è duplice:\n\n1. si mantengono le differenze individuali;\n2. si sfrutta la somiglianza tra soggetti per ottenere stime più stabili e inferenze a livello di popolazione.\n\n\n### Compilazione ed esecuzione\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstanmod <- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit2 <- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4, parallel_chains = 4,\n  seed = 4790,\n  refresh = 500,\n  adapt_delta = 0.995,  # riduce divergenze\n  max_treedepth = 15\n)\n```\n:::\n\n\n\n### Analisi dei risultati\n\nEseguiamo l'analisi dei risultati seguendo lo schema usato sopra.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Estrazione dei campioni posteriori come matrice \nstandraws <- fit2$draws(format = \"draws_matrix\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Statistiche descrittive aggregate\nstandraws |> \n  subset_draws(variable = c(\"alpha\", \"beta\", \"sigma\", \"alpha_mean\", \"beta_mean\", \"alpha_sd\", \"beta_sd\")) |> \n  summarise_draws(\n    mean,\n    ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n  )\n#> # A tibble: 125 × 5\n#>    variable   mean `2.5%` `50%` `97.5%`\n#>    <chr>     <dbl>  <dbl> <dbl>   <dbl>\n#>  1 alpha[1]  0.576  0.292 0.587   0.795\n#>  2 alpha[2]  0.385  0.059 0.393   0.664\n#>  3 alpha[3]  0.320  0.019 0.328   0.582\n#>  4 alpha[4]  0.490  0.145 0.505   0.749\n#>  5 alpha[5]  0.367  0.096 0.371   0.621\n#>  6 alpha[6]  0.552  0.257 0.563   0.775\n#>  7 alpha[7]  0.467  0.215 0.471   0.704\n#>  8 alpha[8]  0.221  0.015 0.216   0.459\n#>  9 alpha[9]  0.510  0.209 0.520   0.754\n#> 10 alpha[10] 0.637  0.425 0.644   0.812\n#> # ℹ 115 more rows\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Estrai le draw per i parametri individuali (alpha e beta per ciascun soggetto)\nposteriors_person <- spread_draws(fit2, alpha[subject], beta[subject])\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calcolo degli intervalli credibili per ciascun soggetto\nCIs_person <- posteriors_person %>%\n  group_by(subject) %>%\n  summarise(\n    across(c(alpha, beta), list(\n      lower = ~quantile(.x, 0.025),\n      mean  = ~mean(.x),\n      upper = ~quantile(.x, 0.975)\n    ), .names = \"{.col}_{.fn}\")\n  ) %>%\n  arrange(alpha_mean) %>%\n  mutate(alpha_order = row_number()) %>%\n  arrange(beta_mean) %>%\n  mutate(beta_order = row_number())\n```\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Grafico: intervalli credibili per alpha\nplot_person_alpha <- ggplot(CIs_person) +\n  geom_point(aes(y = alpha_order, x = alpha_mean)) +\n  geom_errorbarh(aes(y = alpha_order, xmin = alpha_lower, xmax = alpha_upper), color = \"red\") +\n  labs(x = expression(alpha), y = \"Soggetto\") \n\n# Grafico: intervalli credibili per beta\nplot_person_beta <- ggplot(CIs_person) +\n  geom_point(aes(y = beta_order, x = beta_mean)) +\n  geom_errorbarh(aes(y = beta_order, xmin = beta_lower, xmax = beta_upper), color = \"red\") +\n  labs(x = expression(beta), y = \"Soggetto\") \n\n# Grafico: relazione tra alpha e beta per ciascun soggetto\nplot_person_alphabeta <- ggplot(CIs_person) +\n  geom_point(aes(x = alpha_mean, y = beta_mean)) +\n  geom_errorbar(aes(x = alpha_mean, ymin = beta_lower, ymax = beta_upper), color = \"red\", alpha = 0.25) +\n  geom_errorbarh(aes(y = beta_mean, xmin = alpha_lower, xmax = alpha_upper), color = \"red\", alpha = 0.25) +\n  labs(x = expression(alpha), y = expression(beta)) \n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02_dynamic_models_files/figure-html/unnamed-chunk-28-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02_dynamic_models_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02_dynamic_models_files/figure-html/unnamed-chunk-30-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\nInfine, calcoliamo le stime a posteriori degli iper-parametri:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Riassunto per alpha_mean e beta_mean con intervallo al 95%\nstandraws |>\n  subset_draws(variable = c(\"alpha_mean\", \"beta_mean\")) |>\n  summarise_draws(\n    mean,\n    ~quantile(.x, probs = c(0.025, 0.975))\n  )\n#> # A tibble: 2 × 4\n#>   variable    mean `2.5%` `97.5%`\n#>   <chr>      <dbl>  <dbl>   <dbl>\n#> 1 alpha_mean 0.621  0.521   0.732\n#> 2 beta_mean  0.114  0.049   0.176\n```\n:::\n\n\n#### Interpretazione\n\nIl modello gerarchico bayesiano fornisce inferenze a *due livelli*:\n\n* **Livello individuale**: parametri $\\alpha_s$ e $\\beta_s$ per ciascun partecipante, con i relativi intervalli credibili.\n* **Livello di popolazione**: distribuzioni a priori/posteriori degli iper-parametri $\\alpha_{\\text{mean}}, \\alpha_{\\text{sd}}, \\beta_{\\text{mean}}, \\beta_{\\text{sd}}$, più il parametro residuo $\\sigma$.\n\nI grafici per $\\alpha$ e $\\beta$ mostrano chiaramente l’eterogeneità interindividuale, mentre gli iper-parametri descrivono la tendenza generale.\n\nRispetto a un modello puramente individuale, gli intervalli credibili delle stime soggettive risultano *meno dispersi e più regolari*. Questo fenomeno è noto come *shrinkage*: le stime dei singoli soggetti sono “attirate” verso la media della popolazione, riducendo l’impatto dei dati rumorosi o scarsi.\n\nNel grafico bivariato, lo shrinkage si traduce in una distribuzione più compatta dei punti attorno al centro della distribuzione collettiva. L’effetto principale è una maggiore *robustezza* delle inferenze: le stime estreme vengono mitigate, la variabilità non plausibile è penalizzata e la capacità di generalizzare a nuovi dati risulta rafforzata (Boehm et al., 2018).\n\n\n## Differenze tra gruppi\n\nIn questo terzo modello estendiamo la struttura gerarchica introducendo le *condizioni sperimentali* (*approach* vs *avoidance*). L’idea è che i parametri individuali $\\alpha_s$ e $\\beta_s$ non siano estratti da un’unica distribuzione comune, ma da *distribuzioni diverse a seconda del gruppo* di appartenenza del soggetto.\n\nIn questo modo possiamo stimare, per ciascuna condizione, una media e una deviazione standard a livello di popolazione:\n\n* $\\alpha_{\\text{mean},c}, \\alpha_{\\text{sd},c}$,\n* $\\beta_{\\text{mean},c}, \\beta_{\\text{sd},c}$\n  con $c \\in \\{1,2\\}$.\n\n\n### Preparazione dei dati\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1) Ordina per soggetto e trial\ndat <- dat %>% arrange(subject, trial)\n\n# 2) Codifica la condizione come intero (1 = approach, 2 = avoidance)\ndat <- dat %>%\n  mutate(cond_id = as.integer(factor(condition)))\n\n# Verifica che ogni soggetto appartenga a una sola condizione\nchk <- dat %>% distinct(subject, cond_id) %>% count(subject) %>% filter(n > 1)\nstopifnot(nrow(chk) == 0)  # se fallisce, il design non è between-subject\n\n# 3) Standardizza goal e performance su tutto il dataset\ngoal_mean <- mean(dat$goal, na.rm = TRUE); goal_sd <- sd(dat$goal, na.rm = TRUE)\nperf_mean <- mean(dat$performance, na.rm = TRUE); perf_sd <- sd(dat$performance, na.rm = TRUE)\n\ndat <- dat %>%\n  mutate(\n    goal_z = (goal - goal_mean) / goal_sd,\n    perf_z = (performance - perf_mean) / perf_sd\n  )\n\n# 4) Vettore che assegna a ciascun soggetto la sua condizione\nsubjects <- sort(unique(dat$subject))\nsubj_cond <- dat %>%\n  group_by(subject) %>%\n  summarise(cond = first(cond_id), .groups = \"drop\") %>%\n  arrange(subject) %>%\n  pull(cond)\n\n# 5) Lista per Stan\nstan_data <- list(\n  Ntotal        = nrow(dat),\n  Nsubj         = length(subjects),\n  C             = length(unique(dat$cond_id)),   # numero condizioni\n  subject       = dat$subject,\n  trial         = dat$trial,\n  observed_goal = dat$goal_z,\n  performance   = dat$perf_z,\n  subj_cond     = subj_cond\n)\n\nstr(stan_data)\n#> List of 8\n#>  $ Ntotal       : int 600\n#>  $ Nsubj        : int 60\n#>  $ C            : int 2\n#>  $ subject      : int [1:600] 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ trial        : int [1:600] 1 2 3 4 5 6 7 8 9 10 ...\n#>  $ observed_goal: num [1:600] -2 -2 -2 -1.07 -1.07 ...\n#>  $ performance  : num [1:600] -2.89 -1.99 -1.99 -1.1 -1.99 ...\n#>  $ subj_cond    : int [1:60] 1 2 2 1 2 1 2 1 2 1 ...\n```\n:::\n\n\n\n### Definizione del modello Stan\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstancode <- \"\n// Modello gerarchico con iper-parametri specifici per condizione\ndata {\n  int<lower=1> Ntotal;\n  int<lower=1> Nsubj;\n  int<lower=1> C;                            // numero condizioni\n  array[Ntotal] int<lower=1> subject;        // 1..Nsubj\n  array[Ntotal] int<lower=1> trial;          // 1..T all'interno di soggetto\n  vector[Ntotal] observed_goal;              // z-score\n  vector[Ntotal] performance;                // z-score\n  array[Nsubj] int<lower=1, upper=C> subj_cond; // condizione per soggetto\n}\n\nparameters {\n  // Iper-parametri per condizione\n  vector[C] alpha_mean;\n  vector<lower=0>[C] alpha_sd;\n  vector[C] beta_mean;\n  vector<lower=0>[C] beta_sd;\n\n  // Non-centrato: fattori standard per soggetti\n  vector[Nsubj] alpha_raw;\n  vector[Nsubj] beta_raw;\n\n  real<lower=1e-6> sigma;\n}\n\ntransformed parameters {\n  vector[Nsubj] alpha_uncon;\n  vector[Nsubj] beta;\n  vector[Nsubj] alpha;           \n  vector[Ntotal] ghat;\n\n  // Ricostruzione dei parametri individuali in base alla condizione\n  for (s in 1:Nsubj) {\n    int c = subj_cond[s];\n    alpha_uncon[s] = alpha_mean[c] + alpha_sd[c] * alpha_raw[s];\n    beta[s]        = beta_mean[c]  + beta_sd[c]  * beta_raw[s];\n    alpha[s]       = 0.95 * tanh(alpha_uncon[s]); // vincolo di stabilità\n  }\n\n  // Dinamica\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      ghat[i] = observed_goal[i];\n    } else {\n      int s = subject[i];\n      ghat[i] = ghat[i - 1]\n                + alpha[s] * (performance[i - 1] - ghat[i - 1])\n                + beta[s];\n    }\n  }\n}\n\nmodel {\n  // Iper-priori debolmente informativi\n  alpha_mean ~ normal(0, 0.5);\n  alpha_sd   ~ exponential(1);\n  beta_mean  ~ normal(0, 0.5);\n  beta_sd    ~ exponential(1);\n\n  alpha_raw  ~ normal(0, 1);\n  beta_raw   ~ normal(0, 1);\n\n  sigma ~ student_t(3, 0, 0.5);\n\n  // Likelihood\n  observed_goal ~ normal(ghat, sigma);\n}\n\ngenerated quantities {\n  vector[Ntotal] yrep;\n  vector[Ntotal] log_lik;\n  for (i in 1:Ntotal) {\n    yrep[i]    = normal_rng(ghat[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);\n  }\n}\n\"\n```\n:::\n\n\n### Come funziona la distinzione tra gruppi\n\n1. **Assegnazione condizione**\n   Nel blocco `data`, il vettore `subj_cond` assegna a ciascun soggetto il numero della condizione (1 = *approach*, 2 = *avoidance*).\n\n2. **Parametri di gruppo**\n   Gli iper-parametri `alpha_mean[c]`, `alpha_sd[c]`, `beta_mean[c]`, `beta_sd[c]` sono specifici per condizione. Ad esempio:\n\n   * `alpha_mean[1]` = media di $\\alpha$ per il gruppo *approach*\n   * `alpha_mean[2]` = media di $\\alpha$ per il gruppo *avoidance*\n\n3. **Parametri individuali**\n   In `transformed parameters`, i parametri dei singoli soggetti vengono generati in base alla condizione di appartenenza.\n   Così, i soggetti *approach* e quelli *avoidance* condividono rispettivamente due diverse distribuzioni di partenza.\n\nIn sintesi, il modello permette di stimare non solo le differenze tra individui, ma anche *le differenze sistematiche tra condizioni sperimentali*.\n\n\n### Compilazione ed esecuzione\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstanmod <- cmdstan_model(write_stan_file(stancode), compile = TRUE)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit3 <- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 5000,\n  chains = 4, parallel_chains = 4,\n  seed = 123,\n  adapt_delta = 0.999,   # ↑ riduce divergenze\n  max_treedepth = 15\n)\n```\n:::\n\n\n\n### Risultati\n\n#### Ispezione rapida delle variabili (opzionale)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraws_df <- as_draws_df(fit3$draws())   # oppure: fit3$draws(format = \"df\")\nnames(draws_df)[grepl(\"alpha_mean|beta_mean|alpha\\\\[|beta\\\\[\", names(draws_df))]\n#>   [1] \"alpha_mean[1]\" \"alpha_mean[2]\" \"beta_mean[1]\"  \"beta_mean[2]\" \n#>   [5] \"beta[1]\"       \"beta[2]\"       \"beta[3]\"       \"beta[4]\"      \n#>   [9] \"beta[5]\"       \"beta[6]\"       \"beta[7]\"       \"beta[8]\"      \n#>  [13] \"beta[9]\"       \"beta[10]\"      \"beta[11]\"      \"beta[12]\"     \n#>  [17] \"beta[13]\"      \"beta[14]\"      \"beta[15]\"      \"beta[16]\"     \n#>  [21] \"beta[17]\"      \"beta[18]\"      \"beta[19]\"      \"beta[20]\"     \n#>  [25] \"beta[21]\"      \"beta[22]\"      \"beta[23]\"      \"beta[24]\"     \n#>  [29] \"beta[25]\"      \"beta[26]\"      \"beta[27]\"      \"beta[28]\"     \n#>  [33] \"beta[29]\"      \"beta[30]\"      \"beta[31]\"      \"beta[32]\"     \n#>  [37] \"beta[33]\"      \"beta[34]\"      \"beta[35]\"      \"beta[36]\"     \n#>  [41] \"beta[37]\"      \"beta[38]\"      \"beta[39]\"      \"beta[40]\"     \n#>  [45] \"beta[41]\"      \"beta[42]\"      \"beta[43]\"      \"beta[44]\"     \n#>  [49] \"beta[45]\"      \"beta[46]\"      \"beta[47]\"      \"beta[48]\"     \n#>  [53] \"beta[49]\"      \"beta[50]\"      \"beta[51]\"      \"beta[52]\"     \n#>  [57] \"beta[53]\"      \"beta[54]\"      \"beta[55]\"      \"beta[56]\"     \n#>  [61] \"beta[57]\"      \"beta[58]\"      \"beta[59]\"      \"beta[60]\"     \n#>  [65] \"alpha[1]\"      \"alpha[2]\"      \"alpha[3]\"      \"alpha[4]\"     \n#>  [69] \"alpha[5]\"      \"alpha[6]\"      \"alpha[7]\"      \"alpha[8]\"     \n#>  [73] \"alpha[9]\"      \"alpha[10]\"     \"alpha[11]\"     \"alpha[12]\"    \n#>  [77] \"alpha[13]\"     \"alpha[14]\"     \"alpha[15]\"     \"alpha[16]\"    \n#>  [81] \"alpha[17]\"     \"alpha[18]\"     \"alpha[19]\"     \"alpha[20]\"    \n#>  [85] \"alpha[21]\"     \"alpha[22]\"     \"alpha[23]\"     \"alpha[24]\"    \n#>  [89] \"alpha[25]\"     \"alpha[26]\"     \"alpha[27]\"     \"alpha[28]\"    \n#>  [93] \"alpha[29]\"     \"alpha[30]\"     \"alpha[31]\"     \"alpha[32]\"    \n#>  [97] \"alpha[33]\"     \"alpha[34]\"     \"alpha[35]\"     \"alpha[36]\"    \n#> [101] \"alpha[37]\"     \"alpha[38]\"     \"alpha[39]\"     \"alpha[40]\"    \n#> [105] \"alpha[41]\"     \"alpha[42]\"     \"alpha[43]\"     \"alpha[44]\"    \n#> [109] \"alpha[45]\"     \"alpha[46]\"     \"alpha[47]\"     \"alpha[48]\"    \n#> [113] \"alpha[49]\"     \"alpha[50]\"     \"alpha[51]\"     \"alpha[52]\"    \n#> [117] \"alpha[53]\"     \"alpha[54]\"     \"alpha[55]\"     \"alpha[56]\"    \n#> [121] \"alpha[57]\"     \"alpha[58]\"     \"alpha[59]\"     \"alpha[60]\"\n```\n:::\n\n\n\n#### Differenze tra condizioni sugli iper-parametri\n\nL’obiettivo è verificare se i parametri di popolazione *$\\alpha$* (tasso di aggiornamento) e *$\\beta$* (drift/tendenza) differiscono tra le due condizioni sperimentali (*approach* vs *avoidance*). Per rispondere a questa domanda procediamo in quattro passaggi:  \n1. recuperiamo le etichette delle condizioni dal dataset;  \n2. calcoliamo il contrasto tra condizioni ($\\Delta =$ condizione$_2$ − condizione$_1$);  \n3. stimiamo la media della differenza, il 95% CrI e la probabilità a posteriori che la differenza sia negativa;  \n4. visualizziamo i risultati per facilitarne l’interpretazione.  \n\n\n##### Step 1. Etichette di condizione\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncond_labels <- dat %>%\n  distinct(cond_id, condition) %>%\n  arrange(cond_id) %>%\n  pull(condition)\n\ncond_labels\n#> [1] \"approach\"  \"avoidance\"\n# Esempio: c(\"approach\", \"avoidance\")\n```\n:::\n\n\n\n##### Step 2. Contrasto su α (media per condizione)\n\nCalcoliamo $\\Delta_\\alpha = \\alpha_{\\text{avoidance}} - \\alpha_{\\text{approach}}$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndelta_alpha <- fit3 |>\n  spread_draws(alpha_mean[cond]) |>\n  mutate(cond = factor(cond, levels = 1:2, labels = cond_labels)) |>\n  pivot_wider(names_from = cond, values_from = alpha_mean, names_prefix = \"alpha_mean_\") |>\n  mutate(delta_alpha_mean = alpha_mean_avoidance - alpha_mean_approach)\n\ndelta_alpha |> \n  summarise(\n    mean   = mean(delta_alpha_mean),\n    low95  = quantile(delta_alpha_mean, 0.025),\n    upp95  = quantile(delta_alpha_mean, 0.975),\n    p_lt0  = mean(delta_alpha_mean < 0)\n  )\n#> # A tibble: 1 × 4\n#>     mean  low95   upp95 p_lt0\n#>    <dbl>  <dbl>   <dbl> <dbl>\n#> 1 -0.247 -0.481 -0.0349 0.989\n```\n:::\n\n\n##### Step 3. Contrasto su β (media per condizione)\n\nIn modo analogo, calcoliamo $\\Delta_\\beta = \\beta_{\\text{avoidance}} - \\beta_{\\text{approach}}$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndelta_beta <- fit3 |>\n  spread_draws(beta_mean[cond]) |>\n  mutate(cond = factor(cond, levels = 1:2, labels = cond_labels)) |>\n  pivot_wider(names_from = cond, values_from = beta_mean, names_prefix = \"beta_mean_\") |>\n  mutate(delta_beta_mean = beta_mean_avoidance - beta_mean_approach)\n\ndelta_beta |> \n  summarise(\n    mean   = mean(delta_beta_mean),\n    low95  = quantile(delta_beta_mean, 0.025),\n    upp95  = quantile(delta_beta_mean, 0.975),\n    p_lt0  = mean(delta_beta_mean < 0)\n  )\n#> # A tibble: 1 × 4\n#>     mean  low95   upp95 p_lt0\n#>    <dbl>  <dbl>   <dbl> <dbl>\n#> 1 -0.126 -0.251 0.00152 0.974\n```\n:::\n\n\n\n##### Step 4. Visualizzazione delle posterior\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npost_alpha <- fit3 |>\n  spread_draws(alpha_mean[cond]) |>\n  mutate(parameter = \"alpha_mean\",\n         condition = factor(cond, levels = 1:2, labels = cond_labels)) |>\n  rename(value = alpha_mean)\n\npost_beta <- fit3 |>\n  spread_draws(beta_mean[cond]) |>\n  mutate(parameter = \"beta_mean\",\n         condition = factor(cond, levels = 1:2, labels = cond_labels)) |>\n  rename(value = beta_mean)\n\nposterior_both <- bind_rows(post_alpha, post_beta)\n\nggplot(posterior_both, aes(x = value, fill = condition)) +\n  geom_density(alpha = 0.6) +\n  facet_wrap(~parameter, scales = \"free\") +\n  labs(x = \"Posterior mean\", y = \"Density\", fill = \"Condition\") +\n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](02_dynamic_models_files/figure-html/unnamed-chunk-40-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n##### Risultati numerici\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprob_delta_alpha_neg <- mean(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]` < 0)\nprob_delta_beta_neg  <- mean(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]` < 0)\n\ncat(\"P(delta_alpha_mean < 0):\", round(prob_delta_alpha_neg, 3), \"\\n\")\n#> P(delta_alpha_mean < 0): 0.989\ncat(\"P(delta_beta_mean < 0):\", round(prob_delta_beta_neg, 3), \"\\n\")\n#> P(delta_beta_mean < 0): 0.974\n\nsummary_df <- tibble(\n  parameter = c(\"alpha_mean\", \"beta_mean\"),\n  delta_mean = c(\n    mean(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`),\n    mean(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`)\n  ),\n  lower_95 = c(\n    quantile(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`, 0.025),\n    quantile(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`, 0.025)\n  ),\n  upper_95 = c(\n    quantile(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`, 0.975),\n    quantile(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`, 0.975)\n  ),\n  prob_below_0 = c(prob_delta_alpha_neg, prob_delta_beta_neg)\n)\n\nsummary_df\n#> # A tibble: 2 × 5\n#>   parameter  delta_mean lower_95 upper_95 prob_below_0\n#>   <chr>           <dbl>    <dbl>    <dbl>        <dbl>\n#> 1 alpha_mean     -0.247   -0.481 -0.0349         0.989\n#> 2 beta_mean      -0.126   -0.251  0.00152        0.974\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary_df |> \n  ggplot(aes(x = parameter, y = delta_mean)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", width = 0.5) +\n  geom_errorbar(aes(ymin = lower_95, ymax = upper_95), width = 0.2) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(\n    x = \"Parametro\",\n    y = \"Differenza media\\n(cond2 - cond1)\"\n  )\n```\n\n::: {.cell-output-display}\n![](02_dynamic_models_files/figure-html/unnamed-chunk-42-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n##### Interpretazione dei risultati\n\n* **$\\Delta_\\alpha$ (avoidance − approach)**\n  Media = −0.247; CrI 95% = [−0.481, −0.035]; $P(\\Delta<0) = 0.989$.\n  → Evidenza forte che l’aggiornamento ($\\alpha$) è più basso in *avoidance*. L’effetto è moderato (≈0.25 SD).\n\n* **$\\Delta_\\beta$ (avoidance − approach)**\n  Media = −0.126; CrI 95% = [−0.251, 0.002]; $P(\\Delta<0) = 0.974$.\n  → La probabilità che $\\beta$ sia più basso in *avoidance* è elevata, ma l’intervallo credibile include lo zero. Evidenza suggestiva ma non conclusiva.\n\n\n##### Significato sostantivo\n\n* In *avoidance*, i partecipanti *aggiornano più lentamente* le loro credenze (α più basso).\n* Anche la tendenza (β) appare più bassa, ma con incertezza residua.\n\nQuesti risultati indicano che la manipolazione sperimentale ha un impatto soprattutto sulla velocità di apprendimento, mentre l’effetto sulla componente di drift resta da confermare con più dati o modelli più sensibili.\n\n\n## Confronto tra modelli\n\nPer valutare quale modello descriva meglio i dati abbiamo utilizzato la cross-validazione leave-one-out (LOO-CV), che stima la expected log predictive density (ELPD). Un ELPD più alto indica predizioni più accurate.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlog_lik1 <- fit1$draws(variables = \"log_lik\", format = \"matrix\")\nlog_lik2 <- fit2$draws(variables = \"log_lik\", format = \"matrix\")\nlog_lik3 <- fit3$draws(variables = \"log_lik\", format = \"matrix\")\n\n# Calcola LOO per ciascun modello\nloo1 <- loo(log_lik1)\nloo2 <- loo(log_lik2)\nloo3 <- loo(log_lik3)\n\n# Confronto tra i modelli\nmodel_comparison <- loo_compare(loo1, loo2, loo3)\nprint(model_comparison)\n#>        elpd_diff se_diff\n#> model3   0.0       0.0  \n#> model2  -4.7       3.9  \n#> model1 -23.2       7.6\n```\n:::\n\n\nIl modello *gerarchico con condizione (Model 3)* ottiene la predizione migliore. Tuttavia, il confronto con il *modello gerarchico senza condizione (Model 2)* mostra una differenza di ELPD pari a −4.7, con un errore standard di 3.9. Questa differenza è *piccola rispetto all’incertezza della stima*, quindi non possiamo affermare con sicurezza che includere la condizione migliori la predizione, anche se la tendenza è in quella direzione.\n\nDiverso il discorso per il *modello non gerarchico (Model 1)*: la perdita di ELPD rispetto a Model 3 è molto ampia (−23.3, con SE = 7.6). In questo caso la differenza è sufficientemente grande da concludere che Model 1 produce predizioni nettamente peggiori.\n\n\n#### Cosa impariamo\n\n1. *La gerarchia è cruciale*: i modelli gerarchici (Model 2 e 3) descrivono i dati molto meglio del modello non gerarchico. Questo conferma l’importanza di “condividere informazione” tra soggetti per ottenere stime più stabili e predizioni più accurate.\n\n2. *L’effetto della condizione è plausibile, ma non certo*: il modello con condizione (Model 3) tende a comportarsi meglio, ma il vantaggio rispetto al modello gerarchico semplice (Model 2) non è statisticamente robusto. Questo risultato è coerente con le stime dei parametri: la differenza tra condizioni sembra più marcata per $\\alpha$, meno per $\\beta$.\n\n3. *Scelta del modello*:\n\n   * se l’obiettivo principale è la parsimonia, Model 2 è già soddisfacente;\n   * se vogliamo testare esplicitamente l’effetto della condizione, Model 3 è preferibile, anche se il guadagno predittivo rimane incerto.\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nIn questo capitolo abbiamo seguito un percorso *dal singolo al collettivo*, aumentando la struttura del modello in modo controllato:\n\n1. **Person-level**: stime soggetto-specifiche di $(\\alpha_i, \\beta_i)$ rivelano una marcata *eterogeneità* tra individui (diversa velocità di aggiornamento e diversa deriva). Il prezzo da pagare è l’assenza di condivisione dell’informazione: le stime restano fragili quando i dati per soggetto sono scarsi.\n\n2. **Gerarchico**: trattando i parametri individuali come *variabili casuali* provenienti da distribuzioni di popolazione, otteniamo inferenze più *stabili* e *generalizzabili*. Lo *shrinkage* attenua gli estremi non supportati dai dati, migliora le stime dei singoli e fornisce contemporaneamente un *quadro di popolazione*.\n\n3. **Gruppi noti**: introducendo iper-parametri per condizione, isoliamo differenze *sistematiche* tra gruppi a livello di popolazione. I risultati indicano effetti credibili soprattutto su $\\alpha$ (velocità di aggiornamento), con evidenza più incerta su $\\beta$, coerentemente con l’idea che la manipolazione sperimentale incida primariamente sui processi di apprendimento.\n\nSul piano *predittivo*, il confronto tramite *ELPD/LOO-CV* mostra che la *gerarchia* è cruciale: i modelli multilevel predicono i dati sensibilmente meglio del modello non gerarchico. Il vantaggio del modello con *condizione* rispetto al gerarchico semplice è orientato nella direzione attesa ma di *entità modesta* rispetto all’incertezza della stima: utile quando l’obiettivo è testare l’effetto sperimentale, meno decisivo se si privilegia la parsimonia.\n\nTre messaggi metodologici:\n\n* **Progettare la struttura**: scegliere un livello di complessità che rifletta la dipendenza naturale dei dati (tra individui e tra condizioni), evitando sia l’eccesso di libertà sia il vincolo eccessivo.\n* **Inferenza come integrazione**: combinare informazione individuale e di popolazione produce stime più affidabili e interpretazioni più chiare.\n* **Valutazione predittiva**: selezionare i modelli con criteri out-of-sample (ELPD/LOO) allinea la scelta del modello all’obiettivo della *generalizzazione*.\n\nIn sintesi, passare da person-level a *gerarchie con gruppi noti* non è solo un affinamento tecnico: è un cambiamento concettuale verso modelli che *rappresentano la popolazione*, rispettano l’eterogeneità e quantificano con rigore le differenze tra condizioni. Questo impianto pone basi solide per ulteriori estensioni (p.es. *mixture* per identificare sottogruppi latenti, strutture più ricche di dipendenza temporale), mantenendo come bussola la *capacità predittiva* e la *coerenza psicologica* delle ipotesi.\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#>  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#>  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [25] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#>  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#>  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#> [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#> [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#> [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#> [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#> [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#> [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#> [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#> [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#> [34] R.utils_2.13.0        Matrix_1.7-4          splines_4.5.1        \n#> [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#> [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#> [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#> [46] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#> [49] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#> [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#> [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#> [58] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#> [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#> [64] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#> [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#> [70] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#> [73] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#> [76] R.methodsS3_1.8.2     digest_0.6.37         TH.data_1.1-4        \n#> [79] htmlwidgets_1.6.4     farver_2.1.2          R.oo_1.27.1          \n#> [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#> [85] MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n",
    "supporting": [
      "02_dynamic_models_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}