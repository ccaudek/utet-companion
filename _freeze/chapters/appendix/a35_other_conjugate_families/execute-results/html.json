{
  "hash": "f5035448ed2f295f8c98b018e77a01f9",
  "result": {
    "engine": "knitr",
    "markdown": "# Altre famiglie coniugate {#sec-bayesian-inference-conjugate-2}\n\nNei capitoli precedenti abbiamo visto come il concetto di **coniugazione** renda particolarmente semplice l’aggiornamento bayesiano. L’esempio Beta–Binomiale ci ha permesso di osservare in modo diretto come i parametri della distribuzione vengano modificati dai dati senza cambiare la forma della distribuzione stessa.\n\nIn questa appendice presentiamo altri casi di famiglie coniugate, meno immediati ma ugualmente interessanti. L’obiettivo non è memorizzare formule o cataloghi di distribuzioni, ma cogliere un principio generale: **in alcune situazioni fortunate, i calcoli bayesiani diventano particolarmente trasparenti, perché il posterior appartiene alla stessa famiglia della prior**.\n\nDal punto di vista della ricerca psicologica, non è indispensabile padroneggiare tutti questi casi. Nella pratica, la maggior parte dei modelli che incontreremo non ammetterà una forma coniugata, e dovremo ricorrere a metodi computazionali generali come il campionamento MCMC. Tuttavia, conoscere queste famiglie ha due vantaggi didattici:\n\n* permette di consolidare l’intuizione su come i dati aggiornano i parametri, in contesti diversi da quello binomiale;\n* aiuta a riconoscere situazioni in cui i calcoli possono essere svolti senza simulazioni, facilitando l’analisi.\n\nSe è la prima volta che affronti questi argomenti, puoi leggere questa sezione in modo rapido, come un approfondimento facoltativo. Nei capitoli successivi torneremo a concentrarci sui metodi computazionali, che costituiscono lo strumento essenziale per affrontare i problemi psicologici reali.\n\n\n## Panoramica del capitolo {.unnumbered .unlisted}\n\n- Introdurre il modello Normale-Normale come esempio di famiglia coniugata.\n- Mostrare come combinare prior e verosimiglianza per ottenere la distribuzione a posteriori.  \n- Calcolare media e varianza a posteriori in forma chiusa. \n- Interpretare il ruolo relativo di prior e dati nell’aggiornamento bayesiano.  \n- Applicare il modello a casi concreti (tempi di reazione, punteggi di QI).  \n\n::: {.callout-tip collapse=true}\n## Prerequisiti\n\n- Leggere il capitolo *Conjugate Families* del testo di @Johnson2022bayesrules.\n:::\n\n::: {.callout-caution collapse=true title=\"Preparazione del Notebook\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |>\n    source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)\n```\n:::\n\n:::\n\n\n## Perché scegliere una distribuzione normale?\n\nLa scelta di una distribuzione a priori (e di una verosimiglianza) Normale offre numerosi vantaggi, sia dal punto di vista teorico che pratico:\n\n1.  **Simmetria e Adattabilità**:\n    La caratteristica forma \"a campana\" e simmetrica della distribuzione Normale ben si adatta a descrivere molti fenomeni naturali, psicologici e cognitivi, come i tempi di reazione, i punteggi di abilità, o gli errori di misurazione. Questa simmetria facilita l'interpretazione della media $\\mu$ come misura di tendenza centrale e della varianza $\\sigma^2$ come misura della dispersione o incertezza.\n\n2.  **Efficienza Parametrica**:\n    Nel modello Normale-Normale con varianza nota, l'incertezza sulla media $\\mu$ nella distribuzione a priori è descritta dal singolo parametro $\\sigma_0^2$ (la varianza della prior). Analogamente, la variabilità dei dati è descritta da $\\sigma^2$. Questa parsimonia parametrica semplifica sia la fase di modellizzazione sia la comunicazione dei risultati.\n\n3.  **Convergenza con l'Inferenza Classica**:\n    Per campioni di dati sufficientemente ampi, le stime bayesiane ottenute con il modello Normale tendono a convergere verso quelle dell'inferenza frequentista. Questa proprietà, legata al teorema di Bernstein-von Mises, è talvolta indicata come *calibrazione asintotica* e fa sì che il modello Normale-Normale possa agire da ponte tra i due paradigmi inferenziali.\n\n4.  **Semplicità Computazionale**:\n    Le operazioni matematiche tra distribuzioni Normali (come il prodotto richiesto dal teorema di Bayes) risultano in un'altra distribuzione Normale. Questo permette di ottenere *soluzioni analitiche in forma chiusa* per i parametri della distribuzione a posteriori, evitando la necessità di ricorrere a metodi di approssimazione numerica complessi, come le simulazioni Monte Carlo Markov Chain (MCMC), almeno nei casi più semplici.\n\n**In sintesi**: se le nostre conoscenze preliminari suggeriscono una distribuzione unimodale e simmetrica per il parametro di interesse, o se ci aspettiamo che la distribuzione a posteriori abbia tali caratteristiche (cosa spesso favorita dal Teorema del Limite Centrale quando si ha un campione ampio), la distribuzione Normale rappresenta una scelta robusta, elegante e computazionalmente vantaggiosa per condurre un'inferenza rigorosa.\n\n\n## Inferenza bayesiana per la media di una popolazione normale (varianza nota)\n\nImmaginiamo di voler stimare il tempo medio di reazione $\\mu$ (in millisecondi, ms) di una popolazione di studenti impegnati in un compito Stroop. Supponiamo di aver raccolto i tempi di reazione $y_1, \\dots, y_n$ da un campione di $n$ studenti. Assumiamo che questi dati provengano da una distribuzione Normale $y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$ e, per semplificare inizialmente il modello, *assumiamo che la varianza $\\sigma^2$ della popolazione sia nota* (ad esempio, da studi precedenti o dalla natura standardizzata del compito). Sia $\\sigma = 50$ ms la deviazione standard nota.\n\n\n### I tre passi fondamentali dell'inferenza bayesiana\n\nIl processo di inferenza bayesiana si articola nei seguenti passaggi chiave:\n\n| Passo                     | Significato Intuitivo                                      | Formalizzazione Matematica (Modello Normale-Normale)         |\n| :------------------------ | :--------------------------------------------------------- | :----------------------------------------------------------- |\n| **A. Distribuzione a Priori** | Le nostre convinzioni iniziali sulla media $\\mu$.         | $\\mu \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$                    |\n| **B. Verosimiglianza dei Dati** | L'informazione su $\\mu$ contenuta nei dati osservati. | $y_i \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)$  |\n| **C. Distribuzione a Posteriori** | Le nostre convinzioni aggiornate su $\\mu$ dopo i dati. | $\\mu \\mid \\mathbf{y} \\sim \\mathcal{N}(\\mu_p, \\sigma_p^2)$   |\n\nQuando la varianza $\\sigma^2$ dei dati è nota e la prior per $\\mu$ è Normale, la distribuzione Normale è *coniugata* per la media $\\mu$. Ciò significa che la distribuzione a posteriori per $\\mu$ sarà anch'essa Normale, mantenendo la stessa forma funzionale attraverso l'aggiornamento bayesiano.\n\n\n### Distribuzione a priori\n\n$\\mu \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)$: descrive dove crediamo sia $\\mu$ e quanta incertezza abbiamo, una varianza grande significa poca informazione.\n\n\n### Verosimiglianza\n\n$$\np(y\\mid\\mu,\\sigma)=\\prod_{i=1}^{n}\\frac{1}{\\sigma\\sqrt{2\\pi}}\n                  \\exp\\!\\Bigl[-\\tfrac{(y_i-\\mu)^2}{2\\sigma^2}\\Bigr].\n$$ \n\n\n### Teorema di Bayes\n\nIl teorema di Bayes combina prior e verosimiglianza attraverso un prodotto ponderato:\n\n$$\np(\\mu\\mid y)=\\frac{p(y\\mid\\mu)\\,p(\\mu)}{p(y)} \\;\\; \\propto\\;\\;\n\\underbrace{\\mathcal{N}(\\mu_0,\\sigma_0^2)}_{\\text{prior}}\n\\; \\times \\;\n\\underbrace{\\mathcal{N}(\\bar y,\\sigma^2/n)}_{\\text{verosimiglianza}} .\n$$\nIl prodotto di due distribuzioni gaussiane è una distribuzione gaussiana: basta *aggiornare media e varianza*.\n\n\n### Media a posteriori\n\n$$\n\\mu_p=\\frac{\\tfrac{1}{\\sigma_0^2}\\,\\mu_0 + \\tfrac{n}{\\sigma^2}\\,\\bar y}\n           {\\tfrac{1}{\\sigma_0^2} + \\tfrac{n}{\\sigma^2}},\n\\qquad\n\\bar y=\\frac{1}{n}\\sum_{i=1}^{n}y_i.\n$$ {#eq-post-normal-normal-mean}\n\n* $\\mu_0$: l'idea iniziale.\n* $\\sigma_0^2$: la fiducia in quell’idea.\n* $\\bar y$: ciò che dicono i dati.\n* $n/\\sigma^2$: la quantità di informazione empirica, aumenta con più casi e diminuisce con misure rumorose.\n\n* **Interpretazione:** Il peso relativo di prior e dati dipende dalla loro credibilità:\n    * La prior è influente se ha alta precisione, ovvero 1/$\\sigma_0^2$ è grande, o se ci sono pochi dati, $n$ piccolo.\n    * I dati sono dominanti se la prior ha bassa precisione o se c'è un ampio campione.\n\n### Varianza a posteriori\n\n$$\n\\sigma_p^2=\\frac{1}{\\tfrac{1}{\\sigma_0^2}+\\tfrac{n}{\\sigma^2}}.\n$$ {#eq-post-normal-normal-var}\n\n* **Proprietà Chiave:** $\\sigma_p^2 \\le \\min(\\sigma_0^2, \\sigma^2/n)$. L'incertezza diminuisce monotonicamente all'aumentare di $n$.\n\n::: {.callout-note collapse=\"true\"}\n## Esercizio 1.\n\nSupponiamo di voler stimare il tempo medio di reazione $\\mu$ (in millisecondi) di un gruppo di studenti a un compito Stroop. Dalla letteratura o da esperienze precedenti, assumiamo che la deviazione standard dei tempi di reazione per questo tipo di compito sia $\\sigma = 50$ ms.\n\nDefiniamo la nostra *distribuzione a priori* per $\\mu$ basandoci su una nostra conoscenza preliminare o un'ipotesi plausibile. Ad esempio, potremmo ipotizzare che il tempo medio sia attorno ai 500 ms, con una certa incertezza:\n* Media a priori: $\\mu_0 = 500$ ms\n* Deviazione standard a priori: $\\sigma_0 = 100$ ms (quindi varianza a priori $\\sigma_0^2 = 100^2 = 10000$)\n\nSuccessivamente, raccogliamo i dati da $n=20$ studenti e osserviamo una media campionaria dei tempi di reazione $\\bar{y} = 480$ ms.\n\nRiepilogo dei parametri:\n\n| Simbolo      | Descrizione                      | Valore     |\n| :----------- | :------------------------------- | :--------- |\n| $\\mu_0$      | Media a priori                   | 500 ms     |\n| $\\sigma_0$   | Dev. std. a priori               | 100 ms     |\n| $\\sigma_0^2$ | Varianza a priori                | 10000 ms²  |\n| $\\sigma$     | Dev. std. dei dati (nota)      | 50 ms      |\n| $\\sigma^2$   | Varianza dei dati (nota)         | 2500 ms²   |\n| $n$          | Numero di osservazioni           | 20         |\n| $\\bar{y}$    | Media campionaria osservata      | 480 ms     |\n\n**1. Calcolo delle Precisioni (Pesi):**\n\n* Precisione a priori: $w_0 = \\frac{1}{\\sigma_0^2} = \\frac{1}{100^2} = \\frac{1}{10000} = 0.0001$\n* Precisione dei dati: $w_{\\text{dati}} = \\frac{n}{\\sigma^2} = \\frac{20}{50^2} = \\frac{20}{2500} = 0.008$\n\n**2. Calcolo della Media a Posteriori ($\\mu_n$):**\n$$ \\mu_n = \\frac{w_0 \\mu_0 + w_{\\text{dati}} \\bar{y}}{w_0 + w_{\\text{dati}}} = \\frac{0.0001 \\times 500 + 0.008 \\times 480}{0.0001 + 0.008} = \\frac{0.05 + 3.84}{0.0081} = \\frac{3.89}{0.0081} \\approx 480.247 \\text{ ms} $$\n\n**3. Calcolo della Varianza a Posteriori ($\\sigma_n^2$):**\n$$ \\sigma_n^2 = \\frac{1}{w_0 + w_{\\text{dati}}} = \\frac{1}{0.0001 + 0.008} = \\frac{1}{0.0081} \\approx 123.457 \\text{ ms}^2 $$\nLa deviazione standard a posteriori è $\\sigma_n = \\sqrt{\\sigma_n^2} \\approx \\sqrt{123.457} \\approx 11.11 \\text{ ms}$.\n\n**Risultato e Interpretazione:**\nSiamo partiti da una stima a priori di $\\mu \\approx 500 \\pm 100$ ms. Dopo aver osservato 20 tempi di reazione con una media di 480 ms (e sapendo che $\\sigma=50$ ms), la nostra stima aggiornata per la media dei tempi di reazione è $\\mu_n \\approx 480.25 \\pm 11.11$ ms.\nNotiamo che la media a posteriori (480.25 ms) è molto più vicina alla media campionaria (480 ms) che alla media a priori (500 ms). Questo perché la precisione dei dati (0.008) è significativamente maggiore della precisione a priori (0.0001). Inoltre, la nostra incertezza si è drasticamente ridotta: la deviazione standard è passata da 100 ms a circa 11 ms dopo sole 20 osservazioni. Questo illustra il potere dell'aggiornamento bayesiano nel raffinare le nostre stime e ridurre l'incertezza.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ---- Parametri dell'esempio -------------------------------------------\nmu0    <- 500   # Media a priori\nsigma0 <- 100   # Deviazione standard a priori\nsigma  <- 50    # Deviazione standard nota dei dati\nn      <- 20    # Dimensione del campione\nybar   <- 480   # Media campionaria osservata\n\n# ---- Calcolo dei parametri a posteriori -------------------------------\n# Precisioni\nprec_prior <- 1 / sigma0^2\nprec_data  <- n / sigma^2\n\n# Parametri posteriori\nsigma_p2 <- 1 / (prec_prior + prec_data)  # Varianza a posteriori\nsigma_p  <- sqrt(sigma_p2)                # Deviazione standard a posteriori\nmu_p     <- (mu0 * prec_prior + ybar * prec_data) / (prec_prior + prec_data) # Media a posteriori\n\n# ---- Griglia di valori per il parametro mu -----------------------------\n# Definiamo un range che copra bene tutte e tre le distribuzioni\nmin_mu <- min(mu0 - 3*sigma0, ybar - 3*sigma/sqrt(n), mu_p - 3*sigma_p)\nmax_mu <- max(mu0 + 3*sigma0, ybar + 3*sigma/sqrt(n), mu_p + 3*sigma_p)\nmu_grid <- seq(min_mu, max_mu, length.out = 1000)\n\n# ---- Calcolo delle densità delle tre curve -----------------------------\nprior_dens <- dnorm(mu_grid, mean = mu0,  sd = sigma0)            # Densità a priori\npost_dens  <- dnorm(mu_grid, mean = mu_p, sd = sigma_p)           # Densità a posteriori\n\n# Verosimiglianza (standardizzata per mu, basata sulla media campionaria)\n# La sd per la verosimiglianza di mu è sigma/sqrt(n)\nlik_dens_raw <- dnorm(mu_grid, mean = ybar, sd = sigma / sqrt(n))\n# Riscaliamo la verosimiglianza per renderla graficamente confrontabile con la prior\n# Questo è solo per visualizzazione, la verosimiglianza non è una densità per mu in senso stretto\nlik_dens_scaled <- lik_dens_raw * (max(prior_dens) / max(lik_dens_raw))\n\n# ---- Preparazione dati in formato \"lungo\" per ggplot2 ------------------\ndf <- data.frame(\n  mu         = mu_grid,\n  Prior      = prior_dens,\n  Likelihood_scaled = lik_dens_scaled, # Usiamo quella riscalata\n  Posterior  = post_dens\n)\n\ndf_long <- pivot_longer(df, -mu, names_to = \"Distribuzione\", values_to = \"Densita\")\ndf_long$Distribuzione <- factor(df_long$Distribuzione, \n                                levels = c(\"Prior\", \"Likelihood_scaled\", \"Posterior\"),\n                                labels = c(\"A Priori\", \"Verosimiglianza (riscalata)\", \"A Posteriori\"))\n\n\n# ---- Grafico delle distribuzioni ---------------------------------------\nggplot(df_long, aes(x = mu, y = Densita, colour = Distribuzione)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x      = expression(paste(\"Media dei Tempi di Reazione \", mu, \" (ms)\")),\n    y      = \"Densità\",\n    title  = \"Aggiornamento Bayesiano: dal Prior al Posteriori\",\n    subtitle = paste0(\"Prior: N(\", mu0, \", \", sigma0^2, \"), \",\n                      \"Verosimiglianza (per μ): N(\", ybar, \", \", round((sigma^2/n),2), \"), \",\n                      \"Posteriori: N(\", round(mu_p,2), \", \", round(sigma_p2,2), \")\")\n  ) +\n  scale_color_manual(values = c(\"A Priori\" = \"dodgerblue\", \n                                \"Verosimiglianza (riscalata)\" = \"forestgreen\", \n                                \"A Posteriori\" = \"orangered\")) +\n  theme(legend.title = element_blank(), legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![Distribuzioni a priori, verosimiglianza (standardizzata e riscalata) e a posteriori per la media dei tempi di reazione (μ).](a35_other_conjugate_families_files/figure-html/fig-stroop-1.png){#fig-stroop fig-align='center' width=85%}\n:::\n:::\n\n\nIl grafico @fig-stroop illustra chiaramente come la distribuzione a posteriori sia \"spostata\" verso la verosimiglianza (che è più informativa della prior in questo caso) e come la sua varianza sia notevolmente ridotta rispetto a entrambe.\n:::\n\n\n::: {.callout-note appearance=\"simple\"}\n## Messaggi chiave sull'inferenza con varianza nota\n\n1. Dialogo Costruttivo: L'inferenza bayesiana è un processo dinamico di dialogo tra le nostre ipotesi iniziali (prior) e l'evidenza empirica (dati/verosimiglianza).\n2. Calcoli Trasparenti: Con la varianza della popolazione $\\sigma^2$ nota, i calcoli per la media e la varianza a posteriori sono diretti e possono essere eseguiti analiticamente (anche \"a mano\" per esempi semplici).\n3. Riduzione Garantita dell'Incertezza: Dopo aver osservato i dati, l'incertezza sul parametro (misurata dalla varianza a posteriori) non può che diminuire o, al limite, rimanere uguale (caso teorico di dati non informativi), rispetto alla varianza a priori.\n4. Peso dell'Evidenza:\nCon pochi dati o dati molto \"rumorosi\" (alta $\\sigma^2$), la distribuzione a priori esercita un'influenza maggiore sulla stima finale.\nCon molti dati o dati molto precisi (bassa $\\sigma^2$), l'informazione proveniente dai dati tende a dominare, e l'influenza della prior sulla stima a posteriori diminuisce.\n5. Applicabilità Vasta: Lo schema concettuale e matematico del modello Normale-Normale si applica a una vasta gamma di problemi in diverse discipline, inclusa la psicologia sperimentale (es. tempi di reazione, punteggi a test, ampiezze di segnali EEG), l'ingegneria, l'economia, e molte altre aree dove si misurano quantità continue. :::\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Esercizio 2.\n\nI test standard di Quoziente Intellettivo (QI) sono generalmente calibrati per avere una media di 100 e una deviazione standard di 15 nella popolazione di riferimento. Tuttavia, sono state sollevate questioni riguardo a possibili bias culturali che potrebbero favorire alcuni gruppi rispetto ad altri. Un'ulteriore complicazione sorge quando i punteggi QI vengono aggregati a livello nazionale, poiché le medie nazionali possono mascherare eterogeneità intra-paese significative.\n\nQuesto esempio, ispirato da @gill2015bayesian (che discute i dati di Lynn e Vanhanen, 2001), analizza i dati di QI medio riportati per 80 nazioni. L'obiettivo è stimare un QI medio \"globale\" $\\mu$ utilizzando un approccio bayesiano Normale-Normale, e riflettere criticamente sul risultato.\n\nAssumiamo una deviazione standard nota $\\sigma = 15$ per i punteggi QI (questa è una semplificazione, poiché la variabilità delle medie nazionali potrebbe essere diversa dalla variabilità individuale).\n\nI dati di QI medio per $n=80$ nazioni sono forniti di seguito:\n\n\n| Paese          | IQ  | Paese          | IQ  | Paese          | IQ  | Paese          | IQ  |\n|----------------|-----|----------------|-----|----------------|-----|----------------|-----|\n| Argentina      | 96  | Australia      | 98  | Austria        | 102 | Barbados       | 78  |\n| Belgium        | 100 | Brazil         | 87  | Bulgaria       | 93  | Canada         | 97  |\n| China          | 100 | Congo (Br.)    | 73  | Congo (Zr.)    | 65  | Croatia        | 90  |\n| Cuba           | 85  | Czech Repub.   | 97  | Denmark        | 98  | Ecuador        | 80  |\n| Egypt          | 83  | Eq. Guinea     | 59  | Ethiopia       | 63  | Fiji           | 84  |\n| Finland        | 97  | France         | 98  | Germany        | 102 | Ghana          | 71  |\n| Greece         | 92  | Guatemala      | 79  | Guinea         | 66  | Hong Kong      | 107 |\n| Hungary        | 99  | India          | 81  | Indonesia      | 89  | Iran           | 84  |\n| Iraq           | 87  | Ireland        | 93  | Israel         | 94  | Italy          | 102 |\n| Jamaica        | 72  | Japan          | 105 | Kenya          | 72  | Korea (S.)     | 106 |\n| Lebanon        | 86  | Malaysia       | 92  | Marshall I.    | 84  | Mexico         | 87  |\n| Morocco        | 85  | Nepal          | 78  | Netherlands    | 102 | New Zealand    | 100 |\n| Nigeria        | 67  | Norway         | 98  | Peru           | 90  | Philippines    | 86  |\n| Poland         | 99  | Portugal       | 95  | Puerto Rico    | 84  | Qatar          | 78  |\n| Romania        | 94  | Russia         | 96  | Samoa          | 87  | Sierra Leone   | 64  |\n| Singapore      | 103 | Slovakia       | 96  | Slovenia       | 95  | South Africa   | 72  |\n| Spain          | 97  | Sudan          | 72  | Suriname       | 89  | Sweden         | 101 |\n| Switzerland    | 101 | Taiwan         | 104 | Tanzania       | 72  | Thailand       | 91  |\n| Tonga          | 87  | Turkey         | 90  | Uganda         | 73  | U.K.           | 100 |\n| U.S.           | 98  | Uruguay        | 96  | Zambia         | 77  | Zimbabwe       | 66  |\n\nImpostazione del Modello Bayesiano:\n\n1. Prior per $\\mu$:\nStabiliamo una prior basata sulla standardizzazione tipica dei test QI:\n\n- $\\mu_0 = 100$ (media a priori)\n- $\\sigma_0 = 15$ (deviazione standard a priori, che riflette una certa incertezza sulla media globale, o la stessa scala della $\\sigma$ individuale). Quindi, $\\mu \\sim \\mathcal{N}(100, 15^2)$.\n\n2. Verosimiglianza:\nOgni QI nazionale $y_i$ è considerato come un'osservazione della media \"vera\" $\\mu$ con varianza $\\sigma^2 = 15^2$. La media campionaria dei QI nazionali sarà $\\bar{y}$.\n\n(Nota: Questa è una semplificazione. Idealmente, ogni $y_i$ è già una media, e dovremmo considerare la sua precisione $N_i/\\sigma^2$ se $N_i$ fosse la dimensione del campione per quella nazione. Qui, trattiamo ogni media nazionale come un singolo dato $y_i$ proveniente da $\\mathcal{N}(\\mu, \\sigma^2)$).\n\nImplementiamo le informazioni necessarie in R.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Dati IQ delle 80 nazioni (valori aggregati per paese)\niq <- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, \n  87, 98, 87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, \n  90, 96, 98, 102, 78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, \n  89, 72, 101, 91, 100, 100, 66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, \n  67, 86\n) # Dati da Lynn e Vanhanen (2001) come presentati in Gill (2015)\n\n# Numero di osservazioni (nazioni)\nn <- length(iq)\n\n# Media campionaria dei QI nazionali\ny_bar <- mean(iq)\n\n# Deviazione standard assunta nota (per la \"popolazione\" da cui provengono le medie nazionali)\nsigma <- 15\n\n# Parametri a priori\nmu_0 <- 100    # Media a priori\nsigma_0 <- 15  # Dev. std. a priori\n\ncat(paste(\"Numero di nazioni (n):\", n))\n#> Numero di nazioni (n): 72\ncat(paste(\"\\nMedia campionaria dei QI nazionali (y_bar):\", round(y_bar, 2)))\n#> \n#> Media campionaria dei QI nazionali (y_bar): 89.21\n```\n:::\n\n\n**Calcolo dei parametri a posteriori:**\n\nUtilizziamo le formule derivate precedentemente:\n\n$$\\mu_n = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}} \n$$\n\n$$\n\\sigma_n^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}} \n$$\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Precisioni\nprec_prior_iq <- 1 / sigma_0^2\nprec_data_iq  <- n / sigma^2\n\n# Parametri posteriori\nmu_p_iq     <- (mu_0 * prec_prior_iq + y_bar * prec_data_iq) / (prec_prior_iq + prec_data_iq)\nsigma_p_sq_iq <- 1 / (prec_prior_iq + prec_data_iq)\nsigma_p_iq    <- sqrt(sigma_p_sq_iq)\n\ncat(paste(\"Media a posteriori (mu_n):\", round(mu_p_iq, 2)))\n#> Media a posteriori (mu_n): 89.36\ncat(paste(\"\\nVarianza a posteriori (sigma_n^2):\", round(sigma_p_sq_iq, 2)))\n#> \n#> Varianza a posteriori (sigma_n^2): 3.08\ncat(paste(\"\\nDeviazione standard a posteriori (sigma_n):\", round(sigma_p_iq, 2)))\n#> \n#> Deviazione standard a posteriori (sigma_n): 1.76\n```\n:::\n\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto `mu_0` = 100 e `sigma_0` = 15 per la distribuzione a priori.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definizione dei valori sull'asse x per il grafico della posteriori\nx_qi <- seq(mu_p_iq - 4 * sigma_p_iq, mu_p_iq + 4 * sigma_p_iq, length.out = 1000)\n\n# Calcolo della densità di probabilità per la posteriori\npdf_qi <- dnorm(x_qi, mean = mu_p_iq, sd = sigma_p_iq)\n\n# Creazione del grafico\nggplot(data.frame(x = x_qi, pdf = pdf_qi), aes(x = x, y = pdf)) +\n  geom_line(color = \"darkslateblue\", linewidth = 1.2) +\n  geom_area(fill = \"darkslateblue\", alpha = 0.3) +\n  labs(\n    x = \"Media 'Globale' del Quoziente di Intelligenza (μ)\",\n    y = \"Densità di Probabilità\",\n    title = \"Distribuzione a Posteriori del QI Medio Globale\",\n    subtitle = paste0(\"Posteriori: N(\", round(mu_p_iq, 2), \", \", round(sigma_p_sq_iq, 2), \")\")\n  ) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![Distribuzione a posteriori per la media 'globale' del QI (μ), basata sui dati di 80 nazioni.](a35_other_conjugate_families_files/figure-html/fig-qi-posterior-1.png){#fig-qi-posterior fig-align='center' width=85%}\n:::\n:::\n\n\nPer completezza, visualizziamo anche prior, likelihood e posterior:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmu_grid_iq <- seq(min(mu_0 - 3 * sigma_0, y_bar - 3 * sigma / sqrt(n), mu_p_iq - 3 * sigma_p_iq),\n  max(mu_0 + 3 * sigma_0, y_bar + 3 * sigma / sqrt(n), mu_p_iq + 3 * sigma_p_iq),\n  length.out = 1000\n)\n\nprior_dens_iq <- dnorm(mu_grid_iq, mean = mu_0, sd = sigma_0)\nlik_dens_raw_iq <- dnorm(mu_grid_iq, mean = y_bar, sd = sigma / sqrt(n)) # SD della media campionaria\nlik_dens_scaled_iq <- lik_dens_raw_iq * (max(prior_dens_iq) / max(lik_dens_raw_iq, na.rm = TRUE)) # Scalata\npost_dens_iq <- dnorm(mu_grid_iq, mean = mu_p_iq, sd = sigma_p_iq)\n\ndf_iq <- data.frame(\n  mu = mu_grid_iq,\n  Prior = prior_dens_iq,\n  Likelihood_scaled = lik_dens_scaled_iq,\n  Posterior = post_dens_iq\n)\n\ndf_long_iq <- pivot_longer(df_iq, -mu, names_to = \"Distribuzione\", values_to = \"Densita\")\ndf_long_iq$Distribuzione <- factor(df_long_iq$Distribuzione,\n  levels = c(\"Prior\", \"Likelihood_scaled\", \"Posterior\"),\n  labels = c(\"A Priori\", \"Verosimiglianza (riscalata)\", \"A Posteriori\")\n)\n\nggplot(df_long_iq, aes(x = mu, y = Densita, colour = Distribuzione)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(paste(\"Media QI \", mu)),\n    y = \"Densità\",\n    title = \"Aggiornamento Bayesiano per il QI Medio 'Globale'\",\n    subtitle = paste0(\n      \"Prior: N(\", mu_0, \", \", sigma_0^2, \"), \",\n      \"Verosimiglianza (per μ): N(\", round(y_bar, 2), \", \", round((sigma^2 / n), 2), \"), \",\n      \"Posteriori: N(\", round(mu_p_iq, 2), \", \", round(sigma_p_sq_iq, 2), \")\"\n    )\n  ) +\n  scale_color_manual(values = c(\n    \"A Priori\" = \"dodgerblue\",\n    \"Verosimiglianza (riscalata)\" = \"forestgreen\",\n    \"A Posteriori\" = \"orangered\"\n  )) +\n  theme(legend.title = element_blank(), legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](a35_other_conjugate_families_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n**Discussione critica dei risultati**\n\nL'analisi bayesiana ha prodotto una media a posteriori per il QI \"globale\" di $\\mu_n \\approx 89.36$, con una deviazione standard a posteriori molto piccola ($\\sigma_n \\approx 1.66$). Questo valore è notevolmente inferiore alla media standard di 100.\n\nTuttavia, è cruciale interpretare questo risultato con estrema cautela, considerando diversi fattori limitanti e criticità:\n\n- **Effetto di Aggregazione (Ecological Fallacy):** La media a posteriori è calcolata aggregando i dati QI medi di 80 nazioni. Questa media aggregata potrebbe non riflettere accuratamente la distribuzione del QI a livello individuale all'interno delle singole nazioni, né la vera distribuzione \"globale\" se si potessero testare tutti gli individui. Le differenze significative tra le nazioni (in termini di medie, varianze, e contesti socio-culturali) vengono \"appiattite\" in un unico valore, potenzialmente mascherando eterogeneità importanti.\n- **Dati Non Ponderati:** L'analisi tratta ogni nazione come un'singola osservazione, indipendentemente dalla sua popolazione. Nazioni con popolazioni molto diverse contribuiscono allo stesso modo alla stima della media $\\bar{y}$. Una media ponderata per la popolazione potrebbe fornire un quadro diverso, sebbene anch'esso soggetto a critiche.\n- **Contesto e Fattori Concomitanti:** La deviazione dalla media standard di 100 potrebbe riflettere non solo (o non principalmente) differenze \"reali\" nell'intelligenza media, ma anche enormi disparità nei contesti sanitari, educativi, socio-economici e politici in cui i test sono stati (eventualmente) somministrati o i dati raccolti. Fattori come l'accesso all'istruzione di qualità, la nutrizione, la salute pubblica, e l'esposizione a stimoli cognitivi variano drasticamente tra le nazioni e possono influenzare significativamente i punteggi medi.\n- **Bias Culturale dei Test:** I test del QI sono stati storicamente sviluppati e standardizzati in contesti culturali specifici (principalmente occidentali, industrializzati). La loro applicabilità e validità cross-culturale è oggetto di un acceso dibattito. È possibile che i test stessi presentino bias culturali che portano a sottostimare le capacità cognitive in contesti culturali diversi da quello di origine, influenzando così le medie nazionali riportate.\n- **Qualità e Origine dei Dati:** I dati originali di Lynn e Vanhanen sono stati oggetto di numerose critiche metodologiche riguardanti la raccolta, la comparabilità e la qualità dei punteggi QI tra diverse nazioni. Utilizzare questi dati senza un esame approfondito delle loro limitazioni può portare a conclusioni fuorvianti.\n- **Assunzione di $\\sigma$ Nota e Uguale:** L'assunzione che $\\sigma=15$ sia la deviazione standard rilevante per le medie nazionali è una forte semplificazione. La variabilità tra le medie nazionali potrebbe essere diversa dalla variabilità individuale all'interno di una popolazione di riferimento.\n\nIn conclusione, sebbene il modello Normale-Normale fornisca una stima quantitativa ($\\mu_n \\approx 89.36$), le profonde questioni metodologiche, concettuali ed etiche legate ai dati sul QI internazionale rendono problematica un'interpretazione diretta di questo valore come \"vera\" media globale dell'intelligenza. Questo esempio serve più come illustrazione meccanica dell'aggiornamento bayesiano che come un'affermazione sostanziale sul QI globale. Un'analisi seria richiederebbe modelli gerarchici più complessi, una discussione approfondita della validità dei dati e una considerazione attenta dei fattori contestuali.\n\n:::\n\n\n## Riflessioni conclusive {.unnumbered .unlisted}\n\nNei capitoli precedenti abbiamo visto come il concetto di *coniugazione* renda particolarmente semplice l’aggiornamento bayesiano. L’esempio Beta–Binomiale ci ha permesso di osservare in modo diretto come i parametri della distribuzione vengano modificati dai dati senza cambiare la forma della distribuzione stessa.\n\nIn questa appendice presentiamo altri casi di famiglie coniugate, meno immediati ma ugualmente interessanti. L’obiettivo non è memorizzare formule o cataloghi di distribuzioni, ma cogliere un principio generale: *in alcune situazioni fortunate, i calcoli bayesiani diventano particolarmente trasparenti, perché il posterior appartiene alla stessa famiglia della prior*.\n\nDal punto di vista della ricerca psicologica, non è indispensabile padroneggiare tutti questi casi. Nella pratica, la maggior parte dei modelli che incontreremo non ammetterà una forma coniugata, e dovremo ricorrere a metodi computazionali generali come il campionamento MCMC. Tuttavia, conoscere queste famiglie ha due vantaggi didattici:\n\n* permette di consolidare l’intuizione su come i dati aggiornano i parametri, in contesti diversi da quello binomiale;\n* aiuta a riconoscere situazioni in cui i calcoli possono essere svolti senza simulazioni, facilitando l’analisi.\n\nSe è la prima volta che affronti questi argomenti, puoi leggere questa sezione in modo rapido, come un approfondimento facoltativo. Nei capitoli successivi torneremo a concentrarci sui metodi computazionali, che costituiscono lo strumento essenziale per affrontare i problemi psicologici reali.\n\n\n::: {.callout-important title=\"Problemi\" collapse=\"true\"}\nRiprendi i dati della SWLS che sono stati utilizzati nell'esercizio del @sec-gauss-grid. Trova la media e la deviazione standard della distribuzione a posteriori usando il metodo delle distribuzioni coniugate. Confronta i risultati con quelli ottenuti con il metodo basato su griglia. \n\n**Consegna:** Carica il file .qmd, convertito in PDF, su Moodle.\n:::\n\n::: {.callout-tip title=\"Soluzioni\" collapse=\"true\"}\n\nPer risolvere questo esercizio con il *metodo delle distribuzioni coniugate*, assumiamo che i dati provengano da una distribuzione normale con deviazione standard nota e media da stimare. Nel caso di una *verosimiglianza gaussiana* con prior gaussiano, la distribuzione a posteriori sarà ancora una distribuzione normale. Questo approccio è analitico e ci permette di ottenere la media e la deviazione standard della distribuzione a posteriori senza dover ricorrere a metodi numerici come la discretizzazione della griglia.\n\n**Passaggi per il calcolo della distribuzione a posteriori**\n\n1. **Definiamo i dati osservati**:\n   - La media campionaria: $\\bar{x}$\n   - La deviazione standard nota dei dati: $\\sigma$\n   - Il numero di osservazioni: $n$\n\n2. **Scegliamo un prior gaussiano molto diffuso**:\n   - Media a priori: $\\mu_0$\n   - Deviazione standard a priori molto grande: $\\sigma_0$\n\n3. **Calcoliamo la media e la varianza della distribuzione a posteriori**:\n   - La media a posteriori è:\n   \n     $$\n     \\mu_{\\text{post}} = \\frac{\\sigma^2_0 \\bar{x} + \\sigma^2 n \\mu_0}{\\sigma^2_0 + \\sigma^2 n}\n     $$\n     \n   - La varianza a posteriori è:\n   \n     $$\n     \\sigma^2_{\\text{post}} = \\frac{\\sigma^2_0 \\sigma^2}{\\sigma^2_0 + \\sigma^2 n}\n     $$\n\n**Implementazione in R**\n\n```r\n# Caricamento librerie necessarie\nlibrary(dplyr)\nlibrary(tibble)\n\n# Dati SWLS\nswls_data <- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n\n# Parametri comuni per entrambi i metodi\nsigma_conosciuta <- sd(swls_data$soddisfazione)  # Usando la deviazione standard campionaria\nn <- nrow(swls_data)\nmean_x <- mean(swls_data$soddisfazione)\n\ncat(\"Deviazione standard campionaria:\", sigma_conosciuta, \"\\n\")\ncat(\"Media campionaria:\", mean_x, \"\\n\")\n\n# ---- Metodo 1: Griglia ----\n# Definizione della griglia più fine e centrata intorno alla media campionaria\nmu_griglia <- seq(mean_x - 3*sigma_conosciuta/sqrt(n), \n                 mean_x + 3*sigma_conosciuta/sqrt(n), \n                 length.out = 1000)\n\n# Calcolo della verosimiglianza\nlog_likelihood <- numeric(length(mu_griglia))\nfor (i in seq_along(mu_griglia)) {\n  # Utilizzo della log-likelihood per evitare problemi numerici\n  log_likelihood[i] <- sum(dnorm(swls_data$soddisfazione, \n                                mean = mu_griglia[i], \n                                sd = sigma_conosciuta, \n                                log = TRUE))\n}\n\n# Prior uniforme (in scala logaritmica)\nlog_prior <- rep(0, length(mu_griglia))\n\n# Calcolo della posteriori\nlog_posterior <- log_likelihood + log_prior\nposterior <- exp(log_posterior - max(log_posterior))\nposterior <- posterior / sum(posterior)\n\n# Campionamento e calcolo statistiche\nsamples_grid <- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean_post_grid <- mean(samples_grid)\nsd_post_grid <- sd(samples_grid)\nci_grid <- quantile(samples_grid, c(0.03, 0.97))\n\n# ---- Metodo 2: Soluzione analitica ----\n# Prior poco informativo ma non improprio\nmu_prior <- mean_x\nsigma_prior <- 10\n\n# Calcolo posteriori\nmu_post_analytic <- (sigma_prior^2 * mean_x + sigma_conosciuta^2 * mu_prior/n) / \n                    (sigma_prior^2 + sigma_conosciuta^2/n)\nsigma_post_analytic <- sqrt((sigma_prior^2 * sigma_conosciuta^2/n) / \n                           (sigma_prior^2 + sigma_conosciuta^2/n))\n\n# Confronto risultati\nresults <- tibble(\n  Metodo = c(\"Griglia\", \"Analitico\"),\n  `Media Posteriori` = c(mean_post_grid, mu_post_analytic),\n  `Dev. Std. Posteriori` = c(sd_post_grid, sigma_post_analytic)\n)\nresults\n```\n**Interpretazione dei risultati**\n\n- La **media a posteriori** rappresenta la miglior stima aggiornata della media della popolazione dopo aver osservato i dati.\n- La **deviazione standard a posteriori** ci dice quanto è incerta la nostra stima della media dopo aver integrato i dati e il prior.\n\nSiccome abbiamo scelto un prior molto diffuso ($\\sigma_0 = 10$), il risultato ottenuto è molto vicino a quello ottenuto con il metodo della griglia, dove il prior uniforme aveva un impatto minimo sulla distribuzione a posteriori.\n\nQuesta implementazione analitica permette di ottenere il risultato in modo efficiente senza necessità di metodi numerici approssimati.\n:::\n\n\n::: {.callout-note collapse=true title=\"Informazioni sull'ambiente di sviluppo\"}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#>  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#>  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#> [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#> [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#> [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#> [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#> [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#> [25] rio_1.2.3             here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#>  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#>  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#> [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#> [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#> [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#> [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#> [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#> [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#> [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#> [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#> [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#> [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#> [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#> [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#> [46] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#> [49] codetools_0.2-20      curl_7.0.0            pkgbuild_1.4.8       \n#> [52] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#> [55] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#> [58] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#> [61] foreach_1.5.2         stats4_4.5.1          reformulas_0.4.1     \n#> [64] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#> [67] rstantools_2.5.0      scales_1.4.0          minqa_1.2.8          \n#> [70] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#> [73] tools_4.5.1           lme4_1.1-37           mvtnorm_1.3-3        \n#> [76] grid_4.5.1            rbibutils_2.3         QuickJSR_1.8.0       \n#> [79] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#> [82] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#> [85] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#> [88] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#> [91] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#> [94] mitml_0.4-5           MASS_7.3-65\n```\n:::\n\n:::\n\n## Bibliografia {.unnumbered .unlisted}\n\n\n",
    "supporting": [
      "a35_other_conjugate_families_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}