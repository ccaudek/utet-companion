{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodi approssimativi nell'inferenza Bayesiana {#sec-approximations}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisiti**\n",
    "\n",
    "- Si veda il capitolo *Approximations to Bayes* di @vanOijen2024.\n",
    "\n",
    "**Concetti e Competenze Chiave**\n",
    "\n",
    "- Laplace Approximation,\n",
    "- Variational Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzione {.unnumbered}\n",
    "\n",
    "Nell'inferenza bayesiana, spesso ci troviamo di fronte a situazioni in cui i metodi di campionamento come MCMC richiedono tempi di calcolo proibitivi. In questi casi, i metodi approssimativi offrono un'alternativa pratica, sacrificando una parte della precisione per ottenere risultati in tempi ragionevoli.\n",
    "\n",
    "## Panoramica dei Metodi Approssimativi\n",
    "\n",
    "### 1. Approximate Bayesian Computation (ABC)\n",
    "\n",
    "L'ABC è utile quando la funzione di verosimiglianza è difficile o impossibile da calcolare (Lintusaari et al., 2017). Invece di calcolare direttamente la verosimiglianza, l'ABC:\n",
    "\n",
    "1. Genera parametri dalla distribuzione a priori\n",
    "2. Simula dati usando questi parametri\n",
    "3. Confronta i dati simulati con i dati osservati\n",
    "4. Accetta i parametri se la differenza è inferiore a una soglia\n",
    "\n",
    "L'ABC è particolarmente utile per modelli complessi in biologia, ecologia e genetica delle popolazioni.\n",
    "\n",
    "### 2. Linear Bayes (LB)\n",
    "\n",
    "Il Linear Bayes semplifica l'inferenza concentrandosi solo sui primi due momenti (media e varianza) della distribuzione (Goldstein, 2015). Non richiede distribuzioni complete, ma fornisce aggiornamenti approssimativi simili al filtro di Kalman.\n",
    "\n",
    "### 3. Laplace Approximation (LA)\n",
    "\n",
    "La LA approssima la distribuzione a posteriori con una distribuzione gaussiana multivariata (MacKay, 1992). Trova il massimo a posteriori (MAP) e usa la curvatura intorno a questo punto per stimare la matrice di covarianza. È efficace quando la vera posteriori è approssimativamente gaussiana.\n",
    "\n",
    "### 4. Integrated Nested Laplace Approximation (INLA)\n",
    "\n",
    "INLA estende l'idea della LA ai modelli gerarchici (Simpson et al., 2023). Si concentra sulle distribuzioni marginali a posteriori dei singoli parametri, evitando di calcolare le correlazioni complete tra tutti i parametri.\n",
    "\n",
    "### 5. Variational Bayes (VB)\n",
    "\n",
    "Il VB cerca di approssimare la vera distribuzione a posteriori p(θ|y) con una distribuzione più semplice q(θ), scelta da una famiglia trattabile di distribuzioni (Barber & Bishop, 1998).\n",
    "\n",
    "#### Funzionamento del VB\n",
    "\n",
    "1. **Scelta della Famiglia di Distribuzioni**: Si sceglie una famiglia di distribuzioni q(θ) che sia facile da manipolare. Spesso si usa una famiglia fattorizzata, dove q(θ) = Π q_i(θ_i).\n",
    "\n",
    "2. **Ottimizzazione**: Si cerca di minimizzare la divergenza di Kullback-Leibler (KL) tra q(θ) e p(θ|y). Questo equivale a massimizzare un limite inferiore dell'evidenza del modello (ELBO - Evidence Lower BOund).\n",
    "\n",
    "3. **Aggiornamento Iterativo**: Si aggiornano iterativamente i parametri di q(θ) per massimizzare l'ELBO.\n",
    "\n",
    "#### Vantaggi del VB\n",
    "\n",
    "- **Efficienza Computazionale**: Spesso molto più veloce di MCMC per modelli complessi.\n",
    "- **Scalabilità**: Adatto per grandi dataset e modelli ad alta dimensionalità.\n",
    "- **Limite Inferiore dell'Evidenza**: Fornisce automaticamente una stima dell'evidenza del modello, utile per il confronto tra modelli.\n",
    "\n",
    "#### Limitazioni del VB\n",
    "\n",
    "- **Approssimazione**: La distribuzione approssimata potrebbe non catturare completamente la struttura della vera posteriori, soprattutto in caso di multimodalità o forti correlazioni.\n",
    "- **Sottostima dell'Incertezza**: Tende a sottostimare la varianza della posteriori.\n",
    "\n",
    "## Conclusione\n",
    "\n",
    "I metodi approssimativi offrono soluzioni pratiche quando l'inferenza bayesiana esatta è computazionalmente proibitiva. Ogni metodo ha i suoi punti di forza e limitazioni, e la scelta dipende dalla natura del problema, dalla dimensione dei dati e dalle risorse computazionali disponibili. Il Variational Bayes, in particolare, si è dimostrato un approccio versatile e potente in molti campi applicativi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
