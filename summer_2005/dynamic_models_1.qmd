# Modelli dinamici {#sec-dynamic-models-goal-updating}

Molte teorie psicologiche mirano a descrivere *processi dinamici*, ovvero fenomeni che si sviluppano e modificano nel tempo. Prendiamo, ad esempio, la regolazione degli obiettivi, l’apprendimento dalle esperienze o l’emergere di sintomi clinici: in tutti questi casi, il comportamento osservabile in un dato momento *è il risultato di eventi precedenti*. Nonostante ciò, gli strumenti statistici più utilizzati in psicologia spesso trascurano questa dimensione temporale. Misuriamo correlazioni o confrontiamo medie, ma raramente catturiamo *l’evoluzione del processo* stesso.  


## Perché servono modelli dinamici? 

Un *modello dinamico* è un modello matematico che rappresenta esplicitamente *come un sistema evolve nel tempo*. A differenza dei modelli statici, in cui le relazioni tra variabili sono istantanee, nei modelli dinamici almeno una variabile ha *memoria del passato*: il suo valore attuale dipende dai valori precedenti. Queste variabili sono spesso chiamate *variabili di stato* (*stock* o *level variables*) e catturano l’accumulo o il decadimento di un processo nel tempo.  


### Come si costruisce un modello dinamico?

Per formulare un modello dinamico, è necessario:

* *Identificare le variabili rilevanti* – Quali elementi influenzano il sistema?
* *Definire le regole di cambiamento* – Come una variabile evolve in funzione delle altre?
* *Tradurre le regole in equazioni* – Formalizzare matematicamente il processo.
* *Validare il modello* – Verificare se le previsioni corrispondono ai dati osservati.


### Un esempio concreto: il modello di revisione degli obiettivi

Consideriamo un esperimento in cui i partecipanti devono raggiungere un obiettivo (ad esempio, classificare correttamente coppie di immagini). Prima di ogni prova (trial), fissano un goal (un obiettivo soggettivo, come la velocità o l’accuratezza). Dopo ogni tentativo, ricevono un feedback sulla loro performance, che può indurli a aggiustare il goal nel trial successivo.


### Come formalizzare questo processo?

Un possibile modello dinamico potrebbe assumere che:

* L’aggiornamento del goal dipende dalla discrepanza (error) tra il feedback ricevuto e il goal precedente.
* Nel modello proposto da @knight2023tutorial, la regola di cambiamento dell'obiettivo da un trial al successivo è descritta nel modo seguente:

$$
G_t = G_{t-1} + \alpha \cdot (P_{t-1} - G_{t-1}) + \beta
$$

dove:

* $G_t$ è il goal al tempo $t$,
* $P_{t-1}$ è la performance al tempo $t-1$,
* $\alpha$ è il *coefficiente di apprendimento*: indica quanto il partecipante adatta il proprio obiettivo alla luce della discrepanza tra performance e goal precedente;
* $\beta$ è una *spinta costante*: rappresenta una tendenza a modificare il goal anche in assenza di errore (ad es., una crescente ambizione o una pressione esterna).

Questo modello è detto *sample-level* perché assume che tutti i partecipanti seguano *la stessa regola*, con gli stessi parametri $\alpha$ e $\beta$, stimati sull’intero campione.


### Illustrazione numerica del modello

#### Caso 1: Performance superiore all'obiettivo

* Obiettivo precedente: $G_{t-1} = 50$ punti.
* Performance effettiva: $P_{t-1} = 60$ punti.
* Parametri: $\alpha = 0.5$ (apprendimento moderato), $\beta = 2$ (lieve tendenza all'aumento).

Calcolo:

$$
G_t = 50 + 0.5 \cdot (60 - 50) + 2 = 50 + 5 + 2 = \mathbf{57}
$$

*Interpretazione:* il nuovo obiettivo sale a 57: il partecipante si è accorto di poter fare meglio. Il nuovo obiettivo più ambizioso (57) dimostra l'adattamento alle capacità reali.


#### Caso 2: Performance inferiore all'obiettivo

* Obiettivo precedente: $G_{t-1} = 50$ punti.
* Performance effettiva: $P_{t-1} = 40$ punti.
* Parametri invariati: $\alpha = 0.5$, $\beta = 2$.

Calcolo:

$$
G_t = 50 + 0.5 \cdot (40 - 50) + 2 = 50 - 5 + 2 = \mathbf{47}
$$

*Interpretazione:* l'obiettivo si abbassa. Tuttavia, nonostante la performance deludente, la tendenza all'aumento ($\beta$) previene un crollo dell'aspirazione, riflettendo possibili meccanismi di:

  * auto-protezione motivazionale,
  * attribuzione esterna dell'errore,
  * effetto "ancoraggio" all'obiettivo precedente.


### L'Importanza scientifica del modello dinamico

Questo approccio modellistico riveste particolare rilevanza nella ricerca psicologica per la sua capacità di tradurre processi cognitivi complessi in relazioni matematiche verificabili. La struttura dinamica proposta consente di indagare sistematicamente i meccanismi di regolazione degli obiettivi, offrendo diversi vantaggi metodologici e teorici.

In primo luogo, il modello permette di accertare se e in quale misura gli individui modificano le proprie aspettative in risposta ai feedback ricevuti. Attraverso il parametro $\alpha$ possiamo quantificare con precisione la sensibilità individuale alle discrepanze tra performance attese e reali, dove valori più elevati indicano una maggiore prontezza nell'adeguare gli obiettivi.

Il parametro $\beta$ aggiunge un ulteriore livello di comprensione, rivelando eventuali tendenze sistemiche nella revisione degli obiettivi indipendenti dalla performance. Una valore positivo costante di β potrebbe riflettere, ad esempio, una progressiva crescita nell'ambizione o l'effetto di fattori motivazionali esterni.

Oltre alla descrizione del comportamento osservato, il modello si dimostra particolarmente prezioso per la sua capacità predittiva. Una volta stimati i parametri individuali, diventa possibile anticipare come un soggetto modificherà i propri obiettivi in risposta a specifici schemi di feedback, con importanti implicazioni per la progettazione di interventi formativi o terapeutici.

Le applicazioni di questo framework si estendono a numerosi ambiti della psicologia, dalla ricerca sull'apprendimento allo studio dei processi decisionali, offrendo una lente quantitativa per esaminare come gli individui modificano le proprie strategie in base all'esperienza. Nella pratica clinica, ad esempio, potrebbe aiutare a identificare pattern disfunzionali nella regolazione degli obiettivi associati a specifiche condizioni psicopatologiche.

La forza principale di questo approccio risiede nella sua capacità di superare i limiti delle analisi statiche, cogliendo invece la natura processuale e temporale dei fenomeni psicologici. Non si limita a descrivere stati momentanei, ma cattura l'evoluzione dinamica del comportamento, offrendo così una rappresentazione più fedele dei reali processi mentali.


## Estensioni del modello

Il Sample-Level Model è solo il primo passo. Nel resto dell’articolo di @knight2023tutorial, vengono proposte estensioni importanti, tra cui:

1. *Modello a livello individuale*: si stima un $\alpha$ e un $\beta$ per ogni partecipante;
2. *Modello gerarchico (multilevel)*: i parametri individuali sono estratti da una distribuzione comune (es. una distribuzione normale);
3. *Modello per gruppi noti*: si confrontano i parametri tra condizioni sperimentali (es. gruppo "approach" vs. gruppo "avoidance");
4. *Modello a gruppi latenti (mixture model)*: si identificano sottogruppi nascosti di partecipanti che seguono dinamiche diverse.

Questi modelli non vengono presentati nel dettaglio nel nostro manuale, ma rappresentano il naturale sviluppo del modello base. Il lettore interessato potrà approfondirli nei materiali originali.

In sintesi, il Sample-Level Model mostra come una teoria psicologica — in questo caso, la regolazione degli obiettivi — possa essere *formalizzata in termini dinamici*, testata quantitativamente e utilizzata per fare inferenze. Questo approccio supera le semplici correlazioni: ci costringe a formulare **ipotesi esplicite sui meccanismi** e ci permette di valutare **quanto bene una teoria spiega davvero i dati**.

*Formulare modelli dinamici significa portare la psicologia più vicina alla sua ambizione scientifica: capire come cambiano i comportamenti, non solo se sono correlati.*


## Stima dei parametri con Stan

Abbiamo visto che un modello dinamico come il Sample-Level Model descrive *come* le persone modificano i loro obiettivi nel tempo, in funzione delle prestazioni passate. Ma per usare davvero questo modello nella ricerca psicologica, non basta formulare una teoria: dobbiamo anche *stimare i parametri* $\alpha$, $\beta$ e $\sigma$ (variabilità residua) a partire dai dati osservati.


### Dal modello teorico al modello statistico

La formulazione teorica:

$$
G_t = G_{t-1} + \alpha(P_{t-1} - G_{t-1}) + \beta
$$

diventa un modello statistico aggiungendo:

- una distribuzione di probabilità per i dati osservati (qui, normale);
- una verosimiglianza: il goal osservato è vicino a quello previsto;
- una strategia di stima, basata sull’inferenza bayesiana.


### Perché usare l’approccio bayesiano?  

I modelli dinamici sono spesso *ricorsivi*: una variabile al tempo *t* dipende dal suo valore a *t-1*. Questa complessità rende impossibile trovare una *soluzione analitica chiusa* per i parametri, poiché la relazione tra dati e parametri non è esprimibile con semplici equazioni.  


### Stan e MCMC  

Per approssimare la distribuzione a posteriori, usiamo tecniche *Markov Chain Monte Carlo (MCMC)*, che:  

1. partono da un’ipotesi iniziale sui parametri,  
2. generano piccole variazioni, valutandone la compatibilità con i dati,  
3. ripetono il processo migliaia di volte,  
4. restituiscono una *distribuzione di valori plausibili* per ogni parametro.  


### Il codice Stan

Di seguito, riportiamo il modello completo implementato in Stan. Analizzeremo poi ciascuna parte.

```stan
// MODELLO PER L'AGGIORNAMENTO DEGLI OBIETTIVI BASATO SULLA PERFORMANCE PRECEDENTE

// ---------------------------
// BLOCCO DEI DATI: COSA FORNIAMO AL MODELLO
// ---------------------------
data {
  int Ntotal;                      // Numero totale di osservazioni (es. 600 trial)
  real trial[Ntotal];              // Numero del trial (es. 1, 2, 3, ..., 600)
  real observed_goal[Ntotal];      // Obiettivo desiderato osservato in ciascun trial
  real performance[Ntotal];        // Prestazione osservata in ciascun trial
}

// ---------------------------
// PARAMETRI DEL MODELLO: COSA VOGLIAMO STIMARE
// ---------------------------
parameters {
  real alpha;                      // Quanto il partecipante adatta il proprio obiettivo (apprendimento)
  real beta;                       // Tendenza generale a incrementare l’obiettivo (motivazione costante)
  real<lower=0> sigma;             // Variazione casuale attorno al goal previsto (rumore)
}

// ---------------------------
// MODELLO: COME SI SPIEGANO I DATI
// ---------------------------
model {
  real predicted_goal;             // Variabile temporanea per salvare la previsione del goal

  // --- PRIORS: aspettative iniziali sui parametri ---
  alpha ~ normal(0, 1);            // Alpha: in media 0, con incertezza (deviazione standard = 1)
  beta ~ normal(0, 1);             // Beta: idem
  sigma ~ normal(0, 1);            // Sigma: deviazione standard del rumore (deve essere positiva)

  // --- CICLO PER OGNI TRIAL ---
  for (i in 1:Ntotal) {

    // Caso speciale: primo trial → nessuna previsione, usiamo direttamente il dato osservato
    if (trial[i] == 1) {
      predicted_goal = observed_goal[i];
    }

    // Tutti i trial successivi → aggiornamento del goal basato sulla performance precedente
    if (trial[i] > 1) {
      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;
      // ↑ Questa è la "regola di apprendimento":
      // - Se la performance precedente è migliore del goal → l’obiettivo aumenta
      // - Se la performance è peggiore → l’obiettivo diminuisce
      // - Quanto cambia? Dipende da alpha (quanto il partecipante si adatta)
      // - A ogni passo si aggiunge anche un piccolo incremento costante (beta)
    }

    // Likelihood: assumiamo che il goal osservato sia vicino al goal previsto, con un po’ di rumore
    observed_goal[i] ~ normal(predicted_goal, sigma);
  }
}

// ---------------------------
// BLOCCO PER GENERARE PREVISIONI (non necessario, ma utile per valutare il modello)
// ---------------------------
generated quantities {
  real predicted_goal;              // Valore previsto dal modello
  real sampled_goal[Ntotal];        // Goal "simulati", generati dal modello

  for (i in 1:Ntotal) {
    if (trial[i] == 1) {
      predicted_goal = observed_goal[i];
    }
    if (trial[i] > 1) {
      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;
    }

    // Simuliamo un nuovo goal come se fosse stato osservato, aggiungendo variabilità
    sampled_goal[i] = normal_rng(predicted_goal, sigma);
  }
}
```

Questo modello statistico descrive come le persone modificano i propri obiettivi in base alle prestazioni passate.


### Struttura del Codice Stan

Il modello è organizzato in blocchi logici.


#### 1. Blocco `data`: Input del Modello

```stan
data {
  int Ntotal;                      // Numero totale di trial
  real trial[Ntotal];              // Numero del trial (da 1 a 10)
  real observed_goal[Ntotal];      // Obiettivo riportato nel trial
  real performance[Ntotal];        // Prestazione osservata nel trial
}
```

Qui definiamo i dati in input:

- `Ntotal`: numero totale di osservazioni
- Array di lunghezza `Ntotal` per:
  - Numero progressivo del trial,
  - Obiettivo dichiarato,
  - Prestazione osservata.


#### 2. Blocco parameters: Parametri da Stimare

Questi sono i *parametri del modello*. Stan cercherà di stimare per ciascuno *una distribuzione a posteriori*, compatibile con i dati e con le informazioni a priori.


```stan
parameters {
  real alpha;                      // Tasso di apprendimento (0 = nessun adattamento)
  real beta;                       // Tendenza base ad aumentare l'obiettivo
  real<lower=0> sigma;             // Variabilità non spiegata (sempre positiva)
}
```

Cosa rappresentano:

- `alpha`: Quanto la persona si adatta alla prestazione passata,
  - Valore positivo: aumenta obiettivi dopo buone prestazioni,
  - Valore negativo: comportamento opposto,
- `beta`: Tendenza costante ad aumentare/diminuire gli obiettivi,
- `sigma`: Rumore nei dati non spiegato dal modello.


#### 3. Blocco model: Cuore del Modello

```stan
model {
  real predicted_goal;             // Obiettivo previsto dal modello

  // Distribuzioni a priori (conoscenza iniziale)
  alpha ~ normal(0, 1);           // Prior debolmente informativo
  beta ~ normal(0, 1);
  sigma ~ normal(0, 1);

  // Logica di aggiornamento trial-per-trial
  for (i in 1:Ntotal) {
    if (trial[i] == 1) {
      // Caso iniziale: usiamo il primo dato osservato
      predicted_goal = observed_goal[i];
    } else {
      // Regola di aggiornamento:
      predicted_goal += alpha * (performance[i-1] - predicted_goal) + beta;
    }
    
    // Verosimiglianza (come i dati si relazionano al modello)
    observed_goal[i] ~ normal(predicted_goal, sigma);
  }
}
```

Per chiarire il funzionamento del modello, esaminiamo il loop `for`. Un *loop `for`* (in italiano: "ciclo per") è un meccanismo che ripete un blocco di istruzioni più volte, una per ogni elemento di un insieme.

Nel nostro caso:

```stan
for(i in 1:Ntotal){
  // codice che si ripete per ogni trial
}
```

Questo significa: *"Ripeti il codice che segue per ogni trial, dal primo fino all’ultimo (cioè fino a `Ntotal`, che in questo dataset vale 600)."*

Vediamo riga per riga cosa succede *per ogni trial `i`* (cioè ogni riga dei dati):

Primo trial: inizializzazione.

```stan
if(trial[i]==1){
  predicted_goal = observed_goal[i];
}
```

Se è il *primo trial* della sequenza (`trial[i]==1`), allora il modello *non fa alcuna previsione*, ma prende direttamente il goal osservato. Questo serve per *iniziare il processo di previsione* dal secondo trial in poi.

Trial successivi: aggiornamento del goal.

```stan
if(trial[i]>1){
  predicted_goal += alpha*(performance[i-1] - predicted_goal) + beta;
}
```

Se siamo *oltre il primo trial*, il modello *aggiorna la previsione del goal* usando la seguente formula:

$$
\text{predicted_goal} = \text{predicted_goal} + \alpha \cdot (\text{performance precedente} - \text{predicted_goal}) + \beta
$$

Qui:

* `alpha` è quanto il partecipante *adatta il proprio obiettivo* sulla base della prestazione passata.
* `beta` è un *aggiustamento costante* (es., un incremento generale dell’ambizione).
* `performance[i-1]` è la prestazione *del trial precedente*.

In parole semplici: se la prestazione precedente è stata *migliore* del goal previsto, allora il nuovo obiettivo aumenta (e viceversa). L’intensità dell’aggiustamento dipende da `alpha`.

3. Valutazione del modello: confronto con i dati osservati.**

```stan
observed_goal[i] ~ normal(predicted_goal, sigma);
```

* Qui il modello *confronta la previsione (`predicted_goal`) con il goal osservato* effettivamente in quel trial.
* Lo fa *assumendo* che il goal osservato sia distribuito in modo normale (Gaussiano) attorno al goal previsto, con una certa variabilità (`sigma`).


#### 4. Blocco `generated quantities`: Simulazioni

Questo blocco viene eseguito *dopo* che il modello ha stimato i parametri ($\alpha$, $\beta$, $\sigma$).

* Prima, il modello trova le distribuzioni a posteriori di $\alpha$, $\beta$, $\sigma$ (basate sui dati osservati).
* Poi, utilizzando valori estratti a caso dalle distribuzioni a posteriori dei parametri del modello, genera nuove osservazioni (`sampled_goal`). 

**Quali valori di $\alpha$, $\beta$, $\sigma$ vengono usati?**

Il modello ha stimato una distribuzione a posteriori per ogni parametro. Quando viene eseguito `generated quantities`, viene estratto un valore casuale da queste distribuzioni posteriori e usato per generare `sampled_goal`. Quindi, per ogni iterazione del ciclo `for`, si usa un diverso set di valori ($\alpha$, $\beta$, $\sigma$).

**Come viene calcolato predicted_goal?**

Si usa la stessa logica del blocco model:

* Se `trial[i] == 1`, `predicted_goal = observed_goal[1]` (inizializzazione).
* Se `trial[i] > 1`, si aggiorna con:

  * `predicted_goal += alpha * (performance[i-1] - predicted_goal) + beta;`
  
Ma attenzione! Qui $\alpha$, $\beta$, $\sigma$ sono estratti dalla loro distribuzione a posteriori, non sono i valori "veri" (che non conosciamo).

**Come viene generato `sampled_goal[i]`?**

Una volta calcolato `predicted_goal`, si genera un nuovo dato casuale:

`sampled_goal[i] = normal_rng(predicted_goal, sigma);`

Anche in questo caso, `sigma` non è fisso ma, in ogni prova, viene estratto dalla sua distribuzione a posteriori.

**Ripetizione per molte iterazioni**

Questo processo viene ripetuto per migliaia di combinazioni di valori di $\alpha$, $\beta$, $\sigma$ estratti dalle loro distribuzioni a posteriori. Alla fine, avremo un insieme di valori  `sampled_goal` che rappresentano la variabilità delle previsioni del modello.

**A cosa serve sampled_goal?**

* *Posterior Predictive Checks:* Confrontiamo sampled_goal con i dati osservati per vedere se il modello è realistico.
* *Simulazioni future:* Possiamo usare sampled_goal per prevedere come si comporterebbe un nuovo partecipante con lo stesso meccanismo di apprendimento.


**Riassunto finale**
| **Concetto**               | **Spiegazione**                                                                 |
|----------------------------|---------------------------------------------------------------------------------|
| `alpha`, `beta`, `sigma`   | Sono estratti dalla loro distribuzione posteriore (non sono fissi).             |
| `predicted_goal`           | Calcolato con la stessa formula del modello, ma usando parametri casuali.       |
| `sampled_goal`             | Simulato da `normal_rng(predicted_goal, sigma)` (dove `sigma` è casuale).      |
| **Scopo**                  | Verificare se il modello può riprodurre dati simili a quelli osservati.         |


### Cosa otteniamo alla fine?

Dopo l’esecuzione del modello, Stan restituisce:

* campioni dalla distribuzione a posteriori per $\alpha$, $\beta$ e $\sigma$,
* intervalli credibili (es. il 95% più probabile),
* indicatori diagnostici di convergenza (es. `Rhat` e `n_eff`).

Possiamo così rispondere a domande del tipo:

* *Quanto si adattano mediamente i partecipanti alla prestazione?* → si esamina $\alpha$.
* *Tendono ad alzare gli obiettivi nel tempo?* → si esamina $\beta$.
* *Quanto è rumoroso il processo?* → si esamina $\sigma$.


### In sintesi

Questo esempio mostra come:

* Una teoria psicologica può essere formalizzata dinamicamente;
* Il modello può essere tradotto in codice;
* L’approccio bayesiano consente di stimare i parametri anche in presenza di strutture ricorsive;
* Stan offre un modo potente per confrontare teoria e dati.

L’uso di modelli dinamici porta la psicologia più vicina alla sua ambizione scientifica: comprendere come cambiano i comportamenti nel tempo, non solo se sono correlati.


**Riflessioni conclusive**

Il modello *sample-level* presentato in questo capitolo rappresenta un primo passo concreto nella direzione di una psicologia più formale, dinamica e orientata alla spiegazione dei processi nel tempo. Piuttosto che limitarsi a rilevare *se* due variabili sono associate, il modello cerca di descrivere *come* un comportamento evolve, e *quali meccanismi* ne guidano il cambiamento.

Questa impostazione riflette un cambiamento importante nella metodologia della ricerca psicologica. Come sottolineano @knight2023tutorial, un obiettivo fondamentale della scienza del comportamento non dovrebbe essere soltanto la previsione statistica, ma la *costruzione e validazione di teorie esplicative formalizzate*. Questo richiede:

* *specificare un modello generativo*, cioè un insieme di regole che descrivano *come* si generano i dati osservati nel tempo;
* *tradurre la teoria in un modello statistico*, stimabile dai dati e capace di produrre previsioni;
* *valutare la bontà del modello*, confrontando i dati osservati con quelli simulati (*posterior predictive checks*), e considerando anche modelli alternativi.

In questa prospettiva, modelli come quello discusso qui non vanno intesi come descrizioni perfette della realtà, ma come *strumenti espliciti, testabili e migliorabili*. Anche modelli semplici possono essere estremamente utili, se sono ben fondati teoricamente e capaci di generare previsioni empiricamente verificabili.

@knight2023tutorial propongono infatti una gerarchia di modelli, che va da versioni semplici (come il sample-level) a versioni più sofisticate (con parametri individuali, strutture gerarchiche, gruppi latenti). Ogni estensione permette di rispondere a nuove domande di ricerca, mantenendo però lo stesso *cuore dinamico* del modello.

Dal punto di vista didattico, questo esempio mostra chiaramente che:

* le teorie psicologiche possono essere *tradotte in formule*;
* queste formule possono essere *simulate* e *testate* sui dati reali;
* le ipotesi teoriche possono essere *messe in discussione* in modo quantitativo, attraverso il confronto tra modelli.

Questo è il tipo di psicologia che intendiamo promuovere con questo manuale: una psicologia che non si accontenta di correlazioni descrittive, ma si sforza di *capire e modellare i processi* che producono i dati osservati.

> In breve, imparare a costruire modelli dinamici significa imparare a pensare in termini di *processi generativi*, e questo è un passo decisivo verso una scienza psicologica più solida, trasparente e cumulativa.


