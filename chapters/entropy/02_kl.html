<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>42&nbsp; La divergenza di Kullback-Leibler – Psicometria</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/entropy/03_model_comparison.html" rel="next">
<link href="../../chapters/entropy/01_entropy.html" rel="prev">
<link href="../../style/gauss.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-0a72236910a44089af39cd28873f322e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-9908c7b05874059c2106d454ac00f1d0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-QT5S3P9D31"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-QT5S3P9D31', { 'anonymize_ip': true});
</script><style>html{ scroll-behavior: smooth; }</style>
<script>
window.MathJax = {
  tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
  svg: { scale: 1, mtextInheritFont: true, fontCache: 'none', minScale: 1 },
  options: { renderActions: { addMenu: [0, '', ''] } },
  loader: { load: ['input/tex','output/svg'] }
};
</script><script>
window.MathJax = {
  tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
  svg: { scale: 1, mtextInheritFont: true, fontCache: 'none', minScale: 1 },
  options: { renderActions: { addMenu: [0, '', ''] } },
  loader: { load: ['input/tex','output/svg'] }
};
// Suggerimento CSS: vedi sezione 3 per gli spazi attorno a display math
</script><script>
window.MathJax = {
  tex: {
    packages: {'[+]': ['boldsymbol']},
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: { fontCache: 'global' }
};
</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="../../style/_typography-extras.css">
<link rel="stylesheet" href="../../style/_code-extras.css">
<link rel="stylesheet" href="../../style/_math-extras.css">
<link rel="stylesheet" href="../../style/styles.css">
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/entropy/introduction_sec.html">Entropia</a></li><li class="breadcrumb-item"><a href="../../chapters/entropy/02_kl.html"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Psicometria</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/psicometria-r/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalità lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni generali</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Inferenza</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/introduction_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione alla sezione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/01_bayes_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Inferenza bayesiana</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/02_uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Abbracciare l’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/03_uncertainty_quantification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">La quantificazione dell’incertezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/04_statistical_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Modelli statistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/05_subj_prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Aggiornare le credenze su un parametro: dal prior alla posterior</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/06_conjugate_families.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/07_summary_posterior.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/08_balance_prior_post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">L’influenza della distribuzione a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/09_prior_pred_check.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Controllo predittivo a priori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/10_post_pred_distr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Distribuzione predittiva a posteriori</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/bayesian_inference/conclusions_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riflessioni conclusive della sezione</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">MCMC</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/introduction_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione alla sezione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/01_metropolis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">L’algoritmo di Metropolis-Hastings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/02_ppl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Linguaggi di programmazione probabilistici</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/03_stan_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduzione pratica a Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/04_stan_diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/05_mcmc_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Controlli predittivi bayesiani (a priori e a posteriori) con <code>cmdstanr</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/06_stan_odds_ratio_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Analisi bayesiana dell’odds ratio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/07_stan_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Confrontare due medie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/08_stan_poisson_model_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Modello di Poisson</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/09_stan_gaussian_mixture.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Modelli Mistura Gaussiani</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/10_stan_nuisance_parameters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Modelli con più di un parametro</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/11_stan_hier_beta_binom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Modello gerarchico beta-binomiale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/12_stan_parametrization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Parametrizzazioni centered e non-centered</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/13_bayesian_workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Flusso di lavoro bayesiano</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/mcmc/conclusions_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riflessioni conclusive sulla sezione</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Regressione</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/introduction_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione alla sezione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/01_reglin_frequentist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">La regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/02_regr_toward_mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">La regressione verso la media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/03_reglin_bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Modello bayesiano di regressione lineare bivariata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/04_synt_sugar_sea_ice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Zucchero sintattico</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/05_stan_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Regressione lineare in Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/06_specification_error.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Errore di specificazione e bias da variabile omessa</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/07_one_mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Inferenza bayesiana su una media</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/08_two_means.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Confronto tra le medie di due gruppi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/09_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto: valutare la rilevanza pratica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/10_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Pianificazione della dimensione campionaria</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/11_anova_1via.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">ANOVA ad una via</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/linear_models/conclusions_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riflessioni conclusive della sezione</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">GLM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/introduction_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione alla sezione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/01_logistic_regr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Regressione logistica con Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/02_one_proportion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Inferenza sulle proporzioni</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/03_two_proportions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Confronto tra due proporzioni con la regressione logistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/04_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Modello di Poisson</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/05_logistic_process.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Dal GLM a un modello processuale per dati binari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/06_missing_values.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Dati mancanti in psicologia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/glm/conclusions_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riflessioni conclusive sulla sezione</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Entropia</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/introduction_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione alla sezione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/01_entropy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Entropia e informazione di Shannon</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/02_kl.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/03_model_comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Valutare i modelli bayesiani</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/entropy/conclusions_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riflessioni conclusive della sezione</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Modelli</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/formal_models/introduction_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione alla sezione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/formal_models/01_dynamic_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Il modello di revisione degli obiettivi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/formal_models/02_dynamic_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Estensioni</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/formal_models/03_rescorla_wagner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Il modello di Rescorla–Wagner</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/formal_models/04_study_method.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Decisione ottimale e utilità attesa: l’approccio bayesiano</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/formal_models/conclusions_sec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riflessioni conclusive della sezione</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Crisi</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/introduction_replication_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/01_crisis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">La crisi della replicazione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/02_limits_stat_freq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Limiti dell’inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/03_effect_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">La grandezza dell’effetto</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/04_s_m_errors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Errori di segno e errori di grandezza</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/05_p_values.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">La fragilità del <em>p</em>-valore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/06_changes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Riforma</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/07_degrees_of_freedom.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">I gradi di libertà del ricercatore</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/replication_crisis/08_integrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Integrità della ricerca</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Epilogo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/epiloque/epiloque.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Considerazioni Conclusive</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01_shell.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">La Shell</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a01a_files.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Cartelle e documenti</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a02_math_symbols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Simbologia di base</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a03_latex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Equazioni Matematiche in LaTeX</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a11_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Numeri e intervalli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a12_sum_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Sommatorie</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a13_sets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Insiemi</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a14_combinatorics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Calcolo combinatorio</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a15_calculus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Per liberarvi dai terrori preliminari</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a35_other_conjugate_families.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">J</span>&nbsp; <span class="chapter-title">Altre famiglie coniugate</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a36_gamma_poisson_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">K</span>&nbsp; <span class="chapter-title">Modello coniugato Gamma-Poisson</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a40_metropolis_normal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">L</span>&nbsp; <span class="chapter-title">Metropolis: esempio Normale–Normale</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a41_cmdstanr_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">M</span>&nbsp; <span class="chapter-title">Implementazione di modelli Bayesiani con Stan tramite <code>cmdstanr</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a47_first_order_markov.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">N</span>&nbsp; <span class="chapter-title">Catene di Markov</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a50_lin_fun.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">O</span>&nbsp; <span class="chapter-title">La funzione lineare</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendix/a71_install_cmdstan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">P</span>&nbsp; <span class="chapter-title">Come installare CmdStan</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul class="collapse">
<li><a href="#la-generalizzabilit%C3%A0-dei-modelli-e-il-metodo-scientifico" id="toc-la-generalizzabilità-dei-modelli-e-il-metodo-scientifico" class="nav-link active" data-scroll-target="#la-generalizzabilit%C3%A0-dei-modelli-e-il-metodo-scientifico"><span class="header-section-number">42.1</span> La generalizzabilità dei modelli e il metodo scientifico</a></li>
  <li><a href="#lentropia-relativa" id="toc-lentropia-relativa" class="nav-link" data-scroll-target="#lentropia-relativa"><span class="header-section-number">42.2</span> L’entropia relativa</a></li>
  <li><a href="#uso-della-divergenza-d_textkl-nella-selezione-di-modelli" id="toc-uso-della-divergenza-d_textkl-nella-selezione-di-modelli" class="nav-link" data-scroll-target="#uso-della-divergenza-d_textkl-nella-selezione-di-modelli"><span class="header-section-number">42.3</span> Uso della divergenza <span class="math inline">\(D_{\text{KL}}\)</span> nella selezione di modelli</a></li>
  </ul><div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/entropy/02_kl.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/entropy/introduction_sec.html">Entropia</a></li><li class="breadcrumb-item"><a href="../../chapters/entropy/02_kl.html"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-kullback-leibler-divergence" class="quarto-section-identifier"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><section id="introduzione" class="level2 unnumbered unlisted"><h2 class="unnumbered unlisted anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>Nel capitolo precedente abbiamo introdotto l’<em>entropia</em> come misura dell’incertezza di una distribuzione di probabilità. Ora facciamo un passo avanti: invece di misurare l’incertezza <em>di una sola distribuzione</em>, vogliamo misurare <em>quanto una distribuzione differisce da un’altra</em>. Uno strumento cruciale per rispondere a questa domanda è la divergenza di Kullback-Leibler <span class="citation" data-cites="kullback1951information">(<a href="#ref-kullback1951information" role="doc-biblioref">Kullback &amp; Leibler, 1951</a>)</span>, spesso abbreviata come divergenza KL (<span class="math inline">\(D_{\text{KL}}\)</span>). Essa misura quanto si perde in precisione o efficienza se si utilizza un modello errato per descrivere la realtà.</p>
<section id="panoramica-del-capitolo" class="level3 unnumbered unlisted"><h3 class="unnumbered unlisted anchored" data-anchor-id="panoramica-del-capitolo">Panoramica del capitolo</h3>
<ul>
<li>Cos’è la divergenza KL e da dove nasce.</li>
<li>Come si collega al concetto di entropia.</li>
<li>Perché è utile nella scelta tra modelli statistici.</li>
<li>Come calcolarla e interpretarla, anche con esempi in R.</li>
</ul>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Prerequisiti">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prerequisiti
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Per comprendere appieno questo capitolo, dovresti aver già appreso i concetti di <em>entropia e informazione di Shannon</em> (<a href="01_entropy.html" class="quarto-xref"><span>Capitolo 41</span></a>).</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon callout-titled" title="Preparazione del Notebook">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preparazione del Notebook
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org/reference/here.html">here</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"_common.R"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Funzione per il calcolo dei termini della divergenza KL</span></span>
<span><span class="va">kl_terms</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span>, <span class="va">q</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html">stopifnot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">==</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">q</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">non_zero</span> <span class="op">&lt;-</span> <span class="va">p</span> <span class="op">&gt;</span> <span class="fl">0</span> <span class="op">&amp;</span> <span class="va">q</span> <span class="op">&gt;</span> <span class="fl">0</span></span>
<span>  <span class="va">p</span> <span class="op">&lt;-</span> <span class="va">p</span><span class="op">[</span><span class="va">non_zero</span><span class="op">]</span></span>
<span>  <span class="va">q</span> <span class="op">&lt;-</span> <span class="va">q</span><span class="op">[</span><span class="va">non_zero</span><span class="op">]</span></span>
<span>  <span class="va">term</span> <span class="op">&lt;-</span> <span class="va">p</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log2</a></span><span class="op">(</span><span class="va">p</span> <span class="op">/</span> <span class="va">q</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_along</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span>, p <span class="op">=</span> <span class="va">p</span>, q <span class="op">=</span> <span class="va">q</span>, term <span class="op">=</span> <span class="va">term</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Funzione compatta per il valore totale</span></span>
<span><span class="va">kl_divergence</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span>, <span class="va">q</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu">kl_terms</span><span class="op">(</span><span class="va">p</span>, <span class="va">q</span><span class="op">)</span><span class="op">$</span><span class="va">term</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Entropia vera (in bit)</span></span>
<span><span class="va">entropy</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">p</span> <span class="op">&lt;-</span> <span class="va">p</span><span class="op">[</span><span class="va">p</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">]</span></span>
<span>  <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">p</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log2</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Entropia incrociata (in bit)</span></span>
<span><span class="va">cross_entropy</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span>, <span class="va">q</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">non_zero</span> <span class="op">&lt;-</span> <span class="va">p</span> <span class="op">&gt;</span> <span class="fl">0</span> <span class="op">&amp;</span> <span class="va">q</span> <span class="op">&gt;</span> <span class="fl">0</span></span>
<span>  <span class="va">p</span> <span class="op">&lt;-</span> <span class="va">p</span><span class="op">[</span><span class="va">non_zero</span><span class="op">]</span></span>
<span>  <span class="va">q</span> <span class="op">&lt;-</span> <span class="va">q</span><span class="op">[</span><span class="va">non_zero</span><span class="op">]</span></span>
<span>  <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">p</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log2</a></span><span class="op">(</span><span class="va">q</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section></section><section id="la-generalizzabilità-dei-modelli-e-il-metodo-scientifico" class="level2" data-number="42.1"><h2 data-number="42.1" class="anchored" data-anchor-id="la-generalizzabilità-dei-modelli-e-il-metodo-scientifico">
<span class="header-section-number">42.1</span> La generalizzabilità dei modelli e il metodo scientifico</h2>
<p>Uno degli obiettivi fondamentali della scienza è la <em>generalizzabilità</em>: un buon modello non deve spiegare solo i dati che abbiamo già, ma anche prevedere correttamente nuovi dati che potremmo raccogliere in futuro. Un modello troppo semplice rischia di <em>sotto-adattarsi</em> ai dati (<em>underfitting</em>), perdendo informazioni importanti; uno troppo complesso rischia di <em>sovra-adattarsi</em> (<em>overfitting</em>), confondendo il rumore casuale con segnali reali. Il problema della generalizzabilità è quindi centrale nel metodo scientifico: vogliamo modelli abbastanza flessibili da catturare i pattern reali, ma non così flessibili da adattarsi anche a variazioni casuali.</p>
<p>Nell’approccio bayesiano, come osserva <span class="citation" data-cites="McElreath_rethinking">McElreath (<a href="#ref-McElreath_rethinking" role="doc-biblioref">2020</a>)</span>, la scelta di un modello implica trovare un equilibrio tra due esigenze:</p>
<ol type="1">
<li>
<em>accuratezza predittiva</em> – il modello deve produrre previsioni affidabili sui dati futuri;</li>
<li>
<em>controllo della complessità</em> – il modello non deve introdurre più complessità di quanta ne richieda il fenomeno studiato.</li>
</ol>
<p>Questo principio è vicino a quello noto come <em>rasoio di Occam</em>: tra due modelli che spiegano altrettanto bene i dati, preferiamo quello più semplice. La differenza è che, in ambito bayesiano, questa preferenza non è solo una regola intuitiva, ma può essere formalizzata in termini quantitativi, misurando quanta “informazione in più” dobbiamo spendere quando il nostro modello si discosta dalla realtà. Questa misura è data dalla <em>divergenza di Kullback–Leibler</em>, che vedremo nel seguito.</p>
</section><section id="lentropia-relativa" class="level2" data-number="42.2"><h2 data-number="42.2" class="anchored" data-anchor-id="lentropia-relativa">
<span class="header-section-number">42.2</span> L’entropia relativa</h2>
<p>Nel <a href="01_entropy.html" class="quarto-xref"><span>Capitolo 41</span></a> abbiamo visto che l’<em>entropia</em> <span class="math inline">\(H(P)\)</span> misura la lunghezza media del codice più efficiente per descrivere una distribuzione di probabilità <span class="math inline">\(P\)</span>. Ora estendiamo il ragionamento al confronto tra due distribuzioni:</p>
<ul>
<li>
<span class="math inline">\(P\)</span> = distribuzione <em>vera</em> dei dati, cioè quella che genera realmente gli eventi;</li>
<li>
<span class="math inline">\(Q\)</span> = distribuzione <em>approssimata</em>, cioè quella fornita dal modello.</li>
</ul>
<p>La <em>divergenza di Kullback–Leibler</em>, <span class="math inline">\(D_{\text{KL}}(P \parallel Q)\)</span>, risponde alla seguente domanda:</p>
<blockquote class="blockquote">
<p>in media, quanta informazione in più dobbiamo spendere se usiamo <span class="math inline">\(Q\)</span> invece di <span class="math inline">\(P\)</span> per descrivere i dati?</p>
</blockquote>
<p>Dal punto di vista della codifica, questa quantità rappresenta l’aumento medio della lunghezza del codice quando si usa un modello impreciso.</p>
<section id="definizione-formale" class="level3" data-number="42.2.1"><h3 data-number="42.2.1" class="anchored" data-anchor-id="definizione-formale">
<span class="header-section-number">42.2.1</span> Definizione formale</h3>
<p>Per una variabile casuale discreta <span class="math inline">\(X\)</span>:</p>
<p><span id="eq-kl-div-def"><span class="math display">\[
D_{\text{KL}}(P \parallel Q) = \sum_x p(x) \log_2 \frac{p(x)}{q(x)}
\tag{42.1}\]</span></span></p>
<p>che può essere riscritta come:</p>
<p><span id="eq-kl-div-def2"><span class="math display">\[
D_{\text{KL}}(P \parallel Q) = \sum_x p(x) \left[ \log_2 p(x) - \log_2 q(x) \right].
\tag{42.2}\]</span></span></p>
<p>Questa forma mette in evidenza un’interpretazione intuitiva:</p>
<ul>
<li>
<span class="math inline">\(\log_2 p(x)\)</span> è l’<em>informazione</em> (in bit) associata all’esito <span class="math inline">\(x\)</span> secondo la distribuzione vera <span class="math inline">\(P\)</span>;</li>
<li>
<span class="math inline">\(\log_2 q(x)\)</span> è l’<em>informazione</em> associata allo stesso esito secondo il modello <span class="math inline">\(Q\)</span>;</li>
<li>la differenza <span class="math inline">\(\log_2 p(x) - \log_2 q(x)\)</span> indica, per quell’esito, quanto il modello <span class="math inline">\(Q\)</span> sottostima o sovrastima la sorpresa rispetto a <span class="math inline">\(P\)</span>;</li>
<li>moltiplicando per <span class="math inline">\(p(x)\)</span> e sommando su tutti gli esiti otteniamo <em>una media ponderata</em> (pesata in base a quanto l’esito è probabile nella realtà).</li>
</ul>
<p>In sintesi, <span class="math inline">\(D_{\text{KL}}(P \parallel Q)\)</span> è <em>la perdita media di efficienza</em> quando descriviamo la variabile <span class="math inline">\(X\)</span> con la distribuzione approssimata <span class="math inline">\(Q\)</span> invece che con la distribuzione vera <span class="math inline">\(P\)</span>.</p>
<p>Se <span class="math inline">\(P = Q\)</span> la divergenza è 0, perché non vi è alcuna perdita. Quanto più <span class="math inline">\(Q\)</span> si discosta da <span class="math inline">\(P\)</span>, tanto più grande sarà la divergenza, segnalando un “costo informativo” maggiore.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Esempio: Divergenza KL (1)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esempio: Divergenza KL (1)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Supponiamo che la variabile casuale <span class="math inline">\(X\)</span> possa assumere tre valori: A, B e C.</p>
<p>La <em>distribuzione vera</em> (<span class="math inline">\(P\)</span>) è:</p>
<table class="caption-top table">
<thead><tr class="header">
<th>x</th>
<th><span class="math inline">\(p(x)\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>0.5</td>
</tr>
<tr class="even">
<td>B</td>
<td>0.3</td>
</tr>
<tr class="odd">
<td>C</td>
<td>0.2</td>
</tr>
</tbody>
</table>
<p>Il <em>modello approssimante</em> (<span class="math inline">\(Q\)</span>) è:</p>
<table class="caption-top table">
<thead><tr class="header">
<th>x</th>
<th><span class="math inline">\(q(x)\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>0.4</td>
</tr>
<tr class="even">
<td>B</td>
<td>0.4</td>
</tr>
<tr class="odd">
<td>C</td>
<td>0.2</td>
</tr>
</tbody>
</table>
<p>Calcoliamo la divergenza KL:</p>
<p><span class="math display">\[
\begin{aligned}
D_{\text{KL}}(P \parallel Q) &amp;= 0.5 \log_2\!\left(\frac{0.5}{0.4}\right)
+ 0.3 \log_2\!\left(\frac{0.3}{0.4}\right)
+ 0.2 \log_2\!\left(\frac{0.2}{0.2}\right) \\[4pt]
&amp;= 0.5 \log_2(1.25) + 0.3 \log_2(0.75) + 0.2 \log_2(1) \\[4pt]
&amp;\approx 0.160 - 0.125 + 0 \\[4pt]
&amp;= 0.035 \ \text{bit}.
\end{aligned}
\]</span></p>
<p><strong>Interpretazione</strong></p>
<ul>
<li>Per <em>A</em>, il modello <span class="math inline">\(Q\)</span> sottostima la probabilità vera (0.4 invece di 0.5). Questo comporta un costo informativo positivo: il codice dovrà essere leggermente più lungo rispetto all’uso di <span class="math inline">\(P\)</span>.</li>
<li>Per <em>B</em>, il modello <span class="math inline">\(Q\)</span> sovrastima la probabilità vera (0.4 invece di 0.3). Qui il costo informativo è negativo, ma va pesato dal fatto che nella divergenza KL la somma è <em>pesata secondo <span class="math inline">\(P\)</span></em>, e dunque conta di più la stima errata sugli eventi più probabili.</li>
<li>Per <em>C</em>, il modello è perfetto (<span class="math inline">\(p(x) = q(x)\)</span>) e il contributo alla divergenza è nullo.</li>
</ul>
<p>Il risultato complessivo, <em>0.035 bit per evento</em>, è molto piccolo: significa che, in media, usando <span class="math inline">\(Q\)</span> al posto di <span class="math inline">\(P\)</span> spenderemmo appena 0.035 bit di informazione in più per descrivere ogni osservazione. Le due distribuzioni sono quindi molto simili, ma la divergenza KL rileva comunque la differenza residua.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Esempio: Divergenza KL (2)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esempio: Divergenza KL (2)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Supponiamo che la variabile casuale <span class="math inline">\(X\)</span> possa assumere tre valori: <code>x = 1, 2, 3</code>.</p>
<ul>
<li>
<strong>Distribuzione vera</strong> (<span class="math inline">\(P\)</span>): <span class="math inline">\([0.1, \ 0.6, \ 0.3]\)</span>
</li>
<li>
<strong>Distribuzione approssimata</strong> (<span class="math inline">\(Q\)</span>): <span class="math inline">\([0.2, \ 0.5, \ 0.3]\)</span>
</li>
</ul>
<p>Calcoliamo la divergenza KL secondo la formula <span class="quarto-unresolved-ref">?eq-kl-def</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Definizione delle distribuzioni</span></span>
<span><span class="va">P</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.6</span>, <span class="fl">0.3</span><span class="op">)</span>  <span class="co"># distribuzione vera</span></span>
<span><span class="va">Q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.3</span><span class="op">)</span>  <span class="co"># distribuzione approssimata</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calcolo dei contributi per ciascun esito</span></span>
<span><span class="va">df_kl_terms</span> <span class="op">&lt;-</span> <span class="fu">kl_terms</span><span class="op">(</span><span class="va">P</span>, <span class="va">Q</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">df_kl_terms</span><span class="op">)</span></span>
<span><span class="co">#&gt;   x   p   q   term</span></span>
<span><span class="co">#&gt; 1 1 0.1 0.2 -0.100</span></span>
<span><span class="co">#&gt; 2 2 0.6 0.5  0.158</span></span>
<span><span class="co">#&gt; 3 3 0.3 0.3  0.000</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Visualizzazione dei contributi</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">df_kl_terms</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">term</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_col</span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"steelblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_hline</span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, color <span class="op">=</span> <span class="st">"black"</span>, linewidth <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Valori possibili di X"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Contributo alla Divergenza KL"</span>,</span>
<span>    title <span class="op">=</span> <span class="st">"Contributo di ciascun esito alla Divergenza KL"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="02_kl_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p>Infine, sommiamo i contributi per ottenere la divergenza totale:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">KL_total</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">df_kl_terms</span><span class="op">$</span><span class="va">term</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Divergenza KL da P a Q: %.4f bit\n"</span>, <span class="va">KL_total</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Divergenza KL da P a Q: 0.0578 bit</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Interpretazione</strong></p>
<ul>
<li>
<strong>Esito 1</strong> (<span class="math inline">\(p=0.1\)</span>, <span class="math inline">\(q=0.2\)</span>) – Il modello <span class="math inline">\(Q\)</span> <em>sovrastima</em> un evento raro. Il contributo alla divergenza è negativo, ma l’impatto è ridotto perché l’evento è poco probabile nella realtà (<span class="math inline">\(p\)</span> piccolo).</li>
<li>
<strong>Esito 2</strong> (<span class="math inline">\(p=0.6\)</span>, <span class="math inline">\(q=0.5\)</span>) – Il modello <em>sottostima</em> l’evento più frequente. Poiché <span class="math inline">\(p\)</span> è alto, questa sottostima ha un peso maggiore nella media ponderata, generando il contributo positivo più grande.</li>
<li>
<strong>Esito 3</strong> (<span class="math inline">\(p=0.3\)</span>, <span class="math inline">\(q=0.3\)</span>) – Qui il modello è perfetto: <span class="math inline">\(p(x) = q(x)\)</span>, quindi il contributo alla divergenza è zero.</li>
</ul>
<p>Il valore complessivo di <span class="math inline">\(D_{\text{KL}}\)</span> è la somma di questi contributi: rappresenta la <em>perdita media di efficienza</em> (in bit per evento) quando si usa <span class="math inline">\(Q\)</span> al posto di <span class="math inline">\(P\)</span>.</p>
<p>In questo caso, il risultato indica che usare <span class="math inline">\(Q\)</span> comporta una leggera inefficienza: la codifica o le previsioni richiedono, in media, un po’ più informazione di quanto sarebbe necessario usando la distribuzione vera.</p>
</div>
</div>
</div>
</section><section id="legame-con-lentropia-e-lentropia-incrociata" class="level3" data-number="42.2.2"><h3 data-number="42.2.2" class="anchored" data-anchor-id="legame-con-lentropia-e-lentropia-incrociata">
<span class="header-section-number">42.2.2</span> Legame con l’entropia e l’entropia incrociata</h3>
<p>La divergenza di Kullback–Leibler può essere riscritta come differenza tra <em>entropia incrociata</em> e <em>entropia vera</em>:</p>
<p><span id="eq-kl-difference"><span class="math display">\[
D_{\text{KL}}(P \parallel Q) = H(P, Q) - H(P),
\tag{42.3}\]</span></span></p>
<p>dove:</p>
<ul>
<li>
<span class="math inline">\(H(P)\)</span> è l’entropia della distribuzione vera <span class="math inline">\(P\)</span> (incertezza media/lunghezza media del codice ottimale quando conosciamo la distribuzione corretta);</li>
<li>
<span class="math inline">\(H(P, Q)\)</span> è l’<em>entropia incrociata</em>, cioè l’incertezza media <em>se</em> codifichiamo dati generati da <span class="math inline">\(P\)</span> utilizzando un codice ottimizzato per <span class="math inline">\(Q\)</span>:</li>
</ul>
<p><span id="eq-cross-entropy"><span class="math display">\[
H(P, Q) = -\sum_x p(x)\log_2 q(x).
\tag{42.4}\]</span></span></p>
<p><strong>Intuizione.</strong> Con questa forma, <span class="math inline">\(D_{\text{KL}}\)</span> è la <em>sorpresa extra media</em> (o <em>costo informativo</em> in bit per evento) che paghiamo quando usiamo il modello approssimato <span class="math inline">\(Q\)</span> al posto della distribuzione vera <span class="math inline">\(P\)</span>. Poiché <span class="math inline">\(H(P)\)</span> non dipende dal modello, <em>minimizzare <span class="math inline">\(D_{\text{KL}}\)</span> equivale a minimizzare <span class="math inline">\(H(P,Q)\)</span></em>.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Perché serve per ELPD e LOO
</div>
</div>
<div class="callout-body-container callout-body">
<p>Criteri predittivi come <em>ELPD</em> e <em>LOO</em> stimano, in media, la stessa quantità di cui vogliamo minimizzare il valore: l’<em>entropia incrociata</em> <span class="math inline">\(H(P,Q)\)</span>. Per questo, massimizzare ELPD (o ridurre la perdita di log-verosimiglianza predittiva) è un modo pratico per <em>avvicinare <span class="math inline">\(Q\)</span> a <span class="math inline">\(P\)</span></em>, ossia per ridurre indirettamente <span class="math inline">\(D_{\text{KL}}(P\parallel Q)\)</span>.</p>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Esempio: Entropia incrociata (1)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esempio: Entropia incrociata (1)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Utilizziamo le funzioni definite sopra (<code>entropy()</code>, <code>cross_entropy()</code>, <code>kl_divergence()</code>) sullo stesso esempio discusso in precedenza:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Esempio: distribuzione vera P e modello Q</span></span>
<span><span class="va">P</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.6</span>, <span class="fl">0.3</span><span class="op">)</span></span>
<span><span class="va">Q</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.3</span><span class="op">)</span></span>
<span></span>
<span><span class="va">H_P</span>   <span class="op">&lt;-</span> <span class="fu">entropy</span><span class="op">(</span><span class="va">P</span><span class="op">)</span>           <span class="co"># H(P)</span></span>
<span><span class="va">H_PQ</span>  <span class="op">&lt;-</span> <span class="fu">cross_entropy</span><span class="op">(</span><span class="va">P</span>, <span class="va">Q</span><span class="op">)</span>  <span class="co"># H(P,Q)</span></span>
<span><span class="va">DKL</span>   <span class="op">&lt;-</span> <span class="fu">kl_divergence</span><span class="op">(</span><span class="va">P</span>, <span class="va">Q</span><span class="op">)</span>  <span class="co"># D_KL(P||Q)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"H(P)    = %.4f bit\n"</span>, <span class="va">H_P</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; H(P)    = 1.2955 bit</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"H(P,Q)  = %.4f bit\n"</span>, <span class="va">H_PQ</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; H(P,Q)  = 1.3533 bit</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"H(P,Q)-H(P) = %.4f bit (D_KL)\n"</span>, <span class="va">H_PQ</span> <span class="op">-</span> <span class="va">H_P</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; H(P,Q)-H(P) = 0.0578 bit (D_KL)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"D_KL(P||Q)  = %.4f bit (controllo)\n"</span>, <span class="va">DKL</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; D_KL(P||Q)  = 0.0578 bit (controllo)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Interpretazione</strong></p>
<ul>
<li>
<span class="math inline">\(H(P)\)</span> è il limite inferiore: la miglior compressione ottenibile conoscendo la verità (<span class="math inline">\(P\)</span>).<br>
</li>
<li>
<span class="math inline">\(H(P,Q)\)</span> è la compressione che otterremmo usando il modello (<span class="math inline">\(Q\)</span>).<br>
</li>
<li>La loro differenza è <em>esattamente</em> <span class="math inline">\(D_{\text{KL}}(P\parallel Q)\)</span>: la quantità di informazione “sprecata” in media per evento usando <span class="math inline">\(Q\)</span> al posto di <span class="math inline">\(P\)</span>.<br>
</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Esempio: Entropia incrociata (2)">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esempio: Entropia incrociata (2)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In due esempi successivi rendiamo <span class="math inline">\(Q\)</span> sempre più diverso da <span class="math inline">\(P\)</span> e osserviamo come cambiano <em>entropia incrociata</em> e <em>divergenza KL</em>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Distribuzione vera fissata</span></span>
<span><span class="va">P</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.6</span>, <span class="fl">0.3</span><span class="op">)</span></span>
<span><span class="va">H_P</span> <span class="op">&lt;-</span> <span class="fu">entropy</span><span class="op">(</span><span class="va">P</span><span class="op">)</span>  <span class="co"># costante rispetto al modello</span></span>
<span></span>
<span><span class="co"># Due modelli: uno moderatamente errato (Q1), uno molto errato (Q2)</span></span>
<span><span class="va">Q1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.35</span>, <span class="fl">0.30</span>, <span class="fl">0.35</span><span class="op">)</span></span>
<span><span class="va">Q2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.60</span>, <span class="fl">0.30</span>, <span class="fl">0.10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcolo di entropia incrociata e divergenza KL</span></span>
<span><span class="va">H_PQ1</span> <span class="op">&lt;-</span> <span class="fu">cross_entropy</span><span class="op">(</span><span class="va">P</span>, <span class="va">Q1</span><span class="op">)</span></span>
<span><span class="va">H_PQ2</span> <span class="op">&lt;-</span> <span class="fu">cross_entropy</span><span class="op">(</span><span class="va">P</span>, <span class="va">Q2</span><span class="op">)</span></span>
<span></span>
<span><span class="va">KL1</span> <span class="op">&lt;-</span> <span class="fu">kl_divergence</span><span class="op">(</span><span class="va">P</span>, <span class="va">Q1</span><span class="op">)</span></span>
<span><span class="va">KL2</span> <span class="op">&lt;-</span> <span class="fu">kl_divergence</span><span class="op">(</span><span class="va">P</span>, <span class="va">Q2</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"H(P)     = %.4f bit (fissa)\n"</span>, <span class="va">H_P</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; H(P)     = 1.2955 bit (fissa)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"H(P,Q1)  = %.4f bit   -&gt; D_KL(P||Q1) = %.4f bit\n"</span>, <span class="va">H_PQ1</span>, <span class="va">KL1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; H(P,Q1)  = 1.6480 bit   -&gt; D_KL(P||Q1) = 0.3525 bit</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"H(P,Q2)  = %.4f bit   -&gt; D_KL(P||Q2) = %.4f bit\n"</span>, <span class="va">H_PQ2</span>, <span class="va">KL2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; H(P,Q2)  = 2.1125 bit   -&gt; D_KL(P||Q2) = 0.8170 bit</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Interpretazione</strong></p>
<p>Poiché <span class="math inline">\(H(P)\)</span> non cambia, quando <span class="math inline">\(Q\)</span> si allontana da <span class="math inline">\(P\)</span> cresce <span class="math inline">\(H(P,Q)\)</span> e, di conseguenza, aumenta</p>
<p><span class="math display">\[
D_{\text{KL}}(P \parallel Q) = H(P, Q) - H(P) .
\]</span></p>
<ul>
<li>Q1: il modello redistribuisce massa probabilistica, sottostimando l’esito più probabile e sovrastimando gli altri. Gli errori sugli esiti che <span class="math inline">\(P\)</span> considera frequenti pesano di più nella media, aumentando <span class="math inline">\(H(P,Q1)\)</span> e quindi <span class="math inline">\(D_{\text{KL}}\)</span>.</li>
<li>Q2: l’errore è estremo: la probabilità più alta viene assegnata all’esito meno probabile secondo <span class="math inline">\(P\)</span>. I contributi positivi (sottostima degli esiti comuni) dominano, facendo crescere molto <span class="math inline">\(D_{\text{KL}}\)</span>.</li>
</ul>
<p>Questo esempio mostra che minimizzare <span class="math inline">\(H(P,Q)\)</span> (e quindi <span class="math inline">\(D_{\text{KL}}\)</span>) significa allineare il più possibile le probabilità del modello con quelle “vere”, soprattutto per gli esiti a cui <span class="math inline">\(P\)</span> assegna più massa.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Dimostrazione: dalla differenza di entropie alla formula della D-KL">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Dimostrazione: dalla differenza di entropie alla formula della D-KL
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Partiamo dalla definizione come differenza tra entropia incrociata ed entropia vera:</p>
<p><span class="math display">\[
D_{\text{KL}}(P \parallel Q) = H(P, Q) - H(P).
\]</span></p>
<p>Sostituendo: <span class="math display">\[
H(P,Q) = -\sum_x p(x) \log_2 q(x), \quad
H(P)   = -\sum_x p(x) \log_2 p(x),
\]</span></p>
<p>ottieni:</p>
<p><span class="math display">\[
D_{\text{KL}}(P \parallel Q) =
\left[ - \sum_x p(x) \log_2 q(x) \right]
- \left[ - \sum_x p(x) \log_2 p(x) \right].
\]</span></p>
<p>Eliminando i segni negativi:</p>
<p><span class="math display">\[
D_{\text{KL}}(P \parallel Q) =
\sum_x p(x) \log_2 p(x) - \sum_x p(x) \log_2 q(x).
\]</span></p>
<p>Raccogliendo in un’unica somma:</p>
<p><span class="math display">\[
D_{\text{KL}}(P \parallel Q) =
\sum_x p(x) \left[ \log_2 p(x) - \log_2 q(x) \right].
\]</span></p>
<p>Applicando la proprietà dei logaritmi:</p>
<p><span class="math display">\[
D_{\text{KL}}(P \parallel Q) =
\sum_x p(x) \log_2 \frac{p(x)}{q(x)}.
\]</span></p>
<p><strong>Interpretazione:</strong> questa è la forma esplicita più usata della <span class="math inline">\(D_{\text{KL}}\)</span>. Mostra chiaramente che si tratta di <em>una media ponderata secondo <span class="math inline">\(P\)</span></em> della differenza di informazione tra <span class="math inline">\(P\)</span> e <span class="math inline">\(Q\)</span> per ciascun esito <span class="math inline">\(x\)</span>.</p>
</div>
</div>
</div>
</section><section id="interpretazione-della-divergenza-kl" class="level3" data-number="42.2.3"><h3 data-number="42.2.3" class="anchored" data-anchor-id="interpretazione-della-divergenza-kl">
<span class="header-section-number">42.2.3</span> Interpretazione della divergenza KL</h3>
<p>La divergenza <span class="math inline">\(D_{\text{KL}}(P \parallel Q)\)</span> misura <em>l’inefficienza media</em> che si introduce quando si usa la distribuzione <span class="math inline">\(Q\)</span> per descrivere dati che in realtà seguono <span class="math inline">\(P\)</span>. In termini informativi, rappresenta il <em>costo aggiuntivo di sorpresa</em>: quanti bit in più, in media, servono per codificare gli eventi generati da <span class="math inline">\(P\)</span> se utilizziamo un codice ottimizzato per <span class="math inline">\(Q\)</span> invece che per <span class="math inline">\(P\)</span>.</p>
<p>Questa quantità:</p>
<ul>
<li>è <em>sempre non negativa</em>: il modello vero (<span class="math inline">\(P\)</span>) non può mai essere peggiore, in media, del modello approssimato (<span class="math inline">\(Q\)</span>);</li>
<li>è <em>asimmetrica</em>: <span class="math inline">\(D_{\text{KL}}(P \parallel Q) \neq D\_{\text{KL}}(Q \parallel P)\)</span>. L’ordine è importante: invertire <span class="math inline">\(P\)</span> e <span class="math inline">\(Q\)</span> cambia il significato della misura, perché cambia quale distribuzione stiamo trattando come “vera”.</li>
</ul>
<p>Per questo motivo, la divergenza KL non è una “distanza” in senso geometrico, ma <em>una misura direzionale di perdita di informazione</em> o di inefficienza di codifica.</p>
</section><section id="proprietà-fondamentali-della-divergenza-kl" class="level3" data-number="42.2.4"><h3 data-number="42.2.4" class="anchored" data-anchor-id="proprietà-fondamentali-della-divergenza-kl">
<span class="header-section-number">42.2.4</span> Proprietà fondamentali della divergenza KL</h3>
<ul>
<li><p><strong>Non-negatività:</strong> <span class="math inline">\(D_{\text{KL}}(P \parallel Q) \geq 0\)</span> per ogni coppia di distribuzioni <span class="math inline">\(P\)</span> e <span class="math inline">\(Q\)</span>. Il valore minimo (0) si ottiene se e solo se <span class="math inline">\(P = Q\)</span>.</p></li>
<li><p><strong>Asimmetria:</strong> <span class="math inline">\(D_{\text{KL}}(P \parallel Q) \neq D\_{\text{KL}}(Q \parallel P)\)</span> in generale. Non soddisfa quindi le proprietà di una distanza simmetrica.</p></li>
<li>
<p><strong>Unità di misura:</strong> dipende dalla base del logaritmo:</p>
<ul>
<li>base 2 → misura in <em>bit</em>;</li>
<li>base <span class="math inline">\(e\)</span> → misura in <em>nat</em> (unità naturale di informazione).</li>
</ul>
</li>
</ul></section></section><section id="uso-della-divergenza-d_textkl-nella-selezione-di-modelli" class="level2" data-number="42.3"><h2 data-number="42.3" class="anchored" data-anchor-id="uso-della-divergenza-d_textkl-nella-selezione-di-modelli">
<span class="header-section-number">42.3</span> Uso della divergenza <span class="math inline">\(D_{\text{KL}}\)</span> nella selezione di modelli</h2>
<p>In teoria, la selezione del modello consiste nello scegliere il modello <span class="math inline">\(Q\)</span> che <em>minimizza la divergenza dalla distribuzione vera</em> <span class="math inline">\(P\)</span>:</p>
<p><span class="math display">\[
\text{Modello ottimale} = \arg\min_Q D_{\text{KL}}(P \parallel Q).
\]</span></p>
<p>In altre parole, il modello ideale è quello che si avvicina di più a <span class="math inline">\(P\)</span> e quindi riduce al minimo la perdita media di informazione quando lo usiamo per descrivere i dati.</p>
<p><strong>Problema:</strong> nella pratica, <em><span class="math inline">\(P\)</span> è sconosciuta</em> — non possiamo osservare direttamente la distribuzione vera che ha generato i dati. Di conseguenza, non possiamo calcolare <span class="math inline">\(D_{\text{KL}}\)</span> in modo esatto.</p>
<section id="come-procedere-nella-pratica" class="level3" data-number="42.3.1"><h3 data-number="42.3.1" class="anchored" data-anchor-id="come-procedere-nella-pratica">
<span class="header-section-number">42.3.1</span> Come procedere nella pratica</h3>
<p>Anche se <span class="math inline">\(P\)</span> è ignota, possiamo comunque <em>confrontare</em> modelli in termini di divergenza KL sfruttando il legame con l’entropia incrociata <span class="math inline">\(H(P,Q)\)</span>. Infatti, ricordiamo che:</p>
<p><span class="math display">\[
D_{\text{KL}}(P \parallel Q) = H(P,Q) - H(P).
\]</span></p>
<p>L’entropia <span class="math inline">\(H(P)\)</span> non dipende dal modello <span class="math inline">\(Q\)</span>: è una <em>costante</em> rispetto al confronto tra modelli. Se prendiamo la differenza di divergenza KL tra due modelli <span class="math inline">\(Q_1\)</span> e <span class="math inline">\(Q_2\)</span>, questa costante si <em>annulla</em>:</p>
<p><span id="eq-div-kl-models-comparison"><span class="math display">\[
D_{\text{KL}}(P \parallel Q_1) - D_{\text{KL}}(P \parallel Q_2)
= H(P,Q_1) - H(P,Q_2).
\tag{42.5}\]</span></span></p>
<p>Quindi, <em>per confrontare modelli non serve conoscere <span class="math inline">\(H(P)\)</span></em>: basta confrontare le loro entropie incrociate <span class="math inline">\(H(P,Q)\)</span>, che dipendono solo da <span class="math inline">\(Q\)</span> e che possono essere <em>stimate dai dati</em>.</p>
<p>Nel prossimo capitolo vedremo due strumenti dell’approccio bayesiano che stimano proprio <span class="math inline">\(H(P,Q)\)</span> (o, più precisamente, il suo opposto <span class="math inline">\(-H(P,Q)\)</span>):</p>
<ul>
<li>
<strong>Leave-One-Out Cross-Validation (LOO-CV)</strong> – valuta quanto bene il modello predice dati non usati nella stima;</li>
<li>
<strong>Expected Log Predictive Density (ELPD)</strong> – fornisce la stima della qualità predittiva media del modello.</li>
</ul>
<p>Questi metodi permettono di confrontare modelli in termini di <em>differenza di divergenza KL</em>, avvicinandoci così alla scelta del modello che, tra quelli considerati, è più vicino alla distribuzione vera <span class="math inline">\(P\)</span>.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Esempio psicologico">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esempio psicologico
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Immaginiamo di voler prevedere il <em>punteggio di ansia settimanale</em> di uno studente.</p>
<ul>
<li>
<strong>Modello A</strong>: utilizza come predittore solo il punteggio di <em>coping</em> (capacità di fronteggiare lo stress).<br>
</li>
<li>
<strong>Modello B</strong>: utilizza <em>coping</em> + <em>supporto sociale</em>.</li>
</ul>
<p>Supponiamo che, valutando le loro prestazioni predittive, entrambi i modelli ottengano buoni risultati, ma il Modello B presenti una divergenza KL leggermente inferiore rispetto al Modello A.</p>
<p><strong>Interpretazione:</strong></p>
<ul>
<li>la divergenza KL più bassa del Modello B indica che, in media, le sue previsioni sono leggermente più vicine alla distribuzione “vera” dei dati (minore perdita di informazione);</li>
<li>tuttavia, se la differenza è piccola, potremmo preferire il Modello A per la sua <em>maggiore semplicità e interpretabilità</em>, applicando il <em>principio di parsimonia</em> (o <em>rasoio di Occam</em>).</li>
</ul>
<p>Questo esempio illustra che la selezione del modello non dipende solo dalla precisione predittiva, ma anche dal bilanciamento tra <em>accuratezza</em> e <em>complessità</em>.</p>
</div>
</div>
</div>
</section></section><section id="riflessioni-conclusive" class="level2 unnumbered unlisted"><h2 class="unnumbered unlisted anchored" data-anchor-id="riflessioni-conclusive">Riflessioni conclusive</h2>
<p>In questo capitolo abbiamo approfondito un concetto fondamentale della teoria dell’informazione: la <em>divergenza di Kullback–Leibler</em>. Nata in origine per valutare l’efficienza dei codici di trasmissione, la D-KL è oggi uno strumento essenziale anche nella statistica moderna, perché misura in modo preciso quanto una distribuzione di probabilità approssimata <span class="math inline">\(Q\)</span> (cioè un modello) si discosti dalla distribuzione vera <span class="math inline">\(P\)</span> che genera i dati.</p>
<p>Abbiamo visto che la D-KL può essere interpretata come:</p>
<ul>
<li>
<em>perdita media di informazione</em> quando si usa <span class="math inline">\(Q\)</span> invece di <span class="math inline">\(P\)</span>;</li>
<li>
<em>eccesso di sorpresa</em> o inefficienza di codifica introdotta da un modello imperfetto;</li>
<li>differenza tra <em>entropia incrociata</em> e <em>entropia vera</em>, il che rende possibile stimarla indirettamente.</li>
</ul>
<p>Questo legame con l’entropia incrociata è cruciale: sebbene <span class="math inline">\(P\)</span> non sia nota e la D-KL non possa essere calcolata in valore assoluto, possiamo confrontare modelli stimando le differenze di D-KL, perché la componente costante <span class="math inline">\(H(P)\)</span> si annulla nel confronto.</p>
<p>Nel prossimo capitolo ci concentreremo proprio su come effettuare questi confronti in pratica. Vedremo come strumenti come la <em>Leave-One-Out Cross-Validation (LOO-CV)</em> e l’<em>Expected Log Predictive Density (ELPD)</em> permettano di stimare la capacità predittiva dei modelli e di identificare quello che, tra le alternative considerate, è il più vicino alla distribuzione vera dei dati.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Sintesi finale
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>La divergenza KL quantifica la perdita media di informazione usando <span class="math inline">\(Q\)</span> al posto di <span class="math inline">\(P\)</span>.</li>
<li>Si può scrivere come <span class="math inline">\(\sum_x p(x) \log \frac{p(x)}{q(x)}\)</span> o come <span class="math inline">\(H(P,Q) - H(P)\)</span>.</li>
<li>È uno strumento chiave per valutare <em>quanto bene</em> un modello rappresenta la realtà.</li>
<li>In pratica, può essere confrontata tra modelli stimando <span class="math inline">\(H(P,Q)\)</span> con tecniche come <em>LOO-CV</em> ed <em>ELPD</em>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="Problemi">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problemi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Cosideriamo due distribuzioni di probabilità discrete, <span class="math inline">\(p\)</span> e <span class="math inline">\(q\)</span>:</li>
</ol>
<pre><code>p &lt;- c(0.2, 0.5, 0.3)
q &lt;- c(0.1, 0.2, 0.7)</code></pre>
<p>Si calcoli l’entropia di <span class="math inline">\(p\)</span>, l’entropia incrociata tra <span class="math inline">\(p\)</span> e <span class="math inline">\(q\)</span>, la divergenza di Kullback-Leibler da <span class="math inline">\(p\)</span> a <span class="math inline">\(q\)</span>.</p>
<p>Si consideri <code>q = c(0.2, 0.55, 0.25)</code> e si calcoli di nuovo a divergenza di Kullback-Leibler da <span class="math inline">\(p\)</span> a <span class="math inline">\(q\)</span>. Si confronti con il risultato precedente e si interpreti.</p>
<ol start="2" type="1">
<li>Sia <span class="math inline">\(p\)</span> una distribuzione binomiale di parametri <span class="math inline">\(\theta = 0.2\)</span> e <span class="math inline">\(n = 5\)</span>. Sia <span class="math inline">\(q_1\)</span> una approssimazione a <span class="math inline">\(p\)</span>: <code>q1 = c(0.46, 0.42, 0.10, 0.01, 0.01)</code>. Sia <span class="math inline">\(q_2\)</span> una distribuzione uniforme: <code>q2 &lt;- rep(0.2, 5)</code>. Si calcoli la divergenza <span class="math inline">\(\mathbb{KL}\)</span> di <span class="math inline">\(q_1\)</span> da <span class="math inline">\(p\)</span> e da <span class="math inline">\(q_2\)</span> da <span class="math inline">\(p\)</span> e si interpretino i risultati.</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Informazioni sull'ambiente di sviluppo">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Informazioni sull’ambiente di sviluppo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; R version 4.5.1 (2025-06-13)</span></span>
<span><span class="co">#&gt; Platform: aarch64-apple-darwin20</span></span>
<span><span class="co">#&gt; Running under: macOS Sequoia 15.6.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Matrix products: default</span></span>
<span><span class="co">#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co">#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; locale:</span></span>
<span><span class="co">#&gt; [1] C/UTF-8/C/C/C/C</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; time zone: Europe/Rome</span></span>
<span><span class="co">#&gt; tzcode source: internal</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attached base packages:</span></span>
<span><span class="co">#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; other attached packages:</span></span>
<span><span class="co">#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      </span></span>
<span><span class="co">#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     </span></span>
<span><span class="co">#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     </span></span>
<span><span class="co">#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         </span></span>
<span><span class="co">#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           </span></span>
<span><span class="co">#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        </span></span>
<span><span class="co">#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         </span></span>
<span><span class="co">#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            </span></span>
<span><span class="co">#&gt; [25] here_1.0.1           </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; loaded via a namespace (and not attached):</span></span>
<span><span class="co">#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         </span></span>
<span><span class="co">#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     </span></span>
<span><span class="co">#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   </span></span>
<span><span class="co">#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       </span></span>
<span><span class="co">#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          </span></span>
<span><span class="co">#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 </span></span>
<span><span class="co">#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       </span></span>
<span><span class="co">#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      </span></span>
<span><span class="co">#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           </span></span>
<span><span class="co">#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         </span></span>
<span><span class="co">#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         </span></span>
<span><span class="co">#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        </span></span>
<span><span class="co">#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       </span></span>
<span><span class="co">#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        </span></span>
<span><span class="co">#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          </span></span>
<span><span class="co">#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       </span></span>
<span><span class="co">#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    </span></span>
<span><span class="co">#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 </span></span>
<span><span class="co">#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         </span></span>
<span><span class="co">#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    </span></span>
<span><span class="co">#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      </span></span>
<span><span class="co">#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      </span></span>
<span><span class="co">#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     </span></span>
<span><span class="co">#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        </span></span>
<span><span class="co">#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            </span></span>
<span><span class="co">#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section><section id="bibliografia" class="level2 unnumbered unlisted"><h2 class="unnumbered unlisted anchored" data-anchor-id="bibliografia">Bibliografia</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-kullback1951information" class="csl-entry" role="listitem">
Kullback, S., &amp; Leibler, R. A. (1951). On information and sufficiency. <em>The Annals of Mathematical Statistics</em>, <em>22</em>(1), 79–86.
</div>
<div id="ref-McElreath_rethinking" class="csl-entry" role="listitem">
McElreath, R. (2020). <em>Statistical rethinking: <span>A</span> <span>Bayesian</span> course with examples in <span>R</span> and <span>Stan</span></em> (2nd Edition). CRC Press.
</div>
</div>
</section></main><!-- /main --><script>
document.body.classList.add('classic-book');
document.addEventListener('DOMContentLoaded', function() {
  const paragraphs = document.querySelectorAll('p');
  paragraphs.forEach(p => {
    if (p.textContent.length > 200) {
      p.style.hyphens = 'auto';
      p.style.hyphenateCharacter = '-';
    }
  });
  const headings = document.querySelectorAll('h1, h2, h3, h4, h5, h6');
  headings.forEach(h => {
    h.style.fontFeatureSettings = '"liga" 1, "dlig" 1, "smcp" 1';
  });
});
</script><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiato!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiato!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/psicometria-r\/intro\.html");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../chapters/entropy/01_entropy.html" class="pagination-link" aria-label="Entropia e informazione di Shannon">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Entropia e informazione di Shannon</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/entropy/03_model_comparison.html" class="pagination-link" aria-label="Valutare i modelli bayesiani">
        <span class="nav-page-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Valutare i modelli bayesiani</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Psicometria</strong> è una risorsa didattica creata per il corso di Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ccaudek/psicometria-r/blob/main/chapters/entropy/02_kl.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/psicometria-r/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>