[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Metodi bayesiani in psicologia",
    "section": "",
    "text": "Struttura del sito\nQuesto sito accompagna il manuale Metodi bayesiani in psicologia (UTET).\nÈ pensato come risorsa di approfondimento: raccoglie esempi aggiuntivi, materiali integrativi e discussioni che ampliano i capitoli del volume. L’obiettivo è offrire al lettore uno spazio di esplorazione pratica, con particolare attenzione alla riproducibilità e all’applicazione dei metodi presentati.\nIl sito è organizzato in percorsi che rispecchiano e arricchiscono i contenuti del manuale:\nOgni sezione è pensata per fornire continuità con il manuale, senza sovrapporsi ad esso, ma offrendo una prospettiva più applicativa e interattiva.",
    "crumbs": [
      "Struttura del sito"
    ]
  },
  {
    "objectID": "index.html#informazioni-generali",
    "href": "index.html#informazioni-generali",
    "title": "Psicometria",
    "section": "",
    "text": "Anno Accademico: 2024–2025\n\nCodice Insegnamento: B000286 (coorte L–Z)",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#percorso-di-apprendimento",
    "href": "index.html#percorso-di-apprendimento",
    "title": "Psicometria",
    "section": "Percorso di apprendimento",
    "text": "Percorso di apprendimento\nIl corso è strutturato in un flusso di lavoro progressivo che integra teoria e pratica:\n\nFondamenti — Misurazione in psicologia, tipi di dati, disegno della ricerca.\nAnalisi Esplorativa (EDA) — Pulizia, visualizzazione e descrizione dei dati per formulare ipotesi.\nProbabilità e Inferenza Bayesiana — Il linguaggio dell’incertezza: variabili casuali, distribuzioni, e il teorema di Bayes come fondamento dell’apprendimento dai dati.\nModellazione Statistica — Un percorso che dalla regressione lineare (frequenstista e bayesiana) si estende ai Modelli Lineari Generalizzati (regressione logistica e di Poisson) e culmina nell’introduzione dei Modelli Dinamici, per la descrizione e la previsione di fenomeni psicologici.\nWorkflow Bayesiano — Un approccio completo: dalla specificazione del modello all’inferenza a posteriori con MCMC, fino alla verifica e alla critica.\nConfronto e Validazione Predittiva — Valutare quale modello generalizza meglio su nuovi dati usando strumenti all’avanguardia come LOO-CV e ELPD.\n\nOgni capitolo è corredato di esempi completi e riproducibili in \\(\\mathsf{R}\\), con codice commentato e visualizzazioni.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#come-usare-questi-appunti",
    "href": "index.html#come-usare-questi-appunti",
    "title": "Psicometria",
    "section": "Come usare questi appunti",
    "text": "Come usare questi appunti\n\nStudia in modo attivo: Non limitarti a leggere. Copia, esegui e, soprattutto, modifica il codice per sperimentare direttamente l’effetto dei tuoi cambiamenti.\nSegui il flusso: Le sezioni sono pensate in sequenza per costruire competenze solide. Evita salti: le scorciatoie fanno perdere il quadro concettuale che rende interpretabili i risultati.\nInterpreta, non memorizzare: Il tuo obiettivo è capire la sostanza psicologica dei fenomeni, non memorizzare output. Applica questo principio a ogni fase, dall’EDA al confronto tra modelli. Quando confronti i modelli, chiediti perché differiscono: quali assunzioni cambiano? Quali meccanismi psicologici sono resi espliciti nei parametri? Comunica sempre l’incertezza e privilegia semplicità ed interpretabilità rispetto a piccoli guadagni predittivi poco robusti.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#strumenti-e-prerequisiti",
    "href": "index.html#strumenti-e-prerequisiti",
    "title": "Psicometria",
    "section": "Strumenti e prerequisiti",
    "text": "Strumenti e prerequisiti\nPer lavorare efficacemente con questo materiale, è necessario configurare il proprio ambiente di lavoro:\n\nSoftware: \\(\\mathsf{R}\\) (versione 4.5 o superiore) e RStudio (consigliato) o un altro IDE (es. VS Code).\nEcosistema Stan (cruciale): Per la modellazione bayesiana efficiente, installeremo CmdStan tramite il pacchetto cmdstanr. → Guida all’installazione di Stan\nPacchetti \\(\\mathsf{R}\\) principali: tidyverse (manipolazione e visualizzazione dei dati), brms (modellazione), cmdstanr (backend per Stan), loo (confronto di modelli).\nQuarto: Per generare report riproducibili.\nPrerequisiti concettuali: È sufficiente una conoscenza di base dell’algebra e della statistica descrittiva. I concetti di probabilità necessari saranno richiamati e approfonditi nel corso.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#licenza-duso",
    "href": "index.html#licenza-duso",
    "title": "Metodi bayesiani in psicologia",
    "section": "Licenza d’uso",
    "text": "Licenza d’uso\nMateriali rilasciati con licenza\nCC BY-NC-ND 4.0.\nÈ consentita la condivisione con attribuzione, solo per usi non commerciali e senza modifiche.",
    "crumbs": [
      "Struttura del sito"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nL’analisi dei dati rappresenta un insieme di pratiche fondamentali per estrarre significato, scoprire insight e guidare il processo decisionale sulla base delle evidenze. Ma come possiamo rendere l’analisi dei dati psicologici più affidabile e rigorosa? È sufficiente applicare algoritmi standard o seguire procedure predefinite? Oppure, ridurre l’analisi a un semplice insieme di “ricette” statistiche rischia di impoverire la nostra comprensione dei fenomeni psicologici (McElreath, 2020)?\nQueste domande ci invitano a riflettere sulla natura stessa della ricerca empirica in psicologia. Contrariamente a quanto suggerito dall’approccio frequentista del null hypothesis testing, l’analisi dei dati non è un processo meccanico e automatico. Considerarla tale contribuisce a uno dei problemi più urgenti della psicologia contemporanea: la crisi della replicabilità (Korbmacher et al., 2023).\nLa replicabilità costituisce un criterio epistemologico fondamentale nella ricerca psicologica, in quanto garantisce la validità delle inferenze scientifiche e la generalizzabilità dei risultati. L’incapacità di replicare i risultati empirici mina la robustezza delle teorie psicologiche, compromettendone la validità costruttiva ed esterna. Tale instabilità metodologica ha implicazioni sostanziali anche a livello applicativo: interventi clinici basati su evidenze non replicabili possono condurre a conclusioni erronee, mentre politiche educative e strategie organizzative fondate su risultati fragili rischiano di produrre effetti nulli o controproducenti (Funder et al., 2014; Ioannidis, 2019; Shrout & Rodgers, 2018; Tackett et al., 2019).\nIl paradigma frequentista può aver contribuito alla crisi della replicabilità attraverso la sua dipendenza da p-value soglia-dipendenti e la tendenza a favorire risultati statisticamente significativi ma potenzialmente spurii. Parallelamente, gli incentivi accademici—quali la pressione alla pubblicazione e la preferenza per risultati innovativi—hanno sistematicamente incentivato pratiche di ricerca discutibili, tra cui il p-hacking e la selezione selettiva di risultati. Per contrastare queste criticità, è necessario adottare framework analitici alternativi che garantiscano maggiore trasparenza e robustezza metodologica.\nL’inferenza bayesiana rappresenta un approccio promettente, poiché consente una quantificazione diretta della probabilità delle ipotesi e una gestione più flessibile dell’incertezza (Gelman et al., 2013). Tuttavia, la sua adozione richiede più della mera sostituzione dei metodi frequentisti: implica l’integrazione di tecniche avanzate—come la modellazione gerarchica bayesiana e l’identificazione di relazioni causali—con una rigorosa caratterizzazione dei processi generativi dei dati e delle assunzioni teoriche sottostanti (Oberauer & Lewandowsky, 2019; Wagenmakers et al., 2018; Yarkoni, 2022).\nIn questo testo, analizzeremo sistematicamente le limitazioni degli approcci tradizionali, esamineremo i fattori strutturali alla base della crisi di replicabilità e valuteremo l’efficacia di metodologie alternative nel migliorare l’affidabilità della ricerca psicologica. L’obiettivo è fornire un framework metodologico integrato, che combini rigore statistico, trasparenza analitica e coerenza teorica, orientando gli studenti verso pratiche di ricerca empiricamente e concettualmente più solide.",
    "crumbs": [
      "Introduzione"
    ]
  },
  {
    "objectID": "prefazione.html#bibliografia",
    "href": "prefazione.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Funder, D. C., Levine, J. M., Mackie, D. M., Morf, C. C., Sansone, C., Vazire, S., & West, S. G. (2014). Improving the dependability of research in personality and social psychology: Recommendations for research and educational practice. Personality and Social Psychology Review, 18(1), 3–12.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nIoannidis, J. P. (2019). What have we (not) learnt from millions of scientific papers with P values? The American Statistician, 73(sup1), 20–25.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nShrout, P. E., & Rodgers, J. L. (2018). Psychology, science, and knowledge construction: Broadening perspectives from the replication crisis. Annual Review of Psychology, 69(1), 487–510.\n\n\nTackett, J. L., Brandes, C. M., King, K. M., & Markon, K. E. (2019). Psychology’s replication crisis and clinical psychological science. Annual Review of Clinical Psychology, 15(1), 579–604.\n\n\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love, J., Selker, R., Gronau, Q. F., Šmı́ra, M., Epskamp, S., et al. (2018). Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications. Psychonomic Bulletin & Review, 25, 35–57.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_sec.html",
    "href": "chapters/bayesian_inference/introduction_sec.html",
    "title": "Introduzione alla sezione",
    "section": "",
    "text": "In questa sezione muoviamo i primi passi nell’inferenza bayesiana, con l’obiettivo di comprendere come si passi dalla descrizione dei dati alla formulazione di ipotesi e alla loro valutazione quantitativa. La domanda centrale è: come possiamo aggiornare in modo razionale le nostre convinzioni alla luce di nuove evidenze?\nPer rispondere, partiremo dal concetto di incertezza e dal ruolo che essa gioca nella scienza psicologica. Introdurremo quindi il teorema di Bayes come regola generale di aggiornamento, per mostrare come le ipotesi possano essere trattate in modo probabilistico. Vedremo che ogni analisi richiede tre ingredienti fondamentali: un modello statistico che descriva come i dati vengono generati, una distribuzione a priori che rifletta la nostra conoscenza (o ignoranza) prima di osservare i dati, e i dati stessi che permettono di costruire la distribuzione a posteriori.\nLungo il percorso, esploreremo concetti chiave come le famiglie coniugate, i riassunti della distribuzione a posteriori, il bilanciamento tra informazione a priori e dati, e l’importanza dei check predittivi (sia a priori sia a posteriori). Questi strumenti non sono meri dettagli tecnici: costituiscono la grammatica con cui si esprime il ragionamento bayesiano, e gettano le basi per affrontare in seguito modelli più complessi.",
    "crumbs": [
      "Inferenza",
      "Introduzione alla sezione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_bayes_inference.html",
    "href": "chapters/bayesian_inference/01_bayes_inference.html",
    "title": "1  Inferenza bayesiana",
    "section": "",
    "text": "Introduzione\nNel campo della psicologia, la valutazione dell’efficacia di un trattamento clinico rappresenta una sfida metodologica centrale. Immaginiamo, per esempio, di voler testare l’utilità di una nuova psicoterapia per la depressione. Come possiamo concludere, in modo credibile, che il trattamento funzioni? L’approccio tradizionale, di matrice frequentista, risponde a questa domanda confrontando le medie dei punteggi tra un gruppo sperimentale e un gruppo di controllo, producendo un p-value. Questo valore quantifica quanto sarebbe improbabile osservare una differenza così grande o più estrema se il trattamento non avesse alcun effetto. Tuttavia, tale procedura presenta limiti sostanziali, soprattutto quando applicata a fenomeni complessi e variabili come quelli psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_bayes_inference.html#introduzione",
    "href": "chapters/bayesian_inference/01_bayes_inference.html#introduzione",
    "title": "1  Inferenza bayesiana",
    "section": "",
    "text": "Preparazione del Notebook\n\n\n\n\n\n\n# Carica il file _common.R per impostazioni di pacchetti e opzioni\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\nlibrary(brms)\n\n\n\n\n\n1.0.1 Limiti dell’approccio frequentista nella ricerca applicata\nL’inferenza frequentista, pur ampiamente diffusa, non fornisce risposte alla domanda che davvero interessa chi fa ricerca: qual è la probabilità che il trattamento sia efficace, dati i risultati osservati? Il p-value non esprime questa probabilità, ma si riferisce alla possibilità di osservare i dati ottenuti assumendo che l’effetto non esista, ovvero sotto l’ipotesi nulla. È una misura indiretta e controfattuale, che spesso viene fraintesa.\nUn secondo limite importante è l’incapacità dell’approccio frequentista di integrare conoscenze pregresse. Ogni studio viene trattato come un evento isolato, ignorando le evidenze precedenti e le ipotesi teoriche consolidate. Inoltre, il confronto tra medie non permette di modellare i meccanismi psicologici sottostanti, come i processi di mediazione o moderazione, che sono invece centrali per comprendere il funzionamento degli interventi.\nVa considerato anche che la significatività statistica dipende fortemente dalla dimensione campionaria: un effetto piccolo può risultare “statisticamente significativo” in un campione molto ampio, e viceversa. Infine, la logica binaria “significativo/non significativo” imposta una dicotomia artificiosa su fenomeni che sono, per loro natura, continui e incerti. In psicologia, dove le sfumature e le differenze individuali sono cruciali, questa rigidità metodologica si rivela particolarmente problematica.\n\n1.0.2 L’approccio bayesiano: un’alternativa coerente e flessibile\nL’inferenza bayesiana propone un modo differente di pensare l’analisi dei dati: più naturale, flessibile e informativo. Si basa sull’idea che possiamo iniziare con una convinzione preliminare — rappresentata da una distribuzione a priori — e aggiornarla alla luce delle nuove osservazioni — attraverso la verosimiglianza — per ottenere una distribuzione a posteriori. Questo procedimento riflette il modo in cui ragioniamo quotidianamente. Per esempio, se ci svegliamo e vediamo il cielo coperto, possiamo stimare intuitivamente che c’è una probabilità del 70% che piova: un’inferenza soggettiva basata su esperienze pregresse, che può essere aggiornata osservando altri segnali, come il meteo sul telefono.\nApplicando questo approccio alla ricerca psicologica, possiamo non solo rispondere alla domanda se un trattamento funziona, ma anche formulare stime probabilistiche dirette sull’efficacia, integrare conoscenze precedenti e modellare i processi psicologici sottostanti. In questo contesto, il modello bayesiano consente una lettura più profonda dei dati, sia teoricamente che praticamente.\n\n1.0.3 Un esempio concreto: modellizzazione di un effetto di mediazione con un approccio bayesiano\nIn psicologia clinica, spesso si ipotizza che un intervento non agisca direttamente su un esito, ma attraverso un meccanismo intermedio. Questo è noto come effetto di mediazione.\nConsideriamo un’ipotesi di ricerca comune: una psicoterapia (variabile indipendente, \\(X\\)) non riduce i sintomi depressivi (variabile dipendente, \\(Y\\)) in modo diretto, ma agendo su una variabile mediatrice, come l’autoefficacia (mediatore, \\(M\\)).\nIl modello di mediazione può essere scomposto in tre percorsi:\n\n\nPercorso a: L’effetto del trattamento (\\(X\\)) sul mediatore (\\(M\\)). La psicoterapia aumenta l’autoefficacia?\n\nPercorso b: L’effetto del mediatore (\\(M\\)) sull’esito (\\(Y\\)), tenendo sotto controllo l’effetto del trattamento. Una maggiore autoefficacia riduce la depressione?\n\nPercorso c’ (c-primo): L’effetto diretto del trattamento (\\(X\\)) sull’esito (\\(Y\\)), al netto del mediatore.\n\nL’effetto indiretto (o mediato) è quantificato dal prodotto dei percorsi a e b (\\(a \\times b\\)). L’approccio bayesiano è particolarmente potente per stimare questo effetto, poiché ci permette di ottenere una distribuzione di probabilità completa per \\(a \\times b\\), invece di un singolo valore puntuale e un p-value.\nPer illustrare, simuliamo dei dati in R che rispecchino la nostra ipotesi.\n\nset.seed(42)\nn_per_group &lt;- 40\nn &lt;- n_per_group * 2\n\n# Gruppo 0: Controllo, Gruppo 1: Trattamento\ngroup &lt;- rep(c(0, 1), each = n_per_group)\n\n# Path 'a': Il trattamento aumenta l'autoefficacia di circa 8 punti.\n# Aggiungiamo un termine di errore con deviazione standard 5.\na_path &lt;- 8\nself_efficacy &lt;- rnorm(n, mean = 40 + a_path * group, sd = 5)\n\n# Path 'b': Ogni punto di autoefficacia riduce la depressione di 0.7 punti.\n# Path 'c'': Ipotizziamo un piccolo effetto diretto del trattamento (-1.5 punti).\n# Aggiungiamo un termine di errore con deviazione standard 4.\nb_path &lt;- -0.7\nc_prime_path &lt;- -1.5\ndepression &lt;- rnorm(n, mean = 30 + b_path * self_efficacy + c_prime_path * group, sd = 4)\n\n# Creazione del dataframe\ndati &lt;- tibble(\n  group = factor(group, labels = c(\"Controllo\", \"Psicoterapia\")),\n  self_efficacy,\n  depression\n)\n\nUn Primo Sguardo: Confronto tra le Medie\nUn’analisi preliminare può confrontare i livelli medi di depressione tra i due gruppi.\n\ndati %&gt;%\n  group_by(group) %&gt;%\n  summarise(\n    media_depressione = mean(depression),\n    sd_depressione = sd(depression)\n  )\n#&gt; # A tibble: 2 × 3\n#&gt;   group        media_depressione sd_depressione\n#&gt;   &lt;fct&gt;                    &lt;dbl&gt;          &lt;dbl&gt;\n#&gt; 1 Controllo                 2.33           5.31\n#&gt; 2 Psicoterapia             -6.41           4.49\n\nQuesto mostra un effetto complessivo (il gruppo “Psicoterapia” ha una media di depressione più bassa), ma non ci permette di capire come l’intervento funzioni, ovvero se l’effetto sia mediato dall’autoefficacia.\nCostruzione del modello di mediazione bayesiano\nPer stimare l’effetto indiretto, definiamo un sistema di due equazioni di regressione che corrispondono ai percorsi del nostro modello:\n\n\nModello per il mediatore (\\(M\\)): \\(self\\_efficacy \\sim \\mathcal{N}(\\alpha_M + a \\cdot group, \\sigma_M)\\)\n\n\nModello per l’esito (\\(Y\\)): \\(depression \\sim \\mathcal{N}(\\alpha_Y + c' \\cdot group + b \\cdot self\\_efficacy, \\sigma_Y)\\)\n\n\nUsiamo il pacchetto brms per fittare questi due modelli.\n\n# Modello 1: Stima del percorso 'a' (group -&gt; self_efficacy)\nfit1 &lt;- brm(\n  bf(self_efficacy ~ group),\n  data = dati,\n  family = gaussian(),\n  seed = 42,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n\n# Modello 2: Stima dei percorsi 'b' (self_efficacy -&gt; depression) e 'c'' (group -&gt; depression)\nfit2 &lt;- brm(\n  bf(depression ~ self_efficacy + group),\n  data = dati,\n  family = gaussian(),\n  seed = 42,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n\nStima e interpretazione dell’effetto indiretto\nOra combiniamo i risultati. Estraiamo i campioni dalla distribuzione a posteriori per il coefficiente del percorso a (b_groupPsicoterapia da fit1) e per il percorso b (b_self_efficacy da fit2). Il loro prodotto ci fornirà la distribuzione a posteriori dell’effetto indiretto (\\(a \\times b\\)).\n\n# Estrazione dei campioni dalle distribuzioni a posteriori\npost_fit1 &lt;- as_draws_df(fit1)\npost_fit2 &lt;- as_draws_df(fit2)\n\n# Calcolo della distribuzione a posteriori dell'effetto indiretto\nindirect_effect &lt;- post_fit1$b_groupPsicoterapia * post_fit2$b_self_efficacy\n\nAnalizziamo la distribuzione dell’effetto indiretto calcolandone la media e l’intervallo di credibilità al 95%.\n\n# Media a posteriori\nmean(indirect_effect)\n#&gt; [1] -5.3\n\n# Intervallo di Credibilità al 95%\nquantile(indirect_effect, probs = c(0.025, 0.975))\n#&gt;  2.5% 97.5% \n#&gt; -7.30 -3.46\n\nL’analisi bayesiana restituisce una stima media dell’effetto indiretto di circa -5.4 e un intervallo di credibilità al 95% che va da circa -7.7 a -3.4.\nInterpretazione clinica\nPoiché l’intervallo di credibilità non contiene lo zero, abbiamo una forte evidenza a favore di un effetto di mediazione. Possiamo comunicare il risultato in modo intuitivo e probabilistico:\n\n“C’è una probabilità del 95% che la riduzione media dei sintomi depressivi, attribuibile all’aumento di autoefficacia indotto dalla psicoterapia, sia compresa tra 3.4 e 7.7 punti sulla scala della depressione.”\n\nQuesta formulazione è più informativa di un semplice p-value. Non solo ci dice che l’effetto è “statisticamente significativo”, ma ne quantifica la magnitudine e la nostra incertezza su di essa, fornendo uno strumento molto più ricco per la valutazione clinica e la presa di decisioni. Invece di un p-value, otteniamo un intervallo di credibilità, ad esempio: “Con probabilità del 95%, l’intervento riduce la depressione attraverso l’autoefficacia di almeno 3.4 punti.” Questa formulazione è più intuitiva e direttamente utile per decisioni cliniche.\n\n1.0.4 Vantaggi principali dell’inferenza bayesiana\nL’approccio bayesiano presenta diversi vantaggi chiave: le assunzioni del modello sono esplicitate attraverso le distribuzioni a priori; la modellizzazione è flessibile e adattabile a processi psicologici complessi; le conclusioni si esprimono in termini probabilistici e non binari; l’approccio si adatta bene anche a campioni piccoli, grazie all’incorporazione di conoscenze pregresse.\n\n1.0.5 Applicazioni pratiche\nL’inferenza bayesiana non è una curiosità teorica: è ampiamente utilizzata in moltissimi contesti applicativi. Nei sistemi di raccomandazione (Netflix, Spotify), le preferenze degli utenti vengono aggiornate in tempo reale attraverso modelli bayesiani. Nei test A/B su larga scala (Google, Meta), il framework bayesiano consente di monitorare gli esperimenti in tempo reale, di interromperli precocemente se necessario, e di sfruttare esperienze passate per informare nuovi studi.\nIn medicina, l’approccio bayesiano è implicito nel modo in cui i medici interpretano i test diagnostici: combinano la prevalenza della malattia, la sensibilità e la specificità del test per stimare la probabilità che il paziente sia malato. Lo stesso accade nella finanza comportamentale, nella guida autonoma e nell’epidemiologia, come dimostrato durante la pandemia da COVID-19, dove i modelli bayesiani hanno permesso di stimare in tempo reale la diffusione del virus e l’efficacia delle misure di contenimento.\nAnche nella ricerca psicologica l’inferenza bayesiana offre strumenti preziosi: consente di aggregare evidenze da studi precedenti, modellare la variabilità individuale, personalizzare gli interventi in tempo reale e formulare inferenze utili per la pratica clinica. È uno strumento che rafforza il legame tra teoria, dati e decisione.\n\n1.0.6 Perché queste applicazioni funzionano?\nIl successo dei metodi bayesiani si fonda su tre caratteristiche fondamentali: la capacità di aggiornarsi continuamente con l’arrivo di nuovi dati, l’integrazione sistematica delle conoscenze pregresse, e una gestione sofisticata dell’incertezza, che non si riduce a un singolo valore ma si esprime come una distribuzione completa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_bayes_inference.html#oltre-la-differenza-tra-medie-inferenza-bayesiana-unidimensionale",
    "href": "chapters/bayesian_inference/01_bayes_inference.html#oltre-la-differenza-tra-medie-inferenza-bayesiana-unidimensionale",
    "title": "1  Inferenza bayesiana",
    "section": "\n1.1 Oltre la differenza tra medie: inferenza bayesiana unidimensionale",
    "text": "1.1 Oltre la differenza tra medie: inferenza bayesiana unidimensionale\nIn questa sezione esploreremo i fondamenti dell’inferenza bayesiana applicata alla stima di un singolo parametro scalare, una situazione molto frequente nella ricerca psicologica e nelle scienze sociali. Esempi tipici includono la stima della proporzione di pazienti che rispondono a un trattamento, della media di un punteggio di ansia in una popolazione, della frequenza di un evento raro, o della durata media di un episodio clinico.\nAnalizzeremo quattro modelli statistici fondamentali:\n\nil modello binomiale per la stima di proporzioni;\nil modello normale per la stima di medie di variabili continue;\nil modello di Poisson per il conteggio di eventi;\nil modello esponenziale per l’analisi del tempo tra eventi.\n\nPer ciascuno di questi modelli, approfondiremo il processo di aggiornamento bayesiano: come la verosimiglianza interagisce con la distribuzione a priori per produrre la distribuzione a posteriori. Presenteremo due metodi principali per ottenere quest’ultima: l’approssimazione numerica tramite griglia, adatta per problemi didattici e semplici, e l’impiego delle distribuzioni coniugate, che permettono soluzioni analitiche eleganti ed efficienti.\nDedicheremo particolare attenzione all’influenza delle scelte a priori, alla sintesi della distribuzione a posteriori attraverso medie, intervalli di credibilità e rappresentazioni grafiche, e al significato delle inferenze bayesiane in un contesto psicologico.\nNel quadro della crisi di replicabilità che ha colpito la psicologia, l’inferenza bayesiana si distingue come una risposta metodologica matura. Essa evita le decisioni arbitrarie basate su soglie di significatività e promuove un’interpretazione più sfumata, trasparente e cumulativa dei risultati empirici, aprendo la strada a una scienza psicologica più affidabile e teoricamente informata (Gelman et al., 2013; McElreath, 2020).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_bayes_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/01_bayes_inference.html#bibliografia",
    "title": "1  Inferenza bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_uncertainty.html",
    "href": "chapters/bayesian_inference/02_uncertainty.html",
    "title": "2  Abbracciare l’incertezza",
    "section": "",
    "text": "Introduzione\nNella ricerca psicologica, così come in tutte le scienze empiriche, i dati che raccogliamo non sono mai privi di incertezza. Ogni misura, ogni stima e ogni conclusione che traiamo si accompagnano a un margine di dubbio. Comprendere e gestire questa incertezza non è un dettaglio tecnico, ma una parte essenziale del lavoro scientifico.\nQuando chiediamo a un campione di studenti universitari di valutare il proprio livello di ansia su una scala da 1 a 5, non otteniamo una misura perfetta e definitiva del “vero” livello di ansia. Otteniamo invece una stima influenzata da molte fonti di variabilità: la situazione contingente (per esempio, se quel giorno c’era un esame imminente), le caratteristiche individuali, e l’inevitabile errore di misura.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_uncertainty.html#introduzione",
    "href": "chapters/bayesian_inference/02_uncertainty.html#introduzione",
    "title": "2  Abbracciare l’incertezza",
    "section": "",
    "text": "2.0.1 Perché parlare di incertezza?\nIl concetto di incertezza ci obbliga a distinguere tra ciò che osserviamo direttamente (i dati raccolti) e ciò che vogliamo inferire (le proprietà psicologiche latenti, come ansia, autostima, motivazione). In altre parole, l’incertezza è il ponte che collega i nostri dati grezzi alle conclusioni scientifiche. Ignorarla porta a una falsa sensazione di sicurezza; affrontarla in modo esplicito ci consente invece di fare affermazioni più oneste e più utili (Lindley, 2013).\nParlare di incertezza non significa arrendersi al relativismo. Significa piuttosto riconoscere che ogni conclusione scientifica deve essere accompagnata da una valutazione della sua affidabilità. La psicologia, che si confronta con fenomeni complessi e variabili, ha un bisogno particolare di metodi che rendano questa valutazione trasparente e rigorosa.\nPanoramica del capitolo\n\nLa psicologia si confronta sempre con variabilità e incertezza nei dati.\nAbbiamo distinto tre forme di incertezza: aleatoria, epistemica, ontologica.\nL’approccio bayesiano offre un modo intuitivo per rappresentare e aggiornare le nostre convinzioni.\nLe credenze iniziali orientano la ricerca, i dati le modificano, le decisioni ne sono il risultato.\nLa crisi di replicazione mostra l’importanza di trattare l’incertezza in modo esplicito e trasparente.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il primo capitolo di Understanding Uncertainty di Lindley (Lindley, 2013).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(HDInterval)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_uncertainty.html#variabilità-e-incertezza",
    "href": "chapters/bayesian_inference/02_uncertainty.html#variabilità-e-incertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "\n2.1 Variabilità e incertezza",
    "text": "2.1 Variabilità e incertezza\nQuando osserviamo un fenomeno psicologico, raramente troviamo valori identici tra i soggetti o persino nello stesso soggetto in momenti diversi. Questa variabilità è un fatto fondamentale della psicologia sperimentale: due studenti possono riportare livelli molto diversi di ansia prima di un esame, oppure lo stesso studente può mostrare oscillazioni da un giorno all’altro. La variabilità dei dati non è un ostacolo, ma un’informazione preziosa: ci dice che i processi psicologici non sono rigidi, bensì dinamici e influenzati da molteplici fattori.\nTuttavia, per passare dalla semplice descrizione (le misure raccolte) all’inferenza (conclusioni sui processi sottostanti) dobbiamo fare i conti con l’incertezza. L’incertezza non è altro che il riconoscimento formale del fatto che non possiamo mai conoscere con certezza assoluta i parametri psicologici reali (es. il “vero” livello di ansia di un individuo). Inoltre, i dati che raccogliamo sono solo una finestra parziale e rumorosa su questi parametri.\n\n\n\n\n\n\nEsempio\n\n\n\nImmaginiamo di stimare il punteggio medio di autostima in un campione di 50 studenti usando la Rosenberg Self-Esteem Scale. Il valore medio osservato (ad esempio, 28 punti) non è il “vero” livello medio della popolazione: è solo una stima, soggetta a oscillazioni dovute al caso. Se ripetessimo l’indagine con un altro campione di 50 studenti della stessa università, otterremmo quasi sicuramente un valore diverso (magari 27 o 29). Questa differenza riflette l’incertezza insita nel nostro processo di misurazione.\n\n\n\n2.1.1 Perché l’incertezza è cruciale in psicologia?\nIn discipline come la fisica, spesso si assume che i fenomeni abbiano leggi relativamente stabili. In psicologia, invece, i fenomeni sono complessi, soggetti a influenze contestuali, sociali e individuali. L’incertezza non è quindi un “rumore da eliminare”, ma un aspetto strutturale che dobbiamo modellare.\nNella ricerca psicologica, ignorare l’incertezza ha avuto conseguenze gravi: risultati poco replicabili, fiducia eccessiva nei valori “puntuali” delle stime, e difficoltà a distinguere effetti reali da fluttuazioni casuali. La crisi di replicazione in psicologia ci ricorda che non basta riportare un effetto medio; dobbiamo anche comunicare quanto siamo incerti su quell’effetto.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_uncertainty.html#fonti-di-incertezza",
    "href": "chapters/bayesian_inference/02_uncertainty.html#fonti-di-incertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "\n2.2 Fonti di incertezza",
    "text": "2.2 Fonti di incertezza\nL’incertezza rappresenta una componente ineliminabile della ricerca psicologica, la cui origine può essere ricondotta a diverse fonti. Una classificazione articolata di tali fonti non costituisce un mero esercizio teorico, ma offre un quadro concettuale essenziale per comprendere i limiti delle nostre conoscenze, la natura di ciò che rimane imprevedibile e i confini entro i quali operano i modelli scientifici. In particolare, è possibile distinguere tre forme fondamentali di incertezza.\n\n2.2.1 1. Incertezza aleatoria\nL’incertezza aleatoria scaturisce dall’intrinseca imprevedibilità di alcuni fenomeni psicologici. Anche disponendo di una conoscenza completa di tutti i fattori rilevanti, non sarebbe possibile determinare con esattezza l’esito di un singolo evento. Si tratta pertanto di un’incertezza irriducibile, che non può essere eliminata né attraverso il miglioramento degli strumenti di misura, né mediante l’acquisizione di ulteriori dati. Un esempio emblematico proviene dagli studi sull’apprendimento associativo: uno stesso soggetto, pur avendo interiorizzato una regola, può occasionalmente fornire una risposta incongrua a causa della natura non perfettamente deterministica dei processi cognitivi e attentivi.\n\n2.2.2 2. Incertezza epistemica\nL’incertezza epistemica trae origine, invece, dai limiti della nostra conoscenza empirica. Poiché è impossibile osservare l’intera popolazione di interesse o misurare costrutti psicologici in modo del tutto privo di errore, i ricercatori lavorano necessariamente con dati parziali, campioni limitati e strumenti di indagine imperfetti. A differenza dell’incertezza aleatoria, questa forma di incertezza può essere attenuata attraverso il disegno di studi più accurati, il reperimento di campioni più ampi e rappresentativi, o il raffinamento dei modelli statistici. Ad esempio, la stima del livello medio di ansia negli studenti in prossimità di un esame è inevitabilmente affetta da margine di errore; tale incertezza può tuttavia ridursi significativamente qualora venga considerato un campione più numeroso o meglio strutturato.\n\n2.2.3 3. Incertezza ontologica o modellistica\nL’incertezza ontologica, o modellistica, attiene all’adeguatezza del quadro teorico e metodologico adottato. Tutti i modelli scientifici sono, per loro natura, semplificazioni della realtà: nessuno di essi può catturare appieno la complessità del comportamento umano, delle sue determinanti e delle sue manifestazioni. Questa forma di incertezza non dipende dalla quantità dei dati raccolti, bensì dalla bontà della struttura concettuale attraverso cui i dati stessi vengono interpretati. Un esempio rilevante è l’utilizzo di un modello di regressione lineare per analizzare la relazione tra stress e rendimento accademico: sebbene utile, tale approccio trascura inevitabilmente l’influenza di variabili ulteriori—quali le dinamiche temporali, le interazioni sociali o i fattori culturali—che pure contribuiscono a definire il fenomeno indagato.\n\n\n\n\n\n\nSintesi\n\n\n\n\n\nAleatoria → variabilità intrinseca del fenomeno (non eliminabile).\n\nEpistemica → limiti della nostra conoscenza (riducibile con più dati e strumenti migliori).\n\nOntologica → limiti dei nostri modelli (nessun modello è “vero”, solo più o meno utile).\n\nQuesta distinzione ci aiuta a non confondere diversi tipi di incertezza e a non attribuire agli strumenti statistici poteri che non hanno. Nel resto del capitolo vedremo come questi concetti possano essere resi più precisi e operativi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_uncertainty.html#la-quantificazione-dellincertezza-nellapproccio-bayesiano",
    "href": "chapters/bayesian_inference/02_uncertainty.html#la-quantificazione-dellincertezza-nellapproccio-bayesiano",
    "title": "2  Abbracciare l’incertezza",
    "section": "\n2.3 La quantificazione dell’incertezza nell’approccio bayesiano",
    "text": "2.3 La quantificazione dell’incertezza nell’approccio bayesiano\nDopo aver esaminato le diverse nature dell’incertezza, sorge una questione metodologica cruciale: come è possibile rappresentarle in modo sistematico e formalmente rigoroso? L’approccio bayesiano fornisce una cornice concettuale e operativa particolarmente potente ed elegante per questo scopo, una cornice che verrà adottata in modo trasversale in questo volume.\nIl principio fondante di questo approccio è intuitivo nella sua essenza, ma profondo nelle sue implicazioni. Esso propone di abbandonare la tradizionale logica della stima puntuale unica—che ad esempio affermerebbe “il livello medio di ansia è 28”—a favore di una rappresentazione più ricca e informativa. Secondo la prospettiva bayesiana, la conoscenza su un parametro viene espressa attraverso un intero spettro di valori possibili, a ciascuno dei quali viene associato un specifico grado di plausibilità o credibilità.\nIn tal modo, l’inferenza statistica non si limita a indicare qual è il valore più probabile alla luce dei dati osservati, ma comunica esplicitamente anche il livello di incertezza che circonda quella conclusione. Questo passaggio da una stima singola a una distribuzione di probabilità ci consente di quantificare, visualizzare e quindi gestire in modo trasparente tutte le forme di incertezza—aleatoria, epistemica e modellistica—precedentemente discusse, integrandole organicamente all’interno del processo di analisi e interpretazione dei risultati.\n\n\n\n\n\n\nIntuizione\n\n\n\nPensiamo a un professore che, dopo il primo compito scritto, prova a immaginare come andrà l’esame finale di uno studente. Non può dare una previsione precisa: può solo dire che “probabilmente andrà così, ma potrebbe anche andare un po’ meglio o un po’ peggio”. Questa gamma di possibilità, con diverse gradazioni di plausibilità, è esattamente il modo in cui il pensiero bayesiano rappresenta l’incertezza.\n\n\n\n2.3.1 Dal punto di vista bayesiano\nL’approccio bayesiano alla statistica si fonda su un principio fondamentale: la conoscenza scientifica è intrinsecamente dinamica e si evolve attraverso un processo continuo di aggiornamento. Prima di raccogliere i dati, il ricercatore possiede inevitabilmente un insieme di aspettative iniziali, spesso derivate dalla letteratura preesistente, da teorie consolidate o dall’esperienza clinica. Tali aspettative—definite previsioni a priori—non costituiscono un bias da negare, bensì una posizione di partenza esplicita e formalizzabile. Ad esempio, un ricercatore potrebbe ritenere plausibile che il livello medio di ansia negli studenti si collochi intorno a un certo valore, pur ammettendo un margine di variazione. La raccolta dei dati consente quindi di aggiornare queste credenze iniziali, producendo una distribuzione a posteriori che sintetizza in modo coerente il precedente stato di conoscenza e l’evidenza empirica emergente. Il risultato di questo processo non è una stima puntuale e definitiva, bensì una rappresentazione probabilisticamente articolata e più informata della nostra incertezza.\n\n2.3.2 Perché è utile in psicologia?\nLa psicologia, in quanto disciplina che studia fenomeni multivariati, contestuali e spesso di difficile osservazione diretta, trae particolare vantaggio dall’adozione di un framework bayesiano. Questo approccio consente ai ricercatori di esprimere in modo trasparente sia le proprie ipotesi sia i propri dubbi, riconoscendo esplicitamente il ruolo della soggettività e dell’incertezza nel processo scientifico. Inoltre, offre un meccanismo formale per integrare—in modo coerente e riproducibile—informazioni provenienti da fonti eterogenee, quali risultati di studi precedenti, modelli teorici o conoscenze cliniche. Infine, la rappresentazione probabilistica dell’incertezza evita l’illusione di una precisione ingiustificata, sostituendo il ricorso a valori unici e apparentemente definitivi con intervalli di credibilità che comunicano in modo più onesto lo stato effettivo della conoscenza.\n\n2.3.3 Un esempio intuitivo: il lancio della moneta\nSi consideri l’esempio intuitivo del lancio di una moneta del quale ignoriamo l’effettivo bilanciamento. In assenza di informazioni, potremmo inizialmente ritenere plausibile che la moneta sia equilibrata, attribuendo approssimativamente la stessa probabilità agli esiti “testa” e “croce”. Tuttavia, dopo aver osservato una sequenza di dieci lanci—ad esempio, otto teste e due croci—è ragionevole rivedere questa convinzione iniziale, aggiornando le nostre credenze verso l’ipotesi che la moneta possa favorire l’uscita della testa. È importante notare che ciò che cambia non è la proprietà fisica della moneta, bensì il nostro stato di conoscenza riguardo ad essa. L’approccio bayesiano fornisce gli strumenti formali per quantificare esattamente questo tipo di aggiornamento delle credenze.\n\n2.3.4 Un esempio psicologico parallelo\nUn analogo contesto psicologico può chiarire ulteriormente il meccanismo bayesiano. Si supponga di voler stimare il livello medio di ansia provato da studenti in prossimità di un esame, misurato su una scala da 1 a 5. In assenza di dati, il ricercatore potrebbe ritenere plausibile un valore medio intorno a 3, pur ammettendo un ampio margine di incertezza. Tuttavia, dopo aver raccolto le risposte di un primo gruppo di dieci studenti—otto dei quali riportano punteggi elevati (4 o 5)—la nostra rappresentazione dell’ansia media si modifica: non solo il valore più plausibile si sposta verso l’alto, ma anche l’incertezza residua assume una forma diversa, più informata e circoscritta. Anche in questo caso, il risultato non è una certezza assoluta, bensì una rinnovata stima della plausibilità dei diversi valori possibili, condizionata all’evidenza osservata.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nL’approccio bayesiano non ha l’obiettivo di eliminare l’incertezza, ma di renderla esplicita, quantificabile e gestibile. Esso consente di esprimere il grado di plausibilità relativa delle diverse ipotesi—cioè quanto un’ipotesia sia più o meno credibile di un’altra—alla luce sia delle conoscenze pregresse sia dei nuovi dati a disposizione.\n\n\n\n2.3.5 Il ruolo delle credenze e delle decisioni nella ricerca psicologica\nL’approccio bayesiano riconosce esplicitamente che ogni impresa scientifica—in psicologia come in altre discipline—inizia da un insieme di credenze. Tali credenze, che orientano la formulazione delle domande di ricerca e la progettazione degli studi, non sono viste come distorsioni indesiderate, bensì come componenti legittime e inevitabili del processo conoscitivo. Nel quadro bayesiano, esse vengono rese esplicite sotto forma di distribuzioni a priori e sottoposte a un rigoroso processo di revisione alla luce dei dati empirici.\n\n2.3.5.1 Credenze che si aggiornano\nSi consideri l’ipotesi che la pratica della mindfulness possa ridurre i livelli di stress negli studenti universitari. Un ricercatore potrebbe, sulla base di teorie e risultati precedenti, partire da un moderato ottimismo. Se i dati raccolti mostrano una chiara riduzione dello stress nel gruppo sperimentale, la credenza iniziale verrà rafforzata; se, al contrario, l’evidenza empirica risulta debole o contraddittoria, la stessa credenza verrà ridimensionata. L’obiettivo non è dimostrare di aver avuto inizialmente ragione, bensì apprendere dall’evidenza e aggiornare coerentemente il proprio stato di conoscenza.\n\n2.3.5.2 Dalle credenze alle decisioni\nLa ricerca psicologica ha quasi sempre ricadute pratiche che implicano processi decisionali. Uno psicologo clinico deve decidere se implementare un nuovo protocollo terapeutico, un docente valuta se introdurre cambiamenti nella didattica, un ricercatore stabilisce se approfondire una certa linea di indagine. L’approccio bayesiano supporta queste decisioni non offrendo certezze illusorie, ma fornendo un quadro probabilistico esplicito che permette di soppesare rischi, benefici e gradi di incertezza associati a ciascuna opzione.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nLe credenze iniziali forniscono un punto di partenza necessario e esplicito per la ricerca. I dati empirici permettono di aggiornarle in modo logico e coerente. Le decisioni pratiche—cliniche, educative, di policy—possono quindi basarsi su una valutazione trasparente e matura dell’incertezza residua, piuttosto che su conclusioni fittiziamente definitive.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_uncertainty.html#lincertezza-e-la-crisi-di-replicazione-in-psicologia",
    "href": "chapters/bayesian_inference/02_uncertainty.html#lincertezza-e-la-crisi-di-replicazione-in-psicologia",
    "title": "2  Abbracciare l’incertezza",
    "section": "\n2.4 L’incertezza e la crisi di replicazione in psicologia",
    "text": "2.4 L’incertezza e la crisi di replicazione in psicologia\nLa crisi di replicazione che ha investito la psicologia negli ultimi decenni ha sollevato interrogativi fondamentali sulla solidità delle evidenze scientifiche nella disciplina. Come emerso da progetti sistematici di replicazione (Collaboration, 2015), molti risultati considerati consolidati si sono rivelati meno robusti del previsto, quando non francamente irreplicabili. Tale crisi ha avuto il merito di portare all’attenzione della comunità scientifica un problema epistemologico centrale: la sistematica sottovalutazione dell’incertezza insita nei processi di ricerca e comunicazione dei risultati.\nFrequentemente, i risultati sono stati presentati come conclusioni definitive, sebbene ottenuti da campioni di modeste dimensioni, attraverso strumenti di misura affetti da errore e servendosi di modelli statistici che operano inevitabili semplificazioni della realtà. In altri termini, l’incertezza—pur essendo sempre presente—è stata spesso omessa o nascosta nel processo di comunicazione scientifica, creando un’impressione ingiustificata di stabilità e precisione.\n\n2.4.1 Un esempio concreto\nSi consideri uno studio che riporta un aumento statisticamente significativo dell’autostima in seguito a un breve training motivazionale. Il risultato potrebbe essere comunicato come una scoperta solida e pronta per l’applicazione. Tuttavia, un esame più attento dello studio potrebbe rivelare che il campione era composto da soli 20 partecipanti, che la variabilità individuale nelle risposte era elevata e che l’effetto osservato—sebbene statisticamente significativo in quel contesto—era di entità modesta e potenzialmente influenzato da fluttuazioni casuali. Quando un successivo tentativo di replicazione condotto con un campione più ampio e metodologicamente rigoroso non riesce a riprodurre lo stesso effetto, la fragilità della conclusione iniziale emerge in tutta la sua evidenza. Il problema non risiede necessariamente in un “falso” risultato, quanto piuttosto in una sottostima dell’incertezza associata alla stima originaria.\n\n2.4.2 Il ruolo dell’approccio bayesiano\nL’approccio bayesiano si propone come una risposta metodologica a questa criticità, non eliminando l’incertezza—cosa peraltro impossibile—ma rendendola invece esplicita, quantificata e comunicabile. Rinunciando all’idea di una stima unica e definitiva, esso fornisce una rappresentazione probabilistica completa dei parametri di interesse, mostrando l’intera gamma di valori plausibili e il loro relativo grado di credibilità alla luce dei dati.\nQuesta trasparenza operativa costituisce un potente antidoto alle distorsioni emerse durante la crisi di replicazione. In primo luogo, consente di valutare e comunicare in modo più realistico la robustezza—o la fragilità—di un risultato. In secondo luogo, aiuta a distinguere tra effetti replicabili e dotati di consistenza empirica e mere oscillazioni casuali, amplificate da campioni di piccole dimensioni o da disegni sperimentali vulnerabili. Infine, facilità l’integrazione dei risultati tra studi differenti, poiché le stime bayesiane sono intrinsecamente cumulative e in grado di incorporare criticamente l’evidenza pregressa.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nLa crisi di replicazione ha insegnato alla psicologia una lezione cruciale: ignorare o nascondere l’incertezza conduce a conclusioni illusorie e a una fragilità cumulativa del sapere. Un approccio che, come quello bayesiano, riconosce, quantifica e comunica onestamente l’incertezza, non garantisce di per sé la replicabilità di ogni risultato, ma promuove indubbiamente una pratica scientifica più matura, trasparente e progressivamente cumulativa.\n\n\n\n\n\n\n\n\n\nFigura 2.1: Effetto della dimensione campionaria sull’incertezza della stima (media). A sinistra (n=20) la distribuzione delle stime della media è più larga: molte realizzazioni possibili. A destra (n=200) la distribuzione è più concentrata intorno al valore “vero” (linea tratteggiata). Questo illustra come l’incertezza sulla stima si riduca con campioni più grandi — un punto chiave per comprendere la replicabilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_uncertainty.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/02_uncertainty.html#riflessioni-conclusive",
    "title": "2  Abbracciare l’incertezza",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo è emerso con chiarezza come l’incertezza non costituisca un limite accidentale o un difetto della ricerca psicologica, bensì una sua caratteristica intrinseca e ineliminabile. I fenomeni psicologici, per loro natura complessi, sfumati e contestuali, sfuggono a rappresentazioni deterministiche e richiedono un approccio capace di riconoscere—piuttosto che negare—i margini di indeterminazione che li accompagnano.\nAbbiamo proposto una tripartizione concettuale delle fonti di incertezza, distinguendo tra l’incertezza aleatoria, radicata nell’intrinseca variabilità e imprevedibilità dei processi psicologici; l’incertezza epistemica, generata dai limiti operativi della nostra osservazione—quali campioni finiti e strumenti imperfetti—e in linea di principio riducibile attraverso il miglioramento metodologico; e infine l’incertezza ontologica o modellistica, che scaturisce dalla necessaria semplificazione operata da qualsiasi modello teorico, e che ci ricorda come la complessità del reale ecceda sempre la nostra capacità di rappresentazione.\nDi fronte a questa articolata natura dell’incertezza, l’approccio bayesiano offre una prospettiva profondamente coerente e feconda. La sua intuizione fondamentale consiste nell’abbandonare la ricerca illusoria di stime definitive, a favore di una rappresentazione probabilistica che contempli un ventaglio di esiti possibili, ciascuno associato a un diverso grado di plausibilità. In questo modo, è possibile aggiornare in modo rigoroso e trasparente le nostre convinzioni iniziali alla luce dei nuovi dati, e fondare su una base più realistica le decisioni—siano esse cliniche, educative o di policy.\nInfine, abbiamo collegato queste riflessioni di metodo alla crisi di replicazione che ha attraversato la psicologia, mostrando come una cronica sottovalutazione dell’incertezza abbia contribuito a produrre un corpus di risultati apparentemente solidi, ma in realtà fragili e poco riproducibili. Riconoscere, misurare e comunicare l’incertezza non risolve magicamente tutti i problemi metodologici, ma rappresenta un passo necessario verso una scienza più umile, trasparente e autenticamente cumulativa.\n\n\n\n\n\n\nSintesi finale\n\n\n\nL’incertezza non è un nemico da sconfiggere, ma il terreno stesso su cui si costruisce una scienza matura e responsabile. Il framework bayesiano fornisce gli strumenti concettuali e operativi per navigare in questo territorio con consapevolezza e rigore. Nei prossimi capitoli, tradurremo queste intuizioni in procedure analitiche concrete, mostrando come implementare nella pratica della ricerca un modo più plausibile e informato di produrre conoscenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_uncertainty.html#bibliografia",
    "href": "chapters/bayesian_inference/02_uncertainty.html#bibliografia",
    "title": "2  Abbracciare l’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_uncertainty_quantification.html",
    "href": "chapters/bayesian_inference/03_uncertainty_quantification.html",
    "title": "3  La quantificazione dell’incertezza",
    "section": "",
    "text": "Introduzione\nNel capitolo precedente abbiamo visto che l’incertezza è una componente inevitabile della ricerca psicologica. Abbiamo distinto diversi tipi di incertezza e abbiamo mostrato come l’approccio bayesiano offra un linguaggio per rappresentarla in modo esplicito.\nIn questo capitolo iniziamo a costruire gli strumenti tecnici di base del pensiero bayesiano. L’obiettivo non è ancora quello di entrare nei dettagli matematici, ma di sviluppare un’intuizione solida su alcuni concetti chiave:\nL’idea centrale è che il metodo bayesiano funziona come un processo di aggiornamento coerente delle credenze: partiamo da ciò che sappiamo, osserviamo i dati, e arriviamo a conclusioni più raffinate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_uncertainty_quantification.html#introduzione",
    "href": "chapters/bayesian_inference/03_uncertainty_quantification.html#introduzione",
    "title": "3  La quantificazione dell’incertezza",
    "section": "",
    "text": "Credenze iniziali (priori): come rappresentare ciò che sappiamo o supponiamo prima di raccogliere i dati.\n\nDati (likelihood): come descrivere formalmente l’informazione che proviene dall’osservazione empirica.\n\nCredenze aggiornate (posteriori): come combinare priori e dati per ottenere una descrizione più informata dell’incertezza.\n\n\n\n\n\n\n\n\nIntuizione\n\n\n\nIl pensiero bayesiano non elimina il dubbio, ma ci permette di trattarlo in modo sistematico: i dati non sostituiscono le nostre ipotesi, ma le trasformano.\n\n\nPanoramica del capitolo\n\nCome quantificare e rappresentare matematicamente l’incertezza attraverso le distribuzioni di densità.\nIl processo di integrazione delle nuove evidenze con le conoscenze preesistenti.\nCome i parametri sconosciuti determinano i dati osservati attraverso processi probabilistici.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Bayesian statistics for clinical research di Goligher et al. (2024).\nLeggere Dicing with the unknown di Tony O’Hagan, per una descrizione chiara della distinzione tra incertezza aleatoria e incertezza epistemica.\nLeggere il capitolo Estimation (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_uncertainty_quantification.html#lincertezza-come-distribuzione-di-probabilità",
    "href": "chapters/bayesian_inference/03_uncertainty_quantification.html#lincertezza-come-distribuzione-di-probabilità",
    "title": "3  La quantificazione dell’incertezza",
    "section": "\n3.1 L’incertezza come distribuzione di probabilità",
    "text": "3.1 L’incertezza come distribuzione di probabilità\nFinora abbiamo parlato di incertezza in modo concettuale. Ora facciamo un passo in più: impariamo a rappresentarla formalmente.L’idea di base è che l’incertezza non si descrive con un singolo valore, ma con una gamma di valori possibili, a ciascuno dei quali attribuiamo un grado di plausibilità. Questo insieme di valori e plausibilità è ciò che chiamiamo distribuzione di probabilità.\n\n3.1.1 Un esempio intuitivo\nSupponiamo di stimare il livello medio di ansia negli studenti prima di un esame.\n\nNon sappiamo con certezza quale sia: potrebbe essere 2.8, oppure 3.1, o forse 3.5 su una scala da 1 a 5.\nAlcuni valori ci sembrano più plausibili di altri. Per esempio, 3.0 è più verosimile di 1.0 o di 5.0.\nPossiamo quindi rappresentare la nostra incertezza con una curva che assegna più “peso” ai valori plausibili e meno a quelli estremi.\n\n3.1.2 Perché usare distribuzioni?\nUsare distribuzioni di probabilità per rappresentare l’incertezza ha due vantaggi fondamentali:\n\n\nTrasparenza: invece di fingere di conoscere un valore preciso, dichiariamo chiaramente quanto siamo incerti.\n\nFlessibilità: possiamo aggiornare la distribuzione quando raccogliamo nuovi dati, vedendo come la nostra rappresentazione dell’incertezza cambia.\n\n3.1.3 Collegamento con la psicologia\nQuesta idea non vale solo per punteggi medi, ma per qualsiasi parametro di interesse psicologico:\n\nla forza di un effetto terapeutico,\nla relazione tra ansia e rendimento,\nla probabilità che un soggetto scelga una certa opzione in un compito cognitivo.\n\nIn tutti questi casi, non possiamo mai dire “il valore vero è X”: possiamo solo attribuire una distribuzione di probabilità ai possibili valori.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nRappresentare l’incertezza come una distribuzione di probabilità significa passare da una visione rigida (“il valore è uno solo”) a una visione più realistica e informativa (“alcuni valori sono più plausibili di altri”).\n\n\n\n\n\n\n\n\n\nFigura 3.1: Rappresentare l’incertezza sulla media dell’ansia come distribuzione di probabilità.\n\n\n\n\n\n3.1.4 La natura dinamica dell’incertezza bayesiana\nUn aspetto fondamentale dell’approccio bayesiano è che l’incertezza non è statica. Non rimaniamo bloccati nella distribuzione iniziale che assegniamo ai valori possibili: ogni volta che osserviamo nuovi dati, aggiorniamo la distribuzione.\nIn questo modo, la rappresentazione dell’incertezza è dinamica: evolve con l’accumularsi delle informazioni.\nEsempio psicologico:\n\nPrima di raccogliere i dati, possiamo pensare che la media dell’ansia degli studenti prima di un esame sia plausibilmente intorno a 3.\nDopo aver osservato le prime risposte, la distribuzione si sposta: se molti studenti riportano valori alti, la parte destra della curva diventa più plausibile.\nSe in seguito raccogliamo ancora più dati, la curva si restringe, riflettendo una maggiore precisione nelle nostre stime.\n\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nNel pensiero bayesiano, l’incertezza è viva: si muove, si aggiorna e si affina ogni volta che impariamo qualcosa di nuovo dai dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_uncertainty_quantification.html#le-fondamenta-concettuali-dellinferenza-bayesiana",
    "href": "chapters/bayesian_inference/03_uncertainty_quantification.html#le-fondamenta-concettuali-dellinferenza-bayesiana",
    "title": "3  La quantificazione dell’incertezza",
    "section": "\n3.2 Le fondamenta concettuali dell’inferenza bayesiana",
    "text": "3.2 Le fondamenta concettuali dell’inferenza bayesiana\nL’approccio bayesiano si fonda su un’idea semplice: ogni volta che raccogliamo dati, possiamo aggiornare in modo coerente le nostre credenze. Questa idea è riassunta in una formula molto celebre: il teorema di Bayes.\n\\[\nP(\\text{Ipotesi} \\mid \\text{Dati}) \\;=\\;\n\\frac{P(\\text{Dati} \\mid \\text{Ipotesi}) \\; \\times \\; P(\\text{Ipotesi})}{P(\\text{Dati})}\n\\]\n\n3.2.1 Intuizione della formula\n\n\n\\(P(\\text{Ipotesi})\\) → la nostra convinzione iniziale, detta prior (“quanto credevo plausibile questa ipotesi prima di raccogliere i dati”).\n\n\\(P(\\text{Dati} \\mid \\text{Ipotesi})\\) → la compatibilità tra l’ipotesi e ciò che osserviamo, detta verosimiglianza o likelihood.\n\n\\(P(\\text{Ipotesi} \\mid \\text{Dati})\\) → la convinzione aggiornata, detta posterior (“quanto credo plausibile questa ipotesi dopo aver visto i dati”).\n\n\\(P(\\text{Dati})\\) → un fattore di normalizzazione: garantisce che tutte le ipotesi considerate abbiano probabilità che sommano a 1.\n\nIn sintesi:\n\\[\n\\text{Posterior} \\;\\propto\\; \\text{Likelihood} \\times \\text{Prior}\n\\]\n\n3.2.2 Un esempio psicologico\nImmaginiamo di voler valutare se un nuovo training cognitivo riduce l’ansia negli studenti.\n\nPrima di raccogliere i dati, abbiamo una convinzione iniziale: pensiamo che l’effetto sia possibile, ma non ne siamo sicuri (prior).\nDopo aver somministrato il training a un piccolo gruppo, osserviamo una riduzione dell’ansia (dati). Questi dati sono più compatibili con l’ipotesi “il training funziona” che con “il training non funziona” (likelihood).\nCombinando le due cose otteniamo una nuova convinzione più informata (posterior): l’ipotesi che il training riduca l’ansia diventa più plausibile, ma con un margine di incertezza che continueremo a considerare.\n\n3.2.3 Perché è importante?\nl teorema di Bayes non è solo una formula: è un principio di ragionamento. Ci dice come passare in modo sistematico da ciò che sappiamo prima (priori) a ciò che sappiamo dopo aver osservato i dati (posteriori). Questa struttura ci permette di integrare teoria e dati in modo coerente, esplicitare le assunzioni iniziali e rappresentare sempre l’incertezza residua.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nIl teorema di Bayes è la regola che collega credenze iniziali, dati osservati e credenze aggiornate. Non elimina l’incertezza, ma ci mostra come aggiornarla in modo coerente.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_uncertainty_quantification.html#laggiornamento-bayesiano-in-azione-lesempio-del-globo-terrestre",
    "href": "chapters/bayesian_inference/03_uncertainty_quantification.html#laggiornamento-bayesiano-in-azione-lesempio-del-globo-terrestre",
    "title": "3  La quantificazione dell’incertezza",
    "section": "\n3.3 L’aggiornamento bayesiano in azione: l’esempio del globo terrestre",
    "text": "3.3 L’aggiornamento bayesiano in azione: l’esempio del globo terrestre\nPer capire come funziona concretamente il teorema di Bayes, immaginiamo un esperimento mentale proposto da McElreath nel suo testo Statistical Rethinking (McElreath, 2020). Abbiamo davanti a noi un globo terrestre (una sfera blu e marrone) e ci poniamo una domanda:\n\n“Quale proporzione della superficie terrestre è coperta da acqua?”\n\nSappiamo che gran parte del pianeta è mare, ma non conosciamo la percentuale precisa. Vogliamo stimarla con un piccolo “esperimento casuale”.\n\n3.3.1 Il setup sperimentale\nChiamiamo \\(p\\) la vera proporzione di superficie coperta d’acqua. Questo è il nostro parametro di interesse: il numero che vogliamo stimare.\nOgni volta che facciamo girare il globo e puntiamo il dito otteniamo un’osservazione:\n\n\nW se tocchiamo acqua,\n\nL se tocchiamo terra.\n\nIl nostro modello dei dati assume che ogni lancio sia indipendente e che la probabilità di osservare acqua sia proprio \\(p\\).\nAll’inizio non sappiamo nulla di preciso: potremmo allora assegnare a \\(p\\) una distribuzione a priori uniforme, cioè ritenere ogni valore compreso tra 0 e 1 ugualmente plausibile. Questo rappresenta uno stato di “ignoranza informativa”: nessuna preferenza iniziale per alcuni valori rispetto ad altri.\n\n3.3.2 La dinamica dell’apprendimento\n\nPrimo lancio → osserviamo “W” (acqua). Ora valori molto bassi di \\(p\\) diventano poco plausibili (se \\(p\\) fosse vicino a 0, sarebbe stato molto improbabile ottenere acqua al primo colpo). La distribuzione a posteriori si sposta, assegnando più probabilità a valori alti di \\(p\\).\nSecondo lancio → otteniamo “L” (terra). Questo dato porta nella direzione opposta: valori molto alti di \\(p\\) diventano meno plausibili. La distribuzione a posteriori si “riequilibra”, privilegiando valori intermedi.\n\nCon ogni nuova osservazione, il quadro cambia: nessun dato singolo è definitivo, ma ciascuno contribuisce a modificare il profilo della nostra incertezza.\n\n3.3.3 L’accumulo progressivo dell’evidenza\nImmaginiamo di osservare la sequenza: W, L, W, W, L, W, L, W, W.\n\nDopo ogni lancio, la distribuzione si aggiorna.\nOgni posterior diventa automaticamente il prior per il passo successivo.\nIn questo modo, l’apprendimento è cumulativo: non scartiamo mai le informazioni già raccolte, ma le integriamo con le nuove.\n\nQuesta è l’essenza dell’approccio bayesiano: una catena continua di aggiornamento delle credenze.\n\n3.3.4 L’evoluzione dell’incertezza\nUn punto cruciale è che non si aggiorna solo la stima più plausibile di \\(p\\), ma anche la larghezza della distribuzione:\n\ncon pochi dati, la distribuzione è ampia → riflette grande incertezza;\ncon più osservazioni, la distribuzione diventa più stretta → la nostra conoscenza si affina;\nla velocità e la forma del restringimento dipendono dai dati: sequenze molto coerenti riducono l’incertezza rapidamente, sequenze più variabili la riducono gradualmente.\n\n\n\n\n\n\n\n\n\n\n3.3.5 Come leggere il grafico\nIn ogni pannello, la linea grigia mostra il prior (prima dell’osservazione), e la linea blu il posterior (dopo l’osservazione). Si vede chiaramente come, passo dopo passo, la curva blu si restringa e si concentri intorno ai valori più compatibili con i dati. Ogni distribuzione aggiornata diventa la nuova base di partenza per il passo successivo.\nQuesto esempio mostra in modo concreto che l’inferenza bayesiana non cerca “una stima definitiva”, ma costruisce un processo dinamico di apprendimento, in cui l’incertezza si riduce e si adatta man mano che i dati accumulano evidenza.\n\n\n\n\n\n\nPosteriori diverse a confronto\n\n\n\nLo stesso insieme di dati può dare origine a posteriori molto diverse a seconda del prior.\nQuesto non è un “difetto” del Bayes, ma un aspetto centrale: rende esplicita l’influenza delle ipotesi di partenza. Il vantaggio è che possiamo discutere apertamente quanto le conclusioni dipendano dal prior e, se necessario, confrontare più specificazioni (analisi di sensibilità).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_uncertainty_quantification.html#implicazioni-per-la-ricerca-psicologica",
    "href": "chapters/bayesian_inference/03_uncertainty_quantification.html#implicazioni-per-la-ricerca-psicologica",
    "title": "3  La quantificazione dell’incertezza",
    "section": "\n3.4 Implicazioni per la ricerca psicologica",
    "text": "3.4 Implicazioni per la ricerca psicologica\nL’esempio del globo terrestre è un gioco semplice, ma ci insegna alcune lezioni fondamentali che valgono pienamente per la psicologia.\n\nLe nostre convinzioni cambiano con i dati La ricerca psicologica non si limita a raccogliere informazioni: è un processo di apprendimento. Ogni studio modifica il nostro quadro di riferimento, integrando la nuova evidenza con ciò che già sapevamo.\nL’incertezza non scompare, si aggiorna Dopo pochi dati l’incertezza è ampia; con più osservazioni si restringe, ma non arriva mai a zero. In psicologia, dove i fenomeni sono complessi e variabili, è essenziale rappresentare non solo quanto un effetto è plausibile, ma anche quanto siamo incerti su di esso.\nL’informazione è cumulativa Proprio come ogni posterior diventa il nuovo prior, la scienza psicologica avanza grazie all’accumulo coerente di conoscenze. Ogni studio dovrebbe essere visto come un passo in una catena di aggiornamenti, non come un verdetto finale.\n\n\n3.4.1 Un esempio psicologico\nImmaginiamo di valutare l’efficacia di una nuova terapia per l’ansia. Prima dei dati, abbiamo solo intuizioni e risultati preliminari, che costituiscono un prior molto incerto. Dopo il primo studio, otteniamo indicazioni che la terapia potrebbe essere utile, ma con un ampio margine di dubbio, risultando in un posterior ancora largo. Con più studi, le distribuzioni si concentrano progressivamente. Se l’effetto è reale, la curva si restringe intorno a un valore positivo; se l’effetto è debole o assente, la distribuzione si sposterà di conseguenza.\nQuesto approccio rende più chiaro perché una singola ricerca non basta a stabilire verità definitive, e perché è cruciale replicare e accumulare evidenza.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nIl modello del globo mostra in piccolo quello che accade in psicologia:\n\nraccogliamo dati,\naggiorniamo le nostre credenze,\nmanteniamo l’incertezza,\ncostruiamo conoscenza in modo cumulativo.\n\nL’approccio bayesiano fornisce un linguaggio preciso per descrivere questo processo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_uncertainty_quantification.html#considerazioni-pratiche-e-limitazioni",
    "href": "chapters/bayesian_inference/03_uncertainty_quantification.html#considerazioni-pratiche-e-limitazioni",
    "title": "3  La quantificazione dell’incertezza",
    "section": "\n3.5 Considerazioni pratiche e limitazioni",
    "text": "3.5 Considerazioni pratiche e limitazioni\nL’approccio bayesiano offre una cornice concettuale elegante e intuitiva per rappresentare l’incertezza e aggiornare le nostre credenze. Tuttavia, quando passiamo dalla teoria alla pratica della ricerca psicologica, emergono alcune considerazioni importanti.\n\n3.5.1 Scelta delle credenze iniziali (priori)\nUn aspetto caratteristico dell’approccio bayesiano è che richiede di specificare sempre una distribuzione a priori. Questo è un vantaggio perché ci costringe a esplicitare le nostre assunzioni e ad ancorarle a conoscenze precedenti, ma è anche una responsabilità, poiché prior troppo forti o poco giustificate possono influenzare eccessivamente i risultati. In pratica, gli psicologi devono imparare a distinguere tra prior debolmente informativi, che lasciano spazio ai dati, e prior informativi, che incorporano evidenza accumulata o teoria.\n\n3.5.2 Complessità computazionale\nMolti modelli psicologici sono complessi, con più parametri, strutture gerarchiche e dinamiche temporali. Le formule di Bayes, in questi casi, non si possono risolvere a mano. Si usano invece metodi numerici come le simulazioni Monte Carlo (MCMC), che richiedono tempo di calcolo e competenze specifiche. Oggi strumenti come Stan o brms rendono queste tecniche accessibili, ma serve comunque una formazione adeguata.\n\n3.5.3 Interpretazione dei risultati\nI risultati bayesiani sono concettualmente più trasparenti, poiché parlano di plausibilità di valori invece di fornire un verdetto sì/no basato sulla “significatività”. Tuttavia, richiedono un cambio di mentalità. Per chi è abituato a pensare in termini di p-value, questo può sembrare inizialmente meno rassicurante, ma in realtà è più realistico, in quanto fornisce una distribuzione di possibilità.\n\n3.5.4 Limitazioni intrinseche\nInfine, va ricordato che anche l’approccio bayesiano ha limiti. Non elimina l’incertezza, ma la descrive soltanto meglio; dipende comunque dalla qualità dei dati, per cui dati rumorosi o campioni non rappresentativi rimangono problematici; e riflette sempre la struttura del modello scelto, per cui se il modello è inadeguato, anche la migliore inferenza bayesiana porterà a conclusioni distorte.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nIl pensiero bayesiano non è una bacchetta magica: richiede scelte esplicite, strumenti adeguati e una lettura attenta dei risultati. La sua forza non sta nell’eliminare le difficoltà della ricerca psicologica, ma nel renderle visibili e trattabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_uncertainty_quantification.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/03_uncertainty_quantification.html#riflessioni-conclusive",
    "title": "3  La quantificazione dell’incertezza",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo fatto il nostro primo vero passo dentro il pensiero bayesiano. Abbiamo visto che l’incertezza può essere rappresentata come una distribuzione di probabilità e abbiamo introdotto il teorema di Bayes, la regola che collega credenze iniziali, dati osservati e credenze aggiornate. Attraverso l’esempio del globo terrestre, abbiamo compreso come l’aggiornamento bayesiano funzioni in pratica: ogni nuova osservazione restringe o sposta la distribuzione delle nostre convinzioni, riducendo progressivamente l’incertezza.\nAbbiamo discusso le implicazioni per la ricerca psicologica, riconoscendo che i dati non danno risposte definitive, ma guidano un processo di apprendimento cumulativo. Infine, abbiamo esaminato le considerazioni pratiche e le limitazioni dell’approccio, dalla scelta dei priori alla complessità computazionale, dall’interpretazione dei risultati alla dipendenza dalla qualità dei modelli.\nQuesta panoramica ci ha permesso di sviluppare un’intuizione solida: il bayesianesimo non elimina l’incertezza, ma ci fornisce un metodo coerente e trasparente per trattarla. Nei prossimi capitoli tradurremo queste idee in strumenti concreti, imparando a costruire e interpretare modelli bayesiani applicati alla ricerca psicologica.\nUn equivoco comune è pensare che l’approccio bayesiano fornisca “più certezze” rispetto a quello frequentista. In realtà, accade il contrario: i risultati bayesiani mettono in evidenza l’incertezza, anziché nasconderla dietro a un singolo numero o a un verdetto dicotomico. Questo può inizialmente sembrare meno rassicurante, soprattutto per chi è abituato a ragionare in termini di p-value e soglie di significatività. Tuttavia, proprio questa trasparenza costituisce la forza dell’approccio bayesiano: ci permette di comunicare in modo più onesto quali valori dei parametri sono plausibili e quanto spazio rimane per il dubbio. Adottare il pensiero bayesiano significa quindi cambiare prospettiva: non cercare una “certezza definitiva”, ma abituarsi a ragionare in termini di gradi di plausibilità e di apprendimento continuo dai dati.\n\n\n\n\n\n\nApprofondimento\n\n\n\n\n\nA una prima lettura, è sufficiente concentrarsi sul significato generale dell’aggiornamento bayesiano: ogni nuova osservazione modifica le nostre credenze sui parametri, restringendo progressivamente l’incertezza. Per il momento, gli studenti possono tralasciare i dettagli tecnici riportati qui sotto.\nDopo aver studiato le famiglie coniugate nei capitoli successivi, sarà utile tornare su questo esempio per comprenderne appieno il funzionamento. L’aggiornamento bayesiano diventerà allora più chiaro nei suoi aspetti formali, mostrando perché in alcuni casi (come questo) il calcolo può essere svolto in maniera particolarmente semplice ed elegante.\n\n3.5.5 Il modello Beta-Binomiale\nL’esempio del globo è un caso classico di modello Beta-Binomiale:\n\nla distribuzione a priori sulla proporzione \\(p\\) è una Beta;\nla verosimiglianza delle osservazioni (successi/insuccessi) segue una Binomiale;\nper la proprietà di coniugazione, la distribuzione a posteriori risulta anch’essa una Beta.\n\nQuesta proprietà ci permette di aggiornare le credenze con una regola semplice:\n\\[\n\\text{Posterior} \\sim \\text{Beta}(a + W, \\; b + L)\n\\]\ndove \\(a\\) e \\(b\\) sono i parametri della prior (nel nostro caso iniziale \\(a=1, b=1\\)), mentre \\(W\\) e \\(L\\) sono il numero di osservazioni acqua (Water) e terra (Land).\n\n3.5.6 Esempio passo per passo\n\nPrimo pannello (1 osservazione: W) Prior: \\(\\text{Beta}(1,1)\\) → Posterior: \\(\\text{Beta}(2,1)\\). La distribuzione si concentra su valori alti di \\(p\\).\nSecondo pannello (2 osservazioni: W, L) Prior: \\(\\text{Beta}(2,1)\\) → Posterior: \\(\\text{Beta}(3,2)\\). L’evidenza si riequilibra verso valori intermedi.\nTerzo pannello (3 osservazioni: W, L, W) Prior: \\(\\text{Beta}(3,2)\\) → Posterior: \\(\\text{Beta}(4,2)\\). Cresce la plausibilità di valori intorno a \\(p \\approx 0.66\\).\nQuarto pannello (4 osservazioni: W, L, W, W) Posterior: \\(\\text{Beta}(5,2)\\).\nQuinto pannello (5 osservazioni: W, L, W, W, L) Posterior: \\(\\text{Beta}(5,3)\\).\nSesto pannello (6 osservazioni: W, L, W, W, L, W) Posterior: \\(\\text{Beta}(6,3)\\).\nSettimo pannello (7 osservazioni: W, L, W, W, L, W, L) Posterior: \\(\\text{Beta}(6,4)\\).\nOttavo pannello (8 osservazioni: W, L, W, W, L, W, L, W) Posterior: \\(\\text{Beta}(7,4)\\).\nNono pannello (9 osservazioni: W, L, W, W, L, W, L, W, W) Posterior: \\(\\text{Beta}(8,4)\\).\n\n3.5.7 In sintesi\nL’aggiornamento sequenziale mostra come la distribuzione diventi progressivamente più concentrata intorno ai valori di \\(p\\) compatibili con i dati osservati. Con l’accumulo di osservazioni, l’incertezza si riduce, la stima più plausibile di \\(p\\) si stabilizza e l’inferenza diventa più precisa.\nQuesto è l’essenziale del processo bayesiano: un apprendimento cumulativo, coerente e formalmente elegante.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] yaml_2.3.10           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.5.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_7.0.0              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.3    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.5.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_uncertainty_quantification.html#bibliografia",
    "href": "chapters/bayesian_inference/03_uncertainty_quantification.html#bibliografia",
    "title": "3  La quantificazione dell’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_statistical_models.html",
    "href": "chapters/bayesian_inference/04_statistical_models.html",
    "title": "4  Modelli statistici",
    "section": "",
    "text": "Introduzione\nNegli ultimi anni, la psicologia ha vissuto un profondo ripensamento metodologico, sollecitato dalla cosiddetta crisi della replicabilità. Una delle critiche principali emerse in questo dibattito riguarda la tendenza della ricerca tradizionale a concentrarsi prevalentemente sull’identificazione di associazioni statistiche tra variabili, trascurando spesso la modellazione dei processi psicologici sottostanti che potrebbero aver generato i dati osservati.\nSebbene questo approccio descrittivo possa rivelarsi utile in determinate circostanze, esso presenta due limiti fondamentali. In primo luogo, tende a produrre risultati fragili e di difficile replicazione, poiché le relazioni identificate non sono ancorate a una teoria solida riguardante i meccanismi causali che le generano. In secondo luogo, contribuisce a mantenere un divario tra la psicologia e altre discipline scientifiche – come la fisica, la biologia o l’economia – che da tempo fondano il proprio progresso sulla costruzione di modelli formali in grado di rappresentare esplicitamente i processi sottostanti ai fenomeni osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_statistical_models.html#introduzione",
    "href": "chapters/bayesian_inference/04_statistical_models.html#introduzione",
    "title": "4  Modelli statistici",
    "section": "\n4.1 Preparazione del Notebook",
    "text": "Panoramica del capitolo\n\nCosa significa descrivere i dati rispetto a spiegare i processi che li generano.\n\nI limiti dei modelli fenomenologici e perché possono indurre in errore.\n\nIl ruolo delle distribuzioni di probabilità per rappresentare l’incertezza.\n\nCome confrontare modelli alternativi e scegliere quelli che meglio descrivono i dati e generalizzano a nuovi contesti.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Common Statistical Models del testo di Chan & Kroese (2025).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n4.1 Preparazione del Notebook\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n\n\n\n\n4.1.1 Dalla correlazione alla spiegazione\nUn modello che si limita a stimare una correlazione o una regressione lineare può dirci se due variabili si muovono insieme, ma non ci dice perché accade. Per esempio: osservare un’associazione tra stress e rendimento accademico è informativo, ma non basta per capire il processo attraverso cui lo stress influisce (o non influisce) sulla performance.\nIl passo avanti consiste nel cercare di rappresentare come i dati emergono da processi psicologici sottostanti. In altre parole, spostiamo l’attenzione dalle semplici relazioni osservate ai meccanismi generativi che le producono.\n\n4.1.1.1 Perché questo cambiamento è cruciale?\nQuesto cambiamento è cruciale perché permette di costruire modelli più vicini alla realtà dei fenomeni psicologici, rende le teorie più precise e testabili, e fornisce risultati più robusti e potenzialmente più replicabili, poiché radicati in una rappresentazione del processo e non solo in un dato campione.\n\n4.1.2 Anticipazione\nNei prossimi paragrafi vedremo come questo approccio si traduca in pratica: non ci limiteremo a presentare i modelli di regressione nelle loro diverse varianti, ma esploreremo anche modelli che cercano di descrivere processi psicologici espliciti, come ad esempio il modello di Rescorla-Wagner per l’apprendimento associativo.\nL’obiettivo non è sostituire l’analisi statistica classica, ma integrarla con strumenti che ci aiutino a rispondere a una domanda più ambiziosa: quali processi mentali plausibili possono aver generato i dati che osserviamo?",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_statistical_models.html#preparazione-del-notebook",
    "href": "chapters/bayesian_inference/04_statistical_models.html#preparazione-del-notebook",
    "title": "4  Modelli statistici",
    "section": "",
    "text": "here::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_statistical_models.html#campionamento-indipendente-da-una-distribuzione-fissa",
    "href": "chapters/bayesian_inference/04_statistical_models.html#campionamento-indipendente-da-una-distribuzione-fissa",
    "title": "4  Modelli statistici",
    "section": "\n4.2 Campionamento indipendente da una distribuzione fissa",
    "text": "4.2 Campionamento indipendente da una distribuzione fissa\nMolti modelli statistici tradizionali si basano sull’assunzione fondamentale che i dati osservati rappresentino un processo di campionamento indipendente da una distribuzione fissa. Prendiamo ad esempio il caso dei punteggi di ansia misurati in un campione di studenti: si assume che questi punteggi seguano una distribuzione normale caratterizzata da una media \\(\\mu\\) e una deviazione standard \\(\\sigma\\).\nIn questo quadro concettuale:\n\nogni singola osservazione viene considerata come un’estrazione indipendente dalla stessa distribuzione di probabilità sottostante;\nl’obiettivo principale del modello statistico diventa quindi la stima dei parametri che definiscono questa distribuzione (\\(\\mu\\) e \\(\\sigma\\)).\n\nQuesto approccio presenta indubbi vantaggi per la descrizione sintetica dei dati e l’identificazione delle loro caratteristiche distributive fondamentali. Tuttavia, è importante riconoscere i suoi limiti concettuali: questa prospettiva rimane essenzialmente muta riguardo ai meccanismi attraverso i quali i livelli di ansia effettivamente emergono o si modificano nel tempo. In altre parole, descrive i dati nella loro manifestazione osservabile (“così come sono”), ma non offre alcuna insight sui processi psicologici dinamici che li hanno generati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_statistical_models.html#modelli-fenomenologici-descrivere-le-associazioni",
    "href": "chapters/bayesian_inference/04_statistical_models.html#modelli-fenomenologici-descrivere-le-associazioni",
    "title": "4  Modelli statistici",
    "section": "\n4.3 Modelli fenomenologici: descrivere le associazioni",
    "text": "4.3 Modelli fenomenologici: descrivere le associazioni\nUn passo in più è rappresentato dai modelli che analizzano relazioni tra variabili, come la regressione lineare o logistica. Questi approcci ci permettono di andare oltre la semplice descrizione di una distribuzione, consentendoci di studiare sistematicamente come una variabile dipendente cambia in funzione di una o più variabili indipendenti.\nPer esempio, possiamo modellare la relazione tra stress e rendimento accademico, verificando empiricamente se un aumento dei livelli di stress corrisponde effettivamente a un calo delle performance scolastiche.\nQuesti modelli statistici sono estremamente diffusi e costituiscono il fondamento metodologico di gran parte della ricerca psicologica contemporanea. Tuttavia, è importante riconoscere che rimangono essenzialmente modelli fenomenologici: descrivono efficacemente che cosa accade (documentando ad esempio l’esistenza di una correlazione tra stress e rendimento), ma non sono in grado di spiegare perché tale relazione esista.\nUn modello di regressione, infatti, non può dirci se lo stress riduce direttamente il rendimento, se entrambe le variabili sono influenzate da un fattore terzo (come il supporto sociale), o se la relazione evolve nel tempo attraverso complesse dinamiche di adattamento psicologico. Questa fragilità metodologica ha contribuito direttamente alla crisi di replicazione: modelli che descrivono soltanto associazioni spesso sembrano solidi in uno studio, ma non riescono a replicarsi in altri contesti, proprio perché non si appoggiano a un processo generativo condiviso.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_statistical_models.html#modelli-meccanicistici-spiegare-i-processi",
    "href": "chapters/bayesian_inference/04_statistical_models.html#modelli-meccanicistici-spiegare-i-processi",
    "title": "4  Modelli statistici",
    "section": "\n4.4 Modelli meccanicistici: spiegare i processi",
    "text": "4.4 Modelli meccanicistici: spiegare i processi\nI modelli meccanicistici, detti anche processuali, rappresentano un passo ulteriore rispetto ai modelli puramente statistici. Questi modelli non si limitano a descrivere associazioni tra variabili, ma cercano di formalizzare i meccanismi psicologici che generano i dati osservati.\nQuesti modelli sono costruiti a partire da ipotesi specifiche su come le persone percepiscono, apprendono, decidono o reagiscono a stimoli. Ogni parametro del modello possiede un significato psicologico interpretabile, come ad esempio la velocità di apprendimento, una soglia decisionale, o la sensibilità a ricompense e punizioni. In questa prospettiva, i dati non sono più considerati come semplici estrazioni indipendenti da una distribuzione fissa, ma come l’esito dinamico di un processo psicologico sottostante.\nUn esempio particolarmente illustrativo è il modello di Rescorla-Wagner per l’apprendimento associativo. Questo modello descrive come la forza di un’associazione tra stimoli viene aggiornata a ogni prova in base all’errore di previsione commesso dall’individuo. In questo caso, non ci limitiamo a stimare se “esiste un effetto” di uno stimolo, ma modelliamo esplicitamente il processo di apprendimento che produce le risposte osservate, offrendo così una comprensione più profonda e meccanicistica del fenomeno psicologico in esame. Modelli di questo tipo, radicati in un processo psicologico esplicito, hanno il potenziale di produrre risultati più robusti e replicabili: se il modello cattura davvero il meccanismo sottostante, allora la sua applicazione a nuovi dati dovrebbe confermare le stesse dinamiche di base, anche se le osservazioni specifiche cambiano.\n\n4.4.1 Confronto tra i due approcci\nI modelli fenomenologici offrono il vantaggio della semplicità e sono spesso sufficienti per una descrizione iniziale dei dati. Tuttavia, questa semplicità comporta un rischio significativo: tendono a produrre spiegazioni fragili e poco replicabili, in quanto catturano relazioni superficiali senza indagare i meccanismi sottostanti.\nAl contrario, i modelli meccanicistici richiedono un maggior numero di ipotesi iniziali e presentano una complessità analitica superiore. Questo investimento aggiuntivo viene ricompensato da un fondamentale vantaggio epistemologico: ci avvicinano alla logica metodologica delle scienze naturali, permettendoci di spiegare i dati osservati attraverso la formalizzazione di processi generativi sottostanti. In questo modo, non ci limitiamo a descrivere le relazioni tra variabili, ma cerchiamo di comprendere i meccanismi causali che le producono.\n\n\n\n\n\n\nDifferenza intuitiva\n\n\n\nUn modello fenomenologico si limita a descrivere una relazione osservabile, affermando ad esempio che “più ore di studio corrispondono a voti più alti”. Al contrario, un modello meccanicistico cerca di spiegare il processo sottostante questa relazione, proponendo ad esempio che “ogni sessione di studio incrementa la forza della traccia mnestica con un determinato tasso di apprendimento, il quale a sua volta influenza direttamente la probabilità di rispondere correttamente durante l’esame”.\nMentre il primo si concentra sul cosa accade, il secondo cerca di spiegare come e perché accade.\n\n\n\n\n\n\n\n\n\n\nModello fenomenologico: il focus è sulla forma della distribuzione e sui suoi parametri riassuntivi (media, varianza).\n\n\n\n\n\n\n\n\nModello meccanicistico: il focus è sul meccanismo nel tempo (apprendimento): \\(V_t\\) evolve in base all’errore di previsione e le osservazioni \\(Y_t\\) sono rumore attorno a \\(V_t\\).\n**Messaggio chiave:* descrivere associazioni vs spiegare processi generativi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_statistical_models.html#valutazione-e-confronto-dei-modelli",
    "href": "chapters/bayesian_inference/04_statistical_models.html#valutazione-e-confronto-dei-modelli",
    "title": "4  Modelli statistici",
    "section": "\n4.5 Valutazione e confronto dei modelli",
    "text": "4.5 Valutazione e confronto dei modelli\nOgni modello psicologico, che sia descrittivo o meccanicistico, costituisce una rappresentazione semplificata della realtà. Nessun modello può catturare interamente la complessità dei fenomeni psicologici: il suo valore scientifico dipende fondamentalmente dalla capacità di aiutarci a comprendere e prevedere i dati osservati.\n\n4.5.1 Due prospettive complementari\nLa valutazione dei modelli si articola su due dimensioni distinte ma complementari. Da un lato l’adeguatezza esplicativa, che misura quanto bene un modello riesce a descrivere i dati già osservati. Dall’altro la capacità predittiva, che valuta invece l’abilità del modello di generalizzare a nuovi dati non ancora raccolti.\nÈ importante notare come queste due dimensioni non sempre coincidano: un modello eccessivamente complesso può adattarsi perfettamente ai dati esistenti, mostrando un’eccellente adeguatezza esplicativa, ma rivelarsi al contempo incapace di fare previsioni accurate su dati nuovi, manifestando così una scarsa capacità predittiva.\n\n4.5.2 Confrontare i modelli\nLa crisi di replicazione ci ricorda che non basta adattare bene un modello ai dati disponibili: ciò che conta è la capacità di prevedere dati nuovi. È proprio qui che la valutazione e il confronto dei modelli diventano strumenti centrali per una psicologia più solida.\nIl confronto tra modelli rappresenta un aspetto cruciale della ricerca scientifica, poiché riconosce che per uno stesso fenomeno possono esistere multiple spiegazioni plausibili. Il compito del ricercatore consiste nell’identificare il modello che produce le rappresentazioni più utili e coerenti con la realtà osservata.\nQuesto confronto può avvenire sia tra approcci diversi che all’interno dello stesso paradigma. I modelli fenomenologici e meccanicistici, ad esempio, possono essere messi a confronto: mentre il primo si limita a descrivere le associazioni tra variabili, il secondo avanza ipotesi specifiche sui processi generatori dei dati. Allo stesso modo, due modelli meccanicistici alternativi – come diverse teorie dell’apprendimento – possono essere confrontati per determinare quale meglio spieghi il comportamento osservato.\n\n4.5.3 Anticipazione\nNei prossimi capitoli esploreremo le metodologie concrete per condurre questi confronti, introducendo strumenti statistici che quantificano oggettivamente la bontà predittiva dei modelli. In particolare:\n\napprofondiremo criteri statistici come la log-verosimiglianza, il WAIC e il LOO-CV, che permettono un confronto formale delle capacità predittive dei modelli;\nesamineremo casi di studio psicologici in cui modelli alternativi – come diversi modelli di apprendimento o processi decisionali – vengono sottoposti a verifica empirica sugli stessi dati.\n\nQuesto approccio ci permetterà di passare da valutazioni qualitative a giudizi quantitativi e rigorosi sulla bontà dei nostri modelli teorici.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nUn modello non è mai “vero” in senso assoluto: è più o meno utile. La valutazione e il confronto dei modelli sono strumenti fondamentali per rendere la psicologia una scienza cumulativa, in cui teorie diverse possono essere messe a confronto sulla base dei dati.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI modelli possono essere valutati secondo due prospettive fondamentali: quella esplicativa e quella predittiva.\nLa valutazione esplicativa (o fit del modello) misura quanto bene un modello riesce a descrivere i dati già osservati, ovvero quanto sia in grado di adattarsi alle informazioni in nostro possesso.\nLa valutazione predittiva (o validazione del modello) misura invece la capacità del modello di generalizzare, ovvero di fare previsioni accurate su dati nuovi, non ancora osservati e provenienti da outside del campione originario.\nIl messaggio chiave è che un modello statisticamente valido non è solo quello che spiega bene il passato, ma soprattutto quello che dimostra di saper prevedere in modo affidabile il futuro. La vera prova della bontà di un modello risiede nella sua capacità predittiva, non solo in quella descrittiva.\n\n4.5.4 Un esempio psicologico: scelte alimentari negli adolescenti\nImmaginiamo di voler studiare le scelte alimentari di un gruppo di adolescenti, osservando se scelgono uno snack salutare o non salutare in una serie di decisioni.\n\nApproccio fenomenologico Possiamo costruire una regressione logistica che predice la probabilità di scegliere lo snack salutare in funzione di alcune variabili, ad esempio il livello di stress e la disponibilità economica. Questo modello ci direbbe se lo stress è associato a una minore probabilità di fare scelte salutari, senza però chiarire perché avvenga.\nApproccio meccanicistico Possiamo invece ipotizzare un modello di apprendimento associativo (ad esempio il modello di Rescorla–Wagner): ad ogni prova, l’adolescente aggiorna le proprie aspettative di ricompensa per ciascuna opzione sulla base dell’esperienza precedente. In questo quadro, i dati delle scelte non sono solo correlati a variabili esterne, ma sono l’esito di un processo dinamico di apprendimento governato da parametri interpretabili (tasso di apprendimento, sensibilità alla ricompensa, variabilità decisionale).\n\n\n4.5.4.1 Confronto dei due modelli\nEntrambi i modelli possono adattarsi agli stessi dati, ma offrono spiegazioni molto diverse: la regressione descrive un’associazione “statica” tra stress e scelta, mentre il modello di apprendimento descrive un meccanismo dinamico, cioè come gli adolescenti aggiornano le loro preferenze. Valutare e confrontare i modelli significa allora chiedersi quale delle due rappresentazioni sia più utile: quella che ci dice solo quali variabili sono correlate, o quella che propone un processo psicologico plausibile alla base delle decisioni?\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nGli stessi dati possono essere interpretati con modelli diversi. Il confronto tra modelli non è un lusso, ma una necessità: ci permette di capire quale rappresentazione dei dati sia più informativa e più vicina ai processi psicologici reali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_statistical_models.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/04_statistical_models.html#riflessioni-conclusive",
    "title": "4  Modelli statistici",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo distinto tra due modi di intendere i modelli in psicologia:\n\ni modelli fenomenologici, che descrivono le relazioni osservabili tra variabili;\ni modelli meccanicistici, che cercano invece di rappresentare i processi psicologici che generano i dati.\n\nI primi hanno il vantaggio della semplicità e forniscono un punto di partenza utile per descrivere i fenomeni. I secondi, più complessi, ci permettono però di avvicinarci a una spiegazione: ci dicono non solo che cosa accade, ma anche come e perché accade.\nAbbiamo visto che la psicologia, per rafforzare la propria solidità scientifica, non può limitarsi all’analisi delle associazioni. È necessario un salto verso modelli che mettano al centro i meccanismi generativi. Solo così possiamo rendere le nostre teorie più precise, più testabili e più replicabili.\nUn altro punto fondamentale riguarda la valutazione dei modelli: non esiste un modello “vero” in senso assoluto, ma modelli più o meno utili. Per questo dobbiamo sempre confrontare alternative, verificare la loro capacità di spiegare i dati raccolti e soprattutto la loro forza nel prevedere dati nuovi.\nNei prossimi capitoli passeremo dal livello concettuale a quello operativo, vedendo come l’approccio bayesiano ci consenta di costruire e confrontare concretamente modelli fenomenologici e meccanicistici.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nL’uso dei modelli meccanicistici, insieme a strumenti di confronto basati sulla capacità predittiva, rappresenta una via promettente per affrontare la crisi di replicabilità in psicologia. Nei capitoli successivi vedremo come tradurre questi principi in pratiche concrete di analisi statistica e di modellazione.\n\n\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQual è il processo concettuale alla base della modellizzazione e dell’analisi statistica?\nCosa significa che un campione è indipendente e identicamente distribuito (iid) e perché questa assunzione è importante nei modelli statistici?\nCome si differenziano i modelli di campionamento da una singola distribuzione rispetto ai modelli di campioni multipli indipendenti?\nQual è la differenza tra regressione lineare semplice e regressione lineare multipla?\nIn che modo i modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, si differenziano dai modelli statistici tradizionali?\n\nConsegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nIl processo concettuale della modellizzazione e analisi statistica inizia con un problema reale e i dati raccolti su tale problema. Si costruisce quindi un modello probabilistico che rappresenta le conoscenze disponibili e il modo in cui i dati sono stati ottenuti. L’analisi viene condotta all’interno del modello, producendo conclusioni sui suoi parametri. Infine, i risultati vengono tradotti in inferenze sulla realtà, con lo scopo di migliorare la comprensione del fenomeno studiato.\nUn campione è detto indipendente e identicamente distribuito (iid) se le osservazioni sono indipendenti tra loro e seguono la stessa distribuzione di probabilità. Questa assunzione è fondamentale perché semplifica le analisi statistiche e permette di applicare risultati teorici importanti, come la legge dei grandi numeri e il teorema del limite centrale.\nNei modelli di campionamento da una singola distribuzione, si assume che tutte le osservazioni provengano da una stessa popolazione e seguano la stessa distribuzione. Nei modelli di campioni multipli indipendenti, invece, si confrontano più gruppi distinti, ciascuno con la propria distribuzione, per studiare differenze tra le popolazioni. Un esempio è il confronto tra altezze di individui con madri fumatrici e non fumatrici.\nLa regressione lineare semplice analizza la relazione tra una variabile dipendente e una sola variabile indipendente attraverso una relazione lineare. La regressione lineare multipla, invece, estende questo concetto a più variabili indipendenti, permettendo di modellare fenomeni più complessi e controllare l’effetto di più fattori simultaneamente.\nI modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, differiscono dai modelli statistici tradizionali perché mirano a simulare i processi mentali e decisionali sottostanti il comportamento umano. I modelli statistici descrivono principalmente relazioni tra variabili nei dati osservati, mentre i modelli computazionali cercano di rappresentare dinamicamente i meccanismi cognitivi e comportamentali che generano tali dati.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] yaml_2.3.10           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_statistical_models.html#bibliografia",
    "href": "chapters/bayesian_inference/04_statistical_models.html#bibliografia",
    "title": "4  Modelli statistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html",
    "href": "chapters/bayesian_inference/05_subj_prop.html",
    "title": "5  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo esaminato il ruolo fondamentale dell’incertezza nella ricerca psicologica e abbiamo visto come l’approccio bayesiano fornisca un linguaggio particolarmente adatto per rappresentarla. Abbiamo inoltre distinto tra modelli puramente fenomenologici, che si limitano a descrivere associazioni tra variabili, e modelli meccanicistici, che cercano invece di formalizzare i processi psicologici sottostanti.\nIn questo capitolo ci concentreremo su un caso di studio particolarmente comune e rilevante: l’inferenza sulla proporzione di successi in un compito sperimentale o in un campione di soggetti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#introduzione",
    "href": "chapters/bayesian_inference/05_subj_prop.html#introduzione",
    "title": "5  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "",
    "text": "5.0.1 Perché partire dalle proporzioni?\nUna parte significativa della ricerca psicologica si basa su dati di natura binaria: un soggetto che ricorda o non ricorda uno stimolo, un paziente che risponde o non risponde a una terapia, uno studente che sceglie o non sceglie l’opzione corretta in un compito cognitivo.\nIn tutti questi scenari, i dati si riducono essenzialmente a un conteggio di successi e insuccessi, e la quantità di interesse principale diventa la proporzione di successi nella popolazione o nel campione studiato.\nL’analisi di questo caso apparentemente semplice ci offre tre vantaggi fondamentali: in primo luogo, ci permette di stabilire un collegamento chiaro tra dati osservati e modelli probabilistici; in secondo luogo, ci aiuta a comprendere come i priori e i posteriori operano concretamente nel contesto di un modello Beta-Binomiale; infine, getta le basi per modelli più complessi che in seguito potranno descrivere non solo proporzioni statiche, ma veri e propri processi psicologici dinamici che generano le osservazioni.\n\n5.0.2 Collegamento con la crisi di replicazione\nMolti dei risultati controversi emersi in psicologia derivano da studi che confrontavano proporzioni tra diversi gruppi sperimentali - si pensi ad esempio alla percentuale di partecipanti che mostrano un certo effetto. Una delle criticità principali di questi studi è stata la tendenza a presentare queste proporzioni come stime puntuali, tralasciando una adeguata rappresentazione dell’incertezza associata.\nL’approccio bayesiano supera questa limitazione consentendo di comunicare non solo quale sia la proporzione più plausibile, ma anche quanto dubbio residuo permanga attorno a questa stima. Questa trasparenza favorisce interpretazioni più equilibrate e cumulative dei risultati, contribuendo così ad affrontare uno dei fattori che hanno alimentato la crisi di replicabilità nel campo.\nPanoramica del capitolo\n\nApplicare l’aggiornamento bayesiano per affinare credenze.\nRappresentare distribuzioni a priori (discrete e continue).\nCalcolare la verosimiglianza e aggiornare la distribuzione a priori.\nDerivare e interpretare la distribuzione a posteriori.\nUsare il metodo a griglia per approssimare la distribuzione a posteriori.\nApplicare il modello binomiale per stimare probabilità e incertezze.\nCalcolare medie, mode e intervalli di credibilità.\nUtilizzare la distribuzione Beta come prior continuo.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il settimo capitolo del testo di Albert & Hu (2019).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(HDInterval)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/05_subj_prop.html#verosimiglianza-binomiale",
    "title": "5  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n5.1 Verosimiglianza binomiale",
    "text": "5.1 Verosimiglianza binomiale\nNei capitoli precedenti abbiamo visto che l’approccio bayesiano rappresenta l’incertezza con distribuzioni di probabilità. Ora possiamo tradurre questa idea in un caso concreto molto comune nella ricerca psicologica: quando osserviamo una sequenza di successi e insuccessi. Questo tipo di dati non è raro: pensiamo a uno studente che risponde a una serie di domande (corretto/errato), a un paziente che mostra o non mostra un miglioramento, a un partecipante che sceglie o non sceglie un certo stimolo. In questi casi, la distribuzione che descrive le probabilità dei possibili conteggi di successi si chiama distribuzione binomiale. Essa rappresenta il cuore del modello fenomenologico più semplice per i dati binari: il modello binomiale.\nLa distribuzione binomiale descrive il numero di successi \\(y\\) in \\(n\\) prove indipendenti, ciascuna con probabilità di successo \\(\\theta\\):\n\\[\np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y},\n\\]\ndove \\(\\theta\\) rappresenta la probabilità di successo per singola prova, \\(y\\) è il numero osservato di successi e \\(n\\) è il numero totale di prove (fissato a priori).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#esempio-psicologico-giudizio-morale-in-un-dilemma",
    "href": "chapters/bayesian_inference/05_subj_prop.html#esempio-psicologico-giudizio-morale-in-un-dilemma",
    "title": "5  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n5.2 Esempio psicologico: giudizio morale in un dilemma",
    "text": "5.2 Esempio psicologico: giudizio morale in un dilemma\nI dilemmi morali, come il classico problema del treno (Foot, 1967; Greene et al., 2001), sono strumenti usati in psicologia per indagare come le persone prendono decisioni etiche (per es., Bucciarelli et al., 2008). Supponiamo che un ricercatore voglia stimare la proporzione di adulti che considerano accettabile compiere un’azione moralmente controversa (ad es. deviare un treno per salvare cinque persone, causando però la morte di una persona).\nOgni partecipante legge un singolo scenario morale e deve dare una risposta binaria:\n\n1 = giudica l’azione come moralmente accettabile (successo),\n0 = giudica l’azione come non accettabile (fallimento).\n\nIn un campione di 30 soggetti indipendenti, 22 hanno giudicato l’azione accettabile.\nIn questo scenario:\n\nciascun soggetto fornisce un unico giudizio (unità di osservazione indipendente),\nogni risposta è una variabile di Bernoulli con probabilità di successo \\(\\theta\\),\nil numero totale di giudizi favorevoli segue una distribuzione binomiale:\n\n\\[\nY \\sim \\text{Binomiale}(n = 30, \\theta),\n\\]\ndove \\(Y = 22\\) rappresenta il numero di successi osservati.\n\n5.2.1 Obiettivo inferenziale\nIl nostro scopo è stimare \\(\\theta\\): la probabilità che un adulto, scelto a caso dalla popolazione, giudichi moralmente accettabile l’azione descritta nel dilemma. Nel quadro bayesiano combiniamo:\n\nla verosimiglianza (dati osservati: 22 su 30),\nuna distribuzione a priori (credenze iniziali su \\(\\theta\\)),\n\nottenendo la distribuzione a posteriori, che rappresenta la nostra conoscenza aggiornata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia",
    "title": "5  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n5.3 Metodo basato su griglia",
    "text": "5.3 Metodo basato su griglia\nIl metodo basato su griglia è un approccio intuitivo e didatticamente efficace per approssimare una distribuzione a posteriori. La sua semplicità lo rende ideale per comprendere il meccanismo di aggiornamento delle credenze. L’idea fondamentale è di discretizzare lo spazio dei parametri e calcolare la distribuzione a posteriori in punti isolati, evitando il ricorso a metodi analitici complessi.\nI passaggi operativi sono i seguenti:\n\n\nDefinizione della griglia: Si suddivide l’intervallo dei valori plausibili per il parametro di interesse (ad esempio, \\(\\theta\\), compreso tra 0 e 1) in una sequenza finita di punti equidistanti.\n\nCalcolo della verosimiglianza: Per ogni punto \\(\\theta_i\\) sulla griglia, si calcola la funzione di verosimiglianza \\(P(D \\mid \\theta_i)\\), che rappresenta la probabilità di osservare i dati \\(D\\) dato quel specifico valore del parametro.\n\nProdotto priori-verosimiglianze: Per ogni punto della griglia, si moltiplica il valore della verosimiglianza per il valore della distribuzione a priori \\(P(\\theta_i)\\). Questo prodotto è proporzionale alla distribuzione a posteriori non normalizzata.\n\nNormalizzazione: I valori ottenuti nel passo precedente vengono sommati e ciascuno di essi è diviso per questa somma totale. Il risultato è una distribuzione di probabilità discreta a posteriori valida, i cui valori per ogni \\(\\theta_i\\) sommano a 1.\n\nIl risultato finale è un’approssimazione della vera distribuzione a posteriori continua, che mostra in modo chiaro come l’evidenza fornita dai dati (\\(D\\)) abbia aggiornato e modificato le credenze iniziali (la distribuzione a priori) sul parametro \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "5  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n5.4 Aggiornamento bayesiano con una distribuzione a priori discreta",
    "text": "5.4 Aggiornamento bayesiano con una distribuzione a priori discreta\n\n5.4.1 Costruzione della distribuzione a priori\nIn assenza di informazioni specifiche, possiamo assumere che tutti i valori di \\(\\theta\\) siano ugualmente plausibili. Per implementare concretamente questo approccio:\n\ndefiniamo un insieme discreto di valori possibili per \\(\\theta\\): {0, 0.1, 0.2, …, 1},\n\nassegniamo a ciascun valore la stessa probabilità a priori: \\(p(\\theta) = 1/11 \\approx 0.09\\).\n\nQuesta scelta rappresenta uno stato di massima incertezza iniziale, dove nessun valore di \\(\\theta\\) risulta a priori più plausibile di altri.\n\n5.4.2 Aggiornamento con i dati\nAbbiamo osservato \\(y = 22\\) giudizi di accettabilità su \\(n = 30\\) partecipanti. Per ogni valore \\(\\theta\\) nella griglia:\n\n\ncalcoliamo la verosimiglianza binomiale:\n\\[\np(y \\mid \\theta) = \\theta^{22}(1-\\theta)^8 ,\n\\]\ndove \\(\\theta\\) rappresenta la probabilità che un adulto giudichi l’azione come moralmente accettabile,\n\nmoltiplichiamo per la probabilità a priori,\nnormalizziamo dividendo per la somma totale di tutti i prodotti ottenuti.\n\nIl risultato è una distribuzione a posteriori discreta che mostra come l’osservazione aggiorna le nostre credenze iniziali. I valori di \\(\\theta\\) vicini a \\(22/30 \\approx 0.7\\) ricevono una maggiore probabilità a posteriori.\n\n5.4.3 Interpretazione\n\nPrima dei dati, ogni valore di \\(\\theta\\) era ugualmente plausibile.\n\nDopo i dati, valori come \\(\\theta = 0.7\\) o \\(0.75\\) hanno alta probabilità a posteriori.\n\nValori estremi (\\(0.2\\), \\(0.9\\)) diventano poco plausibili.\n\nIn altre parole, la distribuzione a posteriori concentra la massa di probabilità attorno ai valori che rendono i dati osservati più plausibili.\n\n5.4.4 Implementazione in R\nDefinizione della griglia:\n\ntheta &lt;- seq(0, 1, by = 0.1)  # Griglia di valori da 0 a 1 con passo 0.1\n\nQuando non abbiamo informazioni preliminari, usiamo una distribuzione uniforme:\n\npriori_unif &lt;- rep(1 / length(theta), length(theta))  # Probabilità uniformi\n\nVisualizziamo questa distribuzione:\n\nggplot(data.frame(theta, prob = priori_unif), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"Densità di probabilità\")\n\n\n\n\n\n\n\nSe invece riteniamo più probabili valori centrali di \\(\\theta\\):\n\npriori_inf &lt;- c(\n  0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05\n)\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = priori_inf), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"Densità di probabilità\")\n\n\n\n\n\n\n\nVerosimiglianza:\n\nverosimiglianza &lt;- dbinom(22, size = 30, prob = theta)\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = verosimiglianza), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"L(θ|dati)\")\n\n\n\n\n\n\n\nCalcolo della distribuzione a posteriori:\n\nposteriori_non_norm &lt;- priori_inf * verosimiglianza\nposteriori &lt;- posteriori_non_norm / sum(posteriori_non_norm)  # Normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = posteriori), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(x = expression(theta),\n       y = \"P(θ|dati)\")\n\n\n\n\n\n\n\nStatistiche descrittive:\n\nmedia_post &lt;- sum(theta * posteriori)\nvar_post &lt;- sum(theta^2 * posteriori) - media_post^2\nmoda_post &lt;- theta[which.max(posteriori)]\n\ncat(\"Media a posteriori:\", round(media_post, 3),\n    \"\\nVarianza a posteriori:\", round(var_post, 3),\n    \"\\nModa a posteriori:\", moda_post)\n#&gt; Media a posteriori: 0.689 \n#&gt; Varianza a posteriori: 0.005 \n#&gt; Moda a posteriori: 0.7\n\nInterpretazione grafici. Il grafico della verosimiglianza mostra un picco tra 0.6 e 0.8: significa che questi valori di \\(\\theta\\) rendono i dati osservati particolarmente plausibili. La combinazione con il prior porta la curva a posteriori ad accentuare o attenuare questa evidenza, a seconda della distribuzione iniziale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "5  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n5.5 Aggiornamento bayesiano con una distribuzione a priori continua",
    "text": "5.5 Aggiornamento bayesiano con una distribuzione a priori continua\nUn’estensione naturale è usare una distribuzione continua come priori. La più adatta nel caso di proporzioni è la Beta:\n\nsupporto: \\(\\[0,1]\\) (come \\(\\theta\\)),\nconiugata della Binomiale (la posteriori è ancora una Beta),\nparametri: \\(\\text{Beta}(\\alpha, \\beta)\\).\n\nEsempi:\n\n\n\\(\\text{Beta}(2,2)\\): priori simmetrica e non troppo informativa,\n\n\\(\\text{Beta}(2,5)\\): priori che privilegia valori bassi di \\(\\theta\\).\n\n\n5.5.1 Implementazione in R\nCalcoliamo la densità della distribuzione \\(\\text{Beta}(2, 2)\\) su una griglia fine di valori di \\(\\theta\\):\n\ntheta &lt;- seq(0, 1, length.out = 1000)\nprior_beta_2_2 &lt;- dbeta(theta, 2, 2)\n\nVisualizzazione:\n\nggplot(data.frame(theta, prior = prior_beta_2_2), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2, color = \"#5d5349\") +\n  labs(x = expression(theta), y = \"Densità\")\n\n\n\n\n\n\n\nContinuiamo con l’esempio precedente, in cui 22 partecipanti su 30 hanno giudicato l’azione come moralmente accettabile. La verosimiglianza associata a ciascun valore di \\(\\theta\\) è calcolata come:\n\nlikelihood &lt;- dbinom(22, size = 30, prob = theta)\n\nPoiché il prior è continuo, otteniamo la distribuzione a posteriori moltiplicando punto a punto la densità a priori per la verosimiglianza, e normalizzando:\n\nposterior_unnorm &lt;- prior_beta_2_2 * likelihood\nposterior &lt;- posterior_unnorm / sum(posterior_unnorm)\n\nVisualizziamo le tre curve (per gli scopi della visualizzazione, standardizziamo ciascuna distribuzione):\n\ndf &lt;- data.frame(\n  theta, \n  prior = prior_beta_2_2 / sum(prior_beta_2_2), \n  likelihood = likelihood / sum(likelihood), \n  posterior\n  )\n\ndf_long &lt;- df |&gt;\n  pivot_longer(cols = c(\"prior\", \"likelihood\", \"posterior\"),\n               names_to = \"Distribuzione\", values_to = \"Densità\")\n\nggplot(df_long, aes(x = theta, y = Densità, color = Distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(x = expression(theta), y = \"Densità\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nOra consideriamo una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di \\(\\theta\\).\n\nprior_2_5 &lt;- dbeta(theta, 2, 5)\nposterior &lt;- (prior_2_5 * likelihood) / sum(prior_2_5 * likelihood)\n\nVisualizziamo le tre distribuzioni:\n\ndf &lt;- data.frame(\n  theta, \n  prior = prior_2_5 / sum(prior_2_5), \n  likelihood = likelihood / sum(likelihood), \n  posterior\n  )\n\ndf_long &lt;- df |&gt;\n  pivot_longer(cols = c(\"prior\", \"likelihood\", \"posterior\"),\n               names_to = \"Distribuzione\", values_to = \"Densità\")\n\nggplot(df_long, aes(x = theta, y = Densità, color = Distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(x = expression(theta), y = \"Densità\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nInterpretazione. L’aggiornamento bayesiano con una distribuzione a priori continua fornisce una stima aggiornata di \\(\\theta\\), la probabilità che un adulto giudichi moralmente accettabile l’azione proposta nel dilemma. Questa stima tiene conto sia delle credenze iniziali (prior) sia dell’evidenza empirica (verosimiglianza).\nNel nostro esempio, la distribuzione a posteriori risulta spostata verso valori alti rispetto al prior simmetrico \\(\\text{Beta}(2,2)\\), riflettendo l’evidenza che 22 partecipanti su 30 hanno espresso un giudizio di accettabilità. In alternativa, utilizzando un prior asimmetrico come \\(\\text{Beta}(2,5)\\), la distribuzione a posteriori mostra un compromesso: da un lato la tendenza iniziale a ritenere poco probabile l’accettazione morale, dall’altro i dati osservati che indicano una proporzione maggiore di giudizi favorevoli.\nSintesi didattica. Questo esempio illustra il cuore dell’inferenza bayesiana: la conoscenza non è mai statica, ma si aggiorna continuamente integrando dati empirici e credenze iniziali in modo trasparente e quantitativo.\n\n\n\n\n\n\nApprofondimento — Metodo su griglia con la Normale (media ignota, \\(\\sigma\\) nota)\n\n\n\n\n\nIl metodo su griglia non vale solo per la Binomiale: si applica anche al caso Normale quando vogliamo stimare la media \\(\\mu\\) assumendo la deviazione standard nota. L’idea è la stessa: scegliamo una griglia di valori plausibili per \\(\\mu\\), calcoliamo la verosimiglianza per ciascun valore, la combiniamo con il prior e normalizziamo per ottenere la posterior.\nScenario. Studiamo i punteggi di QI di bambini ad alto potenziale. Supponiamo che i punteggi seguano una Normale con deviazione standard nota \\(\\sigma = 5\\), mentre la media \\(\\mu\\) è ignota. Usiamo un prior informativo \\(\\mu \\sim \\mathcal{N}(140, 3^2)\\).\n\n5.5.2 Dati ed elementi del modello\n\nset.seed(123)\ncampione &lt;- round(rnorm(10, mean = 130, sd = 5))  # 10 osservazioni simulate\ncampione\n#&gt;  [1] 127 129 138 130 131 139 132 124 127 128\nsigma &lt;- 5\n\nLa verosimiglianza congiunta per un dato \\(\\mu\\) è il prodotto delle densità Normali:\n\\[\nL(\\mu) \\;=\\; \\prod_{i=1}^n \\text{Normal}\\bigl(y_i \\mid \\mu, \\sigma\\bigr).\n\\]\nNel calcolo numerico conviene usare i logaritmi (stabilità): il prodotto diventa somma.\n\n5.5.3 Metodo su griglia (versione stabile)\n\n# Griglia di valori plausibili per mu: centrata tra prior e dati\nmu_griglia &lt;- seq(120, 150, length.out = 400)\n\n# Log-verosimiglianza: somma delle densità log-normali\nlog_lik &lt;- sapply(mu_griglia, function(mu)\n  sum(dnorm(campione, mean = mu, sd = sigma, log = TRUE))\n)\n\n# Prior (log-densità normale): mu ~ N(140, 3^2)\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\n\n# Log-posterior non normalizzata\nlog_post_unnorm &lt;- log_lik + log_prior\n\n# Normalizzazione numericamente stabile (log-sum-exp)\nlog_post_stab &lt;- log_post_unnorm - max(log_post_unnorm)\npost &lt;- exp(log_post_stab)\npost &lt;- post / sum(post)  # posterior discreta sulla griglia (somma = 1)\n\n# Sommari deterministici (somme pesate sulla griglia)\npost_mean &lt;- sum(mu_griglia * post)\npost_var  &lt;- sum((mu_griglia - post_mean)^2 * post)\npost_sd   &lt;- sqrt(post_var)\n\nc(media_post = post_mean, sd_post = post_sd)\n#&gt; media_post    sd_post \n#&gt;      132.6        1.4\n\n\n5.5.4 Visualizzare prior, verosimiglianza e posterior\nPer confrontare forme diverse (prior, verosimiglianza, posterior) portiamo verosimiglianza e prior “in scala comparabile” (solo a fini grafici).\n\n# Rescaling per confronto visivo (non usato nei calcoli)\nprior_vis &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\nprior_vis &lt;- prior_vis / max(prior_vis)\n\nlik_vis   &lt;- exp(log_lik - max(log_lik))  # anche qui versione stabile\n\ndf &lt;- tibble(\n  mu = mu_griglia,\n  Prior = prior_vis,\n  Verosimiglianza = lik_vis,\n  Posterior = post / max(post)\n)\n\ndf |&gt;\n  pivot_longer(-mu, names_to = \"Distribuzione\", values_to = \"Densita\") |&gt;\n  ggplot(ggplot2::aes(x = mu, y = Densita, color = Distribuzione)) +\n  geom_line(linewidth = 1.1) +\n  geom_vline(xintercept = mean(campione), linetype = \"dashed\") +\n  geom_vline(xintercept = 140, linetype = \"dotted\") +\n  geom_vline(xintercept = post_mean, linetype = \"dotdash\") +\n  labs(\n    x = expression(mu), y = \"Scala comparabile\\n(solo per confronto visivo)\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nCome leggere il grafico. La verosimiglianza (linea centrata sulla media campionaria) riflette dove i dati sono più plausibili; il prior rappresenta la conoscenza iniziale (centrata a 140); la posterior è il compromesso bayesiano tra i due. Con più dati, la posterior tende ad avvicinarsi e a stringersi attorno alla media empirica.\n\n5.5.5 Collegamento con la soluzione analitica (conjugacy)\nNel caso Normale con \\(\\sigma\\) nota e prior Normale per \\(\\mu\\), la posterior è ancora Normale:\n\\[\n\\mu \\mid y \\;\\sim\\; \\mathcal{N}\\!\\Bigl(\\,\\mu_\\text{post},\\, \\tau_\\text{post}^2\\Bigr),\n\\]\ndove\n\\[\n\\tau_\\text{post}^2\n= \\left(\\frac{n}{\\sigma^2} + \\frac{1}{\\tau_0^2}\\right)^{-1},\n\\qquad\n\\mu_\\text{post}\n= \\tau_\\text{post}^2\\left(\\frac{n\\,\\bar y}{\\sigma^2} + \\frac{\\mu_0}{\\tau_0^2}\\right).\n\\]\nQui \\(\\mu\\_0=140\\) e \\(\\tau\\_0=3\\) sono media e deviazione standard del prior; \\(\\bar y\\) è la media campionaria.\nVerifichiamo numericamente l’accordo con la griglia:\n\nn      &lt;- length(campione)\nybar   &lt;- mean(campione)\nmu0    &lt;- 140\ntau0   &lt;- 3\n\ntau2_post &lt;- 1 / (n / sigma^2 + 1 / tau0^2)\nmu_post   &lt;- tau2_post * (n * ybar / sigma^2 + mu0 / tau0^2)\nsd_post   &lt;- sqrt(tau2_post)\n\nc(analitico_media = mu_post, analitico_sd = sd_post,\n  griglia_media   = post_mean, griglia_sd   = post_sd)\n#&gt; analitico_media    analitico_sd   griglia_media      griglia_sd \n#&gt;           132.6             1.4           132.6             1.4\n\nI risultati coincidono (entro il passo di griglia), mostrando che il metodo su griglia “ricostruisce” la soluzione coniugata. Questo è didatticamente utile: gli studenti vedono sia la meccanica computazionale (griglia + normalizzazione) sia la struttura teorica (conjugacy).\n\n5.5.6 Nota numerica: perché i logaritmi\nLa verosimiglianza congiunta è il prodotto di molte densità, quindi può diventare numericamente piccolissima. Usare le somme dei logaritmi evita l’underflow e rende stabile la normalizzazione finale (tramite il trucco “log-sum-exp”). È una buona pratica anche con campioni moderati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_subj_prop.html#riflessioni-conclusive",
    "title": "5  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo affrontato uno dei casi più fondamentali dell’inferenza statistica: la stima della proporzione di successi. Attraverso la combinazione della verosimiglianza binomiale con un prior Beta, abbiamo visto come il teorema di Bayes ci consenta di ottenere una distribuzione a posteriori che rappresenta in maniera trasparente la nostra incertezza riguardo al parametro di interesse. Questo esempio, per quanto elementare, ci permette di osservare in azione la logica dell’aggiornamento bayesiano presentata nei capitoli precedenti: ciò che sapevamo prima viene modificato dalla nuova evidenza empirica, producendo credenze aggiornate che incorporano tanto le informazioni pregresse quanto i dati osservati.\nQuesta applicazione mette in luce un punto centrale che ha accompagnato tutta la nostra discussione fino a qui: l’incertezza non è un ostacolo da eliminare, ma una componente intrinseca e inevitabile dell’inferenza scientifica. Al contrario di quanto avviene in molti approcci tradizionali, dove il risultato viene spesso ridotto a un singolo numero o a un verdetto dicotomico, il metodo bayesiano ci offre una rappresentazione più onesta e informativa, in cui diversi valori rimangono plausibili con gradi di sostegno differenti. La distinzione tra conoscenza preliminare (prior), evidenza empirica (dati) e credenze aggiornate (posterior) fornisce così un quadro concettuale coerente e cumulativo, che si integra con le riflessioni sviluppate nei capitoli precedenti sulla crisi di replicabilità e sulla necessità di modelli trasparenti e confrontabili.\nDal punto di vista computazionale, l’approccio basato su griglia che abbiamo utilizzato si è rivelato particolarmente utile come strumento didattico. La sua logica è semplice e intuitiva: si discretizza lo spazio dei parametri, si calcolano prior e verosimiglianza in ciascun punto e si normalizza per ottenere una distribuzione coerente di probabilità. Questa procedura esplicita, anche se rudimentale, permette di visualizzare con chiarezza i passaggi fondamentali dell’inferenza bayesiana e di comprenderne la natura dinamica. Tuttavia, sappiamo che la sua utilità pratica diminuisce rapidamente con l’aumentare della complessità dei modelli: la cosiddetta maledizione della dimensionalità1 rende presto insostenibile il calcolo.\nQuesta consapevolezza ci prepara ad affrontare, nei prossimi capitoli, strumenti più sofisticati come i metodi di campionamento MCMC. Essi sono concettualmente più complessi, ma offrono la potenza computazionale necessaria per affrontare modelli realistici e a più alta dimensionalità, mantenendo però intatta la logica di fondo che abbiamo visto emergere anche nel caso semplice del modello binomiale. In questo senso, il metodo a griglia conserva il suo valore formativo: è un punto di accesso privilegiato al pensiero bayesiano, un laboratorio concettuale in cui gli studenti possono osservare direttamente come si realizza l’aggiornamento delle credenze, prima di cimentarsi con strumenti più potenti e astratti.\n\n\n\n\n\n\nMessaggio chiave\n\n\n\nPartire da casi semplici come la proporzione di successi ci aiuta a capire in profondità l’idea centrale: l’inferenza bayesiana non fornisce un numero definitivo, ma una distribuzione che rappresenta i valori plausibili e il grado di incertezza associato. Nei prossimi capitoli vedremo come questa logica si estenda a modelli più articolati, inclusi quelli che cercano di rappresentare i processi psicologici che generano i dati.\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn uno studio sulla percezione delle emozioni, un partecipante osserva 10 fotografie di volti arrabbiati. Deve indicare se il volto esprime rabbia o no. Ogni risposta può essere corretta (1) o errata (0).\nI dati osservati del partecipante sono:\n1, 0, 1, 1, 1, 0, 0, 1, 1, 1\n→ Totale: 7 successi su 10 prove → \\(y = 7\\), \\(n = 10\\).\nObiettivo: stimare la probabilità \\(\\theta\\) che il partecipante riconosca correttamente un volto arrabbiato, tenendo conto sia dei dati osservati sia di conoscenze pregresse.\nPrior Informativo.\nSupponiamo di voler adottare un approccio cautamente pessimistico sulle capacità iniziali del partecipante, basandoci su studi precedenti che indicano un riconoscimento della rabbia non sempre accurato, ad esempio mediamente intorno al 40% con moderata incertezza.\nPer rappresentare questa convinzione, scegliamo come distribuzione a priori una Beta(4, 6):\n\n\nMedia: \\(\\mu = \\frac{4}{4+6} = 0.4\\)\n\n\nVarianza: \\(\\frac{4 \\cdot 6}{(10)^2 \\cdot 11} = 0.0218\\)\n\n\nQuesta prior concentra la massa di probabilità su valori inferiori a 0.5, ma lascia spazio anche a livelli di competenza superiori.\nCalcolo della Distribuzione a Posteriori con il Metodo Basato su Griglia.\n1. Griglia di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, length.out = 1000)\nhead(theta)\n#&gt; [1] 0.00000 0.00100 0.00200 0.00300 0.00400 0.00501\ntail(theta)\n#&gt; [1] 0.995 0.996 0.997 0.998 0.999 1.000\n\n2. Calcolo della distribuzione a priori Beta(4, 6).\n\nprior &lt;- dbeta(theta, shape1 = 4, shape2 = 6)\nprior &lt;- prior / sum(prior)  # normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, prior), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n3. Calcolo della verosimiglianza per 7 successi su 10.\n\nlikelihood &lt;- dbinom(7, size = 10, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, likelihood), aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n4. Calcolo della distribuzione a posteriori.\n\nunnormalized_posterior &lt;- prior * likelihood\nposterior &lt;- unnormalized_posterior / sum(unnormalized_posterior)\n\n5. Visualizzazione congiunta: prior, likelihood e posteriori.\n\ndata &lt;- data.frame(theta, prior, likelihood, posterior)\n\n# Imposta i livelli desiderati con nomi leggibili\nlong_data &lt;- pivot_longer(\n  data,\n  cols = c(\"prior\", \"likelihood\", \"posterior\"),\n  names_to = \"distribution\",\n  values_to = \"density\"\n) |&gt;\n  mutate(distribution = factor(\n    distribution,\n    levels = c(\"prior\", \"likelihood\", \"posterior\"),\n    labels = c(\"A Priori\", \"Verosimiglianza\", \"A Posteriori\")\n    )\n  )\n\nggplot(\n  long_data, \n  aes(x = theta, y = density, color = distribution)\n  ) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Densità (normalizzata)\",\n    color = NULL\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nRiepilogo:\n\nla prior (Beta(4,6)) riflette una convinzione iniziale più scettica;\nla verosimiglianza è centrata su \\(\\theta = 0.7\\), corrispondente a 7 successi su 10;\nla posteriori media tra prior e dati, ma si sposta chiaramente verso destra, evidenziando l’effetto aggiornamento bayesiano.\n\nQuesto esempio mostra come l’approccio bayesiano:\n\n\nintegra in modo trasparente dati individuali e credenze pregresse;\n\nproduce una stima personalizzata della capacità del partecipante;\npermette di quantificare l’incertezza in modo completo, tramite la distribuzione a posteriori.\n\nQuantità a Posteriori.\nMedia:\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.55\n\nDeviazione standard:\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.109\n\nModa:\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.556\n\nIntervallo di credibilità al 94%:\n\nsamples &lt;- sample(theta, size = 10000, replace = TRUE, prob = posterior)\nquantile(samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 0.342 0.750\n\nQuesto esercizio mostra come:\n\nl’informazione pregressa può essere incorporata in modo trasparente in un modello bayesiano;\nla posteriori riflette una combinazione tra dati osservati e conoscenze precedenti.\n\n\n\n\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nIn uno studio sull’analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicità, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull’informazione che la condivisione dei materiali è un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l’intervallo di credibilità al 89%.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Definizione dei possibili valori di theta (probabilità discreta)\ntheta &lt;- seq(0.05, 0.95, by = 0.10)\n\n# Definizione della distribuzione a priori\nprior &lt;- c(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02)\n\n# Normalizzazione della prior (se necessario, ma in questo caso già normalizzata)\nprior &lt;- prior / sum(prior)\n\n# Dati osservati\nsuccessi &lt;- 20  # studi che hanno condiviso materiali\nn &lt;- 100        # studi totali\n\n# Calcolo della verosimiglianza usando la distribuzione binomiale\nlikelihood &lt;- dbinom(successi, size = n, prob = theta)\n\n# Calcolo della distribuzione a posteriori (applicazione del teorema di Bayes)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n# Calcolo della media della distribuzione a posteriori\nposterior_mean &lt;- sum(theta * posterior)\n\n# Calcolo dell'intervallo di credibilità al 89%\ncdf &lt;- cumsum(posterior)  # Distribuzione cumulativa\nlower_bound &lt;- theta[which.min(abs(cdf - 0.055))]  # 5.5% quantile\nupper_bound &lt;- theta[which.min(abs(cdf - 0.945))]  # 94.5% quantile\n\n# Output dei risultati\nlist(\n  posterior_mean = posterior_mean,\n  credibility_interval_89 = c(lower_bound, upper_bound)\n)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nL’obiettivo di questo esercizio è applicare il metodo basato su griglia per stimare la distribuzione a posteriori di una proporzione, utilizzando dati dalla Scala della Rete Sociale di Lubben (LSNS-6). Si assume che un punteggio LSNS-6 superiore a una soglia prefissata indichi isolamento sociale. Il compito è:\n\nScegliere una soglia per classificare i partecipanti in due gruppi (isolati vs. non isolati), garantendo che la proporzione osservata non sia inferiore a 0.1 o superiore a 0.9.\nCalcolare la distribuzione a posteriori della proporzione usando un’approssimazione discreta su una griglia di valori.\nDeterminare l’intervallo di credibilità all’89%.\nInterpretare i risultati.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nDati e Modellizzazione\nSi assume che i dati siano rappresentati da una variabile binaria \\(y\\), con \\(y = 1\\) per individui classificati come isolati e \\(y = 0\\) altrimenti. Supponiamo che su un campione di \\(n\\) individui, \\(s\\) siano isolati.\nDefiniamo il modello statistico:\n\\[ y_i \\sim \\text{Bernoulli}(\\theta) \\]\ncon:\n\n\n\\(y_i \\in \\{0,1\\}\\) per \\(i=1,\\dots,n\\),\n\n\\(\\theta\\) proporzione di individui isolati nella popolazione.\n\nLa distribuzione a priori su \\(\\theta\\) è scelta come \\(\\text{Beta}(2,2)\\), che rappresenta una conoscenza iniziale moderata e non estrema.\nMetodo basato su griglia\nIl metodo a griglia approssima la distribuzione a posteriori calcolando la probabilità per una serie di valori discreti di \\(\\theta\\).\n\n\nDefinire una griglia di valori per \\(\\theta\\):\ntheta &lt;- seq(0, 1, length.out = 100)\n\n\nCalcolare la distribuzione a priori:\nprior &lt;- dbeta(theta, 2, 2)\nprior &lt;- prior / sum(prior)  # Normalizzazione\n\n\nCalcolare la verosimiglianza:\nlikelihood &lt;- dbinom(s, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # Normalizzazione\n\n\nCalcolare la distribuzione a posteriori:\nposterior &lt;- prior * likelihood\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n\n** Calcolo dell’intervallo di credibilità all’89%**\nL’intervallo di credibilità è calcolato come l’intervallo che contiene il 89% della probabilità a posteriori.\nci_89 &lt;- quantile(sample(theta, size = 10000, prob = posterior, replace = TRUE), probs = c(0.055, 0.945))\nci_89\nInterpretazione dei risultati\n\n\nValore atteso e moda a posteriori:\nmean_theta &lt;- sum(theta * posterior)\nmode_theta &lt;- theta[which.max(posterior)]\n\nIl valore atteso fornisce una stima puntuale di \\(\\theta\\).\nLa moda indica il valore più probabile della proporzione di isolamento sociale.\n\n\n\nIntervallo di credibilità:\n\nL’89% della probabilità a posteriori cade tra i valori dell’intervallo di credibilità.\nSe l’intervallo è stretto, c’è maggiore certezza sulla proporzione stimata.\nSe l’intervallo è ampio, vi è maggiore incertezza sulla proporzione.\n\n\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HDInterval_0.2.4      pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           yaml_2.3.10           knitr_1.50           \n#&gt; [19] labeling_0.4.3        bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [22] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [25] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [28] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [31] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [34] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [37] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [40] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [43] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [46] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [49] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [52] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [55] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [58] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [61] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [64] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [67] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [70] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [73] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [76] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [79] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#bibliografia",
    "href": "chapters/bayesian_inference/05_subj_prop.html#bibliografia",
    "title": "5  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBucciarelli, M., Khemlani, S., & Johnson-Laird, P. N. (2008). The psychology of moral reasoning. Judgment and Decision making, 3(2), 121–139.\n\n\nFoot, P. (1967). The problem of abortion and the doctrine of the double effect. Oxford Review, 5, 5–15.\n\n\nGreene, J. D., Sommerville, R. B., Nystrom, L. E., Darley, J. M., & Cohen, J. D. (2001). An fMRI investigation of emotional engagement in moral judgment. Science, 293(5537), 2105–2108.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014–2017). Perspectives on Psychological Science, 17(1), 239–251.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/05_subj_prop.html#footnotes",
    "title": "5  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "",
    "text": "La maledizione della dimensionalità si riferisce al fatto che lo spazio dei parametri cresce in modo esponenziale con il numero delle dimensioni. Se, ad esempio, dividiamo ogni parametro in 100 possibili valori e vogliamo esplorare un modello con 10 parametri, dovremmo valutare \\(100^{10} = 10^{20}\\) combinazioni: un numero astronomico, impossibile da gestire con un approccio esaustivo a griglia. Questo rende necessarie tecniche di campionamento più efficienti, come i metodi Monte Carlo che introdurremo nei capitoli successivi.↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families.html",
    "href": "chapters/bayesian_inference/06_conjugate_families.html",
    "title": "6  Distribuzioni coniugate",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto in azione l’aggiornamento bayesiano in un caso concreto: la stima della proporzione di successi con il modello Beta-Binomiale. Lì abbiamo osservato come la distribuzione a priori (Beta) e la verosimiglianza (Binomiale) si combinino attraverso il teorema di Bayes per produrre una distribuzione a posteriori che appartiene alla stessa famiglia della prior. Questo ci ha permesso di seguire passo dopo passo l’evoluzione delle nostre credenze in modo intuitivo e matematicamente elegante.\nIn questo capitolo generalizziamo questa idea e introduciamo il concetto di distribuzioni coniugate. Due distribuzioni sono dette coniugate quando, combinando una prior con la corrispondente verosimiglianza, otteniamo un posterior che appartiene alla stessa famiglia della prior. In altre parole, la forma della distribuzione rimane stabile, e a cambiare sono soltanto i parametri.\nQuesta proprietà, apparentemente tecnica, ha in realtà un grande valore didattico e pratico. Dal punto di vista concettuale, ci aiuta a visualizzare con chiarezza come i dati modifichino le nostre credenze: i parametri della distribuzione si aggiornano in modo diretto e cumulativo. Dal punto di vista operativo, rende il calcolo immediato, senza dover ricorrere a metodi di approssimazione numerica.\nNaturalmente, sappiamo già dai capitoli precedenti che il mondo reale è spesso più complesso: non sempre abbiamo a disposizione una coppia coniugata, e per modelli più articolati ricorriamo a metodi computazionali come il campionamento MCMC. Ma prima di affrontare quei casi, è utile familiarizzare con le famiglie coniugate, che costituiscono il laboratorio ideale per comprendere a fondo la logica dell’aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families.html#introduzione",
    "href": "chapters/bayesian_inference/06_conjugate_families.html#introduzione",
    "title": "6  Distribuzioni coniugate",
    "section": "",
    "text": "Panoramica del capitolo\n\nIntroduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nAescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall’uso di distribuzioni coniugate.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Conjugate Families del testo di Johnson et al. (2022).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n    source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/06_conjugate_families.html#il-modello-beta-binomiale",
    "title": "6  Distribuzioni coniugate",
    "section": "\n6.1 Il modello Beta-Binomiale",
    "text": "6.1 Il modello Beta-Binomiale\nIl modello beta-binomiale è un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilità di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova è indipendente e con la stessa probabilità di successo \\(\\theta\\), che appartiene all’intervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, è espressa come:\n\\[\n\\mathcal{Binomial}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\] dove \\(\\binom{n}{y}\\) è il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un’ampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families.html#la-distribuzione-beta",
    "href": "chapters/bayesian_inference/06_conjugate_families.html#la-distribuzione-beta",
    "title": "6  Distribuzioni coniugate",
    "section": "\n6.2 La distribuzione Beta",
    "text": "6.2 La distribuzione Beta\nLa distribuzione Beta è definita come:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\] dove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i parametri che determinano la forma della distribuzione,\n\n\\(B(\\alpha, \\beta)\\) è la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, una generalizzazione del fattoriale.\n\n\nIn termini bayesiani, possiamo pensare a questi parametri nel modo seguente:\n\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di “successi” a priori,\n\n\\(\\beta -1\\) rappresenta il numero ipotetico di “fallimenti” a priori.\n\nAd esempio:\n\nuna distribuzione Beta(1, 1) è uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate);\nuna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poiché deriva da un totale di 28 osservazioni virtuali che riflettono le nostre credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all’evidenza disponibile o alla fiducia nella stima.\nLa distribuzione Beta è estremamente versatile:\n\nvalori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi;\nvalori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze più forti.\n\nQuesta flessibilità rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali sulle proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/06_conjugate_families.html#aggiornamento-bayesiano",
    "title": "6  Distribuzioni coniugate",
    "section": "\n6.3 Aggiornamento bayesiano",
    "text": "6.3 Aggiornamento bayesiano\nL’aggiornamento bayesiano combina le informazioni iniziali (distribuzione a priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle nostre credenze (distribuzione a posteriori). Nel caso del modello beta-binomiale, questo processo è particolarmente semplice grazie alla “coniugazione”: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\n\nTeorema 6.1 Sia \\(Y\\sim\\mathrm{Binomial}(n,\\theta)\\) il numero di successi \\(y\\) in \\(n\\) prove indipendenti con probabilità di successo \\(\\theta\\), e sia la nostra distribuzione a priori su \\(\\theta\\) una Beta\\(\\bigl(\\alpha,\\beta\\bigr).\\) Allora la distribuzione a posteriori di \\(\\theta\\) dato l’osservazione \\(Y=y\\) è\n\\[\n\\theta \\mid Y=y\n\\;\\sim\\;\n\\mathrm{Beta}\\bigl(\\alpha + y,\\;\\beta + (n - y)\\bigr),\n\\tag{6.1}\\] ovvero i parametri si aggiornano come\n\\[\n\\alpha' = \\alpha + y,\n\\quad\n\\beta' = \\beta + n - y.\n\\tag{6.2}\\]\n\n\n\n\n\n\n\nDerivazione.\n\n\n\n\n\nObiettivo. Mostrare che, con prior \\(\\theta \\sim \\mathrm{Beta}(\\alpha,\\beta)\\) e dati \\(Y\\sim\\mathrm{Binomiale}(n,\\theta)\\), la posteriori è\n\\[\n\\theta \\mid Y=y \\;\\sim\\; \\mathrm{Beta}\\bigl(\\alpha+y,\\;\\beta+n-y\\bigr).\n\\]\n1) Formula di Bayes (forma proporzionale). Per qualunque \\(\\theta\\in(0,1)\\):\n\\[\np(\\theta\\mid y)\\;\\propto\\; p(y\\mid\\theta)\\, p(\\theta),\n\\] dove “\\(\\propto\\)” significa “uguale a una costante (che non dipende da \\(\\theta\\)) per…”. Quella costante verrà ripristinata alla fine.\n2) Verosimiglianza binomiale (parte che dipende da \\(\\theta\\)).\n\\[\np(y\\mid\\theta) \\;=\\; \\binom{n}{y}\\,\\theta^{\\,y}\\,(1-\\theta)^{\\,n-y}.\n\\] Poiché \\(\\binom{n}{y}\\) non dipende da \\(\\theta\\), ai fini di “\\(\\propto\\)” possiamo scrivere:\n\\[\np(y\\mid\\theta)\\;\\propto\\; \\theta^{\\,y}\\,(1-\\theta)^{\\,n-y}.\n\\]\n3) Prior Beta (parte che dipende da \\(\\theta\\)).\n\\[\np(\\theta) \\;=\\; \\frac{1}{B(\\alpha,\\beta)}\\,\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1},\n\\] e dunque, ignorando la costante \\(B(\\alpha,\\beta)\\):\n\\[\np(\\theta)\\;\\propto\\;\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1}.\n\\]\n4) Prodotto “prior × verosimiglianza”. Moltiplichiamo i soli termini che dipendono da \\(\\theta\\):\n\\[\n\\begin{aligned}\np(\\theta\\mid y)\n&\\;\\propto\\; \\bigl[\\theta^{\\,y}(1-\\theta)^{\\,n-y}\\bigr]\\;\\bigl[\\theta^{\\,\\alpha-1}(1-\\theta)^{\\,\\beta-1}\\bigr] \\\\\n&\\;=\\; \\theta^{\\,(\\alpha-1)+y}\\; (1-\\theta)^{\\,(\\beta-1)+(n-y)}.\n\\end{aligned}\n\\]\n5) Riconoscere la forma Beta (matching degli esponenti). La forma non normalizzata di una \\(\\mathrm{Beta}(a,b)\\) è:\n\\[\n\\theta^{\\,a-1}\\,(1-\\theta)^{\\,b-1}.\n\\] Confrontando gli esponenti otteniamo:\n\\[\na-1 = (\\alpha-1)+y \\;\\;\\Rightarrow\\;\\; a = \\alpha + y,\n\\] \\[\nb-1 = (\\beta-1)+(n-y) \\;\\;\\Rightarrow\\;\\; b = \\beta + (n-y).\n\\] Quindi la densità non normalizzata della distribuzione a posteriori è\n\\[\np(\\theta\\mid y)\\;\\propto\\;\\theta^{\\,(\\alpha+y)-1}\\,(1-\\theta)^{\\,(\\beta+n-y)-1}.\n\\]\n6) Ripristino della costante di normalizzazione. Per essere una densità, \\(p(\\theta\\mid y)\\) deve integrare a 1 su \\(\\theta\\in(0,1)\\). La costante corretta è l’inverso della funzione Beta con i nuovi parametri:\n\\[\np(\\theta\\mid y)\n\\;=\\;\n\\frac{1}{B(\\alpha+y,\\;\\beta+n-y)}\\;\n\\theta^{\\,(\\alpha+y)-1}\\,(1-\\theta)^{\\,(\\beta+n-y)-1}.\n\\]\n7) Conclusione (forma parametrica della posteriori).\n\\[\n\\boxed{\n\\;\\theta\\mid Y=y \\;\\sim\\; \\mathrm{Beta}\\bigl(\\alpha+y,\\;\\beta+n-y\\bigr).\\;\n}\n\\]\nIntuizione in termini di “pseudocontenuti di informazione”.\n\nLa Beta\\((\\alpha,\\beta)\\) può essere interpretata in termini di pseudoconteggi: \\(\\alpha-1\\) “successi” e \\(\\beta-1\\) “insuccessi” precedenti ai dati.\n\nDopo aver osservato \\(y\\) successi e \\(n-y\\) insuccessi, si sommano i conteggi:\n\\[\n\\alpha \\to \\alpha+y,\\qquad \\beta \\to \\beta+(n-y).\n\\]\n\nQuesta additività spiega la conjugatezza: prior e posterior appartengono alla stessa famiglia.\n\nControllo rapido della normalizzazione. Usiamo la definizione di \\(B(a,b)\\):\n\\[\nB(a,b) \\;=\\; \\int_0^1 \\theta^{a-1}(1-\\theta)^{b-1}\\,d\\theta.\n\\] Con \\(a=\\alpha+y\\) e \\(b=\\beta+n-y\\), l’integrale della nostra forma non normalizzata è \\(B(\\alpha+y,\\beta+n-y)\\); moltiplicando per \\(1/B(\\alpha+y,\\beta+n-y)\\) otteniamo dunque una densità che integra a 1.\n\n\n\n\n\n\n\n\n\nAlcune quantità riassuntive utili.\n\n\n\n\n\nPer \\(\\theta\\mid y \\sim \\mathrm{Beta}(\\alpha+y,\\beta+n-y)\\):\n\n\nMedia posteriori:\n\\[\n\\mathbb{E}[\\theta\\mid y] \\;=\\; \\frac{\\alpha+y}{\\alpha+\\beta+n}.\n\\]\n\n\nModa (se parametri \\(&gt;1\\)):\n\\[\n\\frac{\\alpha+y-1}{\\alpha+\\beta+n-2}.\n\\]\n\n\nVarianza:\n\\[\n\\mathrm{Var}(\\theta\\mid y) \\;=\\;\n\\frac{(\\alpha+y)(\\beta+n-y)}{(\\alpha+\\beta+n)^2\\,(\\alpha+\\beta+n+1)}.\n\\]\n\n\n\n\n\n\n6.3.1 Vantaggi del modello Beta-Binomiale\n\n\nSemplicità analitica: la coniugatezza della distribuzione Beta-Binomiale semplifica i calcoli, rendendo immediato l’aggiornamento dei parametri.\n\nInterpretazione intuitiva: l’aggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra in modo trasparente come i dati influenzino le credenze.\n\nIn sintesi, il modello Beta-Binomiale è un esempio didattico fondamentale per comprendere l’inferenza bayesiana e rappresenta un punto di partenza ideale per approcci più avanzati.\n\n\n\n\n\n\nEsercizio 1.\n\n\n\n\n\nNel Capitolo 5 abbiamo utilizzato il metodo basato su griglia per determinare la distribuzione a posteriori nel caso di \\(y = 6\\) successi su \\(n = 9\\) prove (vedi anche McElreath, 2020 per una discussione dettagliata). Ora esploriamo un approccio alternativo, sfruttando le proprietà delle famiglie coniugate.\nLa verosimiglianza binomiale per questo esperimento è espressa dalla seguente funzione:\n\\[\n\\mathcal{L}(\\theta) \\propto \\theta^y (1-\\theta)^{n-y},\n\\] dove \\(y = 6\\) rappresenta il numero di successi e \\(n = 9\\) il numero totale di prove.\nScegliendo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 5\\), possiamo applicare il teorema di Bayes per calcolare i parametri aggiornati della distribuzione a posteriori. In base alla regola di aggiornamento per distribuzioni coniugate, otteniamo:\n\\[\n\\alpha' = \\alpha + y = 2 + 6 = 8.\n\\] \\[\n\\beta' = \\beta + n - y = 5 + 9 - 6 = 8.\n\\] La distribuzione a posteriori risultante è quindi una distribuzione Beta con parametri \\(\\mathcal{Beta}(8, 8)\\).\nProcediamo ora a visualizzare le tre distribuzioni rilevanti:\n\n\nDistribuzione a priori: \\(\\mathcal{Beta}(2, 2)\\),\n\nVerosimiglianza binomiale: per \\(y = 6\\) e \\(n = 9\\),\n\nDistribuzione a posteriori: \\(\\text{Beta}(8, 5)\\).\n\nEcco il codice R per generare il grafico comparativo:\n\n# Definizione dei parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 5\ny &lt;- 6\nn &lt;- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\n# Sequenza di valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle PDF\nprior_pdf &lt;- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Normalizzazione della verosimiglianza\nlikelihood_integral &lt;- sum(likelihood) * (theta[2] - theta[1])\nnormalized_likelihood &lt;- likelihood / likelihood_integral\n\nposterior_pdf &lt;- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  densita = c(prior_pdf, normalized_likelihood, posterior_pdf),\n  distribuzione = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(theta))\n)\n\n# Creare il grafico \nggplot(df, aes(x = theta, y = densita, color = distribuzione)) +\n  geom_line(size = 1) +  # Aggiungere le linee per le distribuzioni\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Likelihood\" = \"green\", \"Posterior\" = \"red\")) +  # Assegnare i colori\n  labs(title = \"Distribuzioni Prior, Likelihood e Posterior\",\n       x = expression(theta),\n       y = \"Densità\",\n       color = \"Distribuzione\") +  # Aggiungere titoli e label\n  theme(legend.position = \"top\")  # Posizionare la legenda in alto\n\n\n\n\n\n\n\n\n\nCurva blu: Prior \\(\\mathcal{Beta}(2, 5)\\), che riflette le credenze iniziali prima dell’osservazione dei dati.\n\n\nCurva verde: Likelihood (normalizzata), rappresenta l’evidenza fornita dai dati osservati.\n\n\nCurva rossa: Posterior \\(\\mathcal{Beta}(8, 8)\\), risultato dell’aggiornamento bayesiano che combina prior e likelihood.\n\nNota sulla normalizzazione della verosimiglianza. La verosimiglianza binomiale non è una distribuzione di probabilità (il suo integrale non è pari a 1). Per rappresentarla visivamente accanto alla distribuzione a priori e a quella a posteriori, è necessario normalizzarla. Questo è fatto calcolando il suo integrale su \\(\\theta \\in [0, 1]\\) e dividendo la funzione per il risultato. La normalizzazione serve solo per la visualizzazione e non influisce sui calcoli analitici.\n\n\n\n\n\n\n\n\n\nEsercizio 2.\n\n\n\n\n\nEsaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorità, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come\n\nconsistente nell’ordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che è un complice addestrato dell’esperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‘esperimento di apprendimento’ apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l’esperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre più intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realtà era un attore addestrato) sulla loro capacità di memorizzare una serie di item. Se l’attore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all’attore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l’attore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello “Pericolo: Scossa Grave”. Il problema richiede di costruire la distribuzione a posteriori della probabilità \\(\\theta\\) di infliggere una scossa a l livello “Pericolo: Scossa Grave”, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha &lt;- 1\nbeta_val &lt;- 10\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico\nggplot(df, aes(x = x, y = densita)) +\n  geom_line(color = \"#b97c7c\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(1, 10)\",  # Aggiungere il titolo\n       x = \"x\",  # Label dell'asse x\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  geom_vline(xintercept = 1, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(1, 10)\", color = \"#b97c7c\", size = 5)  # Aggiungere una legenda\n\n\n\n\n\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\ny &lt;- 26\nn &lt;- 40\n\nalpha_prior &lt;- 1\nbeta_prior &lt;- 10\n\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\nalpha_post\n#&gt; [1] 27\nbeta_post\n#&gt; [1] 24\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, alpha_post, beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(27, 24)\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(27, 24)\", color = \"blue\", size = 5)  \n\n\n\n\n\n\n\nCalcolo della media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n#&gt; [1] 0.529\n\nCalcolo della moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#&gt; [1] 0.531\n\nCalcolo della probabilità che \\(\\theta &gt; 0.6\\):\n\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#&gt; [1] 0.156\n\nOvvero:\n\n1 - pbeta(0.6, alpha_post, beta_post)\n#&gt; [1] 0.156\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta &lt;- seq(0, 1, length.out = 100)\n\nCreiamo la distribuzione a priori:\n\nprior &lt;- dbeta(theta, alpha_prior, beta_prior)\n\n# Normalizzazione della densità per ottenere una somma pari a 1\nprior_normalized &lt;- prior / sum(prior)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = prior_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"blue\", size = 1) +  # Linee verticali per rappresentare le probabilità\n  labs(title = \"Distribuzione a priori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCreiamo la verosimiglianza:\n\nlk &lt;- dbinom(y, n, theta)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"red\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Verosimiglianza\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCalcoliamo la distribuzione a posteriori:\n\npost &lt;- (prior * lk) / sum(prior * lk)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"green\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Distribuzione a posteriori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 1e6, replace = TRUE, prob = post)\n\nTroviamo la media a posteriori:\n\nmean(samples)\n#&gt; [1] 0.529\n\nCalcoliamo la probabilità che \\(\\theta &gt; 0.6\\):\n\nmean(samples &gt; 0.6)\n#&gt; [1] 0.152\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.\n\n\n\n\n\n\n\n\n\nEsercizio 3.\n\n\n\n\n\nConsideriamo un esempio discusso da Nalborczyk (2018) nel quale, oltre all’applicazione del teorema beta-binimiale, viene anche introdotto il concetto di posterior-predictive check.\nSupponiamo di reclutare partecipanti per uno studio di mezza ora:\n\nPossiamo farlo fra le 9:00 e le 18:00, con sessioni ogni 30 minuti.\n\nIn una settimana lavorativa (lun–ven) otteniamo \\(n = 90\\) time slot.\n\nAd ogni slot, il partecipante o si presenta (\\(1\\)) o manca (\\(0\\)).\n\nVogliamo stimare la probabilità media di presenza, che chiameremo \\(\\theta\\).\nModello:\n\\[\n\\begin{cases}\n    Y \\mid \\theta \\;\\sim\\;\\mathrm{Binomial}(n,\\theta),\\\\[6pt]\n    \\theta \\;\\sim\\;\\mathrm{Beta}(\\alpha,\\beta).\n    \\end{cases}\n\\]\nScelta del prior:\n\nconoscenze pregresse suggeriscono che \\(\\theta\\) sia intorno a 0.5;\n\nscegliamo quindi un prior \\(\\;\\mathrm{Beta}(2,2)\\), che ha media \\(0.5\\) e riflette incertezza moderata.\n\nDati osservati:\n\n# vettore di 0/1 con n = 90 osservazioni\ny &lt;- c(\n  0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,\n  0,1,0,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,\n  1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,\n  1,0,0,1,1,1,0,1,1,1,1,1,1,0,0,0,0,1,\n  0,1,0,1,1,1,0,0,0,0,0,1,1,1,1,1,1,0\n)\n\nCalcoliamo\n\nn &lt;- length(y)  # numero di slot = 90\nz &lt;- sum(y)     # numero di presenze = numero di 1\n\nPosterior Beta–Binomiale.\nI parametri aggiornati sono\n\\[\n\\alpha_{post} = \\alpha + z,\n\\quad\n\\beta_{post} = \\beta + (n - z).\n\\]\nIn particolare, con \\(\\alpha=\\beta=2\\):\n\na &lt;- b &lt;- 2\na_post &lt;- a + z\nb_post &lt;- b + (n - z)\n\nIl posterior è quindi\n\\[\n\\theta\\mid y \\;\\sim\\;\\mathrm{Beta}(a+z,\\;b+n-z).\n\\]\nVisualizzazione:\n\n# griglia per theta\ngrid &lt;- seq(0, 1, length.out = 1000)\n\n# densità\nprior     &lt;- dbeta(grid, a,      b)\nposterior &lt;- dbeta(grid, a_post, b_post)\n\ndf &lt;- data.frame(theta = grid,\n                 prior = prior,\n                 posterior = posterior)\n\nggplot(df) +\n  geom_area(aes(x = theta, y = prior,\n                fill = \"Prior\", colour = \"Prior\"),\n            alpha = 0.5, size = 1) +\n  geom_area(aes(x = theta, y = posterior,\n                fill = \"Posterior\", colour = \"Posterior\"),\n            alpha = 0.5, size = 1) +\n  scale_fill_grey(name = \"\") +\n  scale_colour_grey(name = \"\") +\n  theme_bw(base_size = 12) +\n  xlab(expression(theta)) +\n  ylab(\"\") +\n  ggtitle(\"Densità Prior e Posterior\\nmodello Beta–Binomiale\")\n\n\n\n\n\n\n\nIntroduzione ai posterior predictive checks.\nIl modello assume indipendenza fra i time slot. Se questa assunzione è violata (ad es. presenza autocorrelata nel tempo), le nostre stime potrebbero essere fuorvianti.\nIdea:\n\nSimulare \\(\\theta\\) dal posterior.\n\nDato ciascun \\(\\theta\\), generare una nuova serie \\(y^{rep}\\) da\\(\\mathrm{Binomial}(n,\\theta)\\).\n\nCalcolare su ogni \\(y^{rep}\\) una test-quantità \\(T(y^{rep})\\).\n\nConfrontare la distribuzione di \\(T(y^{rep})\\) con il valore osservato \\(T(y)\\).\n\nSe \\(T(y)\\) è un outlier rispetto ai \\(T(y^{rep})\\), l’assunzione di indipendenza è sospetta.\nTest‐quantità: numero di “switch”.\nDefiniamo una funzione che conta quante volte la serie passa da 0→1 o da 1→0:\n\ncount_switches &lt;- function(x) {\n  sum(abs(diff(x)) == 1)\n}\n\n# valore osservato\nTy &lt;- count_switches(y)\ncat(\"Switch osservati:\", Ty, \"\\n\")\n#&gt; Switch osservati: 28\n\nSimulazione e istogramma.\n\nset.seed(123)      # per riproducibilità\nnsims &lt;- 10000     # numero di repliche\n\nsim_switches &lt;- replicate(nsims, {\n  # 1) estrai un theta dal posterior\n  theta_sim &lt;- rbeta(1, a_post, b_post)\n  # 2) genera y^rep ~ Bernoulli(theta_sim)\n  y_sim     &lt;- rbinom(n, size = 1, prob = theta_sim)\n  # 3) conta gli switch\n  count_switches(y_sim)\n})\n\n# Istogramma\nhist(sim_switches,\n     breaks = 30,\n     col    = \"lightgrey\",\n     main   = \"Distribuzione Posterior Predictive\\ndel numero di switch\",\n     xlab   = \"Numero di switch\",\n     ylab   = \"Frequenza\")\nabline(v = Ty, col = \"darkgreen\", lty = 2, lwd = 2)\n\n\n\n\n\n\n\nBayesian p‐value.\nCalcoliamo la probabilità di ottenere un numero di switch ≤ di quello osservato:\n\np_value &lt;- mean(sim_switches &lt;= Ty)\ncat(\"Bayesian p-value:\", round(p_value, 4), \"\\n\")\n#&gt; Bayesian p-value: 0.0073\n\n\nUn valore molto basso (es. \\(&lt;0.05\\)) indica che \\(T(y)\\) è sorprendente rispetto alle predizioni del modello.\n\nQui: se \\(p\\approx 0.01\\), la bassa variabilità di switch suggerisce dipendenza fra le osservazioni.\n\nInterpretazione.\n\n\nUn modello non è “giusto” o “sbagliato”, ma deve descrivere bene il processo che genera i dati.\n\nIl nostro check mostra che il numero di switch osservato è molto minore di quanto ci aspetteremmo sotto l’ipotesi di indipendenza.\n\nCon tutta probabilità c’è autocorrelazione temporale (le presenze dipendono dall’ora del giorno).\n\nPer tenerne conto, si potrebbero usare modelli più avanzati (es. processi gaussiani).\n\nIn sintesi, il posterior predictive checking ci offre un modo flessibile per diagnosticare diverse violazioni del modello, scegliendo test‐quantities adatte (media, varianza, max, autocorrelazione, …). Come scrivono Gelman et al. (2013), “i p-valori posteriori … possono essere calcolati per varie test-quantities per valutare più modi in cui un modello può fallire”.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/06_conjugate_families.html#principali-distribuzioni-coniugate",
    "title": "6  Distribuzioni coniugate",
    "section": "\n6.4 Principali distribuzioni coniugate",
    "text": "6.4 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle più note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello Esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello Uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori è \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori è \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/06_conjugate_families.html#riflessioni-conclusive",
    "title": "6  Distribuzioni coniugate",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo approfondito l’idea di famiglia coniugata, mostrando come, in certi casi, il teorema di Bayes mantenga invariata la forma della distribuzione a priori. L’esempio del modello Beta-Binomiale, già incontrato in precedenza, ci ha offerto l’occasione di vedere con chiarezza come i dati modifichino le nostre credenze in modo semplice e cumulativo: basta aggiornare i parametri della distribuzione, senza cambiare la sua struttura.\nQuesta proprietà, apparentemente tecnica, riveste una grande importanza concettuale. Le distribuzioni coniugate costituiscono il laboratorio ideale per comprendere a fondo la logica dell’inferenza bayesiana: permettono di seguire con trasparenza il passaggio da prior a posterior, di vedere come ogni nuova osservazione si traduca in un aggiornamento dei parametri e di cogliere in maniera intuitiva la natura dinamica del processo.\nNaturalmente, sappiamo che la coniugazione è un caso speciale. Nella maggior parte dei problemi reali, soprattutto quando i modelli diventano complessi e includono più parametri o strutture gerarchiche, non esiste una coppia prior–verosimiglianza coniugata che semplifichi i calcoli. È in questi casi che entrano in gioco metodi computazionali più generali, come il campionamento MCMC, che ci permettono di affrontare situazioni realistiche senza rinunciare alla coerenza dell’approccio bayesiano (Johnson et al., 2022).\nIn questo senso, le famiglie coniugate non rappresentano un punto di arrivo, ma un passaggio fondamentale: ci insegnano i principi dell’aggiornamento bayesiano in un contesto semplice, che prepara la strada verso strumenti più potenti e flessibili.\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nSi consideri lo studio “An excess of positive results: Comparing the standard psychology literature with registered reports” di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall’analisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Funzione per trovare i parametri della distribuzione beta\nfind_beta_parameters &lt;- function(mean, lower, upper, conf_level = 0.95) {\n  # Funzione obiettivo da minimizzare\n  objective &lt;- function(alpha) {\n    beta &lt;- alpha * (1 - mean) / mean\n    predicted_ci &lt;- qbeta(c((1-conf_level)/2, 1-(1-conf_level)/2), alpha, beta)\n    error &lt;- (predicted_ci[1] - lower)^2 + (predicted_ci[2] - upper)^2\n    return(error)\n  }\n  \n  # Ottimizzazione per trovare alpha\n  result &lt;- optimize(objective, interval = c(0.1, 100))\n  alpha &lt;- result$minimum\n  beta &lt;- alpha * (1 - mean) / mean\n  \n  return(list(alpha = alpha, beta = beta))\n}\n\n# Parametri degli studi preregistrati\nmean_preregistered &lt;- 0.4366\nci_lower &lt;- 0.3191\nci_upper &lt;- 0.5595\n\n# Calcolo dei parametri della distribuzione beta a priori\nprior_params &lt;- find_beta_parameters(mean_preregistered, ci_lower, ci_upper)\nalpha_prior &lt;- prior_params$alpha\nbeta_prior &lt;- prior_params$beta\n\n# Dati osservati\nn &lt;- 152  # numero di studi\nsuccesses_60 &lt;- round(0.60 * n)  # scenario (a)\nsuccesses_96 &lt;- round(0.96 * n)  # scenario (b)\n\n# Calcolo delle distribuzioni a posteriori\nalpha_post_60 &lt;- alpha_prior + successes_60\nbeta_post_60 &lt;- beta_prior + (n - successes_60)\n\nalpha_post_96 &lt;- alpha_prior + successes_96\nbeta_post_96 &lt;- beta_prior + (n - successes_96)\n\n# Creazione del dataframe per il plotting\ntheta &lt;- seq(0, 1, length.out = 1000)\n\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  density = c(\n    dbeta(theta, alpha_prior, beta_prior),\n    dbeta(theta, alpha_post_60, beta_post_60),\n    dbeta(theta, alpha_post_96, beta_post_96)\n  ),\n  distribution = rep(c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"), \n                    each = length(theta))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    x = expression(theta),\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n# Calcolo degli intervalli di credibilità al 95%\ncredible_intervals &lt;- data.frame(\n  Distribution = c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"),\n  Mean = c(\n    alpha_prior / (alpha_prior + beta_prior),\n    alpha_post_60 / (alpha_post_60 + beta_post_60),\n    alpha_post_96 / (alpha_post_96 + beta_post_96)\n  ),\n  Lower = c(\n    qbeta(0.025, alpha_prior, beta_prior),\n    qbeta(0.025, alpha_post_60, beta_post_60),\n    qbeta(0.025, alpha_post_96, beta_post_96)\n  ),\n  Upper = c(\n    qbeta(0.975, alpha_prior, beta_prior),\n    qbeta(0.975, alpha_post_60, beta_post_60),\n    qbeta(0.975, alpha_post_96, beta_post_96)\n  )\n)\n\n# Visualizzazione dei risultati\nprint(\"Parametri della distribuzione beta a priori:\")\nprint(paste(\"alpha =\", round(alpha_prior, 2)))\nprint(paste(\"beta =\", round(beta_prior, 2)))\n\nprint(\"\\nIntervalli di credibilità al 95%:\")\nprint(credible_intervals)\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nTra i fattori che possono influenzare il rapporto tra i sessi alla nascita c’è la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta è impiantata in basso nell’utero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell’ipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (2013))\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Calcolo della proporzione osservata\np_hat &lt;- y/n\nprint(paste(\"Proporzione osservata di femmine:\", round(p_hat, 3)))\n\n# Test dell'ipotesi utilizzando il Bayes Factor\n# H0: p = 0.485 vs H1: p &lt; 0.485\n\n# Funzione per calcolare la verosimiglianza marginale sotto H1\nmarginal_likelihood_h1 &lt;- function(y, n, p_max = 0.485) {\n  # Integrazione numerica sulla distribuzione uniforme tra 0 e p_max\n  p_grid &lt;- seq(0, p_max, length.out = 1000)\n  likelihood &lt;- dbinom(y, n, p_grid)\n  prior &lt;- dunif(p_grid, 0, p_max)\n  mean(likelihood * prior) * p_max\n}\n\n# Verosimiglianza sotto H0\nlikelihood_h0 &lt;- dbinom(y, n, p0)\n\n# Verosimiglianza marginale sotto H1\nmarg_lik_h1 &lt;- marginal_likelihood_h1(y, n)\n\n# Calcolo del Bayes Factor\nbf10 &lt;- marg_lik_h1 / likelihood_h0\nprint(paste(\"Bayes Factor (H1 vs H0):\", round(bf10, 2)))\n\n# Visualizzazione delle distribuzioni a posteriori\np_grid &lt;- seq(0, 1, length.out = 1000)\nlikelihood &lt;- dbinom(y, n, p_grid)\nprior &lt;- dunif(p_grid, 0, 1)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = p_grid,\n  Posterior = posterior / max(posterior)  # normalizzato per la visualizzazione\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = Posterior)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = p_hat, linetype = \"dashed\", color = \"blue\") +\n  labs(\n    title = \"Distribuzione a Posteriori della Proporzione di Nascite Femminili\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità a Posteriori (normalizzata)\"\n  ) +\n  annotate(\"text\", x = p0, y = 0.1, \n           label = \"Popolazione Generale\", \n           angle = 90, vjust = -0.5, color = \"red\") +\n  annotate(\"text\", x = p_hat, y = 0.1, \n           label = \"Proporzione Osservata\", \n           angle = 90, vjust = -0.5, color = \"blue\")\n\n# Calcolo dell'intervallo di credibilità al 95%\nsorted_p &lt;- sort(p_grid)\ncum_post &lt;- cumsum(posterior)\nlower &lt;- sorted_p[which(cum_post &gt; 0.025)[1]]\nupper &lt;- sorted_p[which(cum_post &gt; 0.975)[1]]\n\nprint(paste(\"Intervallo di credibilità al 95%: [\", \n            round(lower, 3), \",\", round(upper, 3), \"]\"))\n\n# Calcolo della probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- sum(posterior[p_grid &lt; p0])\nprint(paste(\"Probabilità a posteriori che p &lt; 0.485:\", \n            round(prob_less_than_p0, 3)))\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nPer valutare la sensibilità della soluzione precedente alla scelta della distribuzione a priori, ripetere l’esercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione è centrata su 0.485 e concentra la maggior parte della sua massa nell’intervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\nI risultati mostrano che:\n\nLa proporzione osservata nel campione (0.446) è inferiore al valore di riferimento della popolazione generale (0.485)\nLa distribuzione a priori Beta(48.5, 51.5):\n\n\nHa media 0.485\nRiflette la nostra conoscenza iniziale sulla proporzione di nascite femminili\nFornisce un’incertezza ragionevole attorno al valore di riferimento\n\n\nLa distribuzione a posteriori:\n\n\nHa una media di circa 0.447\nL’intervallo di credibilità al 95% esclude il valore di riferimento 0.485\nIndica una probabilità elevata che la vera proporzione sia inferiore a 0.485\n\n\nQuesta analisi suggerisce che:\n\n\nEsiste un’associazione tra placenta previa e una minor proporzione di nascite femminili\nL’effetto è moderato ma statisticamente rilevante\nLa stima è abbastanza precisa grazie alla dimensione campionaria considerevole\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nIn uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralità manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralità manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al. (2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\nL’analisi bayesiana della prevalenza dei mancini combina le informazioni provenienti dalla meta-analisi di Papadatou-Pastou et al. (2020) con i dati più recenti di Gori et al. (2024). Di seguito sono riportati i principali risultati:\n\n\nDistribuzione a priori (basata su Papadatou-Pastou et al., 2020):\n\nModellata come una distribuzione Beta(8, 60).\n\nPresenta una media intorno all’11,8%.\n\nRiflette la variabilità osservata nella meta-analisi.\n\nL’intervallo di credibilità al 95% copre approssimativamente il range 9,3%-18,1%, come riportato nello studio.\n\n\n\nDati osservati (Gori et al., 2024):\n\n202 partecipanti italiani.\n\n13 mancini, corrispondenti al 6,4% del campione.\n\nQuesto valore è inferiore alla media stimata dalla meta-analisi globale.\n\n\n\nDistribuzione a posteriori:\n\nCombina le informazioni a priori con i nuovi dati osservati.\n\nLa media a posteriori si è spostata verso il basso rispetto alla distribuzione a priori.\n\nL’intervallo di credibilità si è ristretto, indicando una riduzione dell’incertezza.\n\nMaggiore peso è stato attribuito ai dati italiani rispetto alla meta-analisi globale.\n\n\n\nInterpretazione:\n\nLa stima finale suggerisce una prevalenza di mancini nella popolazione italiana inferiore alla media globale.\n\nQuesto risultato potrebbe riflettere specificità culturali o metodologiche dello studio italiano.\n\nL’incertezza nella stima finale è diminuita rispetto alla meta-analisi, ma rimane significativa.\n\nI risultati supportano l’ipotesi di una variabilità geografica nella prevalenza della mancinismo.\n\n\n\nLa distribuzione a posteriori fornisce una sintesi equilibrata tra le conoscenze globali precedenti e i dati specifici della popolazione italiana, suggerendo che potrebbero esistere peculiarità culturali o demografiche che influenzano la prevalenza del mancinismo in Italia.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#&gt; [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#&gt; [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#&gt; [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#&gt; [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#&gt; [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [46] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#&gt; [49] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [58] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#&gt; [61] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#&gt; [64] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [67] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#&gt; [70] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [73] lme4_1.1-37           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [76] rbibutils_2.3         QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [79] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [82] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [85] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [88] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [91] htmltools_0.5.8.1     lifecycle_1.0.4       mitml_0.4-5          \n#&gt; [94] MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families.html#bibliografia",
    "href": "chapters/bayesian_inference/06_conjugate_families.html#bibliografia",
    "title": "6  Distribuzioni coniugate",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151–168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNalborczyk, L. (2018, gennaio 23). Checking the Asumption of Independence in Binomial Trials Using Posterior Predictive Checking. https://lnalborczyk.github.io/blog/2018-01-23-ppc\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481–524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distribuzioni coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html",
    "href": "chapters/bayesian_inference/07_summary_posterior.html",
    "title": "7  Sintesi a posteriori",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo imparato a costruire distribuzioni a posteriori combinando la nostra conoscenza preliminare (prior) con i dati osservati attraverso la verosimiglianza. Abbiamo visto come questo processo si realizzi in casi semplici, come la stima di una proporzione di successi con il modello Beta–Binomiale, e come possa essere generalizzato grazie al concetto di famiglie coniugate. Ora ci poniamo una domanda fondamentale: una volta che abbiamo ottenuto una distribuzione a posteriori, come possiamo riassumerla e comunicarla in modo chiaro ed efficace?\nIl posterior non è un singolo numero, ma un’intera distribuzione che rappresenta la nostra incertezza sul parametro. Nella pratica della ricerca psicologica, tuttavia, dobbiamo spesso sintetizzare queste informazioni per presentarle nei risultati di un articolo o per confrontarle con altre stime. Questo capitolo è dedicato proprio a questa esigenza: mostreremo come ricavare quantità riassuntive (media, mediana, moda) e come costruire intervalli credibili che esprimano in modo trasparente i valori più plausibili.\nL’obiettivo non è ridurre l’inferenza bayesiana alla ricerca di un punto o di un intervallo, ma imparare a comunicare l’incertezza in modo comprensibile, senza perdere la ricchezza informativa del posterior. Come vedremo, anche nei contesti più complessi, la capacità di sintetizzare correttamente le distribuzioni a posteriori è ciò che distingue un’analisi meramente tecnica da una presentazione scientifica chiara e convincente.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#introduzione",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#introduzione",
    "title": "7  Sintesi a posteriori",
    "section": "",
    "text": "Panoramica del capitolo\n\nDistribuzione a posteriori = conoscenza aggiornata.\nStime puntuali: MAP, media, mediana.\nIncertezza: varianza e deviazione standard.\nIntervalli di credibilità: simmetrici e HPD.\nVerifica di ipotesi: probabilità a posteriori.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Posterior Inference & Prediction del testo di Johnson et al. (2022).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#riepilogo-numerico",
    "title": "7  Sintesi a posteriori",
    "section": "\n7.1 Riepilogo numerico",
    "text": "7.1 Riepilogo numerico\nLa distribuzione a posteriori contiene in sé tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\). Tuttavia, quando ci troviamo di fronte a vettori di parametri con più di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori: stima puntuale e intervallo di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#stima-puntuale",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#stima-puntuale",
    "title": "7  Sintesi a posteriori",
    "section": "\n7.2 Stima puntuale",
    "text": "7.2 Stima puntuale\nNel contesto dell’inferenza bayesiana, stimare il valore più credibile di un parametro \\(\\theta\\) a partire dalla distribuzione a posteriori può avvenire attraverso tre statistiche principali: moda, mediana e media. La scelta tra queste dipende dalla forma della distribuzione a posteriori. Queste statistiche forniscono una stima puntuale della tendenza centrale della distribuzione, ossia il valore a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sia sui dati osservati sia sulle credenze a priori.\nModa (Massimo a Posteriori, MAP)\nLa moda della distribuzione a posteriori, nota come stima di massimo a posteriori (MAP), corrisponde al valore del parametro \\(\\theta\\) a cui è associata la massima densità di probabilità. Questo concetto rappresenta l’estensione bayesiana della classica stima di massima verosimiglianza (MLE), definita come:\n\\[\n\\hat{\\theta}_{\\text{ML}} = \\arg \\max_\\theta L(\\theta \\mid y),\n\\] dove \\(L(\\theta \\mid y)\\) è la funzione di verosimiglianza. Nell’approccio bayesiano, l’informazione a priori \\(p(\\theta)\\) viene incorporata attraverso il teorema di Bayes, portando alla definizione della stima MAP:\n\\[\n\\hat{\\theta}_{\\text{MAP}} = \\arg \\max_\\theta \\, L(\\theta \\mid y) \\, p(\\theta).\n\\] In altre parole, \\(\\hat{\\theta}_{\\text{MAP}}\\) massimizza la densità a posteriori non normalizzata, combinando in modo esplicito l’evidenza empirica con la conoscenza pregressa.\n\n7.2.0.1 Limitazioni della stima MAP\nNonostante l’interpretazione intuitiva, la stima MAP presenta alcune limitazioni di cui è importante essere consapevoli. In primo luogo, la sua determinazione può risultare computazionalmente impegnativa, specialmente quando la distribuzione a posteriori viene campionata mediante metodi MCMC: individuare con precisione il massimo in uno spazio di parametri ad alta dimensionalità o con forme complesse richiede tecniche specifiche e può essere instabile.\nIn secondo luogo, la bontà della stima MAP dipende fortemente dalla forma della distribuzione a posteriori. In presenza di asimmetrie marcate o di multimodalità, il massimo globale potrebbe non essere rappresentativo della regione di alta probabilità, soprattutto se associato a un picco stretto ma isolato, mentre la maggior parte della massa probabilistica si trova altrove.\nInfine, il MAP è intrinsecamente meno robusto di altre statistiche centrali, come la media o la mediana a posteriori, in quanto basato esclusivamente sul valore di massimo densità, ignorando la forma complessiva della distribuzione. Ciò lo rende sensibile a variazioni nella parametrizzazione del modello e poco informativo riguardo all’incertezza complessiva sul parametro.\nMedia a posteriori\nLa media a posteriori rappresenta il valore atteso del parametro \\(\\theta\\) rispetto alla sua distribuzione a posteriori. Formalmente, essa è definita come:\n\\[\n\\mathbb{E}[\\theta \\mid y] = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta.\n\\] Questa quantità costituisce una stima di \\(\\theta\\) che tiene conto dell’intera distribuzione a posteriori, integrando su tutti i possibili valori del parametro. Una proprietà notevole della media a posteriori è quella di essere lo stimatore che minimizza l’errore quadratico medio (MSE) nella previsione di \\(\\theta\\), il che ne giustifica l’ampio utilizzo in contesti di ottimizzazione statistica.\nTuttavia, in presenza di distribuzioni a posteriori marcatamente asimmetriche o con code pesanti, la media potrebbe non rappresentare adeguatamente la regione di massima densità di probabilità. In tali casi, valori estremi possono influenzare eccessivamente la stima, allontanando la media dalla zona in cui è concentrata la maggior parte della massa probabilistica. Per questo motivo, in situazioni di asimmetria pronunciata, altre statistiche come la mediana o la moda a posteriori possono offrire una rappresentazione più appropriata della tendenza centrale.\nMediana a posteriori\nLa mediana a posteriori è definita come il valore del parametro \\(\\theta\\) che divide la distribuzione a posteriori in due parti di uguale probabilità: il 50% della massa probabilistica si trova al di sotto di tale valore e il restante 50% al di sopra. Formalmente, essa soddisfa la condizione:\n\\[\nP(\\theta \\leq \\hat{\\theta}_{\\text{med}} \\mid y) = 0.5.\n\\]\nRispetto alla media e alla moda a posteriori, la mediana offre una misura di tendenza centrale particolarmente robusta, in quanto poco sensibile alla presenza di valori estremi o code distributive pesanti. Questa proprietà la rende preferibile in contesti in cui la distribuzione a posteriori presenta marcate asimmetrie o è multimodale, situazioni in cui la media può essere distortta da valori anomali e la moda può risultare instabile o non unica. Grazie alla sua stabilità, la mediana a posteriori fornisce una rappresentazione più affidabile della posizione centrale del parametro quando la forma della distribuzione è irregolare, garantendo una sintesi inferenziale solida anche in condizioni di elevata variabilità o non normalità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#misurare-lincertezza-varianza-a-posteriori",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#misurare-lincertezza-varianza-a-posteriori",
    "title": "7  Sintesi a posteriori",
    "section": "Misurare l’incertezza: varianza a posteriori",
    "text": "Misurare l’incertezza: varianza a posteriori\nOltre a individuare il valore più plausibile del parametro \\(\\theta\\), è fondamentale quantificare l’incertezza residua associata alla nostra stima. A questo scopo, la varianza a posteriori fornisce una misura della dispersione dei valori di \\(\\theta\\) attorno alla sua media, condizionatamente ai dati osservati \\(y\\). Formalmente, essa è definita come:\n\\[\n\\mathbb{V}(\\theta \\mid y) = \\mathbb{E}\\left[(\\theta - \\mathbb{E}[\\theta \\mid y])^2 \\mid y \\right] = \\int (\\theta - \\mathbb{E}[\\theta \\mid y])^2 \\, p(\\theta \\mid y) \\, d\\theta.\n\\]\nUn modo equivalente per calcolarla è attraverso l’identità:\n\\[\n\\mathbb{V}(\\theta \\mid y) = \\mathbb{E}[\\theta^2 \\mid y] - \\left(\\mathbb{E}[\\theta \\mid y]\\right)^2.\n\\]\nPer interpretare più facilmente l’incertezza nella stessa unità di misura del parametro \\(\\theta\\), è utile considerare la deviazione standard a posteriori, data semplicemente dalla radice quadrata della varianza.\nIn conclusione, mentre la moda (MAP), la media e la mediana a posteriori forniscono diverse misure di tendenza centrale per la stima puntuale di \\(\\theta\\), la varianza (e la deviazione standard) a posteriori ne quantificano l’affidabilità. La scelta tra le diverse statistiche dipende dalla forma della distribuzione a posteriori e dagli obiettivi dell’analisi. Nel loro insieme, questi indicatori consentono di comunicare in modo sintetico non solo la migliore stima del parametro, ma anche il grado di confidenza ad essa associato, elemento cruciale in qualsiasi processo inferenziale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#intervallo-di-credibilità",
    "title": "7  Sintesi a posteriori",
    "section": "\n7.3 Intervallo di credibilità",
    "text": "7.3 Intervallo di credibilità\nNell’inferenza bayesiana, l’intervallo di credibilità è uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo riflette l’incertezza associata alla stima del parametro: un intervallo più ampio suggerisce una maggiore incertezza. Lo scopo principale dell’intervallo di credibilità è fornire una misura quantitativa dell’incertezza riguardante \\(\\theta\\).\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilità per un dato livello di confidenza \\((1 - \\alpha) \\cdot 100\\%\\). In effetti, è possibile costruire un numero infinito di tali intervalli. Per questo motivo, è necessario stabilire criteri aggiuntivi per selezionare l’intervallo di credibilità più appropriato. Tra le opzioni più comuni ci sono l’intervallo di credibilità simmetrico e l’intervallo di massima densità posteriore (HPD).\nIntervallo di credibilità simmetrico\nQuesto tipo di intervallo è centrato rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) rappresenta la stima del parametro, l’intervallo simmetrico avrà la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) è un valore positivo scelto in modo tale che la massa totale inclusa sia pari a \\((1 - \\alpha)\\). Più formalmente, un intervallo di credibilità simmetrico al livello \\(\\alpha\\) può essere espresso come:\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}],\n\\] dove \\(q_z\\) rappresenta il quantile \\(z\\) della distribuzione a posteriori. Ad esempio, un intervallo di credibilità simmetrico al 94% sarà:\n\\[\nI_{0.06} = [q_{0.03}, q_{0.97}],\n\\] dove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\nIntervallo di credibilità più stretto (intervallo di massima densità posteriore, HPD)\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto possibile che contiene il \\((1 - \\alpha) \\cdot 100\\%\\) della massa a posteriori. A differenza dell’intervallo simmetrico, l’HPD include tutti i valori di \\(\\theta\\) che hanno la maggiore densità a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l’altezza della linea in modo che l’area sotto la curva corrisponda a \\((1 - \\alpha)\\). L’HPD risulta essere il più stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l’HPD coincide con l’intervallo di credibilità simmetrico.\n\n7.3.1 Interpretazione\nIl calcolo degli intervalli di credibilità—in particolare dell’intervallo di massima densità posteriore (HPD)—richiede quasi sempre l’utilizzo di software statistici specializzati. Questo perché, nei modelli bayesiani con distribuzioni posteriori articolate o che richiedono simulazioni numeriche (ad esempio tramite Markov Chain Monte Carlo), ricavare a mano i confini dell’intervallo può risultare molto laborioso.\n\n7.3.1.1 Incertezza nel paradigma frequentista\n\n\nParametro fisso: nel contesto frequentista, il parametro di interesse (ad esempio la media di popolazione \\(\\mu\\)) è un valore costante ma sconosciuto.\n\n\nRipetizione ipotetica: immaginiamo di ripetere all’infinito il prelievo di campioni dalla popolazione. Per ciascun campione otteniamo una media \\(\\bar{x}\\) e costruendo un intervallo di confidenza al \\(100(1-\\alpha)\\%\\) avremo che, nel lungo periodo, il \\(100(1-\\alpha)\\%\\) di questi intervalli conterrà il vero \\(\\mu\\).\n\n\nInterpretazione del singolo intervallo: per un singolo intervallo calcolato, la probabilità che contenga effettivamente \\(\\mu\\) è formalmente 0 o 1, perché \\(\\mu\\) non è soggetto a variabilità stocastica—siamo semplicemente ignari del suo valore reale.\n\n7.3.1.2 Incertezza nel paradigma bayesiano\n\n\nParametro come variabile aleatoria: qui \\(\\mu\\) non è più un valore fisso, ma possiede una distribuzione di probabilità che riflette sia l’informazione a priori sia quella fornita dai dati osservati.\n\n\nCampionamento dalla distribuzione a posteriori: grazie a tecniche di simulazione (ad es. MCMC), otteniamo un insieme di possibili valori di \\(\\mu\\) che segue la distribuzione posteriore.\n\n\nCostruzione diretta dell’intervallo: scegliendo i quantili al \\(2.5\\%\\) e al \\(97.5\\%\\) di questa distribuzione, otteniamo un intervallo di credibilità al 95%. In termini intuitivi, possiamo affermare che «c’è una probabilità del 95% che \\(\\mu\\) cada all’interno di questo intervallo, dati i dati e le ipotesi a priori».\n\n7.3.1.3 Confronto e considerazioni\n\n\nFrequentista: l’intervallo di confidenza è un costrutto legato alla frequenza di lungo periodo di un procedimento ipotetico di campionamento.\n\n\nBayesiano: l’intervallo di credibilità fornisce una misura puntuale dell’incertezza sul parametro, direttamente comprensibile come probabilità condizionata sui dati osservati.\n\n\nIntuizione: per molti, l’interpretazione bayesiana risulta più aderente al senso comune, perché traduce immediatamente il grado di fiducia che possiamo riporre nei valori ipotizzati per il parametro.\n\nIn sintesi, mentre la teoria frequentista quantifica l’affidabilità del metodo di stima nel lungo periodo, l’approccio bayesiano esprime senza ambiguità la probabilità attuale che il parametro si trovi in un certo intervallo, alla luce delle evidenze e delle conoscenze pregresse.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "7  Sintesi a posteriori",
    "section": "\n7.4 Verifica di ipotesi bayesiana",
    "text": "7.4 Verifica di ipotesi bayesiana\nL’inferenza bayesiana può essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come verifica di ipotesi bayesiana. In questo tipo di inferenza, l’obiettivo è valutare la plausibilità che un parametro \\(\\theta\\) assuma valori all’interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto è probabile che \\(\\theta\\) sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\nIn questo approccio, si calcola la probabilità a posteriori che \\(\\theta\\) si trovi all’interno dell’intervallo di interesse. Questa probabilità viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un’ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilità che un parametro rientri in un intervallo specifico, dato l’evidenza osservata e le informazioni a priori.\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all’affermazione che \\(\\theta\\) rientri in un certo intervallo, fornendo una probabilità che rappresenta direttamente la plausibilità di quell’ipotesi.\n\nEsempio 7.1 Per illustrare l’approccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche et al. (2019). Il BDI-II è uno strumento per valutare la gravità dei sintomi depressivi.\nI punteggi del BDI-II per i 30 soggetti sono:\n\n# Dati del BDI-II\nbdi &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#&gt;  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35 33\n#&gt; [26] 28 27 34 27 22\n\nUn punteggio BDI-II \\(\\geq 30\\) indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n# Conteggio di depressione grave\nsum(bdi &gt;= 30)\n#&gt; [1] 17\n\nStima della distribuzione a posteriori.\nSupponiamo di voler stimare la probabilità \\(\\theta\\) di depressione grave nei pazienti clinici utilizzando una distribuzione a priori \\(Beta(8, 2)\\). I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave è un “successo”. La verosimiglianza è quindi binomiale con parametri \\(n = 30\\) e \\(y = 17\\).\nCon una distribuzione a priori \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sarà:\n\\[\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n\\] Tracciamo la distribuzione a posteriori.\n\n# Parametri della distribuzione Beta\nalpha &lt;- 25\nbeta &lt;- 15\n\n# Calcolo della densità per valori di theta\ntheta &lt;- seq(0, 1, length.out = 200)\nposterior_density &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line() +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densità di probabilità\"\n  ) \n\n\n\n\n\n\n\nStime puntuali.\n\n\nMedia a posteriori. La media della distribuzione a posteriori è calcolata come:\n\n\\[\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n\\] In R:\n\n# Calcolo della media a posteriori\nposterior_mean &lt;- alpha / (alpha + beta)\nposterior_mean\n#&gt; [1] 0.625\n\n\n\nModa a posteriori (MAP). La moda della distribuzione a posteriori è:\n\n\\[\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n\\] In R:\n\n# Calcolo della moda a posteriori\nposterior_mode &lt;- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#&gt; [1] 0.632\n\n\n\nMediana a posteriori. La mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n# Calcolo della mediana a posteriori\nposterior_median &lt;- qbeta(0.5, alpha, beta)\nposterior_median\n#&gt; [1] 0.627\n\nIntervallo di credibilità.\n\n\nIntervallo di credibilità simmetrico. L’intervallo di credibilità simmetrico al 94% è dato dai percentili 3% e 97%:\n\n\n# Intervallo di credibilità simmetrico al 94%\ncred_interval &lt;- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#&gt; [1] 0.478 0.761\n\nPossiamo interpretare questo intervallo come segue: c’è una certezza soggettiva del 94% che \\(\\theta\\) sia compreso tra 0.478 e 0.761.\nVerifica di ipotesi bayesiana. Infine, calcoliamo la probabilità che \\(\\theta &gt; 0.5\\):\n\\[\nP(\\theta &gt; 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n\\] In R:\n\n# Probabilità P(theta &gt; 0.5)\nprob_theta_greater_0_5 &lt;- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#&gt; [1] 0.946\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di \\(\\theta\\), ottenuto stime puntuali e costruito intervalli di credibilità. Abbiamo inoltre calcolato la probabilità che \\(\\theta\\) superi una soglia specifica, mostrando la flessibilità e l’interpretabilità delle analisi bayesiane.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-in-contesti-multivariati",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-in-contesti-multivariati",
    "title": "7  Sintesi a posteriori",
    "section": "\n7.5 Sintesi della distribuzione a posteriori in contesti multivariati",
    "text": "7.5 Sintesi della distribuzione a posteriori in contesti multivariati\nL’estensione dell’analisi bayesiana a modelli con più parametri introduce complessità legate alle interdipendenze tra i parametri stessi. Tali relazioni, se non adeguatamente considerate, possono condurre a sintesi incomplete o fuorvianti della distribuzione a posteriori, con possibili errori interpretativi.\n\n7.5.1 La sfida delle correlazioni tra parametri\nUno degli aspetti critici riguarda la presenza di correlazioni tra i parametri. Le distribuzioni marginali a posteriori — spesso utilizzate nei riassunti statistici — possono risultare ingannevoli se esaminate isolatamente. Parametri fortemente correlati possono dar luogo a marginali apparentemente piatte o poco informative, benché la loro struttura congiunta restringa significativamente lo spazio delle combinazioni plausibili. Ciò implica che, nonostante l’incertezza marginale possa sembrare elevata, l’incertezza congiunta su specifiche relazioni parametriche può essere molto ridotta.\nUn’ulteriore complicazione sorge quando le relazioni tra parametri sono non lineari. In tali casi, il massimo della distribuzione congiunta può non coincidere con i massimi delle distribuzioni marginali. Ad esempio, in presenza di strutture a “banana” o altre forme complesse, gli usuali indicatori di tendenza centrale (come la moda o la media) calcolati sui singoli parametri possono non riflettere la regione di massima densità di probabilità nello spazio multivariato.\n\n7.5.2 Approcci per una sintesi efficace\nPer una rappresentazione fedele dell’incertezza in contesti multivariati, è essenziale adottare una prospettiva che vada oltre l’analisi delle marginali:\n\nVisualizzazione delle relazioni congiunte: Grafici di dispersione a coppie (pair plots) o contour plot bidimensionali consentono di esplorare visivamente le dipendenze tra parametri, rivelando strutture non catturate dalle marginali.\nUtilizzo di distribuzioni predittive: Il confronto tra distribuzioni predittive a priori e a posteriori fornisce una visione complessiva dell’incertezza ridotta dall’evidenza dei dati, tenendo conto di tutte le interazioni parametriche.\nMisure di dipendenza avanzate: In casi di relazioni non lineari, misure come la correlazione di Spearman o l’informazione mutua possono integrare la correlazione lineare, offrendo una descrizione più completa delle dipendenze.\nAnalisi di sensibilità: Valutare come variano le inferenze al variare di gruppi di parametri aiuta a identificare le relazioni più influenti e a comprendere la stabilità delle conclusioni.\n\nIn conclusione, una sintesi appropriata della distribuzione a posteriori in presenza di più parametri richiede un esame congiunto delle relazioni tra di essi. La sola inspezione delle distribuzioni marginali rischia di occultare importanti fonti di informazione circa la struttura parametrica, con possibili conseguenze sulle inferenze tratte. Un approccio integrato — che unisca visualizzazione, misure di dipendenza e analisi di sensibilità — è fondamentale per una comprensione robusta dei risultati bayesiani in contesti multivariati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#riflessioni-conclusive",
    "title": "7  Sintesi a posteriori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto che il cuore dell’approccio bayesiano non è soltanto ottenere una distribuzione a posteriori, ma anche imparare a descriverla in modo utile. Abbiamo distinto tra diversi modi di riassumere un posterior (media, mediana, moda) e tra diverse forme di intervallo credibile, chiarendo come ciascuna offra una prospettiva diversa sull’incertezza.\nQueste sintesi non sostituiscono la distribuzione completa, ma la rendono comunicabile. L’intervallo credibile, in particolare, ci permette di dire con chiarezza quali valori del parametro hanno una certa probabilità a posteriori di essere veri, dato il modello e i dati osservati. Questo rappresenta una differenza cruciale rispetto all’approccio frequentista, in cui l’interpretazione degli intervalli di confidenza rimane indiretta e spesso fonte di equivoci.\nDal punto di vista della ricerca psicologica, la capacità di sintetizzare il posterior è indispensabile. Molti risultati sperimentali si basano sulla stima di proporzioni, medie o differenze tra gruppi, e il modo in cui presentiamo l’incertezza può fare la differenza tra una conclusione chiara e una affermazione ambigua. Una sintesi ben costruita non solo comunica meglio, ma rafforza la solidità della conoscenza accumulata, perché rende trasparenti i margini di dubbio.\nQuesto capitolo chiude così un primo ciclo del nostro percorso: abbiamo imparato a costruire distribuzioni a posteriori e a sintetizzarle. Nei prossimi capitoli vedremo come andare oltre i parametri e usare il posterior per fare previsioni sui dati futuri e per confrontare modelli alternativi. È qui che il pensiero bayesiano mostrerà tutta la sua forza: non solo descrivere ciò che sappiamo, ma anche guidare ciò che possiamo aspettarci.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\n\nSpiega le differenze tra moda (MAP), media a posteriori e mediana.\nIn quali contesti è preferibile utilizzare una di queste statistiche rispetto alle altre?\n\n2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?\n\nSpiega le differenze concettuali tra i due approcci.\nQuale dei due è più intuitivo in termini di incertezza sui parametri?\n\n3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?\n\nSpiega il concetto di HPD e perché è più informativo in alcuni casi.\nIn quali situazioni l’HPD è preferibile rispetto all’intervallo di credibilità simmetrico?\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\n\nPerché il MAP può essere meno affidabile rispetto ad altre statistiche?\nQuali problemi si possono incontrare nei modelli bayesiani complessi?\n\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?\n\nQuali sono le principali difficoltà nell’interpretare la distribuzione congiunta di più parametri?\nCome si possono visualizzare e sintetizzare distribuzioni posteriori multivariate?\n\nDomande applicative in R\nPer queste domande, usa il dataset basato sulla Satisfaction with Life Scale (SWLS), supponendo che i dati seguano una distribuzione normale.\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa. - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l’intervallo.\n\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\n4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l’HPD.\n\n5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23.\n\nUsa la distribuzione a posteriori per calcolare questa probabilità.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\nLe tre principali statistiche usate per ottenere una stima puntuale del parametro \\(\\theta\\) nella distribuzione a posteriori sono:\n\n\nModa (Massimo a Posteriori, MAP)\n\nÈ il valore di \\(\\theta\\) che massimizza la distribuzione a posteriori \\(p(\\theta \\mid y)\\).\n\nSe la distribuzione è unimodale e simmetrica, il MAP coincide con la media a posteriori.\n\nIl MAP è spesso simile alla stima di massima verosimiglianza (MLE) quando il prior è uniforme.\n\n\n\nMedia a Posteriori\n\nÈ il valore atteso della distribuzione a posteriori:\\[\nE(\\theta \\mid y) = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta\n\\]\n\nÈ la stima più utile quando si vuole minimizzare l’errore quadratico medio (MSE).\n\nRisente dell’eventuale asimmetria della distribuzione, spostandosi verso le code.\n\n\n\nMediana a Posteriori\n\nÈ il valore che divide la distribuzione a posteriori in due parti uguali:\\[\nP(\\theta \\leq \\theta_{\\text{mediana}} \\mid y) = 0.5\n\\]\n\nÈ più robusta agli outlier rispetto alla media ed è utile quando la distribuzione è fortemente asimmetrica.\n\n\n\n💡 Quando usarle? - Se la distribuzione è simmetrica, tutte e tre le statistiche coincidono. - Se la distribuzione è asimmetrica, la mediana è più robusta, la media può essere influenzata dalle code e il MAP è utile se si vuole un valore più probabile.\n2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?\n\n\n\n\n\n\n\nCaratteristica\nIntervallo di Credibilità (Bayesiano)\nIntervallo di Confidenza (Frequentista)\n\n\n\nSignificato\nEsprime la probabilità che il parametro sia nell’intervallo, dati i dati osservati.\nÈ una proprietà di un metodo di campionamento: se si ripetesse l’esperimento infinite volte, il \\((1 - \\alpha)100\\%\\) degli intervalli conterrebbe il vero valore del parametro.\n\n\nApproccio\nAssume che il parametro sia una variabile casuale con una distribuzione di probabilità.\nAssume che il parametro sia fisso e sconosciuto, mentre i dati sono casuali.\n\n\nInterpretazione\n“C’è il 95% di probabilità che il parametro sia tra questi valori.”\n“Se ripetessimo l’esperimento molte volte, il 95% degli intervalli conterrebbe il vero parametro.”\n\n\n\n💡 Differenza fondamentale:\n\nL’intervallo di credibilità è probabilistico e più intuitivo: si può direttamente dire che il parametro ha il 95% di probabilità di trovarsi nell’intervallo.\n\nL’intervallo di confidenza è basato sulla ripetizione ipotetica dell’esperimento e non può essere interpretato in termini probabilistici sul singolo intervallo.\n\n3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto che contiene una percentuale fissata (es. 94%) della distribuzione a posteriori. Si distingue dall’intervallo di credibilità simmetrico perché:\n\n\n\n\n\n\n\nCaratteristica\nIntervallo HPD\nIntervallo di Credibilità Simmetrico\n\n\n\nDefinizione\nContiene il \\((1 - \\alpha)100\\%\\) della probabilità a posteriori, minimizzando la lunghezza dell’intervallo.\nÈ centrato attorno alla mediana e copre una frazione fissa della distribuzione.\n\n\nForma\nPuò essere asimmetrico e discontinuo se la distribuzione è multimodale.\nÈ sempre simmetrico.\n\n\nVantaggio\nÈ più informativo se la distribuzione è asimmetrica o multimodale.\nÈ più facile da calcolare, specialmente per distribuzioni unimodali.\n\n\n\n💡 Quando usarli?\n\nSe la distribuzione è simmetrica, entrambi gli intervalli danno risultati simili.\n\nSe la distribuzione è asimmetrica o multimodale, l’HPD è più informativo.\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\nSebbene il MAP sia un concetto intuitivo (il valore più probabile della distribuzione a posteriori), presenta alcune limitazioni:\n\n\nDifficoltà computazionale con MCMC\n\nCon metodi di campionamento come Markov Chain Monte Carlo (MCMC), trovare il massimo della distribuzione a posteriori è difficile perché la funzione viene stimata in modo discreto.\nSpesso si preferisce stimare media o mediana, più facili da calcolare con MCMC.\n\n\n\nSensibilità ai dati e al prior\n\nIl MAP dipende fortemente dal prior scelto.\nSe il prior è informativo, il MAP può spostarsi troppo rispetto ai dati.\n\n\n\nProblemi con distribuzioni multimodali\n\nSe la distribuzione a posteriori ha più di un massimo (moda), il MAP potrebbe non essere una buona rappresentazione della distribuzione.\n\n\n\n💡 Quando evitarlo?\n- Se la distribuzione a posteriori è asimmetrica o multimodale. - Se si usa un metodo MCMC, dove la media o la mediana sono più semplici da stimare.\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?\nQuando l’inferenza bayesiana coinvolge più parametri (es. \\(\\mu\\) e \\(\\sigma\\)), l’analisi diventa più complessa per diversi motivi:\n\n\nInterazioni tra parametri\n\nI parametri spesso non sono indipendenti: la distribuzione a posteriori congiunta può mostrare correlazioni che non emergono dalle distribuzioni marginali.\n\n\n\nDifficoltà di visualizzazione\n\nPer un parametro si usa un istogramma o una funzione di densità.\nPer due parametri si usa un contour plot o un grafico 3D.\nCon più di due parametri, si ricorre a pair plots o matrici di correlazione.\n\n\n\nStimare margine e congiunta\n\nLa distribuzione marginale di un parametro si ottiene integrando la distribuzione congiunta rispetto agli altri parametri: \\[\np(\\theta_1) = \\int p(\\theta_1, \\theta_2) d\\theta_2\n\\]\n\nSe i parametri sono fortemente correlati, le marginali possono nascondere informazioni importanti.\n\n\n\nRischio di correlazioni non lineari\n\nLe correlazioni non lineari tra i parametri possono portare a distribuzioni con forme complesse (es. a banana), rendendo difficile la sintesi con MAP o media.\n\n\n\n💡 Strategie per affrontare il problema:\n- Visualizzare le correlazioni tra i parametri con scatter plot o heatmap.\n- Usare tecniche di riduzione della dimensionalità come PCA (Analisi delle Componenti Principali).\n- Utilizzare il MCMC per campionare direttamente dalla distribuzione congiunta.\nEsercizio in R con i dati SWLS\nNell’esercizio, usa i dati della SWLS che sono stati raccolti. Qui useremo i dati seguenti:\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.\n\nUsa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n\nlibrary(tibble)\n\n# Dati\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\nsigma &lt;- 1  # Deviazione standard nota\n\n# Prior diffuso\nmu_prior &lt;- 4.5    \nsigma_prior &lt;- 10  \n\n# Media a posteriori\nmu_post &lt;- (sigma_prior^2 * mean_x + sigma^2 * n * mu_prior) / (sigma_prior^2 + sigma^2 * n)\n\n# Deviazione standard a posteriori\nsigma_post &lt;- sqrt((sigma_prior^2 * sigma^2) / (sigma_prior^2 + sigma^2 * n))\n\n# Moda (MAP)\nposterior_mode &lt;- mu_post  # Per una distribuzione normale, MAP coincide con la media\n\n# Mediana (simile alla media in una distribuzione normale)\nposterior_median &lt;- mu_post\n\ntibble(\"Media a Posteriori\" = mu_post,\n       \"Moda (MAP)\" = posterior_mode,\n       \"Mediana\" = posterior_median)\n2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l’intervallo.\n\ncred_interval &lt;- qnorm(c(0.03, 0.97), mean = mu_post, sd = sigma_post)\ncred_interval\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\nlibrary(ggplot2)\n\n# Campionamento dalla distribuzione a posteriori\nset.seed(123)\nsamples &lt;- rnorm(1000, mean = mu_post, sd = sigma_post)\n\n# Creazione del dataframe\nsamples_df &lt;- tibble(media_campionata = samples)\n\n# Grafico della distribuzione a posteriori\nggplot(samples_df, aes(x = media_campionata)) +\n  geom_density(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Distribuzione a Posteriori della Media SWLS\",\n       x = \"Media\", y = \"Densità\")\n4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l’HPD.\n\nlibrary(bayestestR)\n\n# Calcolo intervallo HPD al 94%\nhpd_interval &lt;- hdi(samples, ci = 0.94)\nhpd_interval\n5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23 – per fare un esempio, qui caloleremo per i dati simulati la probabilità a posteriori per la media SWLS maggiore di 4.7.\n\nUsa la distribuzione a posteriori per calcolare questa probabilità.\n\nprob_greater_4_7 &lt;- 1 - pnorm(4.7, mean = mu_post, sd = sigma_post)\nprob_greater_4_7\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#&gt; [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#&gt; [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#&gt; [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#&gt; [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#&gt; [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [46] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#&gt; [49] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [58] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#&gt; [61] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#&gt; [64] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [67] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#&gt; [70] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [73] lme4_1.1-37           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [76] rbibutils_2.3         QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [79] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [82] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [85] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [88] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [91] htmltools_0.5.8.1     lifecycle_1.0.4       mitml_0.4-5          \n#&gt; [94] MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#bibliografia",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#bibliografia",
    "title": "7  Sintesi a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto come costruire distribuzioni a posteriori combinando ciò che sapevamo prima (priori) con l’informazione proveniente dai dati. Abbiamo anche imparato a riassumere e comunicare queste distribuzioni attraverso quantità sintetiche e intervalli credibili. A questo punto, una domanda diventa cruciale: quanto contano davvero i priori rispetto ai dati nell’inferenza bayesiana?\nQuesta domanda non è solo tecnica, ma profondamente concettuale. In psicologia, come in altre scienze, i dati raccolti sono sempre limitati, e i priori rappresentano sia la conoscenza teorica accumulata sia le assunzioni inevitabili che facciamo prima di osservare i risultati. L’equilibrio tra questi due elementi definisce la natura dell’inferenza bayesiana: non un calcolo meccanico, ma un dialogo continuo tra teoria ed evidenza empirica.\nIn questo capitolo esploreremo come varia l’influenza dei priori in funzione della quantità di dati e della forza delle assunzioni iniziali. Vedremo che, con pochi dati, i priori possono avere un peso decisivo, mentre con molti dati la verosimiglianza tende a dominare. Questo ci aiuterà a capire meglio perché la scelta dei priori è così importante e, allo stesso tempo, perché non bisogna temere che un prior ragionevole “distorca” i risultati quando l’evidenza empirica è abbondante.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#introduzione",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#introduzione",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Panoramica del capitolo\n\nFunzione dei prior nell’inferenza.\nTipologie principali di prior.\nInfluenza della quantità di dati.\nEffetti delle trasformazioni di scala.\nPriori coniugati e sensibilità.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Balance and Sequentiality in Bayesian Analyses di Bayes rules! (Johnson et al., 2022).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "\n8.1 La distribuzione a priori",
    "text": "8.1 La distribuzione a priori\nLa distribuzione a priori descrive ciò che sappiamo o ipotizziamo su un parametro prima di osservare i dati. In psicologia, questo significa poter integrare la conoscenza accumulata da studi precedenti o da esperienze cliniche nelle nostre analisi. Ad esempio, se stiamo studiando l’efficacia di un intervento di mindfulness sulla riduzione dell’ansia, potremmo già sapere da ricerche precedenti che l’effetto tipico si colloca intorno a una riduzione moderata dei sintomi. Una distribuzione a priori ben scelta ci consente di incorporare questa informazione e di rafforzare la plausibilità delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "\n8.2 Tipologie di distribuzioni a priori",
    "text": "8.2 Tipologie di distribuzioni a priori\nLa scelta della prior (nota come elicitazione) è uno dei passaggi più delicati dell’approccio bayesiano. Non va intesa come un atto puramente soggettivo: spesso può e deve basarsi su dati empirici e conoscenze consolidate.\nSi distinguono tre categorie principali:\n\nPriori non informative. Servono quando non abbiamo conoscenze pregresse. Assegnano la stessa credibilità a tutti i valori di un parametro. Esempio: se studiamo la correlazione tra due nuove variabili psicologiche mai indagate prima, potremmo iniziare assumendo che tutte le correlazioni da –1 a +1 siano ugualmente probabili.\nPriori debolmente informative. Introducono ipotesi “di buon senso” senza imporre vincoli rigidi. Esempio: nella ricerca psicologica è improbabile che un trattamento aumenti l’ansia in modo enorme (ad es. di 10 deviazioni standard). Una prior debolmente informativa può limitare la stima a un intervallo plausibile (ad es. effetti compresi tra –2 e +2 deviazioni standard), escludendo valori assurdi.\nPriori informative. Riflettono conoscenze specifiche derivanti da studi precedenti o meta-analisi. Esempio: se una meta-analisi mostra che gli interventi di terapia cognitivo-comportamentale riducono in media i sintomi depressivi con un effetto di circa 0.5 deviazioni standard, possiamo usare questa informazione per formulare una prior centrata intorno a 0.5.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "\n8.3 L’importanza della prior in base ai dati",
    "text": "8.3 L’importanza della prior in base ai dati\nUn principio fondamentale è che più dati osserviamo, meno la prior influisce sulle stime. Se raccogliamo centinaia di osservazioni, la verosimiglianza domina l’inferenza, rendendo meno rilevante la scelta della prior. Viceversa, con pochi dati la prior può avere un peso notevole. Questo è frequente in psicologia quando lavoriamo con campioni ridotti, ad esempio con pazienti affetti da un disturbo raro. In tali casi, una prior ben scelta può rendere le stime più stabili e coerenti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#trasformazioni-e-scala-dei-parametri",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#trasformazioni-e-scala-dei-parametri",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "\n8.4 Trasformazioni e scala dei parametri",
    "text": "8.4 Trasformazioni e scala dei parametri\nUn punto spesso trascurato riguarda il fatto che le prior non sono “neutre” rispetto al cambiamento di scala. Ad esempio, se in uno studio sulla soddisfazione lavorativa esprimiamo un punteggio medio in una scala da 1 a 10, una prior uniforme su quella scala appare “piatta” e non informativa. Ma se trasformiamo la scala in percentuale (0–100), la stessa prior non rimane più uniforme. Questo mostra che una prior non può essere “piatta” per tutte le possibili rappresentazioni del parametro: occorre sempre riflettere su quale scala sia più significativa per il problema psicologico studiato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#priori-coniugate-e-metodi-moderni",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#priori-coniugate-e-metodi-moderni",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "\n8.5 Priori coniugate e metodi moderni",
    "text": "8.5 Priori coniugate e metodi moderni\nStoricamente, i ricercatori preferivano usare priori coniugate, che semplificano i calcoli perché producono posteriori della stessa famiglia di distribuzioni. Ad esempio, la distribuzione Beta è coniugata alla Binomiale: se osserviamo il numero di successi in un test di memoria, una prior Beta consente di calcolare facilmente la posteriori. Oggi, grazie ai metodi di campionamento (ad esempio MCMC), non è più necessario limitarsi alle priors coniugate. Possiamo scegliere priors più flessibili, anche non coniugate, che meglio riflettono le conoscenze psicologiche disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#simulazioni",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#simulazioni",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "\n8.6 Simulazioni",
    "text": "8.6 Simulazioni\nPer comprendere meglio come le distribuzioni a priori influenzano le nostre conclusioni, possiamo usare delle simulazioni. La formula di Bayes\n\\[\np(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\n\\] ci dice che la distribuzione a posteriori nasce dalla combinazione di due elementi:\n\nla distribuzione a priori, cioè ciò che crediamo prima di osservare i dati;\nla verosimiglianza, cioè quanto i dati osservati sono compatibili con ciascun valore possibile del parametro \\(\\theta\\).\n\nIn pratica, se abbiamo i valori della verosimiglianza e della prior su una griglia di possibili valori di \\(\\theta\\), possiamo moltiplicarli “punto per punto” e ottenere così la distribuzione a posteriori.\n\n8.6.1 Un esempio psicologico: tassi di risposta corretta\nImmaginiamo di voler stimare la probabilità \\(\\theta\\) che uno studente risponda correttamente a una domanda di un test di memoria. Abbiamo osservato che, su 9 domande, lo studente ha risposto correttamente a 6. Questo può essere modellato con una verosimiglianza binomiale. Ora ci chiediamo: come cambiano le nostre conclusioni se assumiamo priori differenti?\n\n8.6.2 Passo 1: definire la verosimiglianza\n\n# Dati osservati: 6 risposte corrette su 9\nsuccess &lt;- 6\ntosses &lt;- 9\n\n# Griglia di possibili valori di theta\ngrid_points &lt;- 100\np_grid &lt;- seq(0, 1, length.out = grid_points)\n\n# Verosimiglianza binomiale\nlikelihood &lt;- dbinom(success, tosses, p_grid)\n\nLa verosimiglianza indica quali valori di \\(\\theta\\) (probabilità di risposta corretta) sono più compatibili con i dati. In questo caso, i valori intorno a 0.67 (6/9) hanno la probabilità più alta.\n\n8.6.3 Passo 2: funzione per calcolare e visualizzare la posterior\n\ncomputePosterior &lt;- function(likelihood, prior, p_grid) {\n  # Calcolo della posteriori non normalizzata\n  unstd_posterior &lt;- likelihood * prior\n  # Normalizzazione\n  posterior &lt;- unstd_posterior / sum(unstd_posterior)\n  \n  # Preparazione dati per il grafico\n  data &lt;- tibble(\n    theta = p_grid,\n    Prior = prior,\n    Likelihood = likelihood,\n    Posterior = posterior\n  ) |&gt; \n    pivot_longer(cols = c(Prior, Likelihood, Posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  # Grafico\n  g &lt;- ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    facet_wrap(~distribution, scales = \"free_y\", ncol = 3) +\n    labs(\n      x = expression(theta),\n      y = \"Densità\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5),\n          legend.position = \"none\",\n          strip.text = element_text(size = 12, face = \"bold\"))\n  \n  print(g)\n  return(posterior)\n}\n\nLa funzione non solo calcola la distribuzione a posteriori, ma produce anche un grafico comparativo di prior, likelihood e posterior.\n\n8.6.4 Prior uniforme\n\nprior1 &lt;- rep(1, grid_points)\nposterior1 &lt;- computePosterior(likelihood, prior1, p_grid)\n\n\n\n\n\n\n\nCommento: la prior uniforme assegna uguale credibilità a tutti i valori di \\(\\theta\\). Il risultato è che la posteriori coincide quasi con la verosimiglianza: senza conoscenze pregresse, sono i dati (6 risposte corrette su 9) a guidare completamente l’inferenza.\n\n8.6.5 Prior a gradino\n\nprior2 &lt;- ifelse(p_grid &gt;= 0.5, 1, 0)\nposterior2 &lt;- computePosterior(likelihood, prior2, p_grid)\n\n\n\n\n\n\n\nCommento: qui assumiamo che \\(\\theta\\) non possa essere inferiore a 0.5 (cioè lo studente deve rispondere almeno come “a caso”). La posteriori esclude quindi qualsiasi valore sotto 0.5, anche se la verosimiglianza avrebbe assegnato loro un po’ di probabilità. Questo esempio mostra come una convinzione forte possa vincolare pesantemente le conclusioni.\n\n8.6.6 Prior esponenziale centrata su 0.5\n\nprior3 &lt;- exp(-5 * abs(p_grid - 0.5))\nposterior3 &lt;- computePosterior(likelihood, prior3, p_grid)\n\n\n\n\n\n\n\nCommento: questa prior esprime l’idea che lo studente abbia circa il 50% di probabilità di rispondere correttamente. La posteriori viene “attirata” verso 0.5, pur tenendo conto dei dati (6 su 9 ≈ 0.67). Il risultato finale è un compromesso: né tutto nei dati, né tutto nella prior.\nQuesto esercizio mostra chiaramente il ruolo delle prior:\n\ncon una prior piatta prevalgono i dati,\ncon una prior vincolante (gradino) le ipotesi iniziali dominano,\ncon una prior moderata (esponenziale) si ottiene un compromesso.\n\nIn psicologia, dove spesso i campioni sono piccoli, la scelta della prior può cambiare molto le conclusioni: un motivo in più per rendere trasparenti e motivate le ipotesi di partenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#il-caso-coniugato-beta-binomiale",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#il-caso-coniugato-beta-binomiale",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "\n8.7 Il caso coniugato: Beta-Binomiale",
    "text": "8.7 Il caso coniugato: Beta-Binomiale\nUn esempio classico in cui i calcoli diventano semplici è il modello Beta-Binomiale. La distribuzione Beta è coniugata alla Binomiale: ciò significa che la forma della posteriori rimane una Beta.\n\nplot_beta_binomial &lt;- function(alpha, beta, y, n) {\n  theta &lt;- seq(0, 1, length.out = 100)\n  prior_density &lt;- dbeta(theta, alpha, beta)\n  likelihood &lt;- dbinom(y, n, theta)\n  scaled_likelihood &lt;- likelihood / max(likelihood)\n  posterior_density &lt;- dbeta(theta, alpha + y, beta + n - y)\n  \n  data &lt;- tibble(\n    theta = theta,\n    Prior = prior_density,\n    Likelihood = scaled_likelihood,\n    Posterior = posterior_density\n  ) |&gt; \n    pivot_longer(cols = c(Prior, Likelihood, Posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    labs(x = expression(theta), y = \"Densità\") +\n    theme(plot.title = element_text(hjust = 0.5))\n}\n\nPrior uniforme:\n\nplot_beta_binomial(alpha = 1, beta = 1, y = 6, n = 9)\n\n\n\n\n\n\n\nPrior informativo:\n\nplot_beta_binomial(alpha = 2, beta = 2, y = 6, n = 9)\n\n\n\n\n\n\n\nPrior fortemente informativo:\n\nplot_beta_binomial(alpha = 2, beta = 5, y = 6, n = 9)\n\n\n\n\n\n\n\nCon un prior uniforme, i dati (6 su 9) guidano quasi interamente la stima. Con un prior più informativo, la posterior si sposta nella direzione suggerita dalle credenze pregresse.\nIn sintesi, le simulazioni mostrano due punti chiave:\n\n\nIl peso della prior dipende dalla quantità di dati. Con pochi dati (come i 9 tentativi del nostro studente), la prior può influenzare molto la stima. Con tanti dati, la verosimiglianza tende a prevalere.\n\nLe scelte di prior hanno senso solo se motivate. In psicologia, una prior può derivare da ricerche precedenti (es. meta-analisi), da conoscenze teoriche (es. aspettarci che un trattamento riduca e non aumenti i sintomi) o da ipotesi ragionevoli.\n\nL’approccio bayesiano ci permette quindi di integrare flessibilmente dati e conoscenze pregresse, arrivando a inferenze che sono al tempo stesso empiricamente fondate e teoricamente sensate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "\n8.8 Connessione tra intuizioni e teoria",
    "text": "8.8 Connessione tra intuizioni e teoria\nL’equilibrio tra ciò che crediamo prima (la distribuzione a priori) e ciò che osserviamo dopo (i dati) non è solo una metafora utile: è una vera e propria necessità matematica. Questo diventa evidente guardando al caso della distribuzione Beta-Binomiale, uno dei modelli più semplici e didattici.\nIl valore atteso della distribuzione a posteriori può essere riscritto in questa forma:\n\\[\n\\begin{aligned}\n\\mathbb{E}_{\\text{post}}[\\theta] &= \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\[6pt]\n&= \\underbrace{\\frac{\\alpha+\\beta}{\\alpha+\\beta+n}}_{\\text{peso del priore}} \\cdot\n\\underbrace{\\frac{\\alpha}{\\alpha+\\beta}}_{\\text{media a priori}}\n\\;+\\;\n\\underbrace{\\frac{n}{\\alpha+\\beta+n}}_{\\text{peso dei dati}} \\cdot\n\\underbrace{\\frac{y}{n}}_{\\text{media osservata}} .\n\\end{aligned}\n\\] Questa equazione ci mostra che il valore atteso a posteriori è sempre una media ponderata di due elementi:\n\nla media a priori (\\(\\alpha/(\\alpha+\\beta)\\)), cioè ciò che pensavamo prima di raccogliere i dati;\nla proporzione osservata (\\(y/n\\)), cioè ciò che i dati suggeriscono.\n\nI pesi che regolano il compromesso dipendono dal rapporto tra il numero di osservazioni \\(n\\) e la somma \\(\\alpha+\\beta\\) (che misura quanto “forte” è l’informazione contenuta nella prior).\n\nSe \\(n\\) è molto grande, prevalgono i dati: la posteriori riflette quasi esclusivamente le osservazioni empiriche.\nSe \\(n\\) è piccolo, prevale la prior: la stima finale risente molto delle convinzioni iniziali.\n\n\n8.8.1 Un’analogia psicologica\nPensiamo a uno psicologo che vuole stimare la probabilità che uno studente ricordi correttamente un concetto dopo una lezione.\n\nSe ha già osservato centinaia di risposte di quello studente, i dati domineranno l’inferenza, e la sua idea iniziale (la prior) conterà poco.\nSe invece ha visto solo poche risposte, tenderà ad affidarsi molto di più alle convinzioni iniziali (per esempio, che lo studente abbia in generale una buona memoria).\n\n8.8.2 Come scegliere i parametri\n\nSe vogliamo esprimere completa incertezza, possiamo usare \\(\\alpha = \\beta = 1\\), che assegna la stessa probabilità a tutti i valori possibili di \\(\\theta\\) (da 0 a 1).\nSe abbiamo informazioni pregresse (es. da studi precedenti o da esperienza clinica), scegliamo \\(\\alpha/(\\alpha+\\beta)\\) in modo che coincida con il valore atteso a priori desiderato.\nLa quantità \\(\\alpha+\\beta\\) regola invece “quanto ci crediamo”: più è grande, più dati serviranno per spostare la nostra convinzione iniziale.\n\nIn sintesi, questa formulazione mostra in modo chiaro che l’approccio bayesiano è una combinazione bilanciata tra teoria e dati. Il risultato non è mai solo la nostra ipotesi iniziale, né solo l’evidenza empirica, ma un’integrazione delle due. Questo rende l’inferenza bayesiana particolarmente adatta alle scienze psicologiche, dove spesso lavoriamo con campioni piccoli e dove le conoscenze accumulate in precedenza sono preziose per guidare l’interpretazione dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "\n8.9 Conflitto tra prior e verosimiglianza",
    "text": "8.9 Conflitto tra prior e verosimiglianza\nConsideriamo un esempio discusso da McElreath, che mette in luce un punto importante: anche in situazioni semplici, la combinazione tra distribuzione a priori e verosimiglianza può produrre risultati poco intuitivi.\n\nLesson: Don’t trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\nNella prima figura McElreath invita a riflettere su quattro diversi casi:\n\nNella seconda figura mostra i risultati effettivi delle combinazioni di prior e likelihood:\n\nL’idea centrale è confrontare il comportamento della distribuzione normale (con code sottili) e della distribuzione di Student-t con 2 gradi di libertà (con code molto più spesse). Le code indicano quanto la distribuzione attribuisce ancora una certa plausibilità a valori estremi.\n\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nQuesto è lo scenario “classico”. La posteriori si colloca a metà strada tra prior e likelihood, bilanciando le due informazioni. L’aggiornamento è regolare e prevedibile: i dati spostano la nostra convinzione iniziale, ma senza sorprese.\n\n\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nQui entrambe le distribuzioni hanno code spesse. Ciò significa che attribuiscono alta plausibilità anche a valori molto lontani dal centro. Il risultato è che la posteriori diventa più incerta e “larga”, con un compromesso meno definito. Non esiste un punto centrale netto, ma piuttosto una distribuzione che riflette la forte apertura a valori estremi.\n\n\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, la likelihood normale (con code sottili) è molto rigida: penalizza i valori lontani. Il prior Student-t, invece, non è sorpreso da valori estremi. Il risultato è che la posteriori viene guidata soprattutto dalla likelihood normale, con un effetto limitato del prior.\n\n\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nQui accade l’opposto: il prior normale, con le sue code sottili, esercita un’influenza dominante. La likelihood Student-t, che accetterebbe valori estremi, viene “corretta” dal prior, che restringe la plausibilità attorno al proprio centro.\n\n\nIn sintesi, questo esercizio mostra come il comportamento della posteriori dipenda in modo cruciale dalla forma relativa di prior e likelihood. Con prior e likelihood gaussiane, l’aggiornamento è intuitivo. Appena introduciamo distribuzioni con code spesse (Student-t), la dinamica cambia: a volte prevale la prior, a volte la likelihood, e il risultato può essere molto diverso da quello che ci aspetteremmo a intuito.\nMorale: nell’analisi bayesiana non basta “affidarsi al buon senso”. Quando prior e likelihood hanno forme diverse, il risultato dell’aggiornamento può essere sorprendente. Per questo è sempre necessario eseguire i calcoli, non solo ragionare intuitivamente.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#riflessioni-conclusive",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl tema dell’equilibrio tra priori e dati tocca il cuore dell’approccio bayesiano. Una delle critiche più frequenti al bayesianesimo è che i risultati dipenderebbero “troppo” dai priori. Come abbiamo visto, questa affermazione è vera solo in parte: il peso relativo del prior e dei dati dipende dalla situazione.\nCon pochi dati, i priori hanno un’influenza maggiore, ed è giusto che sia così: in condizioni di scarsità informativa, le nostre assunzioni teoriche forniscono una guida essenziale. Con molti dati, al contrario, l’influenza dei priori tende a ridursi, e i posteriori riflettono quasi interamente l’evidenza empirica. In entrambi i casi, il vantaggio dell’approccio bayesiano è che questo equilibrio è reso esplicito e trasparente, e non nascosto dietro formule o procedure automatiche.\nDal punto di vista psicologico, questo è un aspetto particolarmente rilevante. In un campo in cui i campioni sono spesso piccoli e le misure rumorose, i priori non sono un “problema”, ma una risorsa: permettono di incorporare conoscenze accumulate, di stabilizzare le stime e di ridurre il rischio di interpretazioni fuorvianti. Allo stesso tempo, l’analisi di sensibilità — cioè il confronto tra posteriori ottenuti con priori diversi — ci aiuta a verificare quanto i risultati dipendano dalle scelte iniziali.\nQuesto capitolo mostra quindi che la forza dell’inferenza bayesiana non sta nel dare tutto il potere ai dati o tutto ai priori, ma nel bilanciare i due in modo coerente. Nei capitoli successivi vedremo come questo equilibrio giochi un ruolo decisivo anche nella costruzione di modelli più complessi e, soprattutto, nella loro valutazione comparativa.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nL’obiettivo di questo esercizio è comprendere come la distribuzione a priori influenzi la distribuzione a posteriori a seconda della grandezza del campione. Utilizzeremo dati raccolti della Satisfaction With Life Scale (SWLS), categorizzandoli in base a una soglia e analizzando la proporzione di risposte che superano tale soglia con un approccio bayesiano.\nFase 1: Raccolta e categorizzazione dei dati\n\nOgni studente utilizza i valori della scala SWLS che sono stati raccolti dal suo gruppo TPV.\nSi sceglie una soglia arbitraria (ad esempio, un punteggio superiore a 20 indica “elevata soddisfazione”).\n\nSi calcola la proporzione di persone con punteggi superiori alla soglia:\n\\[\n\\hat{p} = \\frac{k}{n}\n\\]\ndove \\(k\\) è il numero di persone con SWLS sopra la soglia e \\(n\\) è la dimensione del campione (circa 15).\n\n\nFase 2: Inferenza Bayesiana con un Prior Mediamente Informativo\n\n\nSi assume una distribuzione Beta come prior per la proporzione di persone con SWLS sopra la soglia:\n\\[\np \\sim \\text{Beta}(a, b)\n\\]\ndove \\(a = 2\\) e \\(b = 2\\), un prior mediamente informativo (distribuzione simmetrica centrata su 0.5).\n\n\nSi calcola la distribuzione a posteriori utilizzando la coniugazione della Beta con la distribuzione binomiale:\n\\[\np \\mid D \\sim \\text{Beta}(a + k, b + n - k)\n\\]\n\n\nSi calcolano:\n\n\nStima puntuale della proporzione (valore atteso della Beta a posteriori):\n\\[\nE[p \\mid D] = \\frac{a + k}{a + b + n}\n\\]\n\nIntervallo di credibilità (CI al 95%), utilizzando i quantili della distribuzione Beta a posteriori.\n\n\n\nFase 3: Analisi con un Campione Più Grande\n\nSi ripete lo stesso esercizio, ma immaginando che la stessa proporzione \\(\\hat{p}\\) provenga da un campione di n = 1000.\n\nSi calcola la nuova distribuzione a posteriori:\n\\[\np \\mid D \\sim \\text{Beta}(a + k', b + n' - k')\n\\] con \\(k' = \\hat{p} \\times 1000\\).\n\nSi ricalcolano stima puntuale e intervallo di credibilità.\n\nFase 4: Confronto e Interpretazione\n\n\nSi confrontano le due distribuzioni a posteriori:\n\nCome cambia la varianza della distribuzione a posteriori?\nCome cambia l’influenza del prior?\nQual è la differenza nella precisione della stima puntuale e dell’intervallo di credibilità?\n\n\nSi discute come, all’aumentare del campione, l’influenza della distribuzione a priori diminuisce, facendo emergere il ruolo della likelihood.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#&gt; [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#&gt; [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#&gt; [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#&gt; [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#&gt; [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [46] tidyselect_1.2.1      abind_1.4-8           codetools_0.2-20     \n#&gt; [49] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [58] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#&gt; [61] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#&gt; [64] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [67] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#&gt; [70] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [73] lme4_1.1-37           mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [76] rbibutils_2.3         QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [79] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [82] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [85] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [88] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [91] htmltools_0.5.8.1     lifecycle_1.0.4       mitml_0.4-5          \n#&gt; [94] MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#bibliografia",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#bibliografia",
    "title": "8  L’influenza della distribuzione a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html",
    "title": "9  Controllo predittivo a priori",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto che l’inferenza bayesiana nasce dall’integrazione tra ciò che sappiamo prima (i priori) e ciò che osserviamo nei dati (la verosimiglianza). Abbiamo anche discusso il problema del bilanciamento tra assunzioni iniziali ed evidenza empirica, sottolineando che i priori non sono un dettaglio tecnico, ma una parte essenziale del ragionamento statistico. A questo punto si impone una domanda pratica: come possiamo valutare se i priori che abbiamo scelto sono ragionevoli?\nUn modo diretto e intuitivo è ricorrere ai controlli predittivi sui priori [prior predictive checks; Gelman et al. (2020)]. L’idea è semplice: se i priori rappresentano le nostre credenze prima di vedere i dati, allora dovremmo poterli usare per simulare dei dati “ipotetici” e chiederci se questi assomigliano a ciò che potremmo realisticamente osservare in psicologia. Se i dati simulati appaiono del tutto implausibili, significa che i nostri priori non stanno catturando in modo adeguato le conoscenze di partenza.\nIn questo capitolo introdurremo il concetto e la pratica dei controlli predittivi sui priori. Vedremo come si eseguono, perché sono fondamentali per una modellazione coerente e quali errori comuni ci aiutano a evitare.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#introduzione",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#introduzione",
    "title": "9  Controllo predittivo a priori",
    "section": "",
    "text": "Panoramica del capitolo\n\nChe cos’è la distribuzione predittiva a priori e perché è importante nell’inferenza bayesiana.\nSimulare dati prima di osservare quelli reali, per valutare la coerenza tra il modello e ciò che ci aspettiamo dal fenomeno studiato.\nApplicare il controllo predittivo a priori nel caso beta-binomiale, con esempi in R.\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nlibrary(bayesplot)\nlibrary(brms)\nlibrary(posterior)\nlibrary(priorsense)\nlibrary(cmdstanr)\n\n\n\n\n\n9.0.1 L’idea fondamentale\nIl prior predictive check si basa su una domanda chiave: “Se questa distribuzione a priori riflette davvero le nostre aspettative, quali dati dovremmo osservare in pratica?” In altre parole, simuliamo dati plausibili generati dal modello prima di analizzare i dati reali, per verificare se le nostre assunzioni iniziali producono risultati coerenti con la realtà teorica o empirica del fenomeno studiato.\n\n9.0.1.1 Perché è importante?\nNei modelli bayesiani, le distribuzioni a priori codificano la nostra conoscenza (o ignoranza) preliminare. Tuttavia:\n\n\nprior apparentemente innocue possono, combinate con il modello di verosimiglianza, generare previsioni implausibili (es., valori al di fuori del range possibile, comportamenti estremi non realistici);\n\n\nprior troppo informative possono dominare ingiustificatamente l’evidenza dei dati, mentre prior troppo vaghe possono portare a stime instabili.\n\nIl prior predictive check ci permette di esplorare la distribuzione predittiva a priori, \\(p(\\tilde{y})\\), dove \\(\\tilde{y}\\) sono dati simulati, per identificare incongruenze prima della fase inferenziale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#la-definizione-formale",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#la-definizione-formale",
    "title": "9  Controllo predittivo a priori",
    "section": "\n9.1 La definizione formale",
    "text": "9.1 La definizione formale\nNon conoscendo i parametri \\(\\theta\\), non possiamo formulare un’unica predizione \\(p(\\tilde y \\mid \\theta)\\). Invece, la distribuzione predittiva a priori \\(p(\\tilde y)\\) combina le predizioni di tutti i possibili valori di \\(\\theta\\), pesandoli in base alla loro plausibilità a priori.\nÈ come consultare un gruppo di esperti (i possibili \\(\\theta\\)) e aggregare i loro giudizi, ponderandoli in base a quanto li riteniamo affidabili prima di osservare qualsiasi dato. La formula che descrive questo processo è:\n\\[\np(\\tilde y \\mid \\text{prior}) = \\int p(\\tilde y \\mid \\theta)\\, p(\\theta)\\, d\\theta .\n\\tag{9.1}\\] Questo integrale rappresenta una combinazione (mixture) di distribuzioni.1 Non stiamo calcolando una media aritmetica di singoli valori di \\(\\tilde y\\), ma piuttosto mescolando intere distribuzioni condizionate \\(p(\\tilde y \\mid \\theta)\\), ciascuna ponderata dalla sua probabilità a priori \\(p(\\theta)\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#implementazione-e-valutazione-del-ppc",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#implementazione-e-valutazione-del-ppc",
    "title": "9  Controllo predittivo a priori",
    "section": "\n9.2 Implementazione e valutazione del PPC",
    "text": "9.2 Implementazione e valutazione del PPC\nPer verificare l’adeguatezza della distribuzione a priori, seguiamo un approccio sistematico:\n\nDefinizione del modello generativo\nSi stabilisce la relazione tra parametri e dati attraverso la verosimiglianza \\(p(y \\mid \\theta)\\), includendo eventuali funzioni di collegamento (logit, log) necessarie per garantire coerenza con il dominio delle variabili.\nSpecificazione della distribuzione a priori\nLe prior dovrebbero riflettere conoscenze preliminari debolmente informative, adattate alla scala naturale del problema. Per parametri con vincoli naturali (es., deviazioni standard positive), si utilizzano distribuzioni a supporto ristretto (half-normal, esponenziale).\n\nSimulazione della distribuzione predittiva\nLa procedura consiste nel generare valori sintetici dei dati direttamente dalla combinazione prior + verosimiglianza:\n\nsi estrae un valore dei parametri \\(\\theta^{(s)}\\) dalla distribuzione a priori \\(p(\\theta)\\) (quindi con la probabilità relativa specificata da quella distribuzione);\n\ndato \\(\\theta^{(s)}\\), la verosimiglianza \\(p(y \\mid \\theta^{(s)})\\) è completamente definita (es., una Binomiale con probabilità di successo pari a \\(\\theta^{(s)}\\));\n\nsi genera un dato sintetico \\(\\tilde{y}^{(s)}\\) campionando una realizzazione da questa verosimiglianza;\n\nsi ripete la procedura per \\(s = 1, \\dots, S\\).\n\nL’insieme \\(\\{\\tilde{y}^{(s)}\\}_{s=1}^S\\) costituisce un’approssimazione della distribuzione predittiva a priori, cioè la distribuzione dei dati che ci aspettiamo di osservare prima di guardare i dati reali.\n\n\nValidazione empirica\nLe simulazioni vengono confrontate con i vinciti teorici del problema:\n\n\nAderenza al dominio: I valori simulati devono rispettare i limiti naturali della variabile (es., probabilità in [0,1], tempi positivi).\n\n\nRealismo quantitativo: Gli ordini di grandezza devono essere plausibili per il fenomeno studiato.\n\n\nComportamento distributivo: La dispersione e la forma della distribuzione devono essere coerenti con l’aspettativa teorica.\n\n\n\n\n\n\n\n\n\nCaso studio: modellazione di risposte dicotomiche\n\n\n\n\n\nSupponiamo di analizzare la probabilità \\(p\\) di successo in un test psicometrico. La scelta della prior per \\(p\\) influenza direttamente le previsioni del modello:\n\nPrior estrema (es. Beta(0.1, 0.1)):\nAssume che le risposte siano quasi sempre corrette o quasi sempre errate, implicando una popolazione con prestazioni polarizzate. Le simulazioni mostrerebbero prevalentemente tassi di successo vicini a 0% o 100%, scenario spesso irrealistico in contesti educativi.\nPrior bilanciata (es. Beta(2, 2)):\nRiflette l’aspettativa che le risposte siano distribuite attorno al 50%, analogamente al lancio di una moneta equa. Le simulazioni genererebbero una variabilità più plausibile per popolazioni eterogenee.\n\nValidazione attraverso simulazioni.\nIl prior predictive check rivela queste implicazioni:\n\nGenerando dati sintetici con la prior estrema, si osserverebbero distribuzioni bimodali con picchi agli estremi, incongruenti con il comportamento atteso in molti studi psicologici.\n\nCon la prior bilanciata, le simulazioni mostrerebbero invece una dispersione centrata attorno a valori intermedi, coerente con una popolazione mista.\n\nRicalibrazione: Se le simulazioni risultano implausibili (es., &gt;30% di valori estremi non giustificati dalla teoria), si può:\n\nmodificare i parametri della prior (es., passare a Beta(1, 1) per ridurre le assunzioni a priori);\nintrodurre trasformazioni (es., logit per evitare valori al di fuori di [0,1]);\n\nadottare prior gerarchiche per catturare eterogeneità sottogruppo.\n\nProspettiva epistemologica.\nIl processo equivale a:\n\nformalizzare le ipotesi iniziali in termini probabilistici (scelta della prior);\n\nverificarne le conseguenze empiriche attraverso simulazioni;\n\nrivalutare criticamente le assunzioni alla luce delle previsioni generate.\n\nQuesto approccio previene errori comuni nell’analisi bayesiana, come l’uso involontario di prior che sovradeterminano i risultati o generano artefatti. La coerenza tra simulazioni a priori e conoscenza di dominio è un indicatore chiave della robustezza del modello.\n\n\n\n\n\n\n\n\n\nRegola pratica: Una prior adeguata non deve essere “perfetta”, ma deve produrre scenari plausibili. Se le simulazioni appaiono sistematicamente lontane dalla realtà teorica, la specificazione del modello va ripensata, non i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#esempio-un-test-a-10-domande",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#esempio-un-test-a-10-domande",
    "title": "9  Controllo predittivo a priori",
    "section": "\n9.3 Esempio: un test a 10 domande",
    "text": "9.3 Esempio: un test a 10 domande\nQuesto esempio illustra l’idea chiave del prior predictive check (PPC): una prior sui parametri (qui, la probabilità di risposta corretta) implica predizioni sui punteggi osservabili. Se la prior assegna troppa massa a esiti estremi (0/10 o 10/10) senza giustificazione, sta “spingendo” verso scenari poco plausibili.\nConsideriamo uno studente che affronta un test da 10 domande. Il numero di risposte corrette è\n\\[\ny \\sim \\text{Binomiale}(n=10,\\; p),\n\\] dove \\(p\\) è la probabilità di rispondere correttamente a una singola domanda. La prior è su \\(p\\); ciò che osserviamo, però, sono i punteggi \\(y\\). Il PPC “propaga” l’incertezza su \\(p\\) fino ai punteggi, generando la distribuzione predittiva a priori:\n\\[\np(y) \\;=\\; \\int \\underbrace{p(y \\mid p)}_{\\text{Binom}(10,p)} \\;\\underbrace{p(p)}_{\\text{prior}} \\, dp,\n\\] che nel caso \\(p \\sim \\text{Beta}(a,b)\\) è una Beta–Binomiale.\n\n9.3.1 Scenario 1: prior debole (alta incertezza)\nScegliamo una prior larga, ad es. \\(p \\sim \\text{Beta}(2,2)\\).\n\nMedia: \\(\\mathbb{E}[p] = \\tfrac{2}{2+2} = 0.5\\)\n\nForza a priori (pseudo-conteggi): \\(a+b=4\\) (2 “successi immaginari” + 2 “errori immaginari”)\n\nQuesta prior favorisce valori centrali ma non esclude affatto \\(p\\) vicino a 0 o 1, quindi produce più esiti estremi nei punteggi.\n\nset.seed(1)\n\nn &lt;- 10\nS &lt;- 10000\np_sim &lt;- rbeta(S, 2, 2)\ny_sim &lt;- rbinom(S, size = n, prob = p_sim)\n\ntibble(y = y_sim) |&gt;\n  ggplot(aes(x = y)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 11) +\n  labs(x = \"Numero di risposte corrette su 10\", y = \"Densità\")\n\n\n\n\n\n\n\nLettura. Il modello utilizza un prior eccessivamente permissivo, adatto a una popolazione di studenti molto eterogenea (che include sia individui con prestazioni quasi sempre perfette, sia altri quasi sempre insufficienti). Il risultato è una distribuzione predittiva che assegna probabilità irrealisticamente elevate agli estremi (0/10 e 10/10), un chiaro indicatore che il prior è troppo debole (ovvero, troppo diffuso).\n\n9.3.2 Scenario 2: prior informativa (studenti preparati)\nSupponiamo ora che gli studenti siano mediamente ben preparati: \\(p \\sim \\text{Beta}(10,3)\\).\n\nMedia: \\(\\mathbb{E}[p] \\approx 0.77\\)\n\nForza a priori: \\(a+b=13\\) (10 “successi immaginari”, 3 “errori immaginari”)\nVarianza più contenuta (meno peso agli estremi)\n\nCi aspettiamo punteggi tra 6 e 9 risposte corrette.\n\nset.seed(2)\np_sim2 &lt;- rbeta(S, 10, 3)\ny_sim2 &lt;- rbinom(S, size = n, prob = p_sim2)\n\ntibble(y = y_sim2) |&gt;\n  ggplot(aes(x = y)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 11) +\n  labs(x = \"Numero di risposte corrette su 10\", y = \"Densità\")\n\n\n\n\n\n\n\nLettura. Gli esiti molto bassi (0–3) diventano poco probabili; la massa si concentra su esiti coerenti con studenti preparati.\n\n9.3.3 Perché è utile?\nIl confronto mostra che la prior non è un dettaglio tecnico: traduce in probabilità ciò che riteniamo plausibile.\n\nSe la predittiva a priori genera esiti irrealistici (es. molti 0/10), la prior va rivista (più informativa, scala coerente, pseudo-conteggi ragionevoli).\nSe la predittiva a priori è in linea con le aspettative, la prior è adeguata.\n\nIl PPC rende trasparente il legame tra assunzioni sul parametro \\(p\\) e punteggi osservabili \\(y\\), permettendo diagnosi prima di analizzare i dati reali.\nEccoti una versione migliorata dal punto di vista linguistico, tecnico e della chiarezza espositiva:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#prior-predictive-check-con-brms",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#prior-predictive-check-con-brms",
    "title": "9  Controllo predittivo a priori",
    "section": "\n9.4 Prior Predictive Check con brms\n",
    "text": "9.4 Prior Predictive Check con brms\n\nFinora abbiamo eseguito le simulazioni per la Prior Predictive Check (PPC) utilizzando funzioni di base di R. Con brms è possibile ottenere lo stesso risultato in modo più diretto, semplicemente specificando l’opzione sample_prior = \"only\". In questo modo, il modello non utilizza i dati osservati ma genera valori esclusivamente a partire dalle distribuzioni a priori (prior).\n\nn_studenti &lt;- 50\nn_item &lt;- 10\n\ndati_dummy &lt;- tibble(\n  correct  = 0L,   # Valore segnaposto: necessario per la sintassi della formula\n  n_trials = n_item\n) |&gt; slice(rep(1, n_studenti))\n\npriors &lt;- c(\n  prior(normal(0, 1.5), class = \"Intercept\") # Prior sull'intercetta in scala logit\n)\n\nfit_prior_only &lt;- brm(\n  bf(correct | trials(n_trials) ~ 1),\n  data = dati_dummy,\n  family = binomial(),\n  prior = priors,\n  sample_prior = \"only\",  # &lt;-- Simulazione prior predictive\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep &lt;- posterior_predict(fit_prior_only)\nppc_bars(y = rep(0, n_studenti), yrep = yrep[1:200, ]) \n\n\n\n\n\n\n\nInterpretazione.\n\nLa distribuzione a priori Normal(0, 1.5) è specificata per l’intercetta del modello nella scala logit.\nCiò implica che la probabilità sottostante di una risposta corretta, \\(p\\), ha una distribuzione a priori il cui massimo della densità è compreso approssimativamente tra ~0.05 e ~0.95. Questa scelta esclude, in linea di principio, probabilità sistematiche estreme (vicine a 0 o a 1), pur mantenendo un’ampia variabilità di valori plausibili.\nIl grafico mostra le distribuzioni dei punteggi totali (da 0 a 10 su 10 item) che il modello considera plausibili prima di aver osservato i dati reali (distribuzione predittiva a priori).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#prior-predictive-check-con-stan",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#prior-predictive-check-con-stan",
    "title": "9  Controllo predittivo a priori",
    "section": "\n9.5 Prior Predictive Check con Stan\n",
    "text": "9.5 Prior Predictive Check con Stan\n\nCon Stan è possibile eseguire la stessa analisi in modo ancora più esplicito: specifichiamo esclusivamente le distribuzioni a prior (prior), omettendo completamente la verosimiglianza (likelihood), e generiamo i dati simulati direttamente nel blocco generated quantities. Questo approccio permette di comprendere cosa avviene a livello computazionale.\n\nbinom_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;           // numero di studenti simulati\n  int&lt;lower=1&gt; n_items;     // numero di item per studente\n}\nparameters {\n  real alpha;               // intercetta in scala logit\n}\nmodel {\n  alpha ~ normal(0, 1.5);   // prior debolmente informativa\n  // Nessuna verosimiglianza specificata: modello basato solo sulle prior\n}\ngenerated quantities {\n  vector[N] p;              // probabilità individuali di successo\n  array[N] int y_rep;       // punteggi simulati (dati replicati)\n  for (i in 1:N) {\n    p[i] = inv_logit(alpha);            // trasformazione da logit a probabilità\n    y_rep[i] = binomial_rng(n_items, p[i]); // simulazione dei punteggi binomiali\n  }\n}\n'\nwriteLines(binom_prior_ppc_stan, \"binom_prior_ppc.stan\")\n\nCompiliamo ed eseguiamo il modello:\n\nmod_binom &lt;- cmdstan_model(\"binom_prior_ppc.stan\")\nfit_binom &lt;- mod_binom$sample(\n  data = list(N = 100, n_items = 10),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000,\n  seed = 123, refresh = 0\n)\n\nEstrazione dei punteggi simulati e analisi della distribuzione delle medie:\n\ndraws &lt;- fit_binom$draws(variables = \"y_rep\", format = \"draws_matrix\")\ny_rep &lt;- as_draws_matrix(draws)\n\ntibble(mu = rowMeans(y_rep)) |&gt;\n  ggplot(aes(x = mu)) +\n  geom_histogram(bins = 30) +\n  labs(x = \"Media delle risposte corrette (su 10 item)\", \n       y = \"Frequenza\")\n\n\n\n\n\n\n\n\n9.5.1 Interpretazione\n\nAd ogni iterazione di campionamento, viene estratto un valore del parametro \\(\\alpha\\) dalla sua distribuzione a priori, Normal(0, 1.5).\nQuesto valore viene convertito in una probabilità di successo \\(p\\) applicando la funzione logistica inversa: \\(p = \\text{inv\\_logit}(\\alpha)\\).\nUtilizzando questa probabilità \\(p\\), vengono simulati i punteggi di 100 studenti fittizi per una prova di 10 item, assumendo una distribuzione binomiale.\nL’istogramma risultante mostra la distribuzione campionaria della media dei punteggi simulati attraverso tutte le iterazioni.\n\nQuesto processo mostra chiaramente quali valori per la media del punteggio il modello considera plausibili sulla base esclusiva delle distribuzioni a priori specificate. Se avessimo scelto una distribuzione a priori più informativa (ad esempio, Normal(2, 0.5) per il logit), la distribuzione dei punteggi medi si sarebbe concentrata verso valori più elevati (indicando un’aspettativa a priori di una maggior proporzione di risposte corrette).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#esempi-di-modelli-più-complessi",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#esempi-di-modelli-più-complessi",
    "title": "9  Controllo predittivo a priori",
    "section": "\n9.6 Esempi di modelli più complessi",
    "text": "9.6 Esempi di modelli più complessi\nI precedenti esempi si sono concentrati su modelli semplici, in particolare sul caso di una singola proporzione. Estendiamo ora l’analisi a modelli di maggiore complessità. L’obiettivo è illustrare come diverse scelte delle distribuzioni precedenti (prior) per i parametri si traducano in diverse implicazioni predittive per i dati osservabili. Consideriamo tre casi di studio:\n\n\nModello gaussiano (stima dell’intercetta e della varianza dei dati);\n\nRegressione lineare (scala appropriata per i coefficienti e per la varianza residua);\n\nRegressione logistica (interpretazione dei coefficienti nella scala logit e loro impatto sulle probabilità sottostanti).\n\n\n9.6.1 Modello gaussiano semplice\nAssumiamo che il meccanismo generativo dei dati segua una distribuzione normale: \\(y \\sim \\mathcal{N}(\\mu, \\sigma)\\).\nDomanda cruciale: quali scelte delle distribuzioni precedenti per \\(\\mu\\) e \\(\\sigma\\) producono valori predittivi \\(y\\) plausibili per la variabile psicologica in esame (ad esempio, punteggi compresi tra 0 e 100)?\n\nS &lt;- 10000\n\n# Scenario A: prior molto larga\nmu_A    &lt;- rnorm(S, 50, 50)        # media plausibile ma molto incerta\nsigma_A &lt;- rexp(S, rate = 1/20)     # sigma ~ Exp(mean=20), molto larga\nyA      &lt;- rnorm(S, mu_A, sigma_A)\n\n# Scenario B: prior più informativa\nmu_B    &lt;- rnorm(S, 50, 10)\nsigma_B &lt;- rexp(S, rate = 1/10)     # mean=10\nyB      &lt;- rnorm(S, mu_B, sigma_B)\n\nbind_rows(\n  tibble(y = yA, scenario = \"A: prior larghissima\"),\n  tibble(y = yB, scenario = \"B: prior informativa\")\n) |&gt;\n  ggplot(aes(x = y, fill = scenario)) +\n  geom_density(alpha = 0.35) +\n  labs(x = \"y (es. punteggio 0–100)\", y = \"Densità\")\n\n\n\n\n\n\n\nInterpretazione. Se è noto che i punteggi della variabile di interesse sono compresi tra 0 e 100, lo Scenario A potrebbe generare una proporzione eccessiva di valori negativi o superiori a 100, indicando che le distribuzioni precedenti sono troppo poco informative e necessitano di essere ricalibrate (rendendole più informative sia per \\(\\mu\\) che per \\(\\sigma\\)).\nImplementazione in Stan: modello solo con prior e generated quantities.\n\ngauss_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  mu ~ normal(50, 10);\n  sigma ~ exponential(1.0/10); // mean 10\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1:N) {\n    y_rep[i] = normal_rng(mu, sigma);\n  }\n}\n'\nwriteLines(gauss_prior_ppc_stan, \"gauss_prior_ppc.stan\")\n\n\nmod_gauss &lt;- cmdstan_model(\"gauss_prior_ppc.stan\")\n\n\nfit_gauss &lt;- mod_gauss$sample(\n  data = list(N = 200),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000, seed = 123,\n  refresh = 0\n)\n\n\nyrep_g &lt;- fit_gauss$draws(\"y_rep\", format = \"draws_matrix\")\nas_tibble(yrep_g) |&gt;\n  pivot_longer(everything(), values_to = \"y\") |&gt;\n  ggplot(aes(x = y)) +\n  geom_density() \n\n\n\n\n\n\n\n\n9.6.2 Regressione lineare\nConsideriamo il seguente modello generativo:\n\\[\ny = \\alpha + \\beta x + \\varepsilon, \\qquad \\varepsilon \\sim \\mathcal{N}(0,\\sigma).\n\\]\n\n9.6.2.1 Importanza della scelta delle distribuzioni precedenti\nNell’ambito della regressione lineare, l’interpretazione del coefficiente \\(\\beta\\) dipende criticamente dalla scala della variabile predittrice \\(x\\):\n\nSe \\(x\\) è standardizzata (media 0, deviazione standard 1), \\(\\beta\\) rappresenta la variazione attesa in \\(y\\) associata a un incremento di una deviazione standard in \\(x\\).\nAd esempio, specificare una distribuzione a priori \\(\\beta \\sim \\mathcal{N}(0,1)\\) equivale ad assumere che: “effetti di modesta entità sono plausibili, mentre effetti superiori a 3 deviazioni standard sono estremamente rari”.\n\nI controlli predittivi basati sulle distribuzioni a priori (prior predictive checks) consentono di rispondere a due interrogativi fondamentali:\n\nLe rette di regressione simulate generano valori di \\(y\\) compatibili con la scala del fenomeno oggetto di studio?\nLa dispersione residua intorno alla retta (determinata da \\(\\sigma\\)) è realisticamente plausibile?\n\nSe la risposta a queste domande è negativa, è necessario rivedere le distribuzioni precedenti specificate per \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\), o considerare una trasformazione appropriata della variabile \\(y\\).\n\n9.6.2.2 Scenario C: Distribuzioni a priori eccessivamente diffuse\nIn questo scenario specifichiamo varianze eccessivamente ampie per \\(\\alpha\\) e \\(\\beta\\). Il risultato: i valori simulati di \\(y\\) risultano irrealistici (eccessivamente negativi o elevati rispetto alla scala empirica del costrutto).\n\nS &lt;- 10000\nx  &lt;- runif(S, -2, 2)  # predittore standardizzato\n\nalpha_C &lt;- rnorm(S, 0, 10)\nbeta_C  &lt;- rnorm(S, 0, 10)\nsigma_C &lt;- rexp(S, rate = 1/5)  # media ~5\nyC      &lt;- rnorm(S, alpha_C + beta_C * x, sigma_C)\n\nInterpretazione. Distribuzioni precedenti eccessivamente diffuse per \\(\\sigma\\) e \\(\\beta\\) rendono probabilisticamente plausibili valori di \\(y\\) privi di senso nel dominio applicativo. Questo non rappresenta un approccio “cauto” o “umile”, ma piuttosto una specificazione incoerente con l’evidenza empirica disponibile.\n\n9.6.2.3 Scenario D: Distribuzioni a priori debolmente informative\nIn questo scenario adottiamo distribuzioni precedenti centrate su zero ma con varianze moderate:\n\\(\\alpha \\sim \\mathcal{N}(0,1)\\) e \\(\\beta \\sim \\mathcal{N}(0,1)\\): effetti plausibili ma di entità contenuta \\(\\sigma \\sim \\text{Exp}(1/2)\\): valore medio atteso di 2, compatibile con la variabilità tipica di punteggi psicologici standardizzati\n\nalpha_D &lt;- rnorm(S, 0, 1)\nbeta_D  &lt;- rnorm(S, 0, 1)\nsigma_D &lt;- rexp(S, rate = 1/2)  # media ~2\nyD      &lt;- rnorm(S, alpha_D + beta_D * x, sigma_D)\n\nbind_rows(\n  tibble(y = yC, scenario = \"C: prior molto larga\"),\n  tibble(y = yD, scenario = \"D: prior W.I.\")\n) |&gt;\n  ggplot(aes(x = y, fill = scenario)) +\n  geom_density(alpha = 0.35) +\n  labs(x = \"Valori simulati di y\", y = \"Densità\")\n\n\n\n\n\n\n\nInterpretazione. Con distribuzioni precedenti debolmente informative, la distribuzione di \\(y\\) mantiene un’ampiezza plausibile. Al contrario, distribuzioni precedenti eccessivamente diffuse producono una variabilità irrealistica di \\(y\\).\n\n9.6.2.4 Implementazione in Stan: simulazione esclusiva dalle distribuzioni a priori\nPer illustrare esplicitamente il concetto, implementiamo un modello Stan che non incorpora dati osservati ma simula esclusivamente dalle distribuzioni precedenti.\n\nlinear_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta  ~ normal(0, 1);\n  sigma ~ exponential(1.0/2); // media 2\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1:N) {\n    y_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n  }\n}\n'\nwriteLines(linear_prior_ppc_stan, \"linear_prior_ppc.stan\")\n\nEsecuzione della simulazione:\n\nmod_lin &lt;- cmdstan_model(\"linear_prior_ppc.stan\")\nx_new   &lt;- runif(200, -2, 2)\n\nfit_lin &lt;- mod_lin$sample(\n  data = list(N = length(x_new), x = x_new),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000, seed = 123,\n  refresh = 0\n)\n\nVisualizzazione della distribuzione predittiva:\n\nyrep_l &lt;- fit_lin$draws(\"y_rep\", format = \"draws_matrix\")\nas_tibble(yrep_l) |&gt;\n  pivot_longer(everything(), values_to = \"y\") |&gt;\n  ggplot(aes(x = y)) +\n  geom_density() +\n  labs(x = \"Valori simulati di y\", y = \"Densità\")\n\n\n\n\n\n\n\n\n9.6.2.5 Conclusioni\n\nLa scala delle distribuzioni precedenti specificate per \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) determina direttamente la distribuzione dei valori simulati di \\(y\\).\nSe i valori di \\(y\\) simulati risultano al di fuori del dominio realistico (ad esempio, punteggi negativi o superiori al massimo teorico), le distribuzioni precedenti devono essere ricalibrate.\nL’utilizzo di distribuzioni precedenti debolmente informative (centrate su zero con varianze moderate) produce simulazioni coerenti con il contesto psicologico di riferimento.\n\n9.6.3 Regressione logistica\nNella regressione logistica, il modello per un esito binario è specificato come:\n\\[\n\\text{logit}\\, P(y=1 \\mid x) = \\alpha + \\beta x .\n\\]\nIn questo framework, i parametri \\(\\alpha\\) e \\(\\beta\\) operano sulla scala logit, che non è direttamente interpretabile in termini di probabilità. È cruciale ricordare che la funzione logit è caratterizzata da una pendenza accentuata: differenze di 2-3 unità sulla scala logit corrispondono a variazioni estreme nelle probabilità sottostanti (da circa 0.1 a 0.9).\n\n9.6.3.1 Importanza della scelta delle distribuzioni a priori\n\nCon predittori standardizzati (media 0, deviazione standard 1), una distribuzione a priori \\(\\beta \\sim \\mathcal{N}(0,1)\\) implica che effetti di moderata entità sono plausibili, mentre probabilità estreme (vicine a 0 o 1) rimangono poco probabili.\nAl contrario, una distribuzione a priori \\(\\beta \\sim \\mathcal{N}(0,2.5)\\) consente valori sulla scala logit fino a ±5, che corrispondono a probabilità praticamente certe (0 o 1). Questo approccio rischia di incorporare nel modello assunzioni di certezza assoluta prima ancora di osservare i dati.\n\nIl controllo predittivo basato sulle distribuzioni a priori (PPC) permette di verificare se le probabilità implicite generate dalle specifiche scelte parametriche sono coerenti con le aspettative del dominio applicativo.\n\n9.6.3.2 Simulazioni in R\n\nS &lt;- 10000\nx  &lt;- rnorm(S, 0, 1)  # standardizzare è buona pratica\n\n# Scenario E: prior larga\nalpha_E &lt;- rnorm(S, 0, 2.5)\nbeta_E  &lt;- rnorm(S, 0, 2.5)\npE      &lt;- plogis(alpha_E + beta_E * x)\nyE      &lt;- rbinom(S, 1, pE)\n\n# Scenario F: prior weakly-informative\nalpha_F &lt;- rnorm(S, 0, 1)\nbeta_F  &lt;- rnorm(S, 0, 1)\npF      &lt;- plogis(alpha_F + beta_F * x)\nyF      &lt;- rbinom(S, 1, pF)\n\ntibble(p = pE, scenario = \"E: prior larga\") |&gt;\n  bind_rows(tibble(p = pF, scenario = \"F: prior W.I.\")) |&gt;\n  ggplot(aes(x = p, fill = scenario)) +\n  geom_density(alpha = 0.35) +\n  labs(x = \"p(x) = P(y=1|x)\", y = \"Densità\")\n\n\n\n\n\n\n\nInterpretazione.\n\nCon distribuzioni a priori eccessivamente diffuse (Scenario E), le probabilità implicite sono frequentemente vicine ai valori estremi di 0 o 1. Ciò indica che il modello, in assenza di dati osservati, considera plausibili situazioni di quasi-certezza assoluta.\nCon distribuzioni a priori debolmente informative (Scenario F), le probabilità si distribuiscono in un range più realistico (0.05-0.95), riflettendo appropriatamente l’incertezza caratteristica dei fenomeni psicologici.\n\nLinee guida pratiche\n\nCon prior standardizzat, l’utilizzo di distribuzioni \\(\\mathcal{N}(0,1)\\) o \\(\\mathcal{N}(0,1.5)\\) per i coefficienti sulla scala logit rappresenta generalmente una scelta robusta: permette sufficiente variabilità senza generare previsioni probabilistiche estreme.\nDistribuzioni a priori eccessivamente diffuse possono produrre modelli “rigidi” che, a priori, assumono comportamenti quasi deterministici, risultando incoerenti con la variabilità tipica dei dati psicologici.\n\n9.6.3.3 Implementazione in Stan: simulazione esclusiva dalle distribuzioni precedenti\nPossiamo rendere esplicito il processo mediante un modello Stan che non incorpora dati osservati ma genera esclusivamente previsioni a partire dalle distribuzioni a priori.\n\nlogistic_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta  ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[N] p;\n  array[N] int y_rep;\n  for (i in 1:N) {\n    p[i] = inv_logit(alpha + beta * x[i]);\n    y_rep[i] = bernoulli_rng(p[i]);\n  }\n}\n'\nwriteLines(logistic_prior_ppc_stan, \"logistic_prior_ppc.stan\")\n\nEsecuzione del modello:\n\nmod_log &lt;- cmdstan_model(\"logistic_prior_ppc.stan\")\nx_new   &lt;- rnorm(300)\n\nfit_log &lt;- mod_log$sample(\n  data = list(N = length(x_new), x = x_new),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000,\n  seed = 123, refresh = 0\n)\n\nVisualizzazione delle probabilità implicite:\n\npost_p &lt;- fit_log$draws(\"p\", format = \"draws_matrix\")\nas_tibble(post_p) |&gt;\n  pivot_longer(everything(), values_to = \"p\") |&gt;\n  ggplot(aes(x = p)) +\n  geom_density() +\n  labs(x = \"p(x)\", y = \"Densità\")\n\n\n\n\n\n\n\n\n9.6.3.4 Conclusioni\n\nLe distribuzioni a priori nella regressione logistica influenzano direttamente la distribuzione delle probabilità implicite generate dal modello.\nDistribuzioni a priori eccessivamente diffuse equivalgono ad assumere, prima di osservare i dati, che siano probabili risposte quasi certe (0 o 1).\nDistribuzioni a priori moderate preservano invece l’incertezza appropriata, riflettendo più fedelmente la realtà dei fenomeni psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#linee-guida-pratiche-per-la-specificazione-delle-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#linee-guida-pratiche-per-la-specificazione-delle-distribuzioni-a-priori",
    "title": "9  Controllo predittivo a priori",
    "section": "\n9.7 Linee guida pratiche per la specificazione delle distribuzioni a priori",
    "text": "9.7 Linee guida pratiche per la specificazione delle distribuzioni a priori\n\n\nLavorare sulla scala appropriata\n\nQuando possibile, standardizzare i predittori (centrati a media 0 e scalati a deviazione standard 1).\nQuesto approccio garantisce un’interpretazione uniforme dei coefficienti: una distribuzione Normal(0,1) suggerisce che effetti “moderati” (variazioni di circa una deviazione standard nell’outcome per ogni deviazione standard nel predittore) siano i più plausibili.\n\n\n\nCoefficienti di regressione (\\(\\beta\\))\n\nUn punto di partenza solido consiste nell’utilizzare distribuzioni a priori Normal(0, 0.5–2).\nCon \\(\\beta \\sim \\mathcal{N}(0,1)\\): effetti di piccola e media entità sono considerati plausibili, mentre effetti di grande magnitudine rimangono possibili ma meno probabili.\nImportante: senza standardizzazione dei predittori, la scala di \\(\\beta\\) cambia radicalmente, invalidando queste linee guida.\n\n\n\nIntercetta (\\(\\alpha\\))\n\nPer outcome continui (modelli gaussiani), centrare la variabile dipendente \\(y\\) rende l’intercetta più direttamente interpretabile.\nPer outcome binari (modelli logistici), una Normal(0,1–1.5) implica probabilità a priori tipicamente comprese tra 0.05 e 0.95; una Normal(0,2.5) è significativamente più permissiva, rendendo probabili scenari di quasi-certezza.\n\n\n\nParametri di dispersione (\\(\\sigma\\))\n\nUtilizzare distribuzioni a priori definite solo per valori positivi (Half-Normal, Exponential, Gamma).\nSpecificare il parametro di scala dell’Exponential in accordo con l’ordine di grandezza atteso nel dominio applicativo. Ad esempio, per punteggi su scala 0-100, una Exponential(media ≈ 5–10) rappresenta una scelta generalmente ragionevole.\nVerificare sistematicamente mediante simulazioni che la dispersione generata sia coerente con la variabilità attesa nei dati reali.\n\n\n\nTrasformazioni non lineari (logit, log)\n\nEvitare di interpretare esclusivamente i coefficienti sulla scala trasformata: convertire sistematicamente nelle scale naturali di interesse.\nTradurre i coefficienti logit in probabilità implicite e i coefficienti log in tassi attesi.\nPorsi criticamente la domanda: “Queste distribuzioni a priori implicano che i soggetti abbiano probabilità estreme (vicine a 0 o 1) di manifestare il comportamento?”\n\n\n\nValidazione e trasparenza metodologica\n\nEseguire sempre controlli predittivi basati sulle distribuzioni a priori (prior predictive checks): se i dati simulati appaiono “irrealistici” (ad esempio, valori negativi per scale positive o fuori range), le distribuzioni a priori necessitano ri-calibrazione.\nDocumentare dettagliatamente il processo di specificazione: quali distribuzioni sono state testate, quali modifiche sono state apportate e le motivazioni sottostanti. Questa trasparenza costituisce un elemento fondamentale del rigore metodologico nell’analisi bayesiana.\n\n\n\n\n\n\n\n\n\nAppendice: prior predictive con brms per i tre casi\n\n\n\n\n\nModello gaussiano.\n\nN &lt;- 100\ndf_g &lt;- tibble(y = rnorm(N, 50, 10)) # placeholder, non usato con \"only\"\n\nfit_g_prior &lt;- brm(\n  bf(y ~ 1),\n  data = df_g,\n  family = gaussian(),\n  prior = c(\n    prior(normal(50, 10), class = \"Intercept\"),\n    prior(exponential(0.1), class = \"sigma\")        \n    # prior(exponential(1.0/10), class = \"sigma\")   \n  ),\n  sample_prior = \"only\",\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep_g &lt;- posterior_predict(fit_g_prior)\nppc_dens_overlay(y = df_g$y, yrep = yrep_g[1:200, ])\n\n\n\n\n\n\n\nRegressione lineare.\n\nN &lt;- 120\ndf_l &lt;- tibble(\n  y = rnorm(N),\n  x = rnorm(N)\n)\n\n\nfit_l_prior &lt;- brm(\n  bf(y ~ 1 + x),\n  data = df_l,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 1), class = \"Intercept\"),\n    prior(normal(0, 1), class = \"b\", coef = \"x\"),\n    prior(exponential(0.5), class = \"sigma\")      # &lt;-- 0.5 (oppure 1.0/2)\n    # prior(exponential(1.0/2), class = \"sigma\")  # &lt;-- equivalente\n  ),\n  sample_prior = \"only\",\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep_l &lt;- posterior_predict(fit_l_prior)\nppc_dens_overlay(y = df_l$y, yrep = yrep_l[1:200, ]) +\n  xlim(-5, 5)\n\n\n\n\n\n\n\nRegressione logistica.\n\nN &lt;- 150\ndf_log &lt;- tibble(\n  y = rbinom(N, 1, 0.5),  # placeholder\n  x = rnorm(N)\n)\n\n\nfit_log_prior &lt;- brm(\n  bf(y ~ 1 + x),\n  data = df_log,\n  family = bernoulli(),\n  prior = c(\n    prior(normal(0, 1.5), class = \"Intercept\"),\n    prior(normal(0, 1), class = \"b\", coef = \"x\")\n  ),\n  sample_prior = \"only\",\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep_log &lt;- posterior_predict(fit_log_prior)\nppc_bars(y = df_log$y, yrep = yrep_log[1:200, ])",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#riflessioni-conclusive",
    "title": "9  Controllo predittivo a priori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nI controlli predittivi sui priori rappresentano una delle innovazioni più importanti portate dall’approccio bayesiano alla pratica della ricerca psicologica. Non ci limitiamo più a dichiarare i priori come un’astrazione matematica, ma li trattiamo come ipotesi concrete che generano conseguenze osservabili.\nQuesto ha almeno tre implicazioni rilevanti:\n\n\nTrasparenza: invece di nascondere le nostre assunzioni, le rendiamo visibili e criticabili, mostrando quali dati ci aspetteremmo prima ancora di fare l’esperimento.\n\nCoerenza con la teoria psicologica: i priori possono e devono riflettere la letteratura, la teoria o l’esperienza accumulata. Se la simulazione produce risultati incompatibili con ciò che sappiamo, significa che stiamo imponendo assunzioni sbagliate.\n\nRobustezza inferenziale: controllare i priori prima di analizzare i dati riduce il rischio di ottenere posteriori fuorvianti o difficili da interpretare.\n\nDal punto di vista didattico, i prior predictive checks aiutano anche a chiarire agli studenti il significato dei priori: non sono semplici parametri arbitrari, ma veri e propri modelli di ciò che consideriamo plausibile prima di vedere i dati.\nIn sintesi, questo capitolo mostra che i priori non devono essere accettati acriticamente: vanno testati e, se necessario, rivisti. Nei prossimi capitoli vedremo come un approccio analogo possa essere applicato anche ai posteriori, estendendo l’idea dei controlli predittivi all’intero processo di modellazione.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [46] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [49] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [58] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [64] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [73] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [76] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [79] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [82] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#bibliografia",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#bibliografia",
    "title": "9  Controllo predittivo a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modrák, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_prior_pred_check.html#footnotes",
    "href": "chapters/bayesian_inference/09_prior_pred_check.html#footnotes",
    "title": "9  Controllo predittivo a priori",
    "section": "",
    "text": "Immagina di voler sapere che gusto avrà un succo se mescoli vari ingredienti. Non fai la media del gusto di singoli bicchieri, ma prendi un po’ di ogni succo (distribuzione) e li mescoli: il risultato è una nuova bevanda (la distribuzione predittiva a priori).↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_post_pred_distr.html",
    "href": "chapters/bayesian_inference/10_post_pred_distr.html",
    "title": "10  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto due aspetti fondamentali dell’inferenza bayesiana: da un lato, la costruzione delle distribuzioni a posteriori per i parametri di interesse; dall’altro, l’importanza di verificare i priori attraverso i controlli predittivi, per assicurarci che le nostre assunzioni iniziali siano coerenti con la realtà psicologica che vogliamo studiare.\nOra compiamo un passo ulteriore: invece di chiederci se i nostri priori siano ragionevoli, ci chiediamo se l’intero modello, dopo aver incorporato i dati osservati, sia in grado di generare previsioni plausibili. Questo ci porta al concetto di distribuzione predittiva a posteriori (posterior predictive distribution).\nLa logica è semplice e potente: se un modello è una rappresentazione credibile del processo che ha generato i dati, allora dovrebbe essere in grado non solo di adattarsi ai dati raccolti, ma anche di simulare dati nuovi con caratteristiche simili. In questo senso, le distribuzioni predittive a posteriori diventano uno strumento centrale per la valutazione dei modelli: collegano direttamente i parametri stimati ai dati futuri che ci aspettiamo di osservare.\nIn questo capitolo vedremo come costruire la distribuzione predittiva a posteriori, come interpretarla e come utilizzarla per verificare la coerenza del modello con l’evidenza empirica. Questo approccio ci permetterà di mettere alla prova in modo pratico la capacità del modello di spiegare e prevedere i fenomeni psicologici che ci interessano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_post_pred_distr.html#introduzione",
    "href": "chapters/bayesian_inference/10_post_pred_distr.html#introduzione",
    "title": "10  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "Panoramica del capitolo\n\nPrevisione bayesiana: incorporare incertezza parametrica e variabilità intrinseca.\nVerifica di coerenza: valutare l’adeguatezza del modello ai dati osservati.\nCaso beta-binomiale: applicazione pratica del framework predittivo.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Posterior Inference & Prediction di Bayes Rules!.\nConsultare Bayesian statistics and modelling (Schoot et al., 2021).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_post_pred_distr.html#definizione-formale",
    "href": "chapters/bayesian_inference/10_post_pred_distr.html#definizione-formale",
    "title": "10  Distribuzione predittiva a posteriori",
    "section": "\n10.1 Definizione formale",
    "text": "10.1 Definizione formale\nSi considerino dati osservati \\(y = \\{y_1, y_2, \\ldots, y_n\\}\\), generati da un modello probabilistico parametrizzato da \\(\\theta\\), dove \\(\\theta\\) può rappresentare una probabilità, una media, un vettore di coefficienti o altri parametri di interesse. La conoscenza iniziale su \\(\\theta\\) è formalizzata attraverso una distribuzione a priori \\(p(\\theta)\\). L’osservazione dei dati consente di aggiornare questa conoscenza mediante il teorema di Bayes, ottenendo la distribuzione a posteriori:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)\\, p(\\theta)}{p(y)},\n\\] dove:\n\n\\(p(\\theta \\mid y)\\) è la distribuzione a posteriori, che rappresenta l’incertezza su \\(\\theta\\) condizionata ai dati osservati;\n\\(p(y \\mid \\theta)\\) è la funzione di verosimiglianza, che specifica la probabilità dei dati dati i parametri;\n\\(p(\\theta)\\) è la distribuzione a priori;\n\n\\(p(y)\\) è l’evidenza marginale, calcolata come\n\\[\np(y) = \\int p(y \\mid \\theta) p(\\theta)\\, d\\theta.\n\\]\n\n\n\n10.1.1 La distribuzione predittiva a posteriori\nSia \\(\\tilde{y}\\) una nuova osservazione da prevedere. La distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\) fornisce la distribuzione probabilistica di \\(\\tilde{y}\\) condizionata ai dati osservati.\n\n10.1.1.1 Natura di \\(\\tilde{y}\\)\n\n\n\n\\(\\tilde{y}\\) rappresenta un dato futuro non ancora osservato;\nNell’esempio binomiale, se \\(y\\) è il numero di successi in \\(n\\) prove, \\(\\tilde{y}\\) può rappresentare il numero di successi in \\(n_{\\text{new}}\\) prove future.\n\n10.1.1.2 Relazione condizionale\n\n\n\\(p(\\tilde{y} \\mid \\theta)\\) esprime la probabilità di \\(\\tilde{y}\\) assumendo noto il parametro \\(\\theta\\);\nNel caso binomiale: \\(p(\\tilde{y} \\mid \\theta) = \\binom{n_{\\text{new}}}{\\tilde{y}} \\theta^{\\tilde{y}} (1-\\theta)^{n_{\\text{new}}-\\tilde{y}}\\).\n\n10.1.1.3 Integrazione sull’incertezza parametrica\nPoiché \\(\\theta\\) è incerto, la distribuzione predittiva a posteriori integra su tutti i possibili valori di \\(\\theta\\), pesati secondo la distribuzione a posteriori:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta.\n\\tag{10.1}\\]\n\n10.1.1.4 Interpretazione\nLa distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\) rappresenta la migliore previsione probabilistica per dati futuri, incorporando tanto l’incertezza sui parametri del modello quanto la variabilità intrinseca del processo generativo dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_post_pred_distr.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/10_post_pred_distr.html#il-modello-beta-binomiale",
    "title": "10  Distribuzione predittiva a posteriori",
    "section": "\n10.2 Il modello Beta-Binomiale",
    "text": "10.2 Il modello Beta-Binomiale\nSi consideri un esperimento binomiale consistente in \\(n\\) prove indipendenti, dove si osserva il numero di successi \\(y\\) (ad esempio, il numero di teste nel lancio di una moneta). L’approccio bayesiano si articola in tre fasi fondamentali:\n\n\nSpecificazione della distribuzione a priori La conoscenza iniziale riguardante la probabilità di successo \\(p\\) viene formalizzata attraverso una distribuzione Beta(\\(\\alpha, \\beta\\)), particolarmente appropriata per parametri definiti sull’intervallo unitario:\n\nIl parametro \\(\\alpha\\) rappresenta un numero pseudo-osservato di successi;\nIl parametro \\(\\beta\\) rappresenta un numero pseudo-osservato di insuccessi.\n\nQuesta parametrizzazione consente di incorporare conoscenze pregresse in forma di “evidenza virtuale”.\n\n\nAggiornamento bayesiano alla distribuzione a posteriori Dopo l’osservazione di \\(y\\) successi in \\(n\\) prove, la distribuzione a posteriori si ottiene mediante aggiornamento coniugato:\n\\[\np \\mid y \\sim \\text{Beta}(\\alpha + y, \\beta + n - y).\n\\]\nQuesta distribuzione caratterizza completamente l’incertezza residua sul parametro \\(p\\) condizionatamente ai dati osservati.\n\n\nCostruzione della distribuzione predittiva a posteriori Per prevedere il numero di successi \\(y_{\\text{new}}\\) in \\(n_{\\text{new}}\\) prove future, si integra l’incertezza parametrica con la variabilità campionaria attraverso il seguente procedimento:\n\nCampionamento parametrico: \\(p^{(s)} \\sim \\text{Beta}(\\alpha + y, \\beta + n - y)\\)\n\nGenerazione predittiva: \\(y_{\\text{new}}^{(s)} \\sim \\text{Binomial}(n_{\\text{new}}, p^{(s)})\\)\n\n\nLa distribuzione empirica dei valori \\(y_{\\text{new}}^{(s)}\\) costituisce un’approssimazione Monte Carlo della distribuzione predittiva a posteriori, incorporando sia l’incertezza epistemica su \\(p\\) sia la variabilità aleatoria del processo binomiale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_post_pred_distr.html#un-esempio-numerico",
    "href": "chapters/bayesian_inference/10_post_pred_distr.html#un-esempio-numerico",
    "title": "10  Distribuzione predittiva a posteriori",
    "section": "\n10.3 Un esempio numerico",
    "text": "10.3 Un esempio numerico\n\n10.3.1 I dati e le nostre conoscenze iniziali\n\n\nDati osservati: 70 successi su 100 prove (ad esempio, 70 teste su 100 lanci di moneta)\n\nConoscenza iniziale (prior): usiamo una distribuzione Beta(2, 2). Questa prior è “debole” e suggerisce che pensiamo che la moneta sia probabilmente equilibrata (p ≈ 0.5), ma siamo aperti ad altre possibilità.\n\n10.3.2 Aggiornamento delle nostre conoscenze\nDopo aver visto i dati, aggiorniamo le nostre convinzioni sulla probabilità di successo p:\nalpha_posterior = 2 + 70 = 72\nbeta_posterior = 2 + (100 - 70) = 32\nOra crediamo che p segua una distribuzione Beta(72, 32), che è centrata attorno a 0.7.\n\n10.3.3 Simulazione delle previsioni\nVogliamo prevedere cosa succederà in 10 lanci futuri:\n\n# Dati osservati\nsuccessi_osservati &lt;- 70\nlanci_totali &lt;- 100\n\n# Prior (conoscenza iniziale)\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\n\n# Posterior (conoscenza aggiornata)\nalpha_post &lt;- alpha_prior + successi_osservati\nbeta_post &lt;- beta_prior + (lanci_totali - successi_osservati)\n\n# Simuliamo 1000 valori plausibili per p\nvalori_p &lt;- rbeta(1000, alpha_post, beta_post)\n\n# Per ogni valore di p, simuliamo 10 lanci futuri\nsuccessi_futuri &lt;- rbinom(1000, size = 10, prob = valori_p)\n\n# Calcoliamo le proporzioni di successo\nproporzioni_future &lt;- successi_futuri / 10\n\n\n10.3.4 Spiegazione passo per passo\nAbbiamo osservato 70 successi su 100 lanci. Con una prior Beta(2,2), la distribuzione a posteriori diventa Beta(72,32). Questo significa che non conosciamo il valore esatto della probabilità di successo \\(p\\), ma possiamo descrivere in modo plausibile l’incertezza che lo circonda: molto probabilmente \\(p\\) si trova vicino a 0.7, con una certa variabilità intorno a questo valore.\nPer rappresentare questa incertezza, estraiamo 1000 valori da una distribuzione Beta(72,32): valori_p &lt;- rbeta(1000, 72, 32). Ciascun valore estratto è un candidato possibile per \\(p\\), compatibile con i dati osservati e con la nostra conoscenza iniziale. A questo punto, ci chiediamo: cosa potremmo osservare nei prossimi lanci? Per rispondere, per ogni valore di \\(p\\) simuliamo 10 nuovi lanci, ottenendo così 1000 possibili scenari futuri: successi_futuri &lt;- rbinom(1000, size = 10, prob = valori_p).\nInfine, trasformiamo il numero di successi in proporzioni dividendo per 10, in modo da avere risultati immediatamente interpretabili come probabilità di successo nei lanci futuri: proporzioni_future &lt;- successi_futuri / 10. In altre parole, otteniamo un quadro di ciò che possiamo aspettarci, tenendo insieme due fonti di incertezza: da un lato non sappiamo il valore esatto di \\(p\\), dall’altro anche conoscendo \\(p\\) i risultati dei lanci rimarrebbero comunque soggetti al caso.\nIl vettore proporzioni_future riassume queste possibilità: non una singola previsione puntuale, ma un’intera distribuzione di esiti futuri, coerente con i dati raccolti e con il modello bayesiano adottato.\n\n10.3.5 Visualizziamo i risultati\nDistribuzione iniziale (prima di vedere i dati):\n\nggplot(data.frame(x = c(0, 1)), aes(x = x)) +\n  stat_function(fun = dbeta, \n                args = list(shape1 = alpha_prior, shape2 = beta_prior), \n                color = \"#4682B4\", size = 1) +\n  labs(x = \"Probabilità di successo (p)\",\n       y = \"Densità\")\n\n\n\n\n\n\n\nConoscenza aggiornata (dopo aver visto i dati):\n\nggplot(data.frame(x = c(0, 1)), aes(x = x)) +\n  stat_function(fun = dbeta, \n                args = list(shape1 = alpha_post, shape2 = beta_post), \n                color = \"#A0522D\", size = 1) +\n  labs(x = \"Probabilità di successo (p)\",\n       y = \"Densità\")\n\n\n\n\n\n\n\nPrevisioni per i prossimi 10 lanci:\n\nggplot(data.frame(proporzioni = proporzioni_future), aes(x = proporzioni)) +\n  geom_histogram(aes(y = ..density..), bins = 20) +\n  geom_vline(aes(xintercept = successi_osservati / lanci_totali), \n             color = \"black\", size = 1, linetype = \"dashed\") +\n  labs(x = \"Proporzione di successi attesi\",\n       y = \"Densità\")\n\n\n\n\n\n\n\n\n10.3.6 Interpretazione dei risultati\n\nLa nostra conoscenza su \\(p\\) è ora concentrata attorno a 0.7 (grafico in rosso).\nLe previsioni per 10 lanci futuri sono più variabili perché:\n\nSiamo ancora un po’ incerti sul valore esatto di \\(p\\).\nAnche se conoscessimo p perfettamente, 10 lanci potrebbero dare risultati leggermente diversi.\n\n\nIl risultato osservato (70% di successi) cade nella zona più probabile delle nostre previsioni: questo ci dice che il nostro modello è ragionevole e può essere usato per fare previsioni future.\n\nIn pratica: se dovessi scommettere sui prossimi 10 lanci, ti aspetteresti probabilmente 6-8 successi, ma potrebbero essercene anche 5 o 9 per puro caso.\n\n\n\n\n\n\nNota\n\n\n\n\n\nIl fatto che, nel nostro esempio, la distribuzione predittiva a posteriori riproduca efficacemente i dati osservati potrebbe apparire come un risultato scontato. In realtà, questo esito positivo è significativo e tutt’altro che banale; dimostra che il nostro modello semplice è ben calibrato. Abbiamo scelto deliberatamente un modello binomiale con prior Beta proprio per la sua chiarezza espositiva, che ci permette di illustrare in modo trasparente la logica sottostante alla distribuzione predittiva a posteriori e mostrare visivamente come l’incertezza sui parametri e la variabilità intrinseca dei dati si integrino in un unico framework.\nTuttavia, è fondamentale comprendere che nella ricerca psicologica reale ci si confronta con modelli notevolmente più complessi. In questi contesti, la corrispondenza tra i dati effettivamente osservati e quelli generati dal modello attraverso la distribuzione predittiva non può mai essere considerata una garanzia preliminare. Al contrario, questa corrispondenza rappresenta proprio l’obiettivo da verificare.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_post_pred_distr.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/10_post_pred_distr.html#riflessioni-conclusive",
    "title": "10  Distribuzione predittiva a posteriori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLe distribuzioni predittive a posteriori rappresentano il naturale completamento del percorso iniziato con i priori. Se i prior predictive checks ci consentono di controllare la plausibilità delle nostre assunzioni iniziali, i posterior predictive checks ci permettono di verificare la plausibilità del modello alla luce dei dati.\nDal punto di vista concettuale, questo passaggio è cruciale: sposta l’attenzione dai parametri astratti ai dati concreti, e ci chiede di valutare i modelli sulla base della loro capacità di generare osservazioni simili a quelle reali. In questo senso, la distribuzione predittiva a posteriori non è soltanto un accessorio tecnico, ma una vera e propria prova di realtà per i modelli psicologici.\nDal punto di vista applicativo, questo approccio rafforza la trasparenza e la robustezza delle nostre inferenze. Non ci limitiamo più a riportare valori puntuali o intervalli credibili per i parametri: mostriamo esplicitamente quali dati il nostro modello ritiene plausibili e li confrontiamo con i dati effettivamente raccolti. Questo rende la comunicazione dei risultati più chiara e intuitiva, anche per chi non ha familiarità con la statistica bayesiana.\nIn sintesi, le distribuzioni predittive a posteriori ci ricordano che la forza dell’approccio bayesiano non risiede soltanto nella stima dei parametri, ma soprattutto nella capacità di prevedere e spiegare i fenomeni. Nei capitoli successivi vedremo come questa logica si estenda anche al confronto sistematico tra modelli, aprendo la strada a un approccio più rigoroso e cumulativo alla scienza psicologica.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nConsideriamo i dati della SWLS somministrata a un campione di studenti, ottenendo per ciascuno uno score complessivo. Per semplicità, vogliamo “dichiarare positivo” lo studente se il punteggio SWLS supera una determinata soglia (ad esempio, 20 su 35). In questo modo otteniamo una variabile dicotomica (0/1), che useremo come “successo” in un modello binomiale.\n\n\nDati e conteggio dei successi\n\nCarica il dataset con le risposte SWLS.\n\nCostruisci la variabile binaria (ad esempio SWLS_dich) che vale 1 se lo score ≥ 20, e 0 altrimenti.\n\nCalcola il numero di successi (numero di persone che superano la soglia) e il numero totale di osservazioni (N).\n\n\n\nModello beta-binomiale (approccio manuale via simulazione)\n\n\nSpecifica una distribuzione Beta(a, b) come prior per la probabilità di successo \\(p\\). Scegli una coppia \\((a, b)\\) relativamente poco informativa, ad esempio (2,2) o (1,1).\n\nOsservando \\(y\\) successi su \\(n\\) soggetti, aggiorna i parametri a posteriori: \\[\n  a_{\\text{post}} = a + y,\n  \\quad\n  b_{\\text{post}} = b + (n - y).\n\\]\n\nSimula un gran numero di campioni di \\(p\\) dalla distribuzione Beta\\(\\bigl(a_{\\text{post}},\\, b_{\\text{post}}\\bigr)\\).\n\nPer ciascun campione di \\(p\\), genera un valore \\(\\tilde{y}\\) da una Binomiale\\(\\bigl(n_{\\text{new}}, p\\bigr)\\), dove \\(n_{\\text{new}}\\) è la dimensione di un ipotetico nuovo campione (che puoi scegliere, ad esempio, uguale a \\(n\\) oppure un valore diverso). Otterrai così una posterior predictive distribution per \\(\\tilde{y}\\).\n\nInfine, calcola statistiche descrittive (media, varianza, intervalli) e/o disegna un istogramma di \\(\\tilde{y}\\) o della proporzione \\(\\tilde{y}/n_{\\text{new}}\\).\n\n\n\nReplicare con brms\n\n\nUsa il pacchetto brms per costruire un modello binomiale. Per esempio:\nlibrary(brms)\n\n# Crea un data frame con la variabile dicotomica\ndf_binom &lt;- data.frame(\n  successes = y,    # conteggio dei successi\n  failures  = n - y\n)\n\n# Modello binomiale con prior Beta(a,b) approssimato tramite logit\nfit_brms &lt;- brm(\n  bf(successes | trials(n) ~ 1), \n  data = df_binom,\n  family = binomial(link = \"logit\"),\n  prior = c(\n    prior(beta(2, 2), class = \"Intercept\", dpar = \"mu\") \n    # NOTA: la specifica di una \"beta(2,2)\" diretta sull'intercetta\n    # è un'approssimazione, tipicamente serve passare a una scala logit.\n    # In brms, di solito si usa prior su scale normali dell'intercetta.\n  ),\n  seed = 123\n)\n(Le specifiche del prior potrebbero richiedere una formulazione differente se vuoi rispettare esattamente la corrispondenza con Beta(a,b). In ogni caso, l’idea è mostrare come definire un prior e costruire un modello binomiale con brms.)\n\n\nVerifica la convergenza e poi estrai la posterior predictive distribution con le funzioni di brms:\npp_check(fit_brms, nsamples = 100)\nQuesto ti mostrerà come i dati predetti dal modello (in termini di binomiale) si confrontano con i dati osservati.\n\n\n\n\nConfronto e interpretazione\n\nMetti a confronto i risultati della simulazione “manuale” (Beta-Binomial) e quelli ottenuti con brms. Noterai che le distribuzioni predittive dovrebbero essere coerenti, se hai impostato un prior per brms simile a quello del modello Beta-Binomiale.\n\nDiscuti brevemente se la distribuzione predittiva a posteriori acquisita è plausibile rispetto ai dati osservati. Ad esempio, la probabilità di osservare \\(\\tilde{y}\\) simile a \\(y\\) dovrebbe essere relativamente alta se il modello è appropriato.\n\nSe vuoi, puoi cambiare \\(n_{\\text{new}}\\) (es. previsione su 200 soggetti futuri) per vedere come la variabilità della previsione si “ridimensiona” o cresce a seconda della taglia del campione.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nCostruzione del dataset\n\n\nSe la SWLS varia tra 5 e 35, e la soglia è 20, puoi fare:\ndf$SWLS_dich &lt;- ifelse(df$SWLS_score &gt;= 20, 1, 0)\ny &lt;- sum(df$SWLS_dich)\nn &lt;- nrow(df)\n\n\n\n\nApproccio Beta-Binomial manuale\n\nPrior: \\((a, b) = (2, 2)\\)\nPosterior: \\((a_{\\text{post}}, b_{\\text{post}}) = (2 + y,\\, 2 + n - y)\\).\n\nGenerazione dei campioni:\nN_sim &lt;- 2000\np_post &lt;- rbeta(N_sim, a_post, b_post)\ny_pred &lt;- rbinom(N_sim, size = n_new, prob = p_post)\n\n# Se preferisci la proporzione futura:\nprop_pred &lt;- y_pred / n_new\n\n\nStatistiche:\nmean_p &lt;- mean(p_post) # media a posteriori di p\nquantile_p &lt;- quantile(p_post, c(0.025, 0.975))  \n\nmean_prop_pred &lt;- mean(prop_pred)\nquantile_prop_pred &lt;- quantile(prop_pred, c(0.025, 0.975))\n\n\nGrafici (istogramma e densità):\nhist(prop_pred, freq=FALSE, col='lightblue',\n     main='Posterior Predictive Distribution: prop. di successi')\n\n\n\n\nModello con brms\n\nUsa la sintassi di una binomiale con offset o con trials(n).\n\nSpecifica un prior che approssimi Beta(2,2) sullo scale logit, ad esempio:\n# Beta(2,2) ha media ~ 0.5, varianza relativamente ampia.\n# Approssimandola su scala logit ~ normal(0, 2.2) \n# (valore indicativo: la normal(0, 2) su logit copre un intervallo ampio).\n\nprior_approx &lt;- prior(normal(0, 2), class = \"Intercept\")\n\nEsegui pp_check(fit_brms) e interpreta.\n\n\n\nInterpretazione\n\nSe la soglia scelta per la SWLS cattura un “buon livello di soddisfazione”, potresti aspettarti una certa % di successi.\n\nSe i dati futuri simulati sono coerenti con i dati reali — ad esempio, la media di \\(\\tilde{y}\\) è vicina a \\(y\\) — allora il modello sembra descrivere bene la realtà. Altrimenti, potresti rivedere la soglia o la specifica del prior.\n\n\n\nL’elemento chiave è che la distribuzione predittiva a posteriori (posterior predictive distribution) non si limita a considerare un solo valore di \\(p\\), bensì campiona molteplici valori plausibili (dalla posterior), e per ciascuno simula un potenziale outcome. Così facendo, si riflette pienamente l’incertezza residua sul parametro e l’aleatorietà del processo binomiale.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_post_pred_distr.html#bibliografia",
    "href": "chapters/bayesian_inference/10_post_pred_distr.html#bibliografia",
    "title": "10  Distribuzione predittiva a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., et al. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1), 1.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/conclusions_sec.html",
    "href": "chapters/bayesian_inference/conclusions_sec.html",
    "title": "Riflessioni conclusive della sezione",
    "section": "",
    "text": "Questa sezione ha mostrato come l’inferenza bayesiana offra un approccio coerente e trasparente per trasformare i dati in conoscenza. Abbiamo visto che:\n\nl’incertezza non è un ostacolo, ma un elemento costitutivo del ragionamento scientifico, che può essere quantificato e comunicato in termini probabilistici;\nla posterior è il cuore dell’analisi: non un singolo numero, ma una distribuzione che racconta l’intera gamma delle ipotesi compatibili con i dati;\nle prior non sono arbitrarie, ma strumenti per rendere esplicite le nostre assunzioni e per integrare conoscenza pregressa, sempre da valutare con controlli predittivi;\nla valutazione di un modello non si limita alla sua coerenza interna, ma passa attraverso il confronto tra ciò che il modello prevede e ciò che effettivamente osserviamo.\n\nIn definitiva, l’inferenza bayesiana ci insegna a pensare in termini di plausibilità graduata, superando la logica dicotomica dei test di significatività. Questa prospettiva sposta l’attenzione dalla domanda “il risultato è significativo?” a interrogativi più ricchi: quanto è credibile un certo effetto? quali valori sono compatibili con i dati? quanto informativi sono i dati rispetto alle nostre ipotesi?\nCon queste basi, siamo pronti ad affrontare modelli più complessi e strumenti computazionali avanzati (come i metodi MCMC), che ci permetteranno di applicare l’approccio bayesiano a un’ampia varietà di problemi psicologici e sociali.",
    "crumbs": [
      "Inferenza",
      "Riflessioni conclusive della sezione"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_sec.html",
    "href": "chapters/mcmc/introduction_sec.html",
    "title": "Introduzione alla sezione",
    "section": "",
    "text": "Nei capitoli precedenti abbiamo visto come l’inferenza bayesiana possa essere condotta in casi semplici, sfruttando coppie coniugate di distribuzioni o metodi diretti come l’approssimazione su griglia. Questi strumenti ci hanno permesso di capire in modo intuitivo la logica dell’aggiornamento bayesiano, ma hanno anche mostrato i loro limiti: al crescere della complessità dei modelli, i calcoli analitici diventano rapidamente impraticabili e l’approccio su griglia soffre della cosiddetta maledizione della dimensionalità.\nPer affrontare problemi realistici, dobbiamo introdurre strumenti più potenti. È qui che entrano in gioco i metodi Monte Carlo a catena di Markov (MCMC). Queste procedure ci permettono di generare campioni dalla distribuzione a posteriori anche quando non possiamo descriverla con una formula chiusa, rendendo così l’inferenza bayesiana applicabile a modelli complessi e a più parametri.\nIn questa sezione esploreremo passo dopo passo le idee alla base degli algoritmi MCMC. Partiremo dal concetto di simulazione Monte Carlo e dall’algoritmo di Metropolis, per poi introdurre strumenti più avanzati che hanno rivoluzionato la pratica dell’inferenza bayesiana, come il linguaggio Stan. Lavoreremo su esempi concreti – dalla stima di una proporzione al confronto tra due gruppi, fino ai modelli di Poisson per dati di conteggio – per mostrare come i metodi MCMC rendano possibile un’analisi che sarebbe inaccessibile con gli strumenti analitici.\nInfine, discuteremo i modelli gerarchici bayesiani, che estendono ulteriormente le possibilità dell’inferenza permettendo di rappresentare strutture di dati multilivello, frequenti in psicologia e nelle scienze sociali. Questi modelli ci offriranno un primo sguardo a quella che diventerà una delle applicazioni più importanti dell’approccio bayesiano moderno.",
    "crumbs": [
      "MCMC",
      "Introduzione alla sezione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto che l’inferenza bayesiana può essere risolta esattamente in alcuni casi fortunati, grazie alle famiglie coniugate, oppure approssimata con metodi semplici come l’uso di una griglia di valori. Questi strumenti ci hanno permesso di comprendere a fondo la logica dell’aggiornamento bayesiano, ma hanno anche mostrato chiaramente i loro limiti: i casi coniugati sono eccezioni, e l’approccio su griglia diventa rapidamente impraticabile quando il numero di parametri cresce oltre uno o due. Per affrontare problemi realistici, che in psicologia riguardano quasi sempre modelli con più parametri e strutture complesse, dobbiamo introdurre un metodo generale che ci consenta di ottenere campioni dalla distribuzione a posteriori senza doverla calcolare in forma chiusa. Questo metodo esiste, ed è noto come algoritmo di Metropolis (Hastings, 1970; Metropolis et al., 1953).\nL’algoritmo di Metropolis rappresenta una svolta concettuale: offre una soluzione universale per generare campioni dalla distribuzione a posteriori, indipendentemente dalla forma della verosimiglianza e del prior. In questo senso, risolve in modo definitivo il problema di come rendere praticabile l’inferenza bayesiana. Tuttavia, presenta anche due limiti: è relativamente inefficiente dal punto di vista computazionale e richiede di scrivere codice su misura per ogni modello. Nonostante ciò, la sua logica è così generale e potente che costituisce la base di tutti gli algoritmi moderni di campionamento, incluso il metodo NUTS implementato in Stan.\nIn questo capitolo introdurremo passo dopo passo l’algoritmo di Metropolis, ne vedremo il funzionamento intuitivo e lo applicheremo a casi concreti. Questo ci permetterà di capire la logica alla base di gran parte dell’inferenza bayesiana moderna, che rimane immutata anche nei metodi più sofisticati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#introduzione",
    "href": "chapters/mcmc/01_metropolis.html#introduzione",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "Panoramica del capitolo\n\nUtilizzare metodi Monte Carlo per stimare valori attesi e probabilità, evitando calcoli integrali complessi.\nComprendere il ruolo delle catene di Markov nel campionamento dalla distribuzione a posteriori.\nImplementare l’algoritmo di Metropolis per il campionamento a posteriori.\nValutare la convergenza delle catene con strumenti diagnostici come trace plot e autocorrelazione.\nGestire la fase di burn-in e utilizzare più catene per garantire stazionarietà e ridurre l’autocorrelazione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere l’Appendice I.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, reshape2)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#lobiettivo-del-metodo-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#lobiettivo-del-metodo-mcmc",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "\n11.1 L’obiettivo del metodo MCMC",
    "text": "11.1 L’obiettivo del metodo MCMC\nIl metodo MCMC (Markov Chain Monte Carlo) è un approccio computazionale che consente di approssimare distribuzioni di probabilità complesse generando una sequenza di valori campionati che segue la distribuzione a posteriori di interesse. L’idea di base è la seguente: consideriamo la distribuzione a posteriori come una popolazione da cui desideriamo estrarre dei campioni. Generando un numero sufficientemente grande di campioni (ad esempio diverse migliaia), la distribuzione empirica dei campioni ottenuti si avvicina progressivamente alla distribuzione teorica a posteriori. In questo modo, è possibile stimare quantità di interesse, come la media, la varianza o gli intervalli di credibilità, anche senza conoscere la forma analitica esplicita della distribuzione a posteriori.\n\n11.1.1 La natura dipendente del campionamento MCMC\nA differenza delle tecniche di campionamento indipendente precedentemente esaminate, l’approccio MCMC genera una sequenza di valori correlati tramite un meccanismo di transizione markoviana. La caratteristica distintiva di questo processo risiede nella proprietà di Markov: ogni nuovo campione dipende esclusivamente dallo stato corrente della catena e mostra memoria soltanto a breve termine, piuttosto che dipendere dall’intera storia precedente.\nQuesta architettura sequenziale produce inevitabilmente autocorrelazione tra le osservazioni adiacenti. Quando la catena visita una regione ad alta densità della distribuzione target, tende a persistere in tale zona per diverse iterazioni prima di migrare verso altre regioni. Questo comportamento è funzionale all’esplorazione efficiente dello spazio parametrico, ma introduce importanti considerazioni pratiche:\n\nl’informazione effettiva contenuta in \\(N\\) campioni correlati è inferiore a quella di \\(N\\) campioni indipendenti;\nla valutazione della convergenza richiede analisi diagnostiche specifiche;\nla dimensione efficace del campione (ESS) diventa un parametro cruciale per la qualità dell’inferenza.\n\nPer compensare questa riduzione dell’informazione per campione, è generalmente necessario generare sequenze più lunghe rispetto al campionamento indipendente. Tuttavia, questo svantaggio apparente è ampiamente compensato dalla capacità di MCMC di affrontare problemi complessi che risulterebbero altrimenti irrisolvibili con i metodi tradizionali.\n\n11.1.2 Perché utilizzare MCMC\nIl metodo MCMC rappresenta uno strumento fondamentale per l’inferenza bayesiana moderna, in quanto consente di affrontare problemi complessi con distribuzioni a posteriori di forma arbitraria e in spazi ad alta dimensionalità. Uno dei suoi principali vantaggi risiede nella capacità di bypassare il calcolo esplicito dell’evidenza, ovvero dell’integrale di normalizzazione richiesto dal teorema di Bayes, che spesso risulta analiticamente intrattabile. Attraverso la simulazione numerica, è possibile generare campioni la cui distribuzione empirica converge alla vera distribuzione a posteriori, permettendo così una stima accurata di qualsiasi quantità inferenziale di interesse.\nNel seguito ci concentreremo sull’algoritmo di Metropolis, uno dei metodi più semplici ed essenziali per implementare il campionamento MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#lalgoritmo-di-metropolis-introduzione-intuitiva",
    "href": "chapters/mcmc/01_metropolis.html#lalgoritmo-di-metropolis-introduzione-intuitiva",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "\n11.2 L’algoritmo di Metropolis: introduzione intuitiva",
    "text": "11.2 L’algoritmo di Metropolis: introduzione intuitiva\nL’algoritmo di Metropolis è un metodo MCMC che consente di esplorare una distribuzione di probabilità complessa costruendo una sequenza di campioni dipendenti tra loro. La logica dell’algoritmo può essere riassunta nei seguenti passaggi fondamentali:\n\n\nPunto di partenza: si inizia da un valore iniziale \\(\\theta_0\\) scelto arbitrariamente.\n\nProposta di un nuovo punto: si genera un nuovo valore candidato \\(\\theta^*\\) partendo da \\(\\theta_0\\), utilizzando una distribuzione di proposta (ad esempio una distribuzione normale centrata su \\(\\theta_0\\)).\n\nValutazione della proposta: si confrontano le densità a posteriori associate al valore attuale \\(\\theta_0\\) e al valore proposto \\(\\theta^*\\).\n\nDecisione di accettazione:\n\nse \\(\\theta^*\\) ha una densità a posteriori più alta di \\(\\theta_0\\), viene accettato automaticamente;\nse \\(\\theta^*\\) ha una densità a posteriori inferiore, viene accettato con una certa probabilità proporzionale al rapporto delle densità.\n\n\n\nRegistrazione: in ogni caso, si registra la posizione attuale (sia che si sia accettato un nuovo punto, sia che si sia rimasti fermi).\n\nQuesto processo viene ripetuto per un numero elevato di iterazioni, generando una catena di campioni che, dopo un opportuno periodo iniziale (detto burn-in), approssima la distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perché-accettiamo-anche-mosse-peggiori",
    "href": "chapters/mcmc/01_metropolis.html#perché-accettiamo-anche-mosse-peggiori",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "\n11.3 Perché accettiamo anche mosse peggiori",
    "text": "11.3 Perché accettiamo anche mosse peggiori\nUno degli aspetti caratteristici dell’algoritmo di Metropolis è la regola di accettazione che consente, con una certa probabilità, di accettare anche proposte \\(\\theta^*\\) con densità a posteriori inferiore rispetto allo stato corrente. Questa scelta apparentemente controintuitiva è essenziale per garantire un’adeguata esplorazione dello spazio dei parametri.\nSe l’algoritmo accettasse esclusivamente mosse che migliorano la densità, convergerebbe rapidamente verso un picco locale della distribuzione, ma rischierebbe di tralasciare altre regioni significative dello spazio. Accettando occasionalmente mosse verso densità inferiori, la catena può sfuggire a massimi locali ed esplorare in modo più completo la distribuzione target, incluso l’accesso a modalità distinte che altrimenti risulterebbero inaccessibili.\nQuesta proprietà è fondamentale per ottenere una catena in grado di rappresentare fedelmente l’intera distribuzione a posteriori, specialmente quando essa è multimodale o presenta regioni di bassa probabilità tra aree ad alta densità. Senza questo meccanismo, l’algoritmo perderebbe la capacità di esplorare globalmente lo spazio dei parametri, compromettendo la validità delle inferenze ottenute.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#la-scelta-della-larghezza-della-proposta",
    "href": "chapters/mcmc/01_metropolis.html#la-scelta-della-larghezza-della-proposta",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "\n11.4 La scelta della larghezza della proposta",
    "text": "11.4 La scelta della larghezza della proposta\nNell’algoritmo di Metropolis, la proposta di un nuovo valore \\(\\theta^*\\) viene solitamente generata a partire dallo stato corrente \\(\\theta_t\\) utilizzando una distribuzione di proposta simmetrica, ad esempio una distribuzione normale \\(\\mathcal{N}(\\theta_t, \\tau^2)\\), dove \\(\\tau\\) rappresenta la deviazione standard della proposta.\nLa scelta del valore di \\(\\tau\\) (ovvero della larghezza della proposta) è cruciale per il buon funzionamento dell’algoritmo:\n\nse \\(\\tau\\) è troppo piccolo, i passi proposti saranno molto vicini al punto attuale. In questo caso, molte proposte saranno accettate, ma la catena si muoverà lentamente nello spazio dei parametri, esplorandolo inefficientemente (alta correlazione tra i campioni);\nse \\(\\tau\\) è troppo grande, i passi proposti saranno molto lontani dal punto attuale. In questo caso, la maggior parte delle proposte cadrà in regioni di bassa densità, portando a un alto tasso di rifiuto delle proposte e quindi a una scarsa efficienza del campionamento.\n\nUn valore ottimale di \\(\\tau\\) deve bilanciare l’accettazione sufficiente di nuove proposte e l’esplorazione efficiente dello spazio dei parametri. In generale, si cerca di ottenere un tasso di accettazione compreso tra il 40% e il 50% per l’algoritmo di Metropolis a singolo parametro.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#limportanza-dei-grafici-diagnostici-trace-plot-e-correlogramma",
    "href": "chapters/mcmc/01_metropolis.html#limportanza-dei-grafici-diagnostici-trace-plot-e-correlogramma",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "\n11.5 L’importanza dei grafici diagnostici: Trace plot e Correlogramma",
    "text": "11.5 L’importanza dei grafici diagnostici: Trace plot e Correlogramma\nPer valutare la qualità della catena generata dall’algoritmo di Metropolis, è fondamentale analizzare alcuni grafici diagnostici.\n\n11.5.1 Trace plot\nIl trace plot, che rappresenta la sequenza dei valori campionati di \\(\\theta\\) in funzione delle iterazioni, costituisce uno strumento diagnostico essenziale per valutare il comportamento della catena MCMC. Una catena che si comporta bene mostra fluttuazioni stazionarie attorno a un valore medio costante, senza trend o derive prolungate nel tempo, indicando così una corretta esplorazione della regione di alta densità della distribuzione a posteriori.\nAl contrario, trace plot problematici possono rivelare diverse criticità. Una fase iniziale con andamento sistematicamente crescente o decrescente suggerisce un periodo di burn-in insufficiente, richiedendo l’eliminazione di un maggior numero di campioni iniziali. Una catena che presenta bassa variabilità o che si stabilizza prematuramente in una regione ristretta dello spazio dei parametri può indicare una esplorazione incompleta, possibilmente a causa di una parametrizzazione inefficace o di una distribuzione proposta troppo stretta. In casi più gravi, la catena può apparire stazionaria pur essendo bloccata in un massimo locale, senza aver raggiunto la vera distribuzione target, situazione particolarmente insidiosa in presenza di multimodalità.\n\n11.5.2 Correlogramma\nIl correlogramma rappresenta l’autocorrelazione tra i campioni della catena a diversi ritardi (lag). In una catena efficiente, l’autocorrelazione decresce rapidamente al crescere del lag, avvicinandosi a zero dopo pochi passi. Questo comportamento indica un adeguato mescolamento della catena, in cui ciascun campione apporta nuova informazione indipendente.\nAl contrario, un’autocorrelazione persistentemente elevata — che si mantiene alta anche a lag elevati — segnala una forte dipendenza tra campioni consecutivi. In tali casi, la catena si muove lentamente attraverso lo spazio dei parametri, riducendo l’efficienza del campionamento e richiedendo un numero maggiore di iterazioni per ottenere stime affidabili. Un correlogramma di questo tipo suggerisce spesso la necessità di riparametrizzare il modello o di adottare un algoritmo di campionamento più efficiente.\n\n11.5.3 Struttura del capitolo\nQuesti concetti costituiscono il fondamento necessario per affrontare la comprensione operativa e pratica dell’algoritmo di Metropolis che svilupperemo nei prossimi esempi. A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o “a posteriori,” sia già conosciuta o disponibile per l’analisi.\nIn seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#un-esempio-concreto",
    "href": "chapters/mcmc/01_metropolis.html#un-esempio-concreto",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "\n11.6 Un esempio concreto",
    "text": "11.6 Un esempio concreto\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista. Il nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come \\(\\pi\\) (si veda Johnson et al., 2022).\nImportiamo i dati.\n\nmoma_sample &lt;- rio::import(here::here(\"data\", \"moma_sample.csv\"))\n\nEsaminiamo le prime cinque righe del data frame.\n\nmoma_sample |&gt; \n  head()\n#&gt;                artist  country birth death alive  genx gender count\n#&gt; 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n#&gt; 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3\n#&gt; 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n#&gt; 4         David Bates american  1952    NA  TRUE FALSE   male     1\n#&gt; 5          Simon Levy american  1946    NA  TRUE FALSE   male     1\n#&gt; 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n#&gt;   year_acquired_min year_acquired_max\n#&gt; 1              1981              1981\n#&gt; 2              2005              2005\n#&gt; 3              2016              2016\n#&gt; 4              2001              2001\n#&gt; 5              2012              2012\n#&gt; 6              2008              2008\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\n# Calcoliamo la distribuzione delle generazioni\nresult &lt;- table(moma_sample$genx)\nresult\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;    86    14\n\nIl valore osservato \\(y = 14\\) fornisce informazioni sul campione selezionato, ma la vera proporzione \\(\\theta\\) di opere riconducibili alla Generazione X o successive nell’intera collezione del MOMA rimane ignota. Per modellare l’incertezza su questo parametro, i dati possono essere formalizzati come realizzazione di una variabile casuale binomiale:\n\\[\ny \\sim \\text{Binomial}(N = 100, \\theta).\n\\]\nPer incorporare la conoscenza a priori sulla probabilità \\(\\theta\\), assumiamo una distribuzione Beta(4, 6) come priore. Questa scelta riflette una credenza pregressa secondo cui \\(\\theta\\) tende a essere inferiore a 0.5, pur consentendo una certa flessibilità nell’inferenza.\n\ntibble(x = seq(0, 1, .01),\n       y = dbeta(x, 4, 6)) |&gt;\n  ggplot(aes(x=x, y=y)) + \n  geom_line()\n\n\n\n\n\n\n\nSfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori. Il modello specificato può essere rappresentato nel modo seguente:\n\\[\n\\begin{align}\nY &\\sim \\text{Binomiale}(100, \\theta),\\notag\\\\\n\\theta &\\sim \\text{Beta}(4, 6). \\notag\n\\end{align}\n\\] Dopo aver osservato il dato \\(Y = 14\\), la distribuzione a posteriori per \\(\\theta\\) si ottiene per coniugazione: \\[\n\\theta \\mid (Y = 14) \\sim \\text{Beta}(4 + 14, 6 + 100 - 14) = \\text{Beta}(18, 92)\n\\]\nNella figura seguente, è rappresentata la distribuzione a posteriori del parametro \\(\\theta\\) (\\(\\text{Beta}(18, 92)\\); colore arancione), insieme alla distribuzione alla prior specificata (\\(\\text{Beta}(4, 6)\\); colore blu).\n\n\n\n\n\n\n\n\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), per esempio, il risultato esatto è\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n11.6.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:\n\n# Generiamo 10 campioni dalla distribuzione Beta(18, 92)\nset.seed(1234)  # Per riproducibilità\ny &lt;- rbeta(10, shape1 = 18, shape2 = 92)\ny\n#&gt;  [1] 0.1183 0.1751 0.2147 0.0769 0.1817 0.1852 0.1416 0.1426 0.1419 0.1299\n\n\n# Calcoliamo la media dei campioni\nmean(y)\n#&gt; [1] 0.151\n\nTuttavia, con soli 10 campioni, l’approssimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10,000, possiamo ottenere una stima molto più precisa:\n\n# Generiamo 10000 campioni e calcoliamo la media\nset.seed(123)  # Per riproducibilità\nmean(rbeta(10000, shape1 = 18, shape2 = 92))\n#&gt; [1] 0.164\n\nQuando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria converge al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.\nÈ importante sottolineare che l’approccio di simulazione Monte Carlo diretto è applicabile solo quando la forma analitica della distribuzione a posteriori è nota e campionabile mediante apposite funzioni. Questo è stato possibile nel caso presentato, grazie alla coniugazione tra verosimiglianza binomiale e priori beta, che ha condotto a una distribuzione a posteriori beta di parametri noti. Tuttavia, in contesti reali più complessi, le distribuzioni a priori coniugate sono l’eccezione piuttosto che la regola, e la forma della posterior risulta spesso intrattabile analiticamente, impedendo l’uso di metodi di campionamento diretto.\nIn tali scenari, gli algoritmi MCMC, come l’algoritmo di Metropolis, offrono una soluzione flessibile ed efficace. Tali metodi permettono di generare campioni approssimati dalla distribuzione a posteriori senza richiederne una forma chiusa, basandosi esclusivamente sulla valutazione della verosimiglianza e della distribuzione a priori fino a una costante di normalizzazione. Grazie a questa proprietà, le tecniche MCMC costituiscono lo strumento computazionale predominante per l’inferenza bayesiana in modelli avanzati e realistici, dove l’analisi esatta non è praticabile.\n\n11.6.2 L’algoritmo di Metropolis\nDopo aver visto che la simulazione diretta è possibile solo in casi eccezionali, possiamo ora introdurre il primo vero strumento generale per affrontare distribuzioni posteriori di forma arbitraria: l’algoritmo di Metropolis. Questo metodo appartiene alla famiglia MCMC e sfrutta la costruzione di una catena di Markov per produrre campioni che, a regime, si distribuiscono secondo la distribuzione a posteriori desiderata.\n\n11.6.2.1 Logica di base\nIl procedimento è sorprendentemente semplice. La catena parte da un valore iniziale del parametro. A ogni passo, un nuovo candidato viene generato tramite una distribuzione di proposta (spesso una normale centrata sullo stato corrente). Il punto proposto viene poi confrontato con quello attuale: se la sua densità a posteriori è maggiore, viene accettato; se è minore, viene accettato con una probabilità proporzionale al rapporto delle due densità. In questo modo la catena si muove nello spazio dei parametri favorendo le regioni più plausibili, ma senza rimanere intrappolata in massimi locali, poiché di tanto in tanto vengono accettati anche spostamenti verso aree meno probabili.\n\n11.6.2.2 Convergenza e burn-in\nNei primi passi la catena riflette ancora la condizione iniziale e non rappresenta adeguatamente la distribuzione target. È per questo che una quota iniziale di iterazioni, detta burn-in, viene eliminata dall’analisi. Dopo questa fase transitoria, la catena tende alla distribuzione stazionaria: i campioni successivi possono allora essere utilizzati per stimare medie, varianze o probabilità a posteriori. La quantità di burn-in necessaria non è fissata a priori, ma deve essere valutata tramite strumenti diagnostici.\n\n11.6.2.3 Accettazione e rifiuto: un equilibrio sottile\nIl cuore dell’algoritmo sta nella regola di accettazione. Essa realizza un equilibrio tra due esigenze opposte: da un lato lo sfruttamento delle regioni già identificate come ad alta densità, dall’altro l’esplorazione di nuove aree che potrebbero rivelarsi rilevanti. Accettare solo proposte migliori renderebbe la catena miopicamente attratta da un singolo massimo, mentre accettare anche proposte peggiori — seppur con probabilità ridotta — consente una copertura globale dello spazio parametrico. È questo meccanismo che garantisce la capacità dell’algoritmo di approssimare fedelmente la distribuzione a posteriori.\n\n11.6.3 Passaggi fondamentali dell’algoritmo di Metropolis\nIl funzionamento dell’algoritmo può essere riassunto in una sequenza ricorsiva di operazioni, che trasforma un singolo punto di partenza in una catena di campioni distribuiti secondo la posteriori:\n\nInizializzazione. Si sceglie un valore iniziale \\(\\theta_1\\) per il parametro e si fissa l’indice di iterazione \\(t = 1\\). Questo punto rappresenta il primo elemento della catena.\nGenerazione di una proposta. A partire dallo stato corrente \\(\\theta_t\\), si estrae un nuovo candidato \\(\\theta_p\\) da una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\). Una scelta comune è la distribuzione normale centrata su \\(\\theta_t\\) con deviazione standard \\(\\tau\\), che controlla l’ampiezza dei passi.\nControllo di validità. Se il campione proposto non appartiene al dominio consentito (ad esempio, se \\(\\theta\\) rappresenta una probabilità, il valore deve rimanere compreso tra 0 e 1), la proposta viene immediatamente rifiutata e si prosegue con il campione corrente.\n\nCalcolo del rapporto di accettazione. Si valuta il rapporto\n\\[\n\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)},\n\\]\nche confronta la plausibilità a posteriori del punto proposto \\(\\theta_p\\) con quella dello stato corrente \\(\\theta_t\\).\n\n\nDecisione di accettazione.\n\nSe \\(\\alpha \\geq 1\\), la proposta viene accettata senza condizioni: lo stato successivo della catena sarà \\(\\theta_{t+1} = \\theta_p\\).\nSe \\(\\alpha &lt; 1\\), la proposta viene accettata con probabilità \\(\\alpha\\). In caso contrario, lo stato non cambia e \\(\\theta_{t+1} = \\theta_t\\).\n\n\nIterazione. I passaggi precedenti vengono ripetuti molte volte. La sequenza risultante \\({\\theta_1, \\theta_2, \\ldots}\\) costituisce la catena di Markov che, dopo una fase di burn-in, riproduce fedelmente la distribuzione a posteriori.\n\n11.6.4 Alcuni aspetti cruciali\n\nDistribuzione di proposta. La scelta di \\(g(\\theta_p \\mid \\theta_t)\\) determina il ritmo dell’esplorazione. Un valore di \\(\\tau\\) troppo piccolo rende i movimenti minimi: la catena accetta quasi tutte le proposte, ma procede lentamente e i campioni sono fortemente autocorrelati. Viceversa, un \\(\\tau\\) troppo grande genera proposte spesso improbabili, con conseguente alto tasso di rifiuto. L’efficienza dell’algoritmo dipende da un compromesso fra questi due estremi.\nRuolo del rapporto di accettazione. Il meccanismo dell’accettazione probabilistica assicura che la catena non si limiti a inseguire i massimi locali della distribuzione, ma sia in grado di attraversare anche regioni meno dense, favorendo una copertura più completa dello spazio dei parametri.\nEsplorazione globale. Proprio grazie a questa possibilità di accettare campioni peggiori, l’algoritmo di Metropolis è in grado di rappresentare accuratamente distribuzioni multimodali e complesse, garantendo robustezza in contesti in cui metodi deterministici fallirebbero.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "href": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "\n11.7 Esempio di implementazione",
    "text": "11.7 Esempio di implementazione\nRiprendiamo il caso del MoMA: vogliamo stimare la probabilità \\(\\theta\\) che un artista appartenga alla Generazione X o successiva, osservando 14 artisti su 100. Usiamo un modello binomiale con prior \\(\\text{Beta}(4,6)\\), e implementiamo l’algoritmo di Metropolis in R.\n\n11.7.1 Componenti del modello\nDistribuzione a priori Rappresenta la nostra conoscenza iniziale:\n\nprior &lt;- function(p) {\n  dbeta(p, shape1 = 4, shape2 = 6)\n}\n\nVerosimiglianza La probabilità di osservare 14 successi su 100 prove:\n\nlikelihood &lt;- function(p) {\n  dbinom(14, size = 100, prob = p)\n}\n\nPosterior (non normalizzata) Combinazione di priori e verosimiglianza:\n\nposterior &lt;- function(p) {\n  prior(p) * likelihood(p)\n}\n\nDistribuzione di proposta Genera un candidato vicino al punto attuale:\n\nproposal_distribution &lt;- function(current_state, proposal_sigma) {\n  rnorm(1, mean = current_state, sd = proposal_sigma)\n}\n\n\n11.7.2 Algoritmo di Metropolis\nL’implementazione segue esattamente i passaggi teorici discussi sopra:\n\nmetropolis &lt;- function(n_samples, start, proposal_sigma) {\n  samples &lt;- numeric(n_samples)   # per salvare la catena\n  current &lt;- start                # stato iniziale\n\n  for (i in seq_len(n_samples)) {\n    # 1. Genera una proposta\n    proposal &lt;- proposal_distribution(current, proposal_sigma)\n\n    # 2. Controlla se la proposta è valida (qui θ deve stare in [0,1])\n    if (proposal &gt;= 0 && proposal &lt;= 1) {\n      # 3. Calcola il rapporto di accettazione\n      alpha &lt;- posterior(proposal) / posterior(current)\n\n      # 4. Decidi se accettare\n      if (runif(1) &lt; alpha) {\n        current &lt;- proposal   # accettata\n      }\n    }\n    # 5. Salva lo stato (attuale o precedente)\n    samples[i] &lt;- current\n  }\n  return(samples)\n}\n\n\n11.7.3 Interpretazione intuitiva\nSi può immaginare l’algoritmo come una passeggiata su un paesaggio collinare:\n\n\nL’altezza delle colline corrisponde alla densità a posteriori.\n\nOgni passo è una proposta casuale in una direzione vicina.\n\nSe il punto è più alto, lo accettiamo sempre (meglio!).\n\nSe è più basso, lo accettiamo con una probabilità proporzionale a quanto è più basso: qualche volta sì, qualche volta no.\n\nRipetendo questa passeggiata migliaia di volte, i luoghi visitati con più frequenza corrispondono alle zone dove la posteriori è più densa. Ottimo blocco! Ti propongo una versione più pulita e didattica, con micro-migliorie che aiutano a leggere e a verificare (senza aggiungere complessità): aggiungo il calcolo del tasso di accettazione, etichette chiare nei grafici, una gestione del burn-in esplicita e un confronto numerico con i valori esatti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esecuzione-dellalgoritmo",
    "href": "chapters/mcmc/01_metropolis.html#esecuzione-dellalgoritmo",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "\n11.8 Esecuzione dell’algoritmo",
    "text": "11.8 Esecuzione dell’algoritmo\n\n# Parametri dell'algoritmo\nn_samples &lt;- 10000\nstart &lt;- 0.50\nproposal_sigma &lt;- 0.10\n\n# Esecuzione del campionamento\nset.seed(123)  # riproducibilità\nsamples &lt;- metropolis(n_samples, start, proposal_sigma)\n\n# Tasso di accettazione (quante volte la catena si muove)\naccept_rate &lt;- mean(diff(samples) != 0)\naccept_rate\n#&gt; [1] 0.392\n\nIl tasso di accettazione è un indicatore utile del “ritmo” della catena. In 1D valori ~0.4–0.5 sono spesso un buon compromesso.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#analisi-dei-risultati",
    "href": "chapters/mcmc/01_metropolis.html#analisi-dei-risultati",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "\n11.9 Analisi dei risultati",
    "text": "11.9 Analisi dei risultati\n\n11.9.1 Burn-in\nScartiamo i primi 50% dei campioni (criterio semplice e chiaro per questo esempio):\n\nburnin &lt;- floor(n_samples * 0.50)\npost_burnin_samples &lt;- samples[(burnin + 1):n_samples]\n\n\n11.9.2 Riassunti numerici\nMedia e deviazione standard a posteriori (stima via MCMC):\n\nmean(post_burnin_samples)\n#&gt; [1] 0.163\nsd(post_burnin_samples)\n#&gt; [1] 0.0354\n\nConfronto con i valori esatti della Beta(18, 92):\n\nmean_exact &lt;- 18 / (18 + 92)\nsd_exact &lt;- sqrt( (18 * 92) / ( (18 + 92)^2 * (18 + 92 + 1) ) )\nc(media_esatta = mean_exact, sd_esatta = sd_exact)\n#&gt; media_esatta    sd_esatta \n#&gt;       0.1636       0.0351\n\n\n11.9.3 Trace plot (inizio catena e tratto post burn-in)\nPrime 200 iterazioni: si vede l’avvio e l’assestamento:\n\ntibble(\n  Iterazione = 1:200,\n  Theta = samples[1:200]\n) |&gt;\n  ggplot(aes(x = Iterazione, y = Theta)) +\n  geom_line(linewidth = 0.6) +\n  labs(x = \"Iterazioni (prime 200)\", y = expression(theta)) +\n  theme(axis.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\nAndamento dopo il burn-in: la catena oscilla intorno alla regione stazionaria:\n\ntibble(\n  Iterazione = seq_along(post_burnin_samples),\n  Theta = post_burnin_samples\n) |&gt;\n  ggplot(aes(x = Iterazione, y = Theta)) +\n  geom_line(linewidth = 0.6) +\n  labs(x = \"Iterazioni (post burn-in)\", y = expression(theta)) +\n  theme(axis.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n11.9.4 Confronto visivo con la posteriore esatta\nSovrapponiamo l’istogramma dei campioni post burn-in alla densità Beta(18, 92).\n\n# Palette per la legenda\ncolori_custom &lt;- c(\n  \"Istogramma\" = \"#1F77B4\",  # Blu\n  \"Beta(18,92)\" = \"#FF7F0E\"  # Arancione\n)\n\ntibble(Theta = post_burnin_samples) |&gt;\n  ggplot(aes(x = Theta)) +\n  geom_histogram(\n    aes(y = after_stat(density), fill = \"Istogramma\"),\n    bins = 30, color = \"black\", alpha = 0.7, show.legend = TRUE\n  ) +\n  stat_function(\n    aes(color = \"Beta(18,92)\"),\n    fun = dbeta, args = list(shape1 = 18, shape2 = 92),\n    linewidth = 1.1, show.legend = TRUE\n  ) +\n  labs(x = expression(theta), y = \"Densità\") +\n  scale_fill_manual(\n    name = \"Distribuzione\",\n    values = colori_custom,\n    breaks = names(colori_custom)\n  ) +\n  scale_color_manual(\n    name = \"Distribuzione\",\n    values = colori_custom,\n    breaks = names(colori_custom)\n  ) +\n  guides(\n    fill  = guide_legend(override.aes = list(color = NA)),\n    color = guide_legend(override.aes = list(fill = NA))\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(face = \"bold\"),\n    axis.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n11.9.5 Intervallo di credibilità\nStimiamo un 94% ETI dai campioni MCMC e confrontiamolo con l’analitico:\n\n# ETI 94% via MCMC\nquantile(post_burnin_samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 0.102 0.235\n\n# ETI 94% esatto (Beta)\nqbeta(c(0.03, 0.97), shape1 = 18, shape2 = 92)\n#&gt; [1] 0.103 0.235\n\n\n11.9.6 Cosa osservare (guida alla lettura)\n\nIl trace plot post burn-in oscilla senza trend: buon segnale di stazionarietà.\nL’istogramma dei campioni si sovrappone bene alla Beta(18, 92): l’algoritmo sta ricostruendo la posteriore.\n\nMedia, deviazione standard e quantili dai campioni sono molto vicini ai valori esatti: conferma pratica della correttezza dell’implementazione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#catene-di-markov-convergenza-e-diagnostiche-anticipazione",
    "href": "chapters/mcmc/01_metropolis.html#catene-di-markov-convergenza-e-diagnostiche-anticipazione",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "\n11.10 Catene di Markov, convergenza e diagnostiche (anticipazione)",
    "text": "11.10 Catene di Markov, convergenza e diagnostiche (anticipazione)\nDurante una simulazione Monte Carlo basata su Metropolis — o, più in generale, su un algoritmo MCMC — otteniamo una catena, ossia una sequenza ordinata di valori del parametro \\(\\theta\\). Ogni elemento della catena rappresenta uno stato che l’algoritmo ha visitato nello spazio dei parametri. Possiamo immaginare questa sequenza come il percorso di un esploratore che si muove tra diverse regioni del paesaggio della distribuzione a posteriori.\nAll’inizio, la catena riflette soprattutto il punto di partenza: i primi passi sono quindi influenzati dalle condizioni iniziali. Con il procedere delle iterazioni, però, l’effetto del punto di partenza si attenua e la catena converge verso una distribuzione stazionaria. È in questa fase che i campioni possono essere considerati rappresentativi della posteriore.\nPer verificare che ciò avvenga, è prassi comune eseguire più catene indipendenti, ciascuna con un punto di partenza diverso. Questa strategia offre due vantaggi:\n\nconsente di confrontare i trace plot e verificare se le catene si stabilizzano attorno alla stessa distribuzione,\nriduce il rischio che una catena resti bloccata in un massimo locale, aumentando la robustezza complessiva dell’inferenza.\n\nLa valutazione della convergenza e della qualità del campionamento può basarsi su strumenti grafici (trace plot, correlogrammi) o su indicatori quantitativi come la statistica \\(\\hat{R}\\) di Gelman-Rubin e la dimensione del campione effettiva (ESS).\nPoiché queste diagnostiche richiedono un’attenzione dedicata, qui ci limitiamo a introdurle brevemente. Il Capitolo 14 offrirà una trattazione completa, con esempi dettagliati e applicazioni pratiche.\n\n\n\n\n\n\nPer approfondire\n\n\n\n\n\nUn ulteriore esempio dell’algoritmo di Metropolis è presentato nell’Appendice, dove viene affrontato il caso Normale–Normale. In quel contesto la distribuzione a posteriori è nota analiticamente, e il confronto diretto con i campioni MCMC permette di verificare passo per passo la correttezza del procedimento.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "href": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’introduzione dell’algoritmo di Metropolis ha rappresentato una svolta decisiva per l’inferenza bayesiana. Prima della sua comparsa, l’analisi era confinata a pochi casi speciali, gestibili grazie alle distribuzioni coniugate o a modelli estremamente semplici. Con Metropolis diventa invece possibile, almeno in linea di principio, ottenere campioni dalla distribuzione a posteriori in qualunque situazione, senza conoscerne la forma analitica.\nQuesta è la vera potenza dell’algoritmo: dimostrare che il problema concettuale dell’inferenza bayesiana è risolto. Una volta stabilito il modello, non è più necessario calcolare integrali complicati: possiamo affidare l’esplorazione dello spazio dei parametri a una catena di Markov. Restano, naturalmente, limiti pratici: la velocità del campionamento, l’efficienza nel mescolamento e la necessità di implementazioni accurate. Non a caso, gli sviluppi successivi — dal Metropolis-Hastings fino al moderno algoritmo NUTS usato in Stan — possono essere visti come perfezionamenti tecnici di questa intuizione originaria, volti a rendere l’approccio più stabile e automatizzato (Duane et al., 1987; Geman & Geman, 1984; Hanada & Matsuura, 2022; Hoffman et al., 2014).\nDal punto di vista didattico, Metropolis rimane un passaggio fondamentale: non è soltanto un pezzo di storia, ma il nucleo concettuale da cui discendono i metodi odierni. Comprendere la sua logica — fatta di proposte, accettazioni e rifiuti — significa acquisire le chiavi per interpretare anche gli algoritmi più sofisticati, che ne condividono la stessa architettura di base.\nIn definitiva, l’algoritmo di Metropolis ci consegna due insegnamenti centrali. Primo: l’inferenza bayesiana non è limitata a pochi casi fortunati, ma può essere sempre condotta. Secondo: ogni modello psicologico, anche complesso e realistico, può essere trattato con questa logica, purché si disponga degli strumenti computazionali adeguati.\n\n\n\n\n\n\nEsercizio 1: Autostima negli Studenti Universitari\n\n\n\n\n\nIn un campione casuale di 100 studenti, 25 hanno mostrato livelli alti di autostima.\nSupponiamo un prior Beta(2,8) sulla proporzione \\(\\theta\\) di studenti con alta autostima.\nObiettivo: stimare la distribuzione a posteriori di \\(\\theta\\) usando l’algoritmo di Metropolis.\nDefinizione delle Funzioni.\n\nset.seed(123)  # per riproducibilità\n\n# Prior: Beta(2,8)\nprior &lt;- function(p) dbeta(p, shape1 = 2, shape2 = 8)\n\n# Likelihood: binomiale 25 successi su 100\nlikelihood &lt;- function(p) dbinom(25, size = 100, prob = p)\n\n# Posterior non normalizzata\nposterior &lt;- function(p) prior(p) * likelihood(p)\n\n# Distribuzione di proposta\nproposal_distribution &lt;- function(current, proposal_sigma) {\n  rnorm(1, mean = current, sd = proposal_sigma)\n}\n\n# Algoritmo di Metropolis\nmetropolis &lt;- function(n_samples, start, proposal_sigma) {\n  samples &lt;- numeric(n_samples)\n  current &lt;- start\n  \n  for (i in seq_len(n_samples)) {\n    proposal &lt;- proposal_distribution(current, proposal_sigma)\n    if (proposal &gt;= 0 && proposal &lt;= 1) {\n      acceptance_ratio &lt;- min(1, posterior(proposal) / posterior(current))\n      if (runif(1) &lt; acceptance_ratio) {\n        current &lt;- proposal\n      }\n    }\n    samples[i] &lt;- current\n  }\n  samples\n}\n\nEsecuzione dell’Algoritmo.\n\n# Parametri\nn_samples &lt;- 10000\nstart &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione\nsamples &lt;- metropolis(n_samples, start, proposal_sigma)\n\n# Burn-in\nburnin &lt;- floor(n_samples * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\nAnalisi dei Risultati.\n\n# Media e deviazione standard\nmean(post_samples)\n#&gt; [1] 0.244\nsd(post_samples)\n#&gt; [1] 0.0395\n\nCalcolo dell’Intervallo di Credibilità al 94%.\n\nquantile(post_samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 0.170 0.319\n\nConfronto con la Soluzione Analitica.\nLa distribuzione a posteriori teorica è:\n\\[\n\\theta \\sim \\text{Beta}(27, 83)\n\\]\n\n# Media teorica\nmean_beta &lt;- 27 / (27 + 83)\nmean_beta\n#&gt; [1] 0.245\n\n# Intervallo teorico\nqbeta(c(0.03, 0.97), 27, 83)\n#&gt; [1] 0.173 0.326\n\nTrace Plot.\n\n# Trace plot\npost_samples |&gt; \n  tibble(Iteration = 1:length(post_samples), Theta = post_samples) |&gt; \n  ggplot(aes(x = Iteration, y = Theta)) +\n  geom_line() +\n  labs(x = \"Iterazione\", y = expression(theta))\n\n\n\n\n\n\n\nIstogramma e Curva Teorica.\n\n# Prima generiamo il dataset della curva teorica separatamente\nx &lt;- seq(0, 1, length.out = 1000)\ndens_teorica &lt;- dbeta(x, 27, 83)\ncurva_teorica &lt;- tibble(x = x, y = dens_teorica)\n\n# Ora costruiamo il grafico correttamente\ntibble(Theta = post_samples) |&gt; \n  ggplot(aes(x = Theta)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, \n                 color = \"black\", fill = \"lightblue\", alpha = 0.6) +\n  geom_line(data = curva_teorica, aes(x = x, y = y), \n            color = \"red\", size = 1) +\n  labs(x = expression(theta), y = \"Densità\")\n\n\n\n\n\n\n\nRisultati Riassunti.\n\n\nMetodo\nMedia\nIntervallo 94%\n\n\n\nMCMC (Metropolis)\ncirca 0.245\ncirca [0.176, 0.320]\n\n\nTeorico Beta(27,83)\n0.245\n[0.177, 0.318]\n\n\n\nSpiegazioni Didattiche Finali.\n\n\n\n\n\n\nDistribuzione a posteriori: interpretazione\n\n\n\nLa distribuzione a posteriori ci dice quanto sono plausibili i diversi valori di \\(\\theta\\) dopo aver osservato i dati.\n\nAd esempio: “C’è una probabilità del 94% che la vera proporzione di studenti con alta autostima sia tra 17% e 32%.”\n\n\n\n\n\n\n\n\n\nAccettare mosse peggiori: motivo\n\n\n\nAccettiamo campioni con probabilità più bassa per permettere alla catena di esplorare anche aree meno probabili e non restare bloccata nei massimi locali.\n\n\n\n\n\n\n\n\nLarghezza della proposta: trade-off\n\n\n\n\n\nProposta stretta (piccoli passi): alta accettazione, ma esplorazione lenta.\n\nProposta larga (grandi passi): bassa accettazione, ma esplorazione più ampia.\n\nSi cerca un tasso di accettazione tra 40% e 50%.\n\n\n\n\n\n\n\n\nDiagnostica grafica\n\n\n\n\n\nTrace plot: deve mostrare fluttuazioni stabili senza trend.\n\nCorrelogramma: l’autocorrelazione deve decrescere rapidamente.\n\nQuesti strumenti aiutano a diagnosticare una buona esplorazione della distribuzione a posteriori.\n\n\n\n\n\n\n\n\n\n\n\nEsercizio 2 - Depressione (BDI-II)\n\n\n\n\n\nIn uno studio clinico, sono stati raccolti i punteggi BDI-II (Beck Depression Inventory) di 30 pazienti. Vogliamo stimare il valore medio della depressione nella popolazione da cui provengono questi soggetti.\nSupponiamo di avere una conoscenza a priori modellata da una distribuzione Normale(30, 5²) per la media \\(\\mu\\).\nI dati osservati sono i seguenti:\n\ny &lt;- c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43,\n       24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n       41, 36, 26, 35, 33, 28, 27, 34, 27, 22)\nlength(y)  \n#&gt; [1] 30\n\nFunzioni a priori, verosimiglianza e posteriori.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2), sigma stimato dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzata\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nAlgoritmo di Metropolis.\n\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  samples\n}\n\nEsecuzione dell’algoritmo.\n\nset.seed(123)\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nburnin &lt;- 50000\npost_samples &lt;- samples[-seq_len(burnin)]\n\nConfronto con la soluzione analitica.\nNel caso prior Normale e likelihood Normale con varianza nota, la posterior è ancora Normale:\n\n# Prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Likelihood\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nc(mu_post, std_post)\n#&gt; [1] 30.88  1.17\n\nTrace Plot.\n\n# Trace plot\npost_samples |&gt; \n  tibble(Iteration = 1:length(post_samples), Mu = post_samples) |&gt; \n  ggplot(aes(x = Iteration, y = Mu)) +\n  geom_line() +\n  labs(x = \"Iterazione\", y = expression(mu))\n\n\n\n\n\n\n\nIstogramma vs Posterior Analitica.\n\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\ndens_teorica &lt;- dnorm(x, mean = mu_post, sd = std_post)\ncurva_teorica &lt;- tibble(x = x, y = dens_teorica)\n\npost_samples |&gt; \n  tibble(Mu = post_samples) |&gt; \n  ggplot(aes(x = Mu)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.6) +\n  geom_line(data = curva_teorica, aes(x = x, y = y), color = \"red\", linewidth = 1) +\n  labs(x = expression(mu), y = \"Densit\\u00e0\")\n\n\n\n\n\n\n\nCosa significa la distribuzione a posteriori?\nIn termini concreti, la distribuzione a posteriori rappresenta la nostra incertezza residua sul valore di \\(\\mu\\), la media dei punteggi BDI-II nella popolazione, dopo aver visto i dati. Per esempio, se calcoliamo che il 94% della distribuzione a posteriori cade tra 27.5 e 32.3, possiamo dire:\n\n“Date le nostre ipotesi iniziali e i dati osservati, c’è una probabilità del 94% che il vero valore medio della depressione nella popolazione stia tra 27.5 e 32.3”.\n\nQuesta è una affermazione probabilistica sul parametro, che è una caratteristica distintiva dell’inferenza bayesiana.\nQuesta distribuzione combina:\n\nle credenze precedenti (il prior),\ncon l’evidenza osservata (i dati).\n\nIl risultato è una distribuzione che riflette cosa sappiamo del parametro dopo aver osservato i dati, e può essere usata per ottenere medie, intervalli di credibilità, probabilità soggettive, ecc.\n\n\n\n\n\n\nPerché accettare anche campioni con densità più bassa?\n\n\n\nNell’algoritmo di Metropolis, a ogni passo si propone un nuovo valore di \\(\\theta\\). Se questo valore ha una densità a posteriori più alta, viene accettato.\nMa se ha una densità più bassa, viene comunque accettato con una certa probabilità.\nPerché farlo?\nPer evitare che la catena si “blocchi” in un massimo locale. Per esplorare anche le aree meno probabili, ma comunque possibili, della distribuzione.\nÈ un meccanismo simile a quello con cui gli esseri umani esplorano: ogni tanto vale la pena provare strade meno promettenti, per evitare di restare intrappolati. Accettare “mosse peggiori” è quindi un meccanismo di esplorazione utile a garantire che la catena possa visitare l’intero spazio dei parametri e convergere correttamente alla distribuzione desiderata.\n\n\n\n\n\n\n\n\nLarghezza della proposta: un equilibrio delicato\n\n\n\nNel Metropolis, il nuovo valore proposto viene scelto spostandosi dal valore corrente secondo una distribuzione normale:\n\\[\\theta_{new} \\sim \\mathcal{N}(\\theta_{attuale}, \\sigma).\\]\nIl parametro \\(\\sigma\\) controlla la distanza dei passi.\nSe \\(\\sigma\\) è:\n\nPiccolo → i passi sono molto corti:\n\nMolte proposte vengono accettate (alta accettazione),\nMa la catena esplora lentamente → i campioni sono fortemente autocorrelati.\n\n\nGrande → i passi sono molto lunghi:\n\nSi propongono salti drastici → molte proposte vengono rifiutate,\nLa catena si muove poco → anche in questo caso, esplorazione inefficiente.\n\n\n\nObiettivo: trovare un compromesso ottimale.\n\nPer un parametro unidimensionale, si consiglia spesso un tasso di accettazione tra 40% e 50%.\nNegli esercizi puoi provare diversi valori di proposal_sigma e osservare il tasso di accettazione per imparare.\n\n\n\nRisultati.\n\nmean(post_samples)\n#&gt; [1] 30.9\nsd(post_samples)\n#&gt; [1] 1.15\nquantile(post_samples, probs = c(0.03, 0.97))\n#&gt;   3%  97% \n#&gt; 28.7 33.1\n\nValori teorici:\n\nmu_post  # media teorica\n#&gt; [1] 30.9\nqnorm(c(0.03, 0.97), mean = mu_post, sd = std_post)\n#&gt; [1] 28.7 33.1\n\nSpiegazione Didattica.\n\nLa media \\(\\mu\\) rappresenta il livello medio di depressione nella popolazione.\nIl prior rappresenta la nostra credenza iniziale (Normale con media 30).\nL’evidenza fornita dai dati modifica questa credenza.\nL’algoritmo di Metropolis permette di campionare da una distribuzione posterior anche senza conoscere la forma analitica.\nIl confronto tra distribuzione teorica e campioni MCMC mostra un ottimo accordo.\n\nConclusione.\nIn questo esercizio abbiamo:\n\nimplementato l’algoritmo di Metropolis per un caso con prior e likelihood Normali;\nstimato la media della distribuzione posterior;\nconfrontato i risultati con la soluzione analitica;\nverificato la coerenza dei campioni MCMC con la distribuzione teorica.\n\nQuesto mostra la potenza dell’approccio MCMC anche in situazioni dove la soluzione analitica sarebbe disponibile, e pone le basi per affrontare problemi più complessi.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4        cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        rmarkdown_2.29        ps_1.9.1             \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            R.utils_2.13.0       \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [46] plyr_1.8.9            withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          R.methodsS3_1.8.2     digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] R.oo_1.27.1           memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [85] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#bibliografia",
    "href": "chapters/mcmc/01_metropolis.html#bibliografia",
    "title": "11  L’algoritmo di Metropolis-Hastings",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid monte carlo. Physics letters B, 195(2), 216–222.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6, 721–741.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from Scratch. Springer.\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97–109.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087–1092.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html",
    "href": "chapters/mcmc/02_ppl.html",
    "title": "12  Linguaggi di programmazione probabilistici",
    "section": "",
    "text": "Introduzione\nNel capitolo precedente abbiamo introdotto l’algoritmo di Metropolis come soluzione generale al problema dell’inferenza bayesiana. Abbiamo visto che, grazie a questo metodo, è sempre possibile generare campioni dalla distribuzione a posteriori, anche quando non conosciamo la sua forma analitica. Questo rappresenta una conquista concettuale decisiva: l’inferenza bayesiana non è limitata ai casi semplici delle famiglie coniugate, ma può essere applicata a qualunque modello.\nTuttavia, la libertà concettuale offerta da Metropolis si scontra con difficoltà pratiche. Implementare l’algoritmo in modo efficiente per ciascun modello richiede di scrivere molto codice su misura, e non è banale stabilire buone regole di proposta per garantire un campionamento rapido e affidabile. In altre parole, sappiamo che l’inferenza è sempre possibile, ma non sempre è semplice metterla in pratica.\nPer superare questi limiti sono nati i linguaggi probabilistici (probabilistic programming languages, PPL). L’idea è elegante: invece di programmare a mano l’algoritmo per ogni modello, lo scienziato specifica direttamente il modello in un linguaggio formale vicino alla notazione statistica. Sarà poi il software a occuparsi di eseguire il campionamento in modo efficiente, utilizzando algoritmi avanzati che generalizzano e migliorano la logica di Metropolis.\nQuesto cambiamento ha avuto un impatto profondo sulla pratica della ricerca. Con i PPL, il ricercatore può concentrarsi sul modello psicologico che vuole esprimere – ad esempio un modello di apprendimento, un modello gerarchico o un modello di decisione – senza doversi preoccupare di tutti i dettagli computazionali del campionamento. È un passaggio simile a quello che, in altri campi scientifici, ha permesso di separare la formulazione delle teorie dalle tecniche di calcolo numerico necessarie per applicarle.\nTra i PPL disponibili oggi, Stan occupa un posto di rilievo. È diventato lo standard in molti ambiti della statistica bayesiana e delle scienze sociali, grazie alla combinazione di tre caratteristiche: un linguaggio chiaro per specificare i modelli, algoritmi di campionamento all’avanguardia (come NUTS, una variante efficiente di Hamiltonian Monte Carlo) e una forte integrazione con strumenti di analisi dei dati come R e Python.\nDal punto di vista didattico, è importante sottolineare che Stan non è una “scatola nera”. Il cuore concettuale rimane quello visto con l’algoritmo di Metropolis: generare campioni dalla distribuzione a posteriori per approssimarla numericamente. La differenza è che, invece di scrivere da zero il codice per ogni modello, ci limitiamo a dichiarare il modello e lasciamo che il software si occupi delle scelte tecniche necessarie.\nIn questo senso, i PPL non rappresentano una rottura rispetto a quanto appreso finora, ma una naturale evoluzione. Ci permettono di spostare l’attenzione dall’aspetto computazionale all’aspetto scientifico: non tanto come campionare, ma quale modello vogliamo costruire per descrivere il fenomeno psicologico che ci interessa.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "href": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "title": "12  Linguaggi di programmazione probabilistici",
    "section": "12.1 Perché abbiamo bisogno della programmazione probabilistica?",
    "text": "12.1 Perché abbiamo bisogno della programmazione probabilistica?\nAbbiamo visto che l’algoritmo di Metropolis fornisce una soluzione generale: in linea di principio, possiamo sempre ottenere campioni dalla distribuzione a posteriori, qualunque sia il modello specificato. Tuttavia, questa libertà concettuale si accompagna a limiti pratici. Scrivere un campionatore funzionante per ogni modello richiede tempo, competenze tecniche avanzate e una grande attenzione agli aspetti numerici. Basta poco per ritrovarsi con algoritmi inefficienti o catene che non convergono. In altre parole, sappiamo che il problema dell’inferenza bayesiana è risolvibile, ma non è detto che sia agevole affrontarlo a mano ogni volta.\nPer rendere questa potenza utilizzabile anche nella pratica quotidiana, sono nati i linguaggi di programmazione probabilistica (probabilistic programming languages, PPL). Essi rappresentano un’evoluzione naturale: invece di programmare direttamente gli algoritmi di campionamento, lo scienziato dichiara semplicemente il modello in un linguaggio vicino alla notazione statistica. Sarà il software a occuparsi di tradurre questa dichiarazione in inferenza numerica, scegliendo algoritmi avanzati e ottimizzati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#dalle-prime-implementazioni-a-stan",
    "href": "chapters/mcmc/02_ppl.html#dalle-prime-implementazioni-a-stan",
    "title": "12  Linguaggi di programmazione probabilistici",
    "section": "12.2 Dalle prime implementazioni a Stan",
    "text": "12.2 Dalle prime implementazioni a Stan\nI primi PPL, come BUGS e WinBUGS, hanno aperto la strada negli anni ’90. Per la prima volta era possibile scrivere un modello bayesiano in modo dichiarativo e ottenere automaticamente un campione dalla distribuzione a posteriori. Questa idea, che all’epoca sembrava quasi visionaria, ha cambiato il modo di concepire l’inferenza: non più come un calcolo complesso da eseguire a mano, ma come una specifica da fornire a un motore di calcolo.\nNel tempo, questi strumenti si sono evoluti. A fianco di BUGS e del suo successore JAGS, sono nati PPL moderni come PyMC in ambiente Python e soprattutto Stan, che oggi rappresenta uno standard in molti ambiti della statistica applicata. Stan combina un linguaggio chiaro per dichiarare i modelli con algoritmi di campionamento estremamente efficienti, come NUTS (No-U-Turn Sampler), una variante avanzata dell’Hamiltonian Monte Carlo. Ciò che prima era accessibile solo a chi possedeva competenze molto specialistiche è diventato così patrimonio di una comunità scientifica molto più ampia.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#cosa-cambia-per-la-ricerca-psicologica",
    "href": "chapters/mcmc/02_ppl.html#cosa-cambia-per-la-ricerca-psicologica",
    "title": "12  Linguaggi di programmazione probabilistici",
    "section": "12.3 Cosa cambia per la ricerca psicologica",
    "text": "12.3 Cosa cambia per la ricerca psicologica\nPer la psicologia e le scienze sociali, l’arrivo dei PPL ha significato un vero salto di qualità. I ricercatori possono finalmente concentrarsi sui modelli teorici che vogliono testare – modelli di apprendimento, di decisione, di effetti gerarchici nei dati – senza doversi preoccupare di reinventare ogni volta la parte algoritmica. Questo permette di sperimentare con strutture di modelli più ricche, di formalizzare meglio le ipotesi psicologiche e di tradurle direttamente in codice eseguibile.\nLa conseguenza è una maggiore trasparenza e una più stretta connessione tra teoria e analisi empirica. I PPL, infatti, non nascondono i modelli dietro procedure automatiche, ma li rendono espliciti: ogni ipotesi è dichiarata in modo chiaro e tracciabile, e il processo inferenziale diventa riproducibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#interfacce-di-alto-livello",
    "href": "chapters/mcmc/02_ppl.html#interfacce-di-alto-livello",
    "title": "12  Linguaggi di programmazione probabilistici",
    "section": "12.4 Interfacce di alto livello",
    "text": "12.4 Interfacce di alto livello\nNaturalmente, anche i PPL richiedono un certo impegno. Scrivere modelli complessi in Stan o in PyMC comporta comunque una buona familiarità con la programmazione e con la statistica bayesiana. Per ampliare l’accessibilità, negli ultimi anni sono state sviluppate interfacce di più alto livello, come brms (in R, basata su Stan) e Bambi (in Python, basata su PyMC).\nQueste interfacce utilizzano una sintassi semplificata e familiare a chi lavora già con modelli statistici tradizionali. In R, ad esempio, brms consente di specificare un modello di regressione con la stessa logica di lm o lmer, aggiungendo la possibilità di definire priori e di stimare i parametri con algoritmi bayesiani. In questo modo, anche chi non ha esperienza di programmazione avanzata può avvicinarsi con relativa facilità all’inferenza bayesiana, beneficiando della potenza dei PPL senza doverne conoscere i dettagli più tecnici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "href": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "title": "12  Linguaggi di programmazione probabilistici",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nI linguaggi di programmazione probabilistica segnano un momento di svolta nella storia dell’inferenza bayesiana. Essi rappresentano il passaggio da una fase pionieristica, in cui ogni ricercatore doveva implementare da sé algoritmi complicati, a una fase matura, in cui l’attenzione può finalmente concentrarsi sulla costruzione dei modelli e sulla loro interpretazione scientifica.\nLa logica di fondo rimane sempre quella introdotta con Metropolis: campionare dalla distribuzione a posteriori per approssimarla numericamente. La differenza è che, grazie ai PPL, non siamo più costretti a scrivere da zero codice specializzato per ogni problema. Possiamo dichiarare i nostri modelli in un linguaggio standardizzato, lasciare che il software si occupi del campionamento e concentrare le nostre energie sulla sostanza psicologica e teorica.\nQuesto capitolo funge quindi da ponte: dall’algoritmo di Metropolis, che ci ha mostrato la logica generale, passiamo ora a strumenti concreti come Stan e le sue interfacce, che renderanno possibile mettere in pratica questa logica nei contesti complessi della ricerca psicologica contemporanea.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html",
    "href": "chapters/mcmc/03_stan_intro.html",
    "title": "13  Introduzione pratica a Stan",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto come l’algoritmo di Metropolis fornisca una soluzione generale al problema dell’inferenza bayesiana e come i linguaggi di programmazione probabilistica abbiano reso questa soluzione praticabile nella ricerca quotidiana. Ora è il momento di incontrare lo strumento che utilizzeremo concretamente nel nostro percorso: Stan.\nStan non è semplicemente un altro software statistico. È un linguaggio di programmazione probabilistica progettato per esprimere modelli bayesiani in modo chiaro e flessibile e per eseguire l’inferenza con algoritmi di campionamento allo stato dell’arte. In particolare, Stan utilizza varianti avanzate dell’Hamiltonian Monte Carlo (HMC), come l’algoritmo NUTS, che offrono efficienza e affidabilità molto superiori rispetto al semplice Metropolis.\nDal punto di vista concettuale, però, nulla cambia: la logica rimane la stessa che abbiamo già compreso. Stan non fa “magia”, ma implementa con grande efficacia ciò che Metropolis aveva già reso possibile. Per questo è importante vederlo come la naturale evoluzione pratica del percorso che abbiamo seguito fin qui.\nPer la ricerca psicologica, Stan ha un vantaggio particolare. Molti dei modelli che ci interessano – modelli gerarchici, modelli di apprendimento, modelli dinamici – richiedono più parametri e strutture complesse. Implementarli a mano sarebbe quasi impossibile. Con Stan, invece, possiamo concentrarci sul modello teorico e tradurlo in codice relativamente semplice, lasciando al software la gestione dei dettagli computazionali.\nNei prossimi capitoli vedremo come iniziare a scrivere modelli in Stan, partendo da esempi elementari per arrivare a strutture più articolate. L’obiettivo non è soltanto imparare un nuovo linguaggio, ma acquisire la capacità di formalizzare i modelli psicologici come processi generativi, traducendoli in analisi statistiche riproducibili e trasparenti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#introduzione",
    "href": "chapters/mcmc/03_stan_intro.html#introduzione",
    "title": "13  Introduzione pratica a Stan",
    "section": "",
    "text": "Panoramica del capitolo\n\nI blocchi del codice Stan.\n\nScrivere e stimare modelli semplici con cmdstanr.\n\nInterpretare i risultati MCMC tramite riassunti e diagnostiche.\n\nValutare la coerenza del modello con prior e posterior predictive check.\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, insight)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#programmazione-probabilistica-con-stan",
    "href": "chapters/mcmc/03_stan_intro.html#programmazione-probabilistica-con-stan",
    "title": "13  Introduzione pratica a Stan",
    "section": "\n13.1 Programmazione probabilistica con Stan",
    "text": "13.1 Programmazione probabilistica con Stan\nOgni programma Stan è organizzato in blocchi distinti, che corrispondono a funzioni precise (Nicenboim et al., 2025). Nel blocco data dichiariamo le variabili osservate che passiamo dall’esterno; in parameters indichiamo le quantità ignote che vogliamo stimare; nel blocco model specifichiamo le assunzioni probabilistiche — cioè le distribuzioni a priori e la verosimiglianza; infine, in generated quantities possiamo calcolare misure derivate, come predizioni o log-likelihood, che non influiscono sulla stima ma sono utili per l’analisi successiva. Questa architettura modulare rende Stan intuitivo e adattabile a un’ampia gamma di applicazioni statistiche.\n\n13.1.1 Lavorare con Stan in R\nL’interfaccia cmdstanr per R segue un workflow ben definito:\n\nscrittura del modello in un file .stan,\n\ncompilazione del modello,\n\npassaggio dei dati come lista R ,\nesecuzione del campionamento con sample(),\n\nanalisi dei risultati mediante pacchetti specializzati (posterior, bayesplot).\n\nPossiamo pensare a un programma Stan come a una “ricetta”. Nel blocco data mettiamo gli ingredienti che già conosciamo (i dati osservati), in parameters dichiariamo gli ingredienti mancanti (i parametri da stimare), in model scriviamo le regole della preparazione (le distribuzioni a priori e la verosimiglianza) e in generated quantities prepariamo i contorni (diagnostiche, predizioni) che non cambiano la ricetta principale, ma la rendono più completa.\nIn pratica, lavorare con Stan da R segue sempre lo stesso schema. Prima si scrive il modello in un file .stan; poi lo si compila, cioè lo si traduce in un eseguibile; quindi si preparano i dati in una lista R con gli stessi nomi dichiarati nel modello; infine si lancia il campionamento con la funzione sample(). Una volta ottenuti i campioni a posteriori, possiamo analizzarli con pacchetti come posterior o bayesplot, che facilitano sia i riassunti numerici sia le visualizzazioni.\nStan utilizza un sistema di tipizzazione statica: tutte le variabili devono essere dichiarate con tipi specifici (int per interi, real per valori reali, vector per vettori) e possono includere vincoli (es. lower=0 per valori positivi). Questo approccio aumenta la robustezza del codice e previene errori comuni nella specificazione dei modelli.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#modello-betabinomiale",
    "href": "chapters/mcmc/03_stan_intro.html#modello-betabinomiale",
    "title": "13  Introduzione pratica a Stan",
    "section": "\n13.2 Modello Beta–Binomiale",
    "text": "13.2 Modello Beta–Binomiale\nCome primo esempio costruiamo un modello molto semplice, ma già sufficiente per illustrare i principi fondamentali della programmazione in Stan. L’obiettivo è stimare la probabilità di successo \\(\\theta\\) in una sequenza di prove Bernoulliane indipendenti.\nPer rendere l’idea concreta, immaginiamo di lanciare un dado mille volte e di registrare il risultato come variabile dicotomica: assegniamo il valore 1 se esce il numero 6 (considerato “successo”), e 0 in tutti gli altri casi (“fallimento”). Se il dado fosse perfettamente equilibrato, la probabilità di successo sarebbe \\(\\theta = 1/6 \\approx 0.167\\). Tuttavia, nell’approccio bayesiano non assumiamo a priori che il dado sia equo: lasciamo che siano i dati, in combinazione con una distribuzione a priori esplicita, a informare il valore di \\(\\theta\\).\nEcco un esempio di generazione dei dati in R:\n\nset.seed(123)\nn &lt;- 1000\ndice_df &lt;- tibble(res = sample(1:6, size = n, replace = TRUE))\ny &lt;- as.integer(dice_df$res == 6)    # 1 se esce “6”, 0 altrimenti\nmean(y)                              # frequenza relativa di “6”\n#&gt; [1] 0.164\n\nIl modello statistico che sottende a questa situazione è molto semplice:\n\nogni osservazione segue una distribuzione Bernoulliana, \\(y_i \\sim \\text{Bernoulli}(\\theta)\\) per \\(i = 1, \\dots, N\\);\nequivalendo a dire che il numero totale di successi \\(k = \\sum_i y_i\\) segue una distribuzione Binomiale, \\(k \\sim \\text{Binomiale}(N,\\theta)\\);\ncome prior adottiamo una distribuzione uniforme su \\([0,1]\\), cioè \\(\\theta \\sim \\text{Beta}(1,1)\\).\n\nVale la pena notare che, se in Stan dichiariamo un parametro vincolato all’intervallo \\([0,1]\\) ma non specifichiamo alcun prior, il linguaggio assegna automaticamente proprio questa distribuzione uniforme, che corrisponde a una Beta(1,1).\n\n13.2.1 Prima versione: modello Bernoulliano vettoriale\nIl modo più diretto di tradurre il modello in Stan è scrivere la verosimiglianza come sequenza di esiti Bernoulliani. Questo approccio ha anche un valore didattico, perché mostra chiaramente la corrispondenza tra dati osservati e modello probabilistico. Stan, inoltre, vettorializza automaticamente le operazioni sugli array, rendendo il codice conciso:\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                    // numero di prove\n  array[N] int&lt;lower=0, upper=1&gt; y;  // esiti (0/1)\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;      // probabilità di successo\n}\nmodel {\n  theta ~ beta(1, 1);                // prior uniforme su [0,1]\n  y ~ bernoulli(theta);              // verosimiglianza\n}\n\"\n\nIl funzionamento dei blocchi è intuitivo: nel blocco data dichiariamo le variabili osservate (N e il vettore binario y); nel blocco parameters indichiamo il parametro da stimare, \\(\\theta\\); infine, nel blocco model specifichiamo sia la distribuzione a priori sia la verosimiglianza.\nDal punto di vista interno, ogni riga del tipo x ~ distribuzione(...) aggiunge la log-densità (o log-massa) alla quantità interna target, che rappresenta la log-posterior. Se vogliamo essere più espliciti, possiamo scrivere il codice in forma equivalente:\ntarget += beta_lpdf(theta | 1, 1);\ntarget += bernoulli_lpmf(y | theta);\nQuesta seconda scrittura, sebbene meno compatta, è particolarmente utile quando vogliamo costruire verosimiglianze personalizzate o introdurre modifiche non standard.\n\n13.2.2 Seconda versione: modello binomiale sui successi totali\nL’approccio Bernoulliano visto in precedenza ha il pregio della chiarezza, ma può risultare ridondante: stiamo in realtà scrivendo la stessa formula mille volte, una per ciascun lancio del dado. In termini statistici, però, sappiamo che non è necessario conservare l’intera sequenza di zeri e uno: ai fini della stima di \\(\\theta\\) conta solo il numero totale di successi osservati. Questa proprietà prende il nome di sufficienza della statistica \\(k = \\sum_i y_i\\) per la distribuzione binomiale.\nSe dunque nei mille lanci abbiamo osservato, ad esempio, 170 “6”, tutta l’informazione rilevante per stimare \\(\\theta\\) è contenuta in quel singolo numero, non nella sequenza dettagliata dei lanci. La distribuzione binomiale ci permette di formalizzare questa idea in modo compatto, portando a una specificazione del modello più efficiente, ma del tutto equivalente sul piano inferenziale.\nEcco la traduzione in Stan:\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                      // numero di prove\n  array[N] int&lt;lower=0, upper=1&gt; y;    // esiti (0/1)\n}\ntransformed data {\n  int&lt;lower=0, upper=N&gt; k = sum(y);    // numero totale di successi\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;        // probabilità di successo\n}\nmodel {\n  theta ~ beta(1, 1);                  // prior uniforme\n  k ~ binomial(N, theta);              // verosimiglianza sui successi totali\n}\n\"\n\nQuesta versione concentra la verosimiglianza in un’unica riga, calcolata direttamente sul numero complessivo di successi. Le catene MCMC che otteniamo da questo modello coincidono, entro il rumore Monte Carlo, con quelle prodotte dalla versione Bernoulliana, ma richiedono meno operazioni e risultano quindi più efficienti dal punto di vista computazionale.\nCome per la prima versione, possiamo arricchire il modello con un blocco generated quantities per ottenere log-likelihood o repliche predittive. Queste quantità derivate non modificano l’inferenza su \\(\\theta\\), ma ci consentono di eseguire controlli diagnostici, confrontare modelli alternativi o visualizzare come il modello riproduce i dati osservati.\n\n\n\n\n\n\nPerché “Beta–Binomiale”?\n\n\n\n\n\nRicordiamo che, con prior \\(\\theta \\sim \\text{Beta}(a,b)\\) e \\(k \\sim \\text{Binomiale}(N,\\theta)\\), la posterior è\n\\[\n\\theta \\mid y \\sim \\text{Beta}\\big(a+k,\\; b+N-k\\big),\n\\] con \\(a=b=1\\): \\(\\text{Beta}(1+k,\\; 1+N-k)\\).\nQuesto ci consente un controllo didattico: possiamo confrontare media e IC ottenuti da Stan con quelli della Beta a posteriori.\nEsempio in R:\n\nk &lt;- sum(y)\na &lt;- 1\nb &lt;- 1\npost_mean_closed &lt;- (a + k) / (a + b + n)\npost_ci95_closed  &lt;- qbeta(c(0.025, 0.975), a + k, b + n - k)\npost_mean_closed; \n#&gt; [1] 0.165\npost_ci95_closed\n#&gt; [1] 0.142 0.188\n\nLe stime via Stan (campioni MCMC della theta) devono coincidere (entro il rumore Monte Carlo) con queste quantità analitiche.\n\n\n\nUna volta scritto il modello, il passo successivo è la compilazione. Stan traduce il codice in linguaggio C++ e lo trasforma in un piccolo eseguibile che potrà essere richiamato ogni volta che lanceremo le stime. Questo passaggio richiede qualche secondo solo la prima volta; in seguito, il modello compilato può essere riutilizzato con dataset diversi senza dover ricompilare da capo, con un notevole risparmio di tempo.\n\nstanmod &lt;- cmdstanr::cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\nPreparato l’eseguibile, dobbiamo passare a Stan i dati necessari. In questo caso servono due elementi: il numero totale di prove e il vettore con gli esiti dei lanci. È importante che i nomi e i tipi corrispondano esattamente a quanto dichiarato nel blocco data del modello Stan, altrimenti il programma restituirà un errore.\n\ndata_list &lt;- list(\n  N = length(y),\n  y = y\n)\nstr(data_list)\n#&gt; List of 2\n#&gt;  $ N: int 1000\n#&gt;  $ y: int [1:1000] 0 1 0 0 0 1 0 0 0 1 ...\n\nA questo punto siamo pronti per il campionamento MCMC. Nella chiamata a sample() specifichiamo quante iterazioni dedicare alla fase di warmup (che serve per adattare l’algoritmo), quante iterazioni utilizzare effettivamente per l’inferenza, e quante catene indipendenti far partire in parallelo. Due parametri aggiuntivi – adapt_delta e max_treedepth – aiutano a rendere più stabili e accurati i passi dell’algoritmo NUTS, soprattutto in modelli più complessi.\n\nfit1 &lt;- stanmod$sample(\n  data = data_list,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790,\n  refresh = 0,                 # meno output a schermo\n  adapt_delta = 0.9,           # maggiore prudenza nel passo HMC\n  max_treedepth = 12           # profondità massima dell’albero NUTS\n)\n\nCon il modello stimato, possiamo guardare un riepilogo sintetico delle stime. La funzione summary() di Stan mostra media, deviazione standard, quantili e diagnostiche come \\(\\hat R\\) ed ESS.\n\nprint(fit1$summary(variables = \"theta\"), n = Inf)\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 theta    0.165  0.165 0.012 0.012 0.146 0.185 1.001 5070.123 4701.800\n\nIn alternativa, il pacchetto posterior permette di estrarre i campioni e calcolare con maggiore flessibilità le statistiche che ci interessano:\n\ndraws &lt;- fit1$draws(variables = \"theta\", format = \"draws_matrix\")\nposterior::summarise_draws(\n  draws,\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975)), rhat, ess_bulk, ess_tail\n)\n#&gt; # A tibble: 1 × 9\n#&gt;   variable  mean    sd `2.5%` `50%` `97.5%`  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 theta    0.165 0.012  0.143 0.165   0.189 1.001 5070.123 4701.800\n\nCome regola generale, valori di \\(\\hat R\\) molto vicini a 1 (idealmente &lt; 1.01) e un numero elevato di campioni effettivi (ESS) indicano che le catene hanno esplorato bene la distribuzione a posteriori.\nOltre alle statistiche numeriche, le diagnostiche grafiche aiutano a valutare a colpo d’occhio la qualità del campionamento.\n\nbayesplot::mcmc_trace(fit1$draws(\"theta\"), n_warmup = 1000)\n\n\n\n\n\n\n\n\nbayesplot::mcmc_dens_overlay(fit1$draws(\"theta\"))\n\n\n\n\n\n\n\nNel traceplot, le catene dovrebbero mescolarsi bene senza mostrare trend persistenti; nel grafico delle densità, le distribuzioni delle diverse catene dovrebbero risultare sovrapposte.\nIn sintesi: la media a posteriori di \\(\\theta\\) fornisce una stima puntuale della probabilità di ottenere un “6”, l’intervallo di credibilità quantifica l’incertezza residua, e le diagnostiche (R-hat vicino a 1, ESS alto, catene ben mescolate) garantiscono che i campioni siano affidabili per trarre conclusioni.\n\n\n\n\n\n\nConfronto con la frequenza relativa\nLa frequenza mean(y) è solo una stima puntuale. L’analisi bayesiana restituisce un’intera distribuzione per \\(\\theta\\), utile per propagare l’incertezza in previsioni e decisioni.\n\n\n\n\n13.2.3 Distribuzione predittiva posteriore\nStimare \\(\\theta\\) non basta: spesso ciò che ci interessa davvero è capire quali conseguenze pratiche derivano dai risultati. In altre parole, vogliamo sapere cosa il modello ci dice su dati futuri. Per esempio: se rilanciassimo il dado altre mille volte, quanti “6” potremmo aspettarci?\nLa risposta si ottiene con la distribuzione predittiva posteriore. Condizionatamente a un valore di \\(\\theta\\), il numero di successi nei nuovi lanci segue una distribuzione binomiale:\n\\[\ny_{\\text{rep}} \\mid \\theta \\sim \\text{Binomiale}(n_{\\text{new}}, \\theta).\n\\]\nMa noi non conosciamo \\(\\theta\\) con certezza: ne abbiamo solo una distribuzione a posteriori. Per questo motivo, la distribuzione predittiva si ottiene integrando la probabilità condizionata \\(p(y_{\\text{rep}} \\mid \\theta)\\) rispetto alla distribuzione a posteriori di \\(\\theta\\):\n\\[\np(y_{\\text{rep}} \\mid y) = \\int p(y_{\\text{rep}} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta.\n\\]\nDal punto di vista operativo, il procedimento è semplice: estraiamo valori di \\(\\theta\\) dalla posterior e, per ciascuno di essi, simuliamo un nuovo conteggio \\(y_{\\text{rep}}\\). L’insieme di queste simulazioni costituisce la distribuzione predittiva.\n\n# Numero di futuri lanci da simulare\nn_new &lt;- 1000\n\n# Estrazione dei campioni di theta (vettore numerico)\ntheta_draws &lt;- as.numeric(draws[, \"theta\"])\n\n# Simulazione predittiva\nyrep_count &lt;- rbinom(n = length(theta_draws), size = n_new, prob = theta_draws)\n\n# Riassunti predittivi\nmean(yrep_count)                           # valore atteso di \"6\" su n_new lanci\n#&gt; [1] 165\nquantile(yrep_count, c(0.025, 0.5, 0.975)) # intervallo predittivo 95%\n#&gt;  2.5%   50% 97.5% \n#&gt;   134   164   199\n\nPer visualizzare i risultati, rappresentiamo la distribuzione dei conteggi simulati con un istogramma, segnando con una linea verticale tratteggiata il numero di successi realmente osservati.\n\ntibble(count = yrep_count) |&gt;\n  ggplot(aes(x = count)) +\n  geom_histogram(bins = 30, color = \"white\") +\n  geom_vline(xintercept = sum(y), linetype = \"dashed\") +\n  labs(\n    x = \"Numero di '6' osservati\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\nCome leggere il grafico. L’istogramma mostra la variabilità attesa del numero di “6” su mille lanci futuri. La distribuzione è centrata intorno al valore atteso \\(n_{\\text{new}} \\cdot \\mathbb{E}[\\theta \\mid y]\\), cioè il numero medio di successi secondo la stima a posteriori. Se il dado fosse perfettamente equilibrato (\\(\\theta = 1/6\\)), ci aspetteremmo circa 167 successi su 1000, con un intervallo predittivo di circa 150–185. Se i dati simulati si discostano molto da questo scenario, il modello ci sta suggerendo che il dado potrebbe non essere equo.\n\nCome controllo aggiuntivo, possiamo sfruttare la formula chiusa della distribuzione Beta–Binomiale: con prior \\(\\text{Beta}(1,1)\\) e \\(k\\) successi osservati, la predittiva per \\(n_{\\text{new}}\\) prove segue una distribuzione \\(\\text{Beta–Binomiale}(n_{\\text{new}}, 1+k, 1+N-k)\\). I suoi quantili dovrebbero essere coerenti con quelli ottenuti tramite simulazione.\n\n\n13.2.4 Mini check analitico\nUn ulteriore modo per verificare i risultati è confrontare le stime prodotte da Stan con quelle ottenute direttamente dalla forma analitica della distribuzione a posteriori. In questo caso, con prior uniforme e verosimiglianza binomiale, sappiamo che la distribuzione a posteriori di \\(\\theta\\) è ancora una Beta. Possiamo quindi calcolare media e intervallo di credibilità in chiuso e confrontarli con i valori ricavati dal campionamento MCMC:\n\nk &lt;- sum(y); N &lt;- length(y)\na &lt;- 1; b &lt;- 1\n\n# Posterior di theta (soluzione analitica)\npost_mean_closed &lt;- (a + k) / (a + b + N)\npost_ci95_closed &lt;- qbeta(c(0.025, 0.975), a + k, b + N - k)\n\nc(post_mean_closed = post_mean_closed)\n#&gt; post_mean_closed \n#&gt;            0.165\npost_ci95_closed\n#&gt; [1] 0.142 0.188\n\nLe differenze rispetto ai risultati di Stan dovrebbero essere minime e spiegabili unicamente con il normale rumore Monte Carlo. Questo confronto fornisce quindi una garanzia ulteriore che il modello sia stato implementato e stimato correttamente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#dati-continui-stima-della-media-con-varianza-nota",
    "href": "chapters/mcmc/03_stan_intro.html#dati-continui-stima-della-media-con-varianza-nota",
    "title": "13  Introduzione pratica a Stan",
    "section": "\n13.3 Dati continui: stima della media con varianza nota",
    "text": "13.3 Dati continui: stima della media con varianza nota\nPassiamo ora a un caso molto comune nelle scienze psicologiche: la stima della media di popolazione di una variabile continua. Pensiamo, ad esempio, ai punteggi ottenuti in un test di intelligenza (QI).\nPer semplicità ipotizziamo che la deviazione standard \\(\\sigma\\) sia nota. È un’ipotesi forte, certo, ma ci permette di concentrare l’attenzione su un solo parametro incognito: la media \\(\\mu\\). Questa assunzione semplifica il modello e rende più chiaro il passaggio dall’impostazione classica a quella bayesiana.\nMolti dati psicologici possono essere approssimati da una distribuzione normale: è il caso dei punteggi standardizzati come il QI, che hanno distribuzioni simili a una gaussiana in popolazione. Immaginiamo quindi di raccogliere i punteggi di \\(n=30\\) persone, supponendo che la deviazione standard sia \\(\\sigma = 15\\) e che la media reale sia 105.\n\nset.seed(123)\nn     &lt;- 30\nsigma &lt;- 15\ny_cont &lt;- rnorm(n, mean = 105, sd = sigma)\n\ntibble(y = y_cont) |&gt;\n  ggplot(aes(x = y)) +\n  geom_histogram(bins = 15) +\n  labs(x = \"Punteggio\", y = \"Frequenza\")\n\n\n\n\n\n\n\nIn questo scenario, il modello statistico si scrive così:\n\n\nVerosimiglianza: \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma)\\), con \\(\\sigma\\) noto.\n\nPrior su \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau)\\), con \\(\\mu_0 = 100\\) come media attesa a priori e \\(\\tau = 30\\) come deviazione standard del prior, scelta piuttosto ampia per riflettere un’incertezza elevata.\n\nDa notare che \\(\\mu\\) può assumere qualsiasi valore reale: per questo il prior corretto è una distribuzione normale definita su tutto \\(\\mathbb{R}\\).\nEcco la traduzione del modello in Stan:\n\nstancode_norm &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] y;             // dati continui\n  real&lt;lower=0&gt; sigma;     // sd nota\n  real mu0;                // media del prior su mu\n  real&lt;lower=0&gt; tau;       // sd del prior su mu\n}\nparameters {\n  real mu;                 // media: parametro reale non vincolato\n}\nmodel {\n  mu ~ normal(mu0, tau);   // prior corretto su mu\n  y  ~ normal(mu, sigma);  // likelihood\n}\n\"\n\nPrepariamo i dati in R in modo che siano coerenti con quanto richiesto dal blocco data del modello:\n\ndata_list2 &lt;- list(\n  N     = length(y_cont),\n  y     = y_cont,\n  sigma = sigma,\n  mu0   = 100,\n  tau   = 30\n)\n\nCompiliamo il modello:\n\nstanmod2 &lt;- cmdstanr::cmdstan_model(write_stan_file(stancode_norm), compile = TRUE)\n\nE infine lanciamo il campionamento MCMC:\n\nfit2 &lt;- stanmod2$sample(\n  data = data_list2,\n  iter_warmup     = 1000,\n  iter_sampling   = 4000,\n  chains          = 4,\n  parallel_chains = 4,\n  seed            = 4790,\n  refresh         = 0\n)\n\nI risultati possono essere riepilogati in forma sintetica:\n\nprint(fit2$summary(variables = \"mu\"), n = Inf)\n#&gt; # A tibble: 1 × 10\n#&gt;   variable    mean  median    sd   mad     q5     q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       104.240 104.236 2.721 2.740 99.751 108.710 1.001 5499.842 7540.041\n\nOppure, con il pacchetto posterior, possiamo estrarre i campioni e calcolare statistiche più flessibili, come medie, quantili e diagnostiche:\n\ndraws2 &lt;- fit2$draws(variables = \"mu\", format = \"draws_matrix\")\nposterior::summarise_draws(\n  draws2, mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975)), rhat, ess_bulk, ess_tail\n)\n#&gt; # A tibble: 1 × 9\n#&gt;   variable    mean    sd `2.5%`   `50%` `97.5%`  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       104.240 2.721 98.916 104.236 109.627 1.001 5499.842 7540.041\n\nL’interpretazione è immediata:\n\nvalori di \\(\\hat R\\) vicini a 1 e effective sample size elevato ci dicono che le catene sono ben miscelate e la stima è affidabile;\nla media a posteriori di \\(\\mu\\) rappresenta la nostra miglior stima puntuale della media di popolazione;\nl’intervallo di credibilità (ad esempio al 95%) quantifica l’incertezza residua su \\(\\mu\\).\n\nIn questo modo otteniamo non solo una stima centrale, ma un quadro completo della plausibilità dei valori possibili per la media di popolazione, dato quanto osservato.\n\n13.3.1 Controllo analitico della coniugatezza\nIl modello che abbiamo specificato ha una proprietà molto comoda: la coniugatezza. Quando usiamo un prior normale per la media \\(\\mu\\) e assumiamo nota la varianza \\(\\sigma^2\\), anche la distribuzione a posteriori di \\(\\mu\\) rimane normale. Questo ci permette di calcolare media e varianza della posterior in forma chiusa, senza bisogno di simulazioni MCMC.\nIn particolare, la varianza e la media della distribuzione a posteriori si ottengono come:\n\\[\n\\text{Var}(\\mu \\mid y) \\;=\\; \\left(\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}\\right)^{-1},\n\\quad\n\\mathbb{E}[\\mu \\mid y] \\;=\\; \\text{Var}(\\mu \\mid y)\\,\\left(\\frac{n\\bar y}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2}\\right).\n\\]\nCon i nostri dati possiamo calcolare questi valori direttamente:\n\nybar    &lt;- mean(y_cont)\ntau2    &lt;- 30^2\nsigma2  &lt;- sigma^2\npost_var  &lt;- 1 / (n / sigma2 + 1 / tau2)\npost_sd   &lt;- sqrt(post_var)\npost_mean &lt;- post_var * (n * ybar / sigma2 + 100 / tau2)\n\nc(post_mean_closed = post_mean, post_sd_closed = post_sd)\n#&gt; post_mean_closed   post_sd_closed \n#&gt;           104.26             2.73\n\nOra possiamo confrontare questi risultati analitici con quanto ottenuto tramite campionamento MCMC:\n\nmu_draws &lt;- as.numeric(draws2[, \"mu\"])\nc(mean_mcmc = mean(mu_draws), sd_mcmc = sd(mu_draws))\n#&gt; mean_mcmc   sd_mcmc \n#&gt;    104.24      2.72\n\nE per completezza, guardiamo anche i quantili della distribuzione campionata:\n\nquantile(mu_draws, c(0.025, 0.5, 0.975))\n#&gt;  2.5%   50% 97.5% \n#&gt;  98.9 104.2 109.6\n\nLe due soluzioni dovrebbero concordare molto bene: la formula chiusa ci dà il risultato “esatto”, mentre l’MCMC lo approssima tramite simulazione. Le piccole discrepanze sono attribuibili al normale rumore Monte Carlo, che diminuisce all’aumentare del numero di campioni.\n\n13.3.2 Visualizzazione\nUna volta stimato il modello, è molto utile osservare graficamente i campioni MCMC per verificare sia la qualità del campionamento sia la forma della distribuzione a posteriori. Il pacchetto bayesplot fornisce strumenti immediati per questo scopo.\nUn primo passo è guardare l’istogramma dei campioni:\n\nbayesplot::mcmc_hist(fit2$draws(\"mu\"))\n\n\n\n\n\n\n\nQuesto grafico mostra la distribuzione stimata della media \\(\\mu\\): non un singolo numero, ma un ventaglio di valori plausibili con le loro frequenze relative.\nPossiamo poi controllare l’andamento delle catene con un traceplot:\n\nbayesplot::mcmc_trace(fit2$draws(\"mu\"), n_warmup = 1000)\n\n\n\n\n\n\n\nQui l’idea è semplice: le linee delle catene devono sembrare “ben mescolate”, senza trend evidenti o zone piatte. È un indicatore visivo della corretta esplorazione dello spazio dei parametri.\nInfine, è utile sovrapporre le distribuzioni stimate dalle diverse catene per verificarne la concordanza:\n\nbayesplot::mcmc_dens_overlay(fit2$draws(\"mu\"))\n\n\n\n\n\n\n\nSe le curve si sovrappongono bene, abbiamo un’ulteriore conferma che le catene hanno raggiunto la stessa distribuzione stazionaria.\nIn sintesi, questo esempio rappresenta una sorta di “test bayesiano della media” con deviazione standard nota e un prior normale ampio su \\(\\mu\\). A differenza dell’approccio frequentista, non otteniamo soltanto una stima puntuale o un intervallo, ma un’intera distribuzione a posteriori della media. Questo è un vantaggio importante: l’incertezza stimata può essere comunicata in modo trasparente e, soprattutto, può essere propagata nelle fasi successive dell’analisi, ad esempio in previsioni o decisioni basate sul modello.\n\nUna nota pratica su Stan: se omettessimo la prior su \\(\\mu\\), il software assumerebbe implicitamente una prior impropria piatta su \\(\\mathbb{R}\\). Sebbene ciò possa funzionare in casi semplici, didatticamente preferiamo specificare in modo esplicito un prior normale (anche molto ampio). In questo modo le assunzioni sono sempre chiare e il modello rimane ben definito.\n\n\n13.3.3 Intervalli di credibilità\nIn un’analisi bayesiana non otteniamo una singola stima del parametro, ma una distribuzione a posteriori che descrive tutta l’incertezza residua. Gli intervalli di credibilità servono a riassumere questa distribuzione in modo intuitivo:\n\nDato il modello e i dati osservati, c’è una probabilità prefissata (ad esempio 94%) che il parametro cada all’interno dell’intervallo.\n\nÈ un’interpretazione semplice e diretta, molto più naturale rispetto a quella degli intervalli di confidenza frequentisti.\n\n13.3.3.1 Due definizioni principali\n\n\nETI (Equal-Tailed Interval): l’intervallo “a code uguali”. Lascia la stessa probabilità nelle due code della distribuzione (es. 3% a sinistra e 3% a destra in un intervallo al 94%).\n\nVantaggio: è invariante a trasformazioni monotone (se trasformo il parametro, trasformo anche i quantili).\nSvantaggio: se la posterior è molto asimmetrica, l’intervallo può risultare poco compatto.\n\n\n\nHDI (Highest Density Interval): l’intervallo “a massima densità”. È il più stretto possibile che contiene la probabilità fissata.\n\nVantaggio: rimane compatto anche con distribuzioni asimmetriche.\nSvantaggio: non è invariante a trasformazioni monotone; in presenza di distribuzioni multimodali può perfino risultare “spezzato” in più sotto-intervalli.\n\n\n\nSe la distribuzione a posteriori è simmetrica e unimodale (per esempio una Normale), ETI e HDI coincidono.\n\n13.3.3.2 Esempio con i campioni di \\(\\mu\\)\n\nPartiamo dai campioni MCMC della media \\(\\mu\\):\n\nmu_draws &lt;- as.numeric(fit2$draws(\"mu\"))\n\nCalcoliamo sia ETI che HDI al 94% con il pacchetto bayestestR:\n\neti94 &lt;- bayestestR::eti(mu_draws, ci = 0.94)\nhdi94 &lt;- bayestestR::hdi(mu_draws, ci = 0.94)\n\neti94\n#&gt; 94% ETI: [99.12, 109.43]\nhdi94\n#&gt; 94% HDI: [99.22, 109.48]\n\n\n13.3.3.3 Visualizzazione\nCon bayesplot::mcmc_areas() possiamo visualizzare gli intervalli centrali (ETI) e aggiungere i limiti HDI come linee verticali:\n\np &lt;- bayesplot::mcmc_areas(fit2$draws(\"mu\"), prob = 0.94) +\n  xlab(expression(mu)) + ylab(\"Densità\")\n\np + \n  geom_vline(xintercept = hdi94$CI_low,  linetype = \"dashed\") +\n  geom_vline(xintercept = hdi94$CI_high, linetype = \"dashed\")\n\n\n\n\n\n\n\n\n13.3.3.4 Posterior asimmetrica: esempio Beta\nPer apprezzare meglio la differenza, consideriamo una distribuzione asimmetrica, come una Beta(6,2):\n\nset.seed(123)\ntheta_draws &lt;- rbeta(5000, shape1 = 6, shape2 = 2)\n\neti_beta &lt;- bayestestR::eti(theta_draws, ci = 0.94)\nhdi_beta &lt;- bayestestR::hdi(theta_draws, ci = 0.94)\n\neti_beta\n#&gt; 94% ETI: [0.43, 0.96]\nhdi_beta\n#&gt; 94% HDI: [0.49, 0.98]\n\n\nggplot(data.frame(theta = theta_draws), aes(x = theta)) +\n  geom_density() +\n  geom_vline(xintercept = c(eti_beta$CI_low, eti_beta$CI_high), linewidth = 0.7) +\n  geom_vline(xintercept = c(hdi_beta$CI_low, hdi_beta$CI_high), \n             linewidth = 1.2, linetype = \"dashed\") +\n  labs(x = expression(theta), y = \"Densità\")\n\n\n\n\n\n\n\nQui si vede bene che l’HDI è più corto, perché concentra l’intervallo nelle zone di massima densità, evitando code poco informative.\n\n13.3.3.5 Quale livello usare? 89%, 94% o 95%?\n\n\n95%: è la scelta più familiare (ereditata dal frequentismo).\n\n94%: molto usata in manuali bayesiani (es. McElreath, 2018).\n\n89%: proposta da Kruschke come compromesso più stabile con campioni limitati.\n\nLa regola pratica è semplice: scegli un livello coerente con il resto dell’analisi e specifica sempre il metodo (ETI o HDI). Se la posterior è asimmetrica, riportare entrambi può essere molto utile.\n\n13.3.3.6 Riassunto operativo\n\n# Campioni da Stan\nmu_draws &lt;- as.numeric(fit2$draws(\"mu\"))\n\n# Intervalli a 94%\neti94 &lt;- bayestestR::eti(mu_draws, ci = 0.94)\nhdi94 &lt;- bayestestR::hdi(mu_draws, ci = 0.94)\n\n# Riassunti\nlist(\n  mean   = mean(mu_draws),\n  median = median(mu_draws),\n  ETI94  = c(low = eti94$CI_low, high = eti94$CI_high),\n  HDI94  = c(low = hdi94$CI_low, high = hdi94$CI_high)\n)\n#&gt; $mean\n#&gt; [1] 104\n#&gt; \n#&gt; $median\n#&gt; [1] 104\n#&gt; \n#&gt; $ETI94\n#&gt;   low  high \n#&gt;  99.1 109.4 \n#&gt; \n#&gt; $HDI94\n#&gt;   low  high \n#&gt;  99.2 109.5\n\nIn sintesi:\n\ncon distribuzioni simmetriche ETI e HDI sono equivalenti,\ncon distribuzioni asimmetriche l’HDI è di solito più informativo perché si concentra nelle regioni più probabili,\nriportare entrambi può aiutare a comunicare chiaramente le assunzioni e i risultati.\n\nUn esempio di frase per un report potrebbe essere:\n\n“Con un intervallo di credibilità al 94%, possiamo dire che la media del QI nella popolazione ha il 94% di probabilità di trovarsi tra 102 e 107.”",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#test-di-ipotesi-bayesiane",
    "href": "chapters/mcmc/03_stan_intro.html#test-di-ipotesi-bayesiane",
    "title": "13  Introduzione pratica a Stan",
    "section": "\n13.4 Test di ipotesi bayesiane",
    "text": "13.4 Test di ipotesi bayesiane\nL’approccio bayesiano permette di formulare domande dirette del tipo:\n\n“Qual è la probabilità che la media superi una certa soglia?”\n\nA differenza dei test frequentisti, non ci costringe a una risposta secca sì/no, ma restituisce una misura graduata di plausibilità. Inoltre, se abbiamo un margine di tolleranza pratico attorno alla soglia, possiamo definire una ROPE (Region Of Practical Equivalence) e distinguere tre scenari: il parametro stimato è verosimilmente sotto, dentro oppure sopra la zona di equivalenza.\n\n13.4.1 Probabilità a posteriori sopra una soglia\nRiprendiamo l’esempio del QI con modello Normale e \\(\\sigma\\) noto. Una domanda semplice è:\n\\[\nP(\\mu &gt; 110 \\mid y),\n\\]\ncioè la probabilità che la media della popolazione superi il valore 110.\nCalcolo dai campioni MCMC:\n\nmu_draws &lt;- as.numeric(fit2$draws(\"mu\"))\np_gt_110 &lt;- mean(mu_draws &gt; 110)\np_gt_110\n#&gt; [1] 0.0193\n\n\nInterpretazione: dato modello + dati, la probabilità che \\(\\mu\\) superi 110 è p_gt_110. Non un “sì/no”, ma una misura graduata della plausibilità dell’affermazione.\n\nControllo analitico (conjugate Normal-Normal):\n\np_gt_110_closed &lt;- 1 - pnorm(110, mean = post_mean, sd = post_sd)\nc(MCMC = p_gt_110, ClosedForm = p_gt_110_closed)\n#&gt;       MCMC ClosedForm \n#&gt;     0.0193     0.0176\n\nI due valori devono concordare (differenze minime = rumore Monte Carlo).\n\n13.4.2 Decisione pratica\nSe occorre prendere una decisione, possiamo introdurre una regola:\n\n\nagire come se \\(\\mu&gt;110\\) se \\(P(\\mu&gt;110\\mid y)\\ge p^*\\) (es. \\(p^*=0.9\\)),\naltrimenti, non agire (o raccogliere più dati).\n\nIl valore soglia \\(p^\\*\\) dipende dal rapporto costi/benefici degli errori (falsa allerta vs. falsa rassicurazione). L’approccio bayesiano rende esplicita questa scelta.\n\n13.4.3 ROPE: equivalenza pratica\nNella realtà spesso non interessa se \\(\\mu\\) sia esattamente 110, ma se sia praticamente equivalente a 110 entro una tolleranza accettabile. Definiamo allora una ROPE:\n\\[\n\\text{ROPE} = [108,\\,112] .\n\\]\nLe tre probabilità mutuamente esclusive sono:\n\nrope &lt;- c(108, 112)\n\nP_below &lt;- mean(mu_draws &lt;  rope[1])\nP_in    &lt;- mean(mu_draws &gt;= rope[1] & mu_draws &lt;= rope[2])\nP_above &lt;- mean(mu_draws &gt;  rope[2])\n\nc(P_below = P_below, P_in = P_in, P_above = P_above)\n#&gt; P_below    P_in P_above \n#&gt; 0.91463 0.08250 0.00287\n\nCon la posterior Normale si può calcolare anche in forma chiusa:\n\nP_below_cf &lt;- pnorm(rope[1], mean = post_mean, sd = post_sd)\nP_in_cf    &lt;- pnorm(rope[2], mean = post_mean, sd = post_sd) -\n              pnorm(rope[1], mean = post_mean, sd = post_sd)\nP_above_cf &lt;- 1 - pnorm(rope[2], mean = post_mean, sd = post_sd)\n\nc(P_below_cf = P_below_cf, P_in_cf = P_in_cf, P_above_cf = P_above_cf)\n#&gt; P_below_cf    P_in_cf P_above_cf \n#&gt;    0.91498    0.08275    0.00226\n\n\n13.4.4 Interpretazione\n\nSe \\(P(\\mu\\in \\text{ROPE})\\) è alta → \\(\\mu\\) è praticamente equivalente alla soglia.\nSe \\(P(\\mu&gt;\\text{ROPE})\\) è alta → \\(\\mu\\) è sopra la soglia in modo rilevante.\nSe \\(P(\\mu&lt;\\text{ROPE})\\) è alta → \\(\\mu\\) è sotto la soglia in modo rilevante.\nSe le tre probabilità sono simili → il messaggio è incertezza → utile raccogliere più dati o rivedere la tolleranza.\n\n13.4.5 Esempio di frase per un report\n\nCon ROPE = \\(\\[108,112]\\), la probabilità che \\(\\mu\\) sia sotto-ROPE è \\(P(\\mu&lt;108)=0.92\\), dentro-ROPE \\(P(108\\le \\mu\\le112)=0.08\\), sopra-ROPE \\(P(\\mu&gt;112)=0.003\\). Questi risultati indicano che \\(\\mu\\) è verosimilmente inferiore a 110 nel senso pratico definito dalla ROPE.\n\n\n13.4.6 Diagnostiche di campionamento\nDopo aver ottenuto i campioni dalla distribuzione a posteriori, il passo successivo è verificare se questi siano di buona qualità. Un modello ben specificato e un campionamento MCMC efficace producono catene che esplorano lo spazio dei parametri in modo completo e bilanciato. Per questo motivo, nel riepilogo fornito da Stan e dai pacchetti associati compaiono alcune statistiche fondamentali, che meritano di essere interpretate con attenzione (la quantità lp__ è un parametro speciale usato per le diagnostiche).\n\nfit2$summary(variables = c(\"mu\",\"lp__\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       104.240 104.236 2.721 2.740  99.751 108.710 1.001 5499.842 7540.041\n#&gt; 2 lp__     -14.463 -14.195 0.705 0.313 -15.896 -13.967 1.001 7356.664 9175.822\n\nUn primo indicatore è la statistica di convergenza \\(\\hat{R}\\) (o R-hat). Quando le catene sono indipendenti e hanno raggiunto lo stesso equilibrio, i loro valori oscillano intorno alle stesse regioni della distribuzione. In questo caso \\(\\hat{R}\\) assume valori molto vicini a 1. Nel nostro esempio, per i parametri mu e lp__ si ottengono rispettivamente 1.002 e 1.001. Questi valori sono praticamente indistinguibili da 1 e segnalano che le catene hanno raggiunto una buona mescolanza. In termini pratici, valori inferiori a 1.01 sono generalmente considerati ottimali, mentre valori superiori a 1.05 suggeriscono possibili problemi di convergenza.\nUn secondo insieme di statistiche riguarda la dimensione del campione effettivo (ESS, effective sample size). A differenza di un campionamento indipendente, l’MCMC produce campioni correlati tra loro. L’ESS quantifica quanti campioni indipendenti “equivalenti” abbiamo realmente a disposizione. Nel nostro modello, i valori per mu sono di 2768 (bulk) e 3798 (tail), mentre per lp__ superano i 3600. Si tratta di valori molto elevati, che garantiscono stime stabili anche per i quantili delle code della distribuzione. Più l’ESS è alto, più le nostre stime risultano precise. A titolo di esempio, l’errore Monte Carlo sulla media di mu, calcolato come \\(\\text{sd}/\\sqrt{\\text{ESS}}\\), risulta circa 0.05: un valore trascurabile rispetto alla deviazione standard della distribuzione a posteriori, pari a 2.68. Questo significa che l’incertezza introdotta dal metodo numerico è minima.\nOltre agli indici di convergenza e di efficienza, vale la pena soffermarsi sulla forma della distribuzione stimata. Nel riepilogo vediamo che la media e la mediana di mu (104.22 e 104.24) coincidono quasi perfettamente, segnalando una distribuzione sostanzialmente simmetrica. La deviazione standard (2.68) e la MAD (2.65) confermano che la variabilità è ben catturata e non emergono anomalie nelle code. I quantili dal 5° al 95° indicano un intervallo credibile al 90% compreso tra circa 99.8 e 108.6. È interessante osservare che il valore 110 si colloca al di sopra di questo intervallo, fatto che si traduce in una probabilità molto bassa che \\(\\mu\\) superi quella soglia.\nInfine, il parametro lp__, che rappresenta la log-densità a posteriori, non va interpretato come un parametro di interesse ma come strumento diagnostico. Anch’esso mostra valori di \\(\\hat{R}\\) e di ESS ottimi, confermando che l’esplorazione dello spazio dei parametri è avvenuta senza difficoltà.\nIn sintesi, tutte le evidenze diagnostiche — \\(\\hat{R}\\) prossimo a 1, valori elevati di ESS, concordanza tra media, mediana e misure di dispersione — ci permettono di concludere che il campionamento MCMC è stato stabile ed efficiente. Questo garantisce che i risultati ottenuti rappresentano fedelmente la distribuzione a posteriori specificata dal nostro modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#prior-e-posterior-predictive-check",
    "href": "chapters/mcmc/03_stan_intro.html#prior-e-posterior-predictive-check",
    "title": "13  Introduzione pratica a Stan",
    "section": "\n13.5 Prior e Posterior Predictive Check",
    "text": "13.5 Prior e Posterior Predictive Check\nPrima guardiamo se il prior che abbiamo scelto genera valori plausibili anche senza dati: questo è il prior predictive check. Se il prior produce punteggi di QI completamente inverosimili, dobbiamo correggerlo. Poi, dopo aver aggiornato il modello con i dati, passiamo al posterior predictive check. In questo caso le simulazioni devono assomigliare ai dati reali: se non ci riescono, significa che il modello non descrive bene il fenomeno.\n\n13.5.1 Prior Predictive Check\nObiettivo. Prima di guardare i dati, vogliamo chiederci: le nostre assunzioni a priori su \\(\\mu\\) sono plausibili? In altre parole, il prior scelto produce valori di \\(y\\) che hanno senso rispetto al dominio del problema (qui: punteggi QI)?\nIl nostro modello è:\n\\[\ny_i \\mid \\mu \\sim \\mathcal{N}(\\mu,\\; \\sigma),\n\\qquad\n\\mu \\sim \\mathcal{N}(\\mu_0,\\; \\tau).\n\\]\nCombinando likelihood e prior, la distribuzione predittiva a priori di una singola osservazione è:\n\\[\ny_i \\sim \\mathcal{N}\\!\\Big(\\mu_0,\\; \\sqrt{\\sigma^2 + \\tau^2}\\Big).\n\\]\nQuesta distribuzione descrive quali valori ci aspettiamo prima di osservare alcun dato.\n\nSe produce valori estremi o inverosimili (ad es. QI &lt; 40 o &gt; 160), il prior è troppo largo o spostato.\nSe invece produce valori troppo concentrati in un intervallo ristretto, il prior è eccessivamente informativo, lasciando poco spazio ai dati.\n\nPer implementare un prior predictive check possiamo usare lo stesso file Stan dell’inferenza, con una piccola modifica:\n\naggiungiamo una variabile booleana compute_likelihood, che ci permette di decidere se includere o meno la riga y ~ normal(mu, sigma);,\ngeneriamo repliche \\(y_{\\text{rep}}\\) in un blocco generated quantities.\n\nEcco il codice Stan:\n\nstancode_norm_ppc &lt;- \"\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;                 // usato solo se compute_likelihood=1\n  real&lt;lower=0&gt; sigma;         // sd nota\n  real mu0;                    // media del prior su mu\n  real&lt;lower=0&gt; mu_prior_sd;   // sd del prior\n  int&lt;lower=0, upper=1&gt; compute_likelihood; // 1 = usa y ~ normal(..), 0 = disattiva\n}\nparameters {\n  real mu;\n}\nmodel {\n  mu ~ normal(mu0, mu_prior_sd);\n  if (compute_likelihood == 1) {\n    y ~ normal(mu, sigma);\n  }\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik; \n\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma); // repliche prior/posterior predictive\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma); \n  }\n}\n\"\nstanmod_ppc &lt;- cmdstan_model(write_stan_file(stancode_norm_ppc), compile = TRUE)\n\nPer un controllo puro del prior disattiviamo la likelihood (compute_likelihood = 0). In questo modo, Stan genera valori \\(y_{\\text{rep}}\\) esclusivamente a partire dalle assunzioni a priori.\n\nN_ppc &lt;- length(y_cont)\n\nstan_data_prior &lt;- list(\n  N = N_ppc,\n  y = rep(0, N_ppc),   # placeholder, non usato quando compute_likelihood = 0\n  sigma = sigma,\n  mu0 = 100,\n  mu_prior_sd = 30,\n  compute_likelihood = 0\n)\n\nfit_prior &lt;- stanmod_ppc$sample(\n  data = stan_data_prior,\n  iter_warmup = 500,\n  iter_sampling = 2000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790,\n  refresh = 500\n)\n\nDopo il campionamento, estraiamo le repliche \\(y_{\\text{rep}}\\):\n\n# Estrazione dei dati simulati\nyrep_mat_prior &lt;- posterior::as_draws_matrix(fit_prior$draws(\"y_rep\"))\n\n# Selezione solo delle colonne y_rep[1],...,y_rep[N]\nN_ppc &lt;- length(y_cont)\nyrep_mat_prior &lt;- as.matrix(yrep_mat_prior[, paste0(\"y_rep[\", 1:N_ppc, \"]\")])\n\nConfrontiamo i dati osservati con alcune repliche generate dal prior:\n\nidx &lt;- sample(seq_len(nrow(yrep_mat_prior)), 100)\n\nbayesplot::ppc_dens_overlay(\n  y = y_cont,\n  yrep = yrep_mat_prior[idx, , drop = FALSE]\n) \n\n\n\n\n\n\n\nInterpretazione:\n\nSe le distribuzioni simulate coprono bene la variabilità dei dati reali, il prior è plausibile.\nSe le simulazioni sono sistematicamente troppo larghe o troppo strette, il prior va ripensato (riducendo o ampliando mu_prior_sd).\n\n13.5.2 Posterior predictive check\nDopo aver verificato che il prior sia ragionevole, possiamo passare alla fase successiva: confrontare il modello dopo aver visto i dati.\nPer farlo, riattiviamo la verosimiglianza (compute_likelihood = 1) e stimiamo la distribuzione a posteriori di \\(\\mu\\). Nel blocco generated quantities, Stan genera anche delle repliche posterior predictive \\(y_{\\text{rep}}\\), cioè nuovi dataset simulati sotto l’ipotesi che il modello e i parametri stimati siano corretti.\nIn altre parole:\n\nil prior predictive check serve a testare le assunzioni prima dei dati,\nil posterior predictive check serve a valutare se il modello dopo i dati è in grado di riprodurre l’evidenza osservata.\n\n\nstan_data_post &lt;- list(\n  N = length(y_cont),\n  y = y_cont,\n  sigma = sigma,\n  mu0 = 100,\n  mu_prior_sd = 30,\n  compute_likelihood = 1\n)\n\nLancio del campionamento:\n\nfit_post &lt;- stanmod_ppc$sample(\n  data = stan_data_post,\n  iter_warmup = 1000,\n  iter_sampling = 10000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790,\n  refresh = 1000\n)\n\nEstrazione e confronto con i dati reali:\n\ny_rep &lt;- fit_post$draws(\"y_rep\", format = \"matrix\")\nppc_dens_overlay(y = stan_data_post$y, yrep = y_rep[1:100, ])\n\n\n\n\n\n\n\nInterpretazione:\n\nse la distribuzione delle repliche \\(y_{\\text{rep}}\\) copre bene la distribuzione osservata \\(y\\), significa che il modello è in grado di spiegare i dati;\nse invece ci sono scostamenti sistematici (ad es. le repliche hanno media troppo bassa, o varianza troppo alta rispetto ai dati reali), il modello non descrive adeguatamente il fenomeno e potrebbe essere rivisto.\n\nCollegamento con la verifica dei prior.\n\nUn prior troppo largo può portare a simulazioni estreme e poco plausibili prima dei dati.\nUn prior troppo stretto rischia di imporre eccessiva rigidità al modello, lasciando poca flessibilità ai dati.\nNel posterior predictive check, quello che conta è verificare che, dopo aver aggiornato il modello con i dati, le simulazioni riflettano in modo realistico il comportamento osservato.\n\nMetafora. È come provare una ricetta: prima assaggiamo l’impasto crudo per capire se gli ingredienti sono dosati bene; poi, una volta cotto, assaggiamo il piatto finito per verificare che il risultato sia quello che ci aspettavamo.\n\n13.5.3 Nota didattica\nCon \\(\\sigma\\) noto e \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau)\\), la distribuzione predittiva a priori della media campionaria \\(\\bar{y}\\) è:\n\\[\n\\bar{y} \\sim \\mathcal{N}\\!\\big(\\mu_0,\\; \\sqrt{\\tau^2 + \\tfrac{\\sigma^2}{N}}\\big).\n\\]\nQuesta formula fornisce un controllo rapido per tarare il prior rispetto alla precisione attesa del campione. Dopo l’aggiornamento con i dati, la distribuzione a posteriori restringe l’incertezza, e le repliche posterior predictive permettono di verificarne la coerenza empirica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#riflessioni-conclusive",
    "href": "chapters/mcmc/03_stan_intro.html#riflessioni-conclusive",
    "title": "13  Introduzione pratica a Stan",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nStan rappresenta il punto di arrivo naturale del percorso che abbiamo seguito fin qui. Dopo aver compreso la logica generale dell’inferenza bayesiana con Metropolis e aver visto come i linguaggi probabilistici abbiano reso praticabile questa logica, Stan ci offre ora uno strumento concreto per applicare questi principi a modelli reali e complessi.\nIl suo valore non sta soltanto nella potenza computazionale, ma soprattutto nella possibilità di spostare l’attenzione dal calcolo all’idea scientifica. Con Stan possiamo tradurre ipotesi psicologiche in modelli formali, esplicitarne le assunzioni e ottenere inferenze riproducibili senza perdere di vista la sostanza teorica.\nIn questo senso, Stan non è solo un software: è un ambiente che incoraggia la trasparenza, la chiarezza e la cumulatività della ricerca. Nei prossimi capitoli vedremo come utilizzarlo a partire da esempi semplici, per poi affrontare modelli più ricchi. L’obiettivo è acquisire familiarità non solo con la sintassi, ma soprattutto con il modo di pensare che rende la modellazione bayesiana uno strumento essenziale per la psicologia scientifica contemporanea.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#&gt; [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [13] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] utf8_1.2.6            rmarkdown_2.29        ps_1.9.1             \n#&gt; [22] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [28] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [31] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [34] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [37] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [40] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [43] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [46] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [49] bayestestR_0.17.0     withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [52] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [55] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [58] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [61] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [64] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [67] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [70] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [73] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [76] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [79] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [82] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [85] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#bibliografia",
    "href": "chapters/mcmc/03_stan_intro.html#bibliografia",
    "title": "13  Introduzione pratica a Stan",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nNicenboim, B., Schad, D. J., & Vasishth, S. (2025). Introduction to Bayesian data analysis for cognitive science. CRC Press.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html",
    "href": "chapters/mcmc/04_stan_diagnostics.html",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "",
    "text": "Introduzione\nUna volta eseguita la stima di un modello in Stan, il primo passo non è interpretare subito i parametri, ma verificare se la procedura di campionamento ha funzionato correttamente. Le catene MCMC, infatti, possono produrre risultati fuorvianti se non hanno esplorato in modo adeguato lo spazio dei parametri.\nPer questo motivo, Stan fornisce diversi indicatori diagnostici che permettono di valutare la qualità del campionamento. Questi strumenti servono a rispondere a domande fondamentali:\nPrima di utilizzare i risultati di un modello, è quindi necessario controllare con attenzione queste diagnosi. Solo dopo aver verificato che il campionamento sia affidabile possiamo procedere con l’analisi e l’interpretazione dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#introduzione",
    "href": "chapters/mcmc/04_stan_diagnostics.html#introduzione",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "",
    "text": "Le catene hanno raggiunto la convergenza verso una stessa distribuzione?\nLa variabilità campionata rappresenta in modo fedele la distribuzione posteriore?\nCi sono segnali che i campioni non siano sufficienti o che alcune regioni della distribuzione non siano state esplorate?\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; source()\n\n# Carichiamo i pacchetti necessari\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, insight, coda, loo)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#grafici-di-tracciamento",
    "href": "chapters/mcmc/04_stan_diagnostics.html#grafici-di-tracciamento",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.1 Grafici di tracciamento",
    "text": "14.1 Grafici di tracciamento\nUno dei controlli più immediati e istruttivi sulla qualità di un campionamento MCMC consiste nell’osservare i grafici di tracciamento (trace plots). Ogni parametro del modello può essere pensato come una “storia” che si sviluppa lungo le iterazioni: il trace plot ne rappresenta l’andamento, mostrando sull’asse orizzontale il numero di iterazione e sull’asse verticale i valori successivamente campionati.\nQuando il campionamento procede correttamente, il grafico appare come una nuvola irregolare ma compatta, oscillante attorno a una fascia stabile. L’immagine ricorda il “rumore” di un televisore non sintonizzato, ma confinato in un intervallo ben definito. Questo è il segnale che la catena si sta mescolando in modo efficace, esplorando la distribuzione posteriore senza blocchi né derive.\nDiverso è il caso in cui il trace plot presenti anomalie. Catene che non si sovrappongono, pur partendo da condizioni iniziali differenti, indicano che non stanno convergendo verso la stessa distribuzione. Andamenti strutturati, con salti improvvisi, gradini o derive persistenti, rivelano invece che l’algoritmo non sta campionando in maniera efficiente.\nUn trace plot “sano” mostra dunque variazioni casuali e stabili, senza pattern sistematici. Questo fornisce fiducia nelle stime ottenute. Come osservato da [Martin et al. (2022)], è utile confrontare esempi di trace plot ben comportati con altri che evidenziano problemi: i primi confermano la bontà del campionamento, i secondi richiamano la necessità di rivedere il modello o i parametri dell’algoritmo. Nei grafici che seguono, a sinistra si osserva l’andamento delle catene, mentre a destra la densità dei valori campionati. Un campionamento ben riuscito appare oscillante ma privo di tendenze, e la densità corrisponde a una forma regolare e stabile.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.1.1 Codice R\nEsaminiamo il codice R necessario per generare i grafici di tracciamento. Per semplicità, usiamo il modello beta-binomiale in cmdstanr:\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                      // numero di prove\n  array[N] int&lt;lower=0, upper=1&gt; y;    // esiti (0/1)\n}\ntransformed data {\n  int&lt;lower=0, upper=N&gt; k = sum(y);    // numero totale di successi\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;        // probabilità di successo\n}\nmodel {\n  theta ~ beta(1, 1);                  // prior uniforme\n  k ~ binomial(N, theta);              // verosimiglianza sui successi totali\n}\ngenerated quantities {\n  vector[N] log_lik;\n  for (n in 1:N) {\n    log_lik[n] = bernoulli_lpmf(y[n] | theta);\n  }\n}\n\"\n\n\nmod &lt;- cmdstanr::cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\n\ny &lt;- c(1, 1, 1, 1, 1, 1, 1, 0, 0, 0)\ndata_list &lt;- list(\n  N = length(y),\n  y = y\n)\n\n\nfit &lt;- mod$sample(\n  data = data_list,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790,\n  refresh = 0 \n)\n\n\npost &lt;- as.array(fit$draws(\"theta\"))\ndim(post)\n#&gt; [1] 4000    4    1\n\n\nglimpse(post)\n#&gt;  'draws_array' num [1:4000, 1:4, 1] 0.665 0.862 0.834 0.791 0.809 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iteration: chr [1:4000] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n#&gt;   ..$ variable : chr \"theta\"\n\n\nmcmc_trace(fit$draws(\"theta\")) + \n  xlab(\"Post-warmup iteration\")\n\n\n\n\n\n\n\n\n14.1.2 Cosa fare se le catene non convergono?\nSe i trace plot assomigliano a quelli “cattivi” degli esempi, occorre intervenire. Una possibilità è rivedere il modello, domandandosi se la sua struttura o le prior siano adeguate ai dati. In altri casi basta aumentare la lunghezza del campionamento, così da superare transitori iniziali o oscillazioni locali.\nIn ogni caso, i trace plot restano uno degli strumenti diagnostici più semplici ma anche più potenti: abituarsi a leggerli con attenzione è una competenza imprescindibile per chiunque utilizzi modelli bayesiani.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#i-grafici-della-densità-posteriore-sono-adeguati",
    "href": "chapters/mcmc/04_stan_diagnostics.html#i-grafici-della-densità-posteriore-sono-adeguati",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.2 I grafici della densità posteriore sono adeguati?",
    "text": "14.2 I grafici della densità posteriore sono adeguati?\nI grafici della densità posteriore offrono un altro sguardo fondamentale sulla qualità dei risultati di un’analisi bayesiana. Mostrano infatti la distribuzione dei valori campionati per ciascun parametro, fornendo una rappresentazione diretta dell’incertezza residua dopo aver osservato i dati.\nQuando le catene hanno esplorato bene lo spazio dei parametri, la densità assume una forma regolare e ben definita, spesso approssimativamente simmetrica e unimodale (soprattutto in presenza di prior normali). Una curva liscia e compatta segnala che i campioni sono rappresentativi della distribuzione posteriore.\nTuttavia, non sempre il quadro è così rassicurante. Asimmetrie marcate o code molto lunghe possono indicare che il modello fatica a vincolare i parametri. La presenza di più picchi suggerisce che il campionatore abbia esplorato regioni distinte dello spazio senza riuscire a integrarle in un’unica distribuzione coerente. Curve troppo piatte o irregolari, infine, possono riflettere un campionamento insufficiente o catene non ancora convergenti.\nQuando la densità non appare adeguata, esistono diversi rimedi. Prolungare le catene aiuta a ottenere distribuzioni più stabili; rivedere le prior consente di evitare posteriori irrealistiche o mal condizionate; migliorare le impostazioni del campionatore può rendere l’esplorazione più efficiente.\nIn sintesi, l’ispezione delle densità posteriori non è solo un controllo grafico preliminare, ma un passaggio cruciale per valutare l’affidabilità delle inferenze: ci dice se il modello ha catturato la struttura informativa dei dati in maniera coerente ed equilibrata.\n\n14.2.1 Codice R\n\n# Estrai i draw posteriori di theta\ntheta_draws &lt;- fit$draws(\"theta\")\n\n# Densità marginale complessiva\nmcmc_dens(theta_draws) +\n  ggplot2::labs(\n    x = expression(theta),\n    y = \"Densità\"\n  )",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#lautocorrelazione-nelle-catene-mcmc-come-interpretarla-e-gestirla",
    "href": "chapters/mcmc/04_stan_diagnostics.html#lautocorrelazione-nelle-catene-mcmc-come-interpretarla-e-gestirla",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.3 L’autocorrelazione nelle catene MCMC: come interpretarla e gestirla",
    "text": "14.3 L’autocorrelazione nelle catene MCMC: come interpretarla e gestirla\nQuando utilizziamo il metodo Monte Carlo basato su catene di Markov (MCMC) per stimare modelli bayesiani, è importante ricordare che i campioni successivi prodotti dall’algoritmo non sono del tutto indipendenti tra loro. Questo fenomeno, chiamato autocorrelazione, è una caratteristica intrinseca delle catene di Markov. Finché rimane contenuta, non costituisce un problema; ma quando diventa troppo elevata, riduce l’efficienza del campionamento e può compromettere la qualità delle stime.\nL’autocorrelazione misura la somiglianza tra un campione e quelli che lo precedono. In un campionamento ideale questa somiglianza si riduce rapidamente man mano che ci si allontana nel tempo: già dopo pochi passi, i campioni dovrebbero risultare quasi indipendenti. Il modo più immediato per valutare questo comportamento è il correlogramma, che rappresenta l’autocorrelazione in funzione della distanza (lag) tra i campioni. Un correlogramma rassicurante mostra un valore iniziale non troppo alto e un rapido decadimento verso lo zero.\nQuando invece l’autocorrelazione persiste anche a lag elevati, significa che la catena si muove lentamente nello spazio dei parametri e produce campioni molto simili tra loro. In questo caso l’informazione effettiva contenuta nella sequenza è minore di quanto suggerisca il numero complessivo di iterazioni, perché molti campioni risultano ridondanti.\nSe ci troviamo di fronte a una catena con forte autocorrelazione, abbiamo diverse strategie a disposizione. Una possibilità è prolungare il campionamento, così da compensare la perdita di efficienza con un numero maggiore di iterazioni. In alternativa si può applicare il cosiddetto thinning, cioè conservare soltanto un campione ogni certo numero di passi, riducendo così la dipendenza tra osservazioni consecutive; questa soluzione, tuttavia, comporta uno spreco di calcoli e viene consigliata solo in casi particolari. Infine, spesso è più efficace rivedere le impostazioni dell’algoritmo di campionamento, ad esempio regolando i parametri di proposta, così da migliorare la capacità della catena di esplorare lo spazio dei parametri.\nL’analisi dell’autocorrelazione non è quindi un dettaglio tecnico secondario, ma un passaggio essenziale nella diagnosi di un’analisi bayesiana. Osservando il modo in cui la catena si muove nel tempo, possiamo capire se i campioni raccolti forniscono davvero un quadro robusto e affidabile della distribuzione posteriore.\n\n14.3.1 Codice R\nEsaminiamo l’autocorrelazione MCMC di theta per ciascuna catena:\n\n# Estraggo i draw di theta nel formato atteso da bayesplot (iter x chain x param)\ntheta_draws &lt;- fit$draws(\"theta\")  # draws_array\n\n# ACF fino a 10 ritardi \nmcmc_acf(theta_draws, lags = 10)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-dimensione-effettiva-del-campione-un-indicatore-cruciale-per-laffidabilità-delle-stime",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-dimensione-effettiva-del-campione-un-indicatore-cruciale-per-laffidabilità-delle-stime",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.4 La dimensione effettiva del campione: un indicatore cruciale per l’affidabilità delle stime",
    "text": "14.4 La dimensione effettiva del campione: un indicatore cruciale per l’affidabilità delle stime\nUno degli aspetti più importanti da considerare quando utilizziamo metodi MCMC è la dimensione effettiva del campione, indicata con \\(N_{\\text{eff}}\\). A differenza del numero totale di iterazioni prodotte dall’algoritmo, \\(N_{\\text{eff}}\\) rappresenta il numero equivalente di campioni statisticamente indipendenti che avrebbero garantito lo stesso livello di precisione nelle stime.\nPoiché i campioni generati da una catena di Markov tendono a essere correlati tra loro, \\(N_{\\text{eff}}\\) è sempre inferiore al numero complessivo di iterazioni. La formula che ne consente il calcolo tiene conto proprio dell’autocorrelazione presente nella sequenza:\n\\[\nN_{\\text{eff}} = \\frac{T}{1 + 2 \\sum_{s=1}^{S} \\rho_{s}},\n\\] dove \\(T\\) è il numero totale di campioni e \\(\\rho_{s}\\) misura l’autocorrelazione ai diversi lag.\nDal punto di vista pratico, se \\(N_{\\text{eff}}\\) si avvicina a \\(T\\) possiamo concludere che i campioni ottenuti sono quasi indipendenti e che l’algoritmo ha esplorato lo spazio dei parametri in maniera efficiente. Al contrario, un valore molto più basso segnala che la catena ha prodotto osservazioni fortemente correlate, riducendo così l’informazione effettiva disponibile.\nQuando ci troviamo in questa seconda situazione, diverse strategie possono migliorare la qualità delle stime. Prolungare la catena è spesso la soluzione più semplice, perché un numero maggiore di iterazioni permette di accumulare campioni indipendenti anche in presenza di autocorrelazione. In altri casi può essere utile ridurre la dipendenza tra osservazioni successive applicando il cosiddetto thinning, cioè conservando solo un campione ogni determinato numero di iterazioni; questa scelta, tuttavia, implica un costo in termini di dati scartati e va adottata con cautela. Talvolta, infine, è necessario agire a monte, intervenendo sull’algoritmo di campionamento o sulla specificazione del modello, così da aumentare l’efficienza complessiva.\nLa dimensione effettiva del campione non va considerata un dettaglio tecnico marginale, ma un indicatore essenziale della qualità delle nostre inferenze. Solo valori sufficientemente elevati di \\(N_{\\text{eff}}\\) ci consentono di avere fiducia nelle conclusioni che traiamo dai modelli bayesiani.\n\n14.4.1 Codice R\n\nfit$summary(variables = \"theta\")\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 theta    0.668  0.678 0.132 0.137 0.436 0.868 1.001 5663.008 6066.721\n\n\n14.4.1.1 Due versioni: bulk e tail\n\n\n\nESS bulk\n\nmisura l’efficienza nel campionare la parte centrale della distribuzione posteriore.\nè basato su stime di autocorrelazione in regioni vicine alla mediana.\nserve per stimare media, varianza, correlazioni: tutte quantità “di bulk”.\n\n\n\nESS tail\n\nmisura l’efficienza nel campionare le code della distribuzione posteriore.\nè cruciale per quantili estremi (ad esempio 2.5% e 97.5% dell’intervallo credibile).\nse è basso, gli intervalli credibili possono essere instabili, anche se le medie sembrano ben stimate.\n\n\n\n14.4.1.2 Quale considerare?\nDipende da cosa ti interessa:\n\nSe vuoi media, deviazione standard, correlazioni → guarda ESS bulk.\nSe vuoi intervalli credibili affidabili (quantili) → guarda anche ESS tail.\n\nIn pratica:\n\n\nentrambi dovrebbero essere almeno &gt; 400 (regola di Gelman et al.).\nSe bulk è alto ma tail basso → le stime puntuali sono affidabili, ma le code sono male esplorate → gli intervalli possono sottostimare l’incertezza.\n\n\n\n14.4.1.3 Regola pratica in Stan\n\n\ness_bulk troppo basso → media e varianza non affidabili.\n\ness_tail troppo basso → intervalli credibili poco accurati.\n\nEntrambi alti → campionamento ben riuscito.\n\nNel caso presente, ess_bulk è circa 5663: significa che i 16.000 campioni (4 catene × 4000) “valgono” come oltre 5600 campioni indipendenti. È un valore molto alto, quindi la stima della media e di altre statistiche centrali è molto stabile. ess_tail è circa 6067: anche in questo caso le stime dei quantili estremi (ad esempio intervalli al 95%) sono affidabili.\nIl pacchetto bayesplot fornisce una funzione generica di estrazione neff_ratio che restituisce il rapporto \\(N_{\\text{eff}} / N\\):\n\nratios_bb &lt;- neff_ratio(fit)\nprint(ratios_bb)\n#&gt;       theta  log_lik[1]  log_lik[2]  log_lik[3]  log_lik[4]  log_lik[5] \n#&gt;       0.370       0.388       0.388       0.388       0.388       0.388 \n#&gt;  log_lik[6]  log_lik[7]  log_lik[8]  log_lik[9] log_lik[10] \n#&gt;       0.388       0.388       0.333       0.333       0.333\n\nLe funzioni mcmc_neff e mcmc_neff_hist possono quindi essere utilizzate per visualizzare graficamente questi rapporti.\n\nmcmc_neff(ratios_bb, size = 2)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-statistica-hatr-il-termometro-della-convergenza-delle-catene",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-statistica-hatr-il-termometro-della-convergenza-delle-catene",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.5 La statistica \\(\\hat{R}\\): il termometro della convergenza delle catene",
    "text": "14.5 La statistica \\(\\hat{R}\\): il termometro della convergenza delle catene\nTra gli strumenti diagnostici più diffusi e affidabili per valutare la convergenza delle catene MCMC vi è la statistica \\(\\hat{R}\\), nota anche come potenziale scale reduction factor. La sua funzione è semplice ma cruciale: stabilire se catene inizializzate da punti di partenza diversi hanno finito per descrivere la stessa distribuzione posteriore. Quando ciò accade, possiamo considerare le stime prodotte robuste e affidabili.\nIl calcolo di \\(\\hat{R}\\) si basa sul confronto tra due quantità: la variabilità interna a ciascuna catena e la variabilità osservata tra catene differenti. In formule,\n\\[\n\\hat{R} = \\sqrt{\\frac{W + \\tfrac{1}{n}(B - W)}{W}},\n\\] dove \\(W\\) rappresenta la varianza media all’interno delle catene e \\(B\\) la varianza tra catene. Se le catene hanno esplorato bene la stessa distribuzione, queste due fonti di variabilità coincidono, e \\(\\hat{R}\\) risulta vicino a 1.\nDal punto di vista interpretativo, valori esattamente pari a 1 indicano una convergenza perfetta. Nella pratica, si accettano come soddisfacenti valori fino a 1.01 e, più in generale, fino a 1.05. Quando invece \\(\\hat{R}\\) supera 1.1, è opportuno sospendere il giudizio: significa che le catene non si sono ancora stabilizzate e che le inferenze potrebbero non riflettere la vera distribuzione posteriore.\nL’importanza di questa statistica sta nella sua capacità di mettere in luce eventuali discrepanze sistematiche. Se le catene non si sovrappongono, \\(\\hat{R}\\) segnala che esse stanno campionando da regioni diverse dello spazio dei parametri. Le cause possono essere molteplici: un numero insufficiente di iterazioni, difficoltà di identificazione del modello, oppure problemi di esplorazione legati al campionatore.\nOggi la maggior parte dei software per l’inferenza bayesiana calcola automaticamente \\(\\hat{R}\\) per tutti i parametri, rendendo semplice monitorare la qualità del campionamento. Non sorprende quindi che in letteratura si insista sul fatto che catene ben comportate producano valori estremamente prossimi all’unità, mentre catene problematiche si rivelino subito attraverso valori anomali.\nIn conclusione, \\(\\hat{R}\\) può essere considerato a pieno titolo un vero e proprio termometro della convergenza: una misura sintetica, chiara e quantitativa che consente di valutare la credibilità delle simulazioni MCMC e, di conseguenza, delle inferenze tratte dai modelli bayesiani.\n\n14.5.1 Codice R\n\nrhats &lt;- bayesplot::rhat(fit)\nprint(rhats)\n#&gt;       theta  log_lik[1]  log_lik[2]  log_lik[3]  log_lik[4]  log_lik[5] \n#&gt;           1           1           1           1           1           1 \n#&gt;  log_lik[6]  log_lik[7]  log_lik[8]  log_lik[9] log_lik[10] \n#&gt;           1           1           1           1           1\n\nPossiamo visualizzare i valori di \\(\\hat{R}\\) con la funzione mcmc_rhat:\n\nmcmc_rhat(rhats)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-diagnostica-di-geweke",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-diagnostica-di-geweke",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.6 La diagnostica di Geweke",
    "text": "14.6 La diagnostica di Geweke\nLa diagnostica proposta da Geweke rappresenta un metodo semplice ma efficace per verificare se una catena MCMC ha raggiunto la stazionarietà. L’idea alla base è intuitiva: se la catena sta campionando da una distribuzione stabile, allora le sue prime e le sue ultime porzioni dovrebbero produrre stime simili dei parametri.\nIn pratica, il test confronta la media dei valori ottenuti nei primi campioni della catena (spesso il 10% iniziale) con la media calcolata sugli ultimi campioni (ad esempio l’ultimo 50%). Se le due stime coincidono entro i limiti della variabilità campionaria, possiamo considerare la catena stazionaria; se invece differiscono in modo consistente, significa che il processo non si è ancora stabilizzato.\nIl risultato viene espresso sotto forma di uno z-score. Valori vicini allo zero indicano una buona corrispondenza tra le due parti della catena e quindi un campionamento affidabile. Valori con grandezza superiore a 2 segnalano invece una discrepanza degna di nota, che mette in dubbio la qualità del campionamento.\nPossiamo pensare a questa diagnostica come a un termometro della stabilità temporale: misura se l’andamento della catena all’inizio è coerente con quello alla fine. Quando il test evidenzia problemi, le possibili soluzioni consistono nel prolungare il campionamento, nel rivedere i parametri del campionatore o, se necessario, nel interrogarsi sulla specificazione del modello, che potrebbe rendere difficile la convergenza.\nIn definitiva, la diagnostica di Geweke fornisce un’indicazione diretta e facilmente interpretabile sulla qualità della catena, ed è quindi uno strumento utile da affiancare agli altri controlli standard nella valutazione delle analisi bayesiane.\n\n14.6.1 Codice R\n\n# 1) Estrai i draw di theta come data frame con metadati (.chain, .iteration)\ndf_theta &lt;- as_draws_df(fit$draws(\"theta\"))[, c(\".chain\", \".iteration\", \"theta\")]\n\n# 2) Spezza per catena e crea un mcmc.list\nchains &lt;- split(df_theta$theta, df_theta$.chain)\nmcmc_list &lt;- mcmc.list(lapply(chains, mcmc))\n\n# 3) Geweke diagnostic: Z-score per catena\n#    frac1 = frazione iniziale del campione (default 0.1),\n#    frac2 = frazione finale (default 0.5)\ngd &lt;- lapply(mcmc_list, geweke.diag, frac1 = 0.1, frac2 = 0.5)\n\n# 4) Estrai gli Z (uno per catena, parametro univariato)\nz_scores &lt;- sapply(gd, function(x) x$z)\nz_scores\n#&gt; 1.var1 2.var1 3.var1 4.var1 \n#&gt; -1.338  0.815 -0.583  0.915\n\n\n# p-value bilaterale associato a ciascun Z\npvals &lt;- 2 * pnorm(-abs(z_scores))\npvals\n#&gt; 1.var1 2.var1 3.var1 4.var1 \n#&gt;  0.181  0.415  0.560  0.360\n\n\n# 5) Plot diagnostico (per ogni catena)\ngeweke.plot(mcmc_list, auto.layout = TRUE)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#lerrore-standard-di-monte-carlo-quantificare-lincertezza-dellapprossimazione",
    "href": "chapters/mcmc/04_stan_diagnostics.html#lerrore-standard-di-monte-carlo-quantificare-lincertezza-dellapprossimazione",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.7 L’errore standard di Monte Carlo: quantificare l’incertezza dell’approssimazione",
    "text": "14.7 L’errore standard di Monte Carlo: quantificare l’incertezza dell’approssimazione\nQuando utilizziamo i metodi Monte Carlo basati su catene di Markov (MCMC), dobbiamo sempre ricordare che i risultati ottenuti non sono la distribuzione a posteriori “vera”, ma soltanto una sua approssimazione basata su un numero finito di campioni. Come ogni approssimazione, anche questa porta con sé un margine di errore che è necessario quantificare. A questo scopo si utilizza l’Errore Standard di Monte Carlo (MCSE), una misura che indica quanto sia precisa la stima prodotta dalle catene.\nIl calcolo del MCSE si basa su una relazione semplice ma molto informativa:\n\\[\n\\text{MCSE} = \\frac{\\text{SD}}{\\sqrt{N_{\\text{eff}}}},\n\\tag{14.1}\\] dove la deviazione standard (SD) descrive la variabilità della stima e \\(N_{\\text{eff}}\\) rappresenta la dimensione effettiva del campione, cioè il numero equivalente di osservazioni indipendenti che forniscono la stessa quantità di informazione dei campioni autocorrelati generati dall’algoritmo.\nDal punto di vista interpretativo, un MCSE piccolo rispetto alla scala del parametro indica che la stima è sufficientemente precisa per essere considerata affidabile. Se invece il MCSE risulta elevato, significa che la nostra approssimazione è troppo rumorosa e che la catena non ha fornito abbastanza informazione utile. Una regola empirica spesso citata suggerisce che il MCSE dovrebbe essere almeno un ordine di grandezza più piccolo della deviazione standard associata alla stima.\nQuando il MCSE è insoddisfacente, la prima strategia consiste nell’aumentare la lunghezza delle catene, così da raccogliere più campioni indipendenti. Non sempre, però, questo approccio è il più efficiente: in molti casi conviene lavorare sull’efficienza dell’algoritmo, regolando i suoi parametri o rivedendo la specificazione del modello, così da ridurre l’autocorrelazione tra i campioni e ottenere stime più informative a parità di iterazioni.\nIl MCSE, considerato insieme ad altre diagnostiche come la statistica \\(\\hat{R}\\) o il test di Geweke, fornisce un quadro complessivo della qualità delle nostre catene MCMC. Solo quando questi indicatori convergono verso valutazioni positive possiamo avere fiducia che le nostre stime siano davvero pronte per essere interpretate in termini sostantivi.\n\n14.7.1 Codice R\nL’Equazione 14.1 può essere implementata in R così:\n\n# Estrai il sommario per theta\nsumm_theta &lt;- fit$summary(variables = \"theta\")\n\n# Calcola l'errore standard Monte Carlo\nmcse_theta &lt;- summ_theta$sd / sqrt(summ_theta$ess_bulk)\nmcse_theta\n#&gt; [1] 0.00175",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#transizioni-divergenti-segnali-dallarme-nellalgoritmo-hmc",
    "href": "chapters/mcmc/04_stan_diagnostics.html#transizioni-divergenti-segnali-dallarme-nellalgoritmo-hmc",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.8 Transizioni divergenti: segnali d’allarme nell’algoritmo HMC",
    "text": "14.8 Transizioni divergenti: segnali d’allarme nell’algoritmo HMC\nNel campionamento con Hamiltonian Monte Carlo (HMC), la comparsa di transizioni divergenti è un campanello d’allarme che non deve essere ignorato. Questi eventi si verificano quando l’algoritmo incontra difficoltà nell’esplorare regioni complicate dello spazio dei parametri, caratterizzate da forte curvatura o da geometrie irregolari. In tali situazioni, invece di proseguire con un movimento fluido e coerente, la traiettoria simulata “salta” o si interrompe, segnalando che l’integrazione numerica dell’Hamiltoniana non è stata accurata.\nLa presenza di transizioni divergenti ha conseguenze importanti: significa che porzioni rilevanti della distribuzione posteriore potrebbero non essere state esplorate, con il rischio di produrre inferenze incomplete o distorte. È come disporre di una mappa geografica con intere zone lasciate in bianco: ogni conclusione basata su quel campionamento rischia di essere parziale o fuorviante.\nFortunatamente, esistono diverse strategie per affrontare il problema. Talvolta i dati stessi contengono valori estremi o configurazioni che accentuano le difficoltà numeriche, ed è utile verificarne la qualità. In altri casi, la causa va ricercata nelle distribuzioni a priori, che se troppo restrittive o mal calibrate possono creare colli di bottiglia nello spazio dei parametri. Spesso è possibile intervenire regolando i parametri operativi dell’HMC, come la dimensione del passo di integrazione o il numero di passi simulati, così da rendere più accurata e stabile la dinamica. Quando tutto ciò non basta, una riparametrizzazione del modello – cioè una riformulazione delle variabili latenti in forme più semplici da esplorare – può migliorare radicalmente la geometria dello spazio e ridurre le difficoltà del campionatore.\nIn sintesi, le transizioni divergenti non sono un dettaglio secondario, ma un indicatore cruciale della qualità del campionamento. La loro assenza è condizione necessaria per poter considerare affidabile l’esplorazione della distribuzione posteriore: solo in loro mancanza possiamo confidare che il modello stia davvero catturando tutta la complessità del fenomeno in studio.\n\n14.8.1 Codice R\n\n# Numero totale di transizioni divergenti\nfit$diagnostic_summary()$num_divergent\n#&gt; [1] 0 0 0 0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-bayesian-fraction-of-missing-information-bfmi-un-indicatore-di-efficienza-esplorativa",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-bayesian-fraction-of-missing-information-bfmi-un-indicatore-di-efficienza-esplorativa",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.9 La Bayesian Fraction of Missing Information (BFMI): un indicatore di efficienza esplorativa",
    "text": "14.9 La Bayesian Fraction of Missing Information (BFMI): un indicatore di efficienza esplorativa\nNei metodi di campionamento avanzati come l’Hamiltonian Monte Carlo (HMC) e il No-U-Turn Sampler (NUTS), la Bayesian Fraction of Missing Information (BFMI) costituisce uno strumento diagnostico particolarmente utile per valutare l’efficienza con cui l’algoritmo esplora lo spazio dei parametri. A differenza di altre misure che si concentrano sulla convergenza delle catene, la BFMI fornisce informazioni più profonde sul “modo” in cui il campionatore si muove all’interno della distribuzione a posteriori.\nIl concetto si basa sull’analisi delle fluttuazioni di energia durante il processo di campionamento. Possiamo immaginare l’energia come il carburante che consente all’algoritmo di spostarsi da una regione all’altra dello spazio dei parametri: un’esplorazione efficiente richiede che questo carburante venga utilizzato in maniera equilibrata, senza sbalzi eccessivi né stagnazioni.\nL’interpretazione dei valori è piuttosto chiara. Quando la BFMI è uguale o superiore a 0.3, possiamo considerare l’esplorazione soddisfacente: l’algoritmo riesce a coprire in modo efficace tutte le aree rilevanti della distribuzione. Se i valori si collocano tra 0.2 e 0.3, conviene prestare attenzione: l’esplorazione potrebbe essere incompleta e richiede una verifica più accurata. Valori inferiori a 0.2 rappresentano un vero e proprio segnale d’allarme, perché indicano che l’algoritmo incontra notevoli difficoltà e le inferenze risultanti rischiano di essere poco affidabili.\nLe cause di un basso BFMI vanno spesso ricercate nella complessità geometrica della distribuzione posteriore. Parametri fortemente correlati, scale molto diverse tra loro o curvature accentuate rendono più ardua l’esplorazione. Anche scelte di prior troppo restrittive possono introdurre barriere artificiali che ostacolano i movimenti del campionatore.\nQuando ci si trova in questa situazione, diverse strategie possono migliorare le cose. Una riparametrizzazione del modello, magari attraverso trasformazioni più naturali delle variabili, può semplificare notevolmente lo spazio da esplorare. L’aggiustamento della matrice di massa nell’HMC consente di calibrare meglio i movimenti del campionatore. Infine, una revisione critica delle distribuzioni a priori aiuta a rimuovere vincoli inutili che potrebbero ostacolare la dinamica.\nLa BFMI non è dunque un dettaglio tecnico secondario, ma una finestra privilegiata sul comportamento interno dell’algoritmo. Monitorarne i valori significa assicurarsi che le inferenze bayesiane siano basate su un’esplorazione realmente completa e affidabile dello spazio dei parametri, condizione essenziale per la solidità delle conclusioni tratte.\n\n14.9.1 Codice R\n\n# 1) Diagnostiche del sampler come data.frame (senza warmup)\nsd_df &lt;- fit$sampler_diagnostics(inc_warmup = FALSE, format = \"df\")\n\nnp_all &lt;- sd_df %&gt;%\n  pivot_longer(\n    cols = c(accept_stat__, stepsize__, treedepth__, n_leapfrog__, divergent__, energy__),\n    names_to = \"Parameter\", values_to = \"Value\"\n  ) %&gt;%\n  rename(Chain = .chain, Iteration = .iteration) %&gt;%\n  relocate(Chain, Iteration, Parameter, Value)\n\nclass(np_all) &lt;- c(\"nuts_params\", \"data.frame\")\n\n# Tieni SOLO energy__ e le colonne richieste\nnp_energy &lt;- np_all %&gt;%\n  dplyr::filter(Parameter == \"energy__\") %&gt;%\n  dplyr::select(Chain, Iteration, Parameter, Value)\n\n# Assicurati della classe attesa\nclass(np_energy) &lt;- c(\"nuts_params\", \"data.frame\")\n\n# Plot diagnostico dell’energia (BFMI)\nmcmc_nuts_energy(np_energy) \n\n\n\n\n\n\n\n\nenergy_by_chain &lt;- split(np_energy$Value, np_energy$Chain)\nbfmi &lt;- sapply(energy_by_chain, function(e) {\n  de &lt;- diff(e)\n  mean(de^2) / stats::var(e)\n})\nbfmi\n#&gt;    1    2    3    4 \n#&gt; 1.10 1.21 1.11 1.09\n\n\n# BFMI complessiva (media pesata per numero di iterazioni per catena)\nbfmi_overall &lt;- weighted.mean(bfmi, sapply(energy_by_chain, length))\nbfmi_overall\n#&gt; [1] 1.13\n\nPer regola pratica, un BFMI minore di 0.3 è considerato problematico: indica che l’algoritmo NUTS non sta esplorando bene la distribuzione dell’energia, e quindi l’efficienza del campionamento è ridotta.\nTutti i valori sono ben sopra 1, quindi molto più alti della soglia critica. Questo indica che le catene hanno esplorato lo spazio dei parametri con efficienza elevata, senza perdita informativa.\nBFMI &gt; 1 non è un problema: significa semplicemente che la varianza dei salti nell’energia è in linea con (o superiore a) la varianza totale dell’energia. Quello che conta è che non siano troppo bassi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-leave-one-out-cross-validation-uno-sguardo-allaffidabilità-predittiva-del-modello",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-leave-one-out-cross-validation-uno-sguardo-allaffidabilità-predittiva-del-modello",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.10 La Leave-One-Out Cross-Validation: uno sguardo all’affidabilità predittiva del modello",
    "text": "14.10 La Leave-One-Out Cross-Validation: uno sguardo all’affidabilità predittiva del modello\nTra i metodi più efficaci per valutare la capacità predittiva di un modello bayesiano vi è la Leave-One-Out Cross-Validation (LOO). Questa procedura risponde a una domanda cruciale: quanto possiamo fidarci delle previsioni del nostro modello quando deve affrontare nuove osservazioni?\nL’idea alla base della LOO è semplice ed elegante. Immaginiamo di togliere a turno una singola osservazione dal dataset, stimare il modello sui dati rimanenti e verificare quanto bene esso riesce a predire proprio il dato lasciato fuori. Ripetendo questo esperimento concettuale per tutte le osservazioni, otteniamo una misura complessiva della capacità del modello di generalizzare oltre i dati su cui è stato addestrato.\nIl valore di questo approccio sta soprattutto nel suo equilibrio. Da un lato, la LOO riduce il rischio di overfitting, ossia la tendenza di un modello a seguire troppo da vicino le particolarità del campione, perdendo capacità di generalizzazione. Dall’altro, aiuta a individuare l’underfitting, cioè il caso in cui un modello eccessivamente rigido non riesce a cogliere le regolarità effettive nei dati.\nNella pratica, la valutazione si sintetizza attraverso indici come il Leave-One-Out Information Criterion (LOOIC). Valori più bassi di LOOIC indicano una migliore capacità predittiva, perché il modello riesce a bilanciare in modo ottimale adattamento e generalizzazione. Le differenze di LOOIC tra modelli alternativi possono quindi orientare le nostre scelte, ma la loro interpretazione deve essere accompagnata da una riflessione teorica sul modello e sul contesto di applicazione.\nLa LOO, dunque, non è un verdetto definitivo, ma uno strumento diagnostico di grande utilità. Applicata in modo sistematico, ci consente di selezionare modelli non solo statisticamente ben calibrati, ma anche realmente utili per formulare previsioni affidabili. È per questo motivo che costituisce una tappa fondamentale nel percorso verso analisi bayesiane robuste e credibili.\n\n14.10.1 Codice R\n\n# log_lik come array: [iter, chain, N]\nll_array &lt;- as_draws_array(fit$draws(\"log_lik\"))\n\nS &lt;- dim(ll_array)[1]   # iterazioni post-warmup per catena\nC &lt;- dim(ll_array)[2]   # numero di catene\nN &lt;- dim(ll_array)[3]   # numero di osservazioni\n\n# log_lik come matrice: [S*C, N] (formato atteso da loo)\nll_mat &lt;- as_draws_matrix(fit$draws(\"log_lik\"))\n\n# r_eff per PSIS-LOO (consigliato): serve chain_id per correggere autocorrelazione\nchain_id &lt;- rep(1:C, each = S)\nr_eff &lt;- relative_eff(exp(ll_mat), chain_id = chain_id)\n\n# LOO\nloo_res &lt;- loo::loo(ll_mat, r_eff = r_eff)\nprint(loo_res)\n#&gt; \n#&gt; Computed from 16000 by 10 log-likelihood matrix.\n#&gt; \n#&gt;          Estimate  SE\n#&gt; elpd_loo     -7.1 1.3\n#&gt; p_loo         0.9 0.2\n#&gt; looic        14.2 2.6\n#&gt; ------\n#&gt; MCSE of elpd_loo is 0.0.\n#&gt; MCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 0.4]).\n#&gt; \n#&gt; All Pareto k estimates are good (k &lt; 0.7).\n#&gt; See help('pareto-k-diagnostic') for details.\n\nIl calcolo di LOO-CV restituisce in questo esempio un valore di elpd_loo ≈ –7.1 con errore standard 1.3. Poiché l’LOOIC è definito come \\(-2 \\times \\text{elpd\\_loo}\\), otteniamo LOOIC ≈ 14.2. L’effettivo numero di parametri stimati dal modello è indicato da p_loo ≈ 0.9, molto vicino a 1, il che è coerente con la presenza di un unico parametro \\(\\theta\\).\nTutti i valori di Pareto k sono inferiori a 0.7, segnalando che l’approssimazione PSIS-LOO è stabile e affidabile. In pratica, questo significa che il modello ha una complessità adeguata rispetto ai dati e non presenta osservazioni influenti tali da compromettere la validità del criterio predittivo.\nIn sintesi, LOO ci dice che il modello binomiale con prior Beta(1,1) riesce a spiegare i dati senza problemi di adattamento o di stabilità numerica. I valori ottenuti diventano particolarmente utili quando si confrontano più modelli: quello con elpd_loo più alto (o LOOIC più basso) è da preferire, in quanto fornisce predizioni fuori campione più accurate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#il-parametro-κ-un-indicatore-cruciale-per-laffidabilità-delle-stime",
    "href": "chapters/mcmc/04_stan_diagnostics.html#il-parametro-κ-un-indicatore-cruciale-per-laffidabilità-delle-stime",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "\n14.11 Il parametro κ: un indicatore cruciale per l’affidabilità delle stime",
    "text": "14.11 Il parametro κ: un indicatore cruciale per l’affidabilità delle stime\nQuando si utilizza il Pareto Smoothed Importance Sampling (PSIS) per approssimare quantità di interesse in un’analisi bayesiana, il parametro κ (kappa) diventa un indicatore chiave della qualità delle stime. Possiamo considerarlo come un termometro che misura quanto il processo di campionamento sia influenzato da osservazioni particolarmente estreme, cioè da quei dati che rischiano di avere un peso eccessivo nelle conclusioni finali.\nPer capire l’intuizione, immaginiamo di voler stimare le preferenze alimentari di una popolazione molto ampia. Se ci basassimo solo su pochi individui con gusti estremi, le nostre inferenze risulterebbero distorte. Allo stesso modo, in un’analisi bayesiana, campioni con peso anomalo possono compromettere la stabilità delle stime. Il parametro κ misura proprio questo rischio.\nValori bassi di κ (inferiori a 0.5) indicano una situazione rassicurante: la variabilità dei dati è stata rappresentata in modo adeguato e nessuna osservazione domina eccessivamente il processo. Quando κ si colloca tra 0.5 e 0.7, occorre maggiore prudenza: le stime possono ancora essere utilizzabili, ma meritano un controllo più attento. Il vero campanello d’allarme scatta quando κ supera 0.7: in questo scenario, pochi valori influenti stanno probabilmente guidando l’intera stima, riducendone l’affidabilità.\nQuesta diagnosi è particolarmente rilevante nel contesto della Leave-One-Out Cross-Validation (LOO-CV), dove un κ elevato segnala che le valutazioni predittive del modello possono essere seriamente compromesse da un numero eccessivo di osservazioni influenti.\nIn pratica, monitorare κ è una buona abitudine per ogni analista bayesiano. Proprio come un meccanico che controlla regolarmente gli indicatori della propria automobile per assicurarsi che tutto funzioni correttamente, anche chi utilizza modelli bayesiani dovrebbe verificare κ prima di trarre conclusioni dalle analisi. Solo così è possibile distinguere tra inferenze solide e risultati che rischiano di essere fuorvianti.\n\n14.11.1 Codice R\n\n# 1. Estrai il vettore completo dei valori k\nk_values &lt;- pareto_k_values(loo_res)\n\n# 2. Esplora la distribuzione\nsummary(k_values)\n#&gt;     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n#&gt; -0.00138 -0.00138 -0.00138  0.03905  0.09970  0.13340\n\n\nquantile(k_values, probs = c(0.25, 0.5, 0.75, 0.9))\n#&gt;      25%      50%      75%      90% \n#&gt; -0.00138 -0.00138  0.09970  0.13340\n\n\n# 3. Conta e calcola proporzioni per classi di soglia\ncounts &lt;- table(\n  good    = k_values &lt;= 0.5,\n  OK      = k_values &gt; 0.5 & k_values &lt;= 0.7,\n  problematic = k_values &gt; 0.7\n)\nprop.table(counts)\n#&gt; , , problematic = FALSE\n#&gt; \n#&gt;       OK\n#&gt; good   FALSE\n#&gt;   TRUE     1",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#riflessioni-conclusive",
    "href": "chapters/mcmc/04_stan_diagnostics.html#riflessioni-conclusive",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come gli strumenti diagnostici costituiscano una parte imprescindibile del lavoro con i metodi MCMC. Ogni parametro stimato, infatti, non è soltanto un numero, ma il risultato di un processo di campionamento che va attentamente valutato prima di trarne conclusioni sostantive.\nIl percorso di verifica inizia con i controlli di base: l’assenza di transizioni divergenti, il buon completamento della fase di adattamento e la stabilità delle catene nei grafici di tracciamento. Prosegue con l’analisi dell’autocorrelazione, della dimensione effettiva del campione e delle statistiche sintetiche come \\(\\hat{R}\\) e l’errore standard di Monte Carlo. Nei modelli HMC/NUTS entrano in gioco anche indicatori specifici, come la BFMI e il parametro \\(\\kappa\\) quando si utilizzano tecniche di validazione predittiva.\nQuando questi strumenti segnalano problemi, la risposta non consiste in un’unica strategia ma in un lavoro di raffinamento: prolungare il campionamento, rivedere le parametrizzazioni, ripensare le distribuzioni a priori o intervenire sulle impostazioni dell’algoritmo. Ogni correzione ha lo scopo di migliorare la qualità dell’esplorazione e, con essa, l’affidabilità delle stime.\nNella comunicazione dei risultati è buona pratica riportare in modo trasparente non solo le stime dei parametri, ma anche i principali indici diagnostici, insieme a una descrizione delle eventuali difficoltà incontrate e delle soluzioni adottate. Questo non solo rafforza la credibilità del lavoro, ma contribuisce alla riproducibilità, che è il cuore del metodo scientifico.\nIl processo di tuning può dirsi concluso quando le catene risultano stabili e sovrapposte, \\(\\hat{R}\\) è prossimo a 1 per tutti i parametri di interesse, l’MCSE è contenuto, e gli altri indicatori non mostrano criticità. In quel momento possiamo avere fiducia che le inferenze siano solide e che il modello abbia catturato in modo adeguato la struttura dei dati.\nIn definitiva, la diagnostica MCMC è un passaggio necessario: dedicare tempo a questi controlli permette di ottenere analisi più robuste e affidabili. Meglio un modello semplice ma ben diagnosticato, che uno complesso e affascinante, ma sostenuto da catene instabili e inferenze fragili.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] coda_0.19-4.1         insight_1.4.2         cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [82] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#bibliografia",
    "href": "chapters/mcmc/04_stan_diagnostics.html#bibliografia",
    "title": "14  Diagnostica delle catene markoviane",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMartin, O. A., Kumar, R., & Lao, J. (2022). Bayesian Modeling and Computation in Python. CRC Press.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_mcmc_prediction.html",
    "href": "chapters/mcmc/05_mcmc_prediction.html",
    "title": "15  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "",
    "text": "Introduzione\nQuando costruiamo un modello statistico, possiamo rivolgere lo sguardo in due direzioni diverse. Da un lato ci chiediamo che cosa i dati ci dicano sui parametri, ovvero qual è la distribuzione a posteriori che sintetizza la conoscenza aggiornata dopo aver osservato l’evidenza empirica. Dall’altro, possiamo domandarci che cosa il modello ci permette di prevedere riguardo a nuove osservazioni, cioè quale forma assume la distribuzione predittiva a posteriori.\nNella pratica psicologica applicata, è proprio questa seconda prospettiva a rivelarsi spesso decisiva. Lo scopo di un modello non è soltanto stimare parametri astratti, ma soprattutto fornire previsioni su come potrebbero presentarsi nuovi dati e, in particolare, mostrarci se le strutture probabilistiche che abbiamo ipotizzato sono in grado di generare esiti simili a quelli che riscontriamo nella realtà. Da qui derivano due strategie complementari. I controlli predittivi a priori consistono nel generare dati simulati prima ancora di osservare un singolo dato reale, utilizzando soltanto le assunzioni codificate nei prior. Se gli scenari prodotti appaiono manifestamente implausibili, la difficoltà non risiede nei dati, ma nelle ipotesi di partenza. I controlli predittivi a posteriori, invece, vengono effettuati dopo avere osservato i dati: a partire dalla distribuzione aggiornata dei parametri, simuliamo nuove repliche dei dati stessi e le confrontiamo con quelli reali. In questo modo verifichiamo se il modello, una volta informato dall’evidenza, è in grado di riprodurre in maniera plausibile le caratteristiche fondamentali del fenomeno studiato (Gelman et al., 2013; Johnson et al., 2022; McElreath, 2020).\nNel capitolo che segue mostreremo come realizzare operativamente questi controlli con cmdstanr. L’intento non è quello di introdurre nuova teoria, ma di acquisire familiarità con una procedura che diventerà abituale: generare dati simulati dal modello, confrontarli visivamente con i dati osservati e valutare, in modo intuitivo ma rigoroso, la coerenza complessiva delle nostre ipotesi modellistiche.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_mcmc_prediction.html#introduzione",
    "href": "chapters/mcmc/05_mcmc_prediction.html#introduzione",
    "title": "15  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "",
    "text": "Preparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; source()\n\n# Carichiamo i pacchetti necessari\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, insight, bayesplot, ggplot2)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_mcmc_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "href": "chapters/mcmc/05_mcmc_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "title": "15  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "\n15.1 La distribuzione predittiva a posteriori",
    "text": "15.1 La distribuzione predittiva a posteriori\nI controlli predittivi a posteriori costituiscono uno degli strumenti più efficaci per valutare la qualità di un modello bayesiano. La loro logica è semplice ma potente: se il modello è adeguato, allora i dati generati a partire dai parametri posteriori dovrebbero assomigliare, nelle loro caratteristiche essenziali, ai dati effettivamente osservati.\nIl procedimento si articola in tre passaggi concettuali. In primo luogo, estraiamo campioni dei parametri dalla distribuzione a posteriori, ossia da quella distribuzione che riflette ciò che sappiamo dei parametri dopo aver osservato i dati. In secondo luogo, per ciascun campione generiamo un dataset fittizio, simulato secondo il meccanismo del modello. Infine, confrontiamo i dati simulati con quelli reali, verificando fino a che punto le repliche prodotte dal modello sono coerenti con le osservazioni empiriche.\nDal punto di vista formale, la distribuzione predittiva a posteriori si scrive come\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta ,\n\\] dove \\(\\theta\\) rappresenta i parametri del modello, \\(y\\) i dati osservati e \\(\\tilde{y}\\) i dati replicati. Nella pratica, questa integrazione viene approssimata attraverso la simulazione Monte Carlo: si campionano valori \\(\\theta^{(s)}\\) dalla distribuzione posteriore e, per ciascuno di essi, si genera una replica \\(\\tilde{y}^{(s)}\\) secondo il modello. Il risultato è una collezione di dataset simulati che possono essere messi a confronto diretto con i dati osservati.\nL’importanza di questo strumento risiede nel fatto che esso consente di valutare il modello non soltanto in termini di stima dei parametri, ma in termini di capacità generativa. In altri termini, un modello può produrre stime dei parametri apparentemente ragionevoli e tuttavia rivelarsi inadeguato quando si tratta di riprodurre la variabilità o la struttura dei dati. I controlli predittivi a posteriori ci permettono di rilevare queste discrepanze, guidandoci verso una revisione delle assunzioni modellistiche quando necessario.\n\n15.1.1 Esempio: il modello normale–normale\nPer comprendere in maniera concreta il funzionamento dei controlli predittivi, è utile partire da un caso estremamente semplice, ma didatticamente chiaro: il modello normale–normale. Immaginiamo di voler stimare l’altezza media di una popolazione. Decidiamo di descrivere la nostra incertezza a priori assumendo che la media \\(\\mu\\) segua una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\tau_0^2\\). Gli individui osservati, invece, sono considerati come realizzazioni di una distribuzione normale centrata su \\(\\mu\\) e con varianza nota \\(\\sigma^2\\).\nFormalmente, il modello può essere espresso così:\n\\[\n\\mu \\sim \\mathcal{N}(\\mu_0, \\tau_0^2), \\qquad\ny_i \\sim \\mathcal{N}(\\mu, \\sigma^2).\n\\]\nIn questo contesto, la distribuzione predittiva a posteriori per una nuova osservazione \\(\\tilde{y}\\) assume la forma\n\\[\n\\tilde{y} \\mid Y \\sim \\mathcal{N}\\!\\big(\\mu_n, \\; \\tau_n^2 + \\sigma^2 \\big),\n\\] dove \\(\\mu_n\\) e \\(\\tau_n^2\\) rappresentano rispettivamente la media e la varianza della distribuzione a posteriori di \\(\\mu\\).\nQuesta espressione mostra che la nuova osservazione attesa non dipende soltanto dalla varianza campionaria, ma anche dall’incertezza residua sulla stima della media. Tuttavia, il punto cruciale non è tanto la formula in sé, quanto la possibilità di realizzare simulazioni dirette. Grazie a esse possiamo generare dati fittizi dal modello e confrontarli con i dati reali, verificando in modo intuitivo se la nostra rappresentazione probabilistica è in grado di cogliere i tratti caratteristici del fenomeno osservato.\n\n15.1.2 Implementazione con Stan\nPer tradurre queste idee in pratica, costruiamo un semplice modello in Stan, che chiameremo normal_pred.stan. L’obiettivo è duplice: da un lato vogliamo simulare dati a partire soltanto dalle assunzioni iniziali, quindi senza alcuna informazione empirica; dall’altro desideriamo generare dati replicati dopo aver aggiornato le nostre credenze con i dati osservati. In altre parole, lo stesso modello può essere usato sia per i controlli a priori sia per quelli a posteriori, a seconda di come impostiamo i dati di input.\nIl codice Stan è strutturato in modo da riflettere questa distinzione. Nel blocco data specifichiamo il numero di osservazioni, il vettore dei dati (che può anche essere ignorato in caso di prior predictive), i parametri del prior e un indicatore logico (prior_only) che decide se utilizzare o meno i dati osservati. Nel blocco parameters dichiariamo la media \\(\\mu\\), mentre nel blocco model definiamo il prior e, se richiesto, la verosimiglianza dei dati osservati. Infine, nel blocco generated quantities generiamo una nuova osservazione simulata, che rappresenta la replica dei dati secondo il modello.\nQuesto approccio, apparentemente minimale, è estremamente utile in ottica didattica: consente di vedere chiaramente come cambiano le simulazioni se utilizziamo soltanto le ipotesi iniziali oppure se lasciamo che siano i dati a informare la distribuzione dei parametri. In entrambi i casi, il cuore del procedimento resta invariato: generare dati dal modello e metterli a confronto con ciò che abbiamo osservato nella realtà.\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;\n  real mu0;\n  real&lt;lower=0&gt; tau0;\n  real&lt;lower=0&gt; sigma;\n  int&lt;lower=0,upper=1&gt; prior_only;\n}\nparameters {\n  real mu;\n}\nmodel {\n  mu ~ normal(mu0, tau0);          // prior\n  if (prior_only == 0)\n    y ~ normal(mu, sigma);         // likelihood (solo se usiamo i dati)\n}\ngenerated quantities {\n  real y_rep;\n  y_rep = normal_rng(mu, sigma);   // generiamo una nuova osservazione\n}\n\n15.1.3 Codice R\nDopo aver definito il modello in Stan, possiamo passare alla sua applicazione concreta in R. Immaginiamo di simulare un campione di cento altezze, con media pari a 170 centimetri e deviazione standard di 10. Questi dati fungeranno da base per verificare il comportamento del nostro modello.\nPrepariamo dunque la lista dei dati da passare a Stan. Oltre al vettore delle osservazioni, specifichiamo i parametri del prior: una media a priori di 175 centimetri, una deviazione standard a priori di 5 e una deviazione standard nota dei dati pari a 10. Infine, fissiamo il valore dell’indicatore prior_only a zero, in modo da utilizzare effettivamente i dati osservati e non limitarci a una simulazione puramente a priori.\nA questo punto possiamo compilare il modello e lanciare la procedura di campionamento. Con cmdstanr il flusso di lavoro è lineare: si richiama la funzione cmdstan_model() indicando il file Stan e poi si esegue $sample() con i dati appena preparati. Il risultato è un oggetto che contiene i campioni dalla distribuzione a posteriori dei parametri e le repliche dei dati, pronto per essere analizzato e visualizzato.\nQuesto passaggio segna il momento in cui il modello teorico prende vita: da semplici equazioni passiamo a un insieme di simulazioni concrete, attraverso cui possiamo verificare se le assunzioni di partenza riescono a tradursi in previsioni compatibili con i dati empirici.\n\nN &lt;- 100\ny &lt;- rnorm(N, mean = 170, sd = 10)\n\nstan_data &lt;- list(\n  N = N, y = y,\n  mu0 = 175, tau0 = 5, sigma = 10,\n  prior_only = 0\n)\n\nmod &lt;- cmdstan_model(here::here(\"stan\", \"normal_pred.stan\"))\nfit &lt;- mod$sample(data = stan_data, chains = 4, iter_sampling = 1000, refresh = 0)\n\n\n15.1.4 Visualizzazione: Posterior Predictive Checks\nUna volta ottenuti i campioni posteriori, possiamo verificare se il modello è in grado di generare dati “verosimili” rispetto a quelli osservati. L’idea operativa è semplice: per ciascun draw dei parametri dal posteriore, il modello produce una replica dell’intero dataset; mettendo a confronto molte repliche con i dati reali, giudichiamo la coerenza tra ipotesi e fenomeno.\nPer usare le funzioni ppc_*() di bayesplot, è essenziale che Stan restituisca, ad ogni draw, un vettore di repliche lungo N (una per ciascuna osservazione). In termini Stan, in generated quantities deve esserci qualcosa come vector[N] y_rep;. Se nel tuo file hai definito un solo scalare (ad esempio real y_rep;), le funzioni ppc_*() non avranno la struttura attesa: occorre quindi che il modello generi tante repliche quante sono le osservazioni. Con questa premessa, possiamo estrarre le repliche e procedere ai controlli grafici.\nNel nostro esempio, estraiamo yrep dall’oggetto fit (ottenuto con cmdstanr) in forma di matrice. Ogni riga rappresenta un dataset replicato per intero, ogni colonna corrisponde a una delle N osservazioni originarie. Se hai quattro catene e mille iterazioni utili per catena, otterrai circa 4000 righe.\n\nyrep &lt;- fit$draws(\"y_rep\", format = \"matrix\")\n\nPer un dataset con N = 100 osservazioni e S = 4000 repliche, yrep avrà dimensioni:\n\ndim(yrep)  # [4000, 100]\n#&gt; [1] 4000  100\n\nQuesta struttura [S, N] è quella richiesta da bayesplot. Le colonne identificano le posizioni dei dati originali; le righe sono interi dataset “fittizi” generati dal modello ai diversi draw posteriori. Con questa organizzazione, ogni grafico PPC può confrontare in modo coerente osservazioni e repliche.\nUn primo controllo molto informale, ma spesso rivelatore, è la sovrapposizione delle densità: tracciamo la densità empirica dei dati osservati e la confrontiamo con un gruppo di densità simulate dalle repliche. Per evitare un eccesso di linee, usiamo solo le prime cinquanta repliche; il numero è arbitrario, ma sufficiente per far emergere eventuali discrepanze grossolane.\n\nppc_dens_overlay(y, yrep[1:50, ])\n\n\n\n\n\n\n\nNel grafico, la linea scura rappresenta la distribuzione empirica di y, mentre le linee più chiare sono le densità delle repliche simulate. Se il modello è ragionevole, le densità simulate “abbracciano” quella osservata: non devono coincidere in ogni dettaglio, ma ne devono riprodurre posizione, dispersione e forma generale. Se, al contrario, tutte o quasi tutte le repliche risultano più strette, più larghe, o sistematicamente spostate, il modello sta fallendo nel cogliere un tratto saliente della distribuzione.\nPossiamo poi rivolgerci a controlli più mirati su statistiche riassuntive. Ad esempio, verificare se la media dei dati simulati è compatibile con la media osservata è un test di coerenza di base sulla tendenza centrale. bayesplot calcola la statistica su ciascuna replica e ne mostra la distribuzione, mettendola accanto al valore osservato:\n\nppc_stat(y, yrep, stat = \"mean\")\n\n\n\n\n\n\n\nSe il punto corrispondente alla media osservata si colloca in un’area plausibile della distribuzione delle medie simulate (ad esempio vicino al centro o comunque non in coda estrema), il modello non sta introducendo un bias evidente sulla posizione. Se invece il valore osservato cade regolarmente nelle code, il modello tende a sovra- o sotto-stimare la media.\nUn controllo complementare riguarda la variabilità puntuale: gli intervalli predittivi per ciascuna osservazione ci dicono se la dispersione generata dal modello è compatibile con l’ampiezza delle fluttuazioni empiriche. Il grafico seguente visualizza, per le prime cento osservazioni, gli intervalli credibili delle repliche e sovrappone i corrispondenti valori osservati:\n\nppc_intervals(y, yrep[1:100, ])\n\n\n\n\n\n\n\nQuando la maggior parte dei punti osservati cade all’interno delle bande predittive, possiamo dire che la dispersione generata dal modello è adeguata; se molti punti si collocano sistematicamente fuori, o tutti molto vicino al bordo, il modello sta sottostimando o sovrastimando l’incertezza. Questo tipo di grafico è particolarmente utile quando sospetti eteroschedasticità o quando vuoi individuare regioni del dominio in cui il modello fallisce più spesso.\nL’interpretazione di questi controlli è sempre di natura generativa: non stiamo testando l’importanza di un coefficiente, ma verificando che l’intero meccanismo probabilistico sia capace di riprodurre gli aspetti essenziali dei dati. Se la forma delle distribuzioni simulate è incompatibile con quella osservata, se le statistiche riassuntive risultano sistematicamente spostate, o se le bande predittive non coprono i punti osservati in modo plausibile, la conclusione non è “il modello è falso” in senso assoluto, ma “il modello, così specificato, non genera dati con le caratteristiche che vediamo”. In quel caso, la diagnosi va ricercata nelle assunzioni: prior troppo stretti o troppo larghi, verosimiglianza mal specificata (ad esempio una normale con code troppo leggere dove servirebbe una t-student), varianza fissata quando dovrebbe essere stimata, o una struttura mancante (trend, effetti gerarchici, dipendenze nel tempo) che i dati sembrano richiedere.\nIn sintesi, i PPC spostano l’attenzione dalla stima dei parametri alla capacità predittiva del modello come generatore di dati. È questa la domanda che conta quando il modello deve essere usato per comprendere e prevedere fenomeni psicologici: il processo probabilistico che abbiamo ipotizzato “sa fare” dati che assomigliano, per struttura e variabilità, a quelli del mondo reale?",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_mcmc_prediction.html#distribuzione-predittiva-a-priori",
    "href": "chapters/mcmc/05_mcmc_prediction.html#distribuzione-predittiva-a-priori",
    "title": "15  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "\n15.2 Distribuzione predittiva a priori",
    "text": "15.2 Distribuzione predittiva a priori\nPrima ancora di raccogliere un singolo dato, possiamo chiederci che tipo di osservazioni ci aspetteremmo se il mondo fosse davvero descritto dalle nostre assunzioni iniziali. Questa è l’idea dei controlli predittivi a priori: generare dati fittizi soltanto dai prior, senza alcuna informazione empirica, e verificare se questi scenari risultano plausibili alla luce della nostra conoscenza di dominio.\nL’obiettivo non è predire con esattezza i dati reali, ma controllare che i prior non ci conducano in regioni assurde o incoerenti. Se, per esempio, i dati simulati suggerissero altezze negative, valori esageratamente grandi o dispersioni completamente fuori scala, potremmo concludere che il problema non sta nei dati, ma nelle nostre ipotesi iniziali.\nIn termini pratici, questo controllo si traduce in un procedimento molto semplice: campioniamo i parametri direttamente dalla distribuzione a priori e li utilizziamo per generare repliche di dati sintetici attraverso lo stesso meccanismo probabilistico del modello. Così facendo, otteniamo un insieme di dataset simulati che possono essere confrontati con ciò che consideriamo realistico in quel contesto.\n\n15.2.1 Implementazione in Stan\nPer i controlli a priori, il file Stan può essere ridotto all’essenziale. Non servono blocchi di parametri o di modello: i parametri vengono campionati direttamente nel blocco generated quantities tramite funzioni _rng. L’esecuzione avviene con l’opzione fixed_param=TRUE, che dice a Stan di ignorare il sampling MCMC e di limitarsi a produrre simulazioni casuali.\n// file: normal_prior_predictive.stan\ndata {\n  int&lt;lower=0&gt; N;          // dimensione della replica che vuoi generare\n  vector[N] y;             // ignorato (può essere numeric(0) o un vettore qualsiasi)\n  real mu0;                // media a priori di mu\n  real&lt;lower=0&gt; tau0;      // dev. standard a priori di mu\n  real&lt;lower=0&gt; sigma;     // dev. standard nota dei dati\n}\ngenerated quantities {\n  real mu_prior;           // un draw del parametro dal prior\n  vector[N] y_rep;         // una replica completa (lunghezza N)\n\n  mu_prior = normal_rng(mu0, tau0);\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu_prior, sigma);\n  }\n}\nIn questo modo, ogni draw produce un valore casuale del parametro \\(\\mu\\) dal prior e un dataset simulato di lunghezza N. È un’implementazione volutamente minimale, che mette in evidenza la logica del procedimento.\n\n15.2.2 Codice R\nPassiamo ora a R. Per semplicità, chiediamo di generare repliche di lunghezza N = 200. I dati reali non servono, quindi possiamo passare un vettore fittizio di zeri al posto di y.\n\nN &lt;- 200\nstan_data_prior &lt;- list(\n  N    = N,\n  y    = rep(0, N),  # ignorato\n  mu0  = 175,\n  tau0 = 5,\n  sigma= 10\n)\n\nCompiliamo quindi il modello e lanciamo il campionamento. Poiché abbiamo specificato fixed_param=TRUE, Stan non stimerà nulla, ma genererà soltanto simulazioni casuali a partire dai prior.\n\nmod_prior &lt;- cmdstan_model(here::here(\"stan\", \"normal_prior_predictive.stan\"))\n\nfit_prior &lt;- mod_prior$sample(\n  data = stan_data_prior,\n  chains = 4,\n  iter_sampling = 1000,\n  iter_warmup = 0,\n  fixed_param = TRUE,   # fondamentale per prior predictive\n  refresh = 0,\n  seed = 123\n)\n\n\n15.2.3 Analisi dei risultati\nIl risultato di questa simulazione è un insieme di repliche y_rep, organizzate in una matrice con una riga per ogni draw. Possiamo estrarle e metterle in un dataframe per un’ispezione grafica.\n\nyrep_mat &lt;- as_draws_matrix(fit_prior$draws(\"y_rep\"))\ndf_mc &lt;- data.frame(x = as.numeric(yrep_mat))  # vettore lungo S*N\n\nConfrontiamo ora la distribuzione empirica ottenuta via Monte Carlo con quella attesa dal calcolo analitico. Nel modello normale–normale, la deviazione standard della distribuzione predittiva a priori è data da\n\\[\n\\sqrt{\\tau_0^2 + \\sigma^2}.\n\\]\nCon i valori scelti (\\(\\tau_0 = 5\\), \\(\\sigma = 10\\)), otteniamo una deviazione standard predittiva di circa 11.18. Possiamo usare questa quantità per confrontare le code della distribuzione simulata con quelle della distribuzione normale teorica:\n\nsd_prior_pred &lt;- sqrt(5^2 + 10^2)   # ≈ 11.18034\n\np_bassa &lt;- pnorm(150, mean = 175, sd = sd_prior_pred)\np_alta  &lt;- 1 - pnorm(200, mean = 175, sd = sd_prior_pred)\nc(p_bassa = p_bassa, p_alta = p_alta)\n#&gt; p_bassa  p_alta \n#&gt;  0.0127  0.0127\n\nInfine, possiamo visualizzare la distribuzione simulata sovrapponendola alla curva normale analitica attesa:\n\nggplot(df_mc, aes(x = x)) +\n  geom_density() +\n  stat_function(fun = dnorm,\n                args = list(mean = 175, sd = sd_prior_pred),\n                linetype = 2) +\n  labs(x = \"y\", y = \"Densità\")\n\n\n\n\n\n\n\nIn questo grafico, la curva tratteggiata rappresenta la distribuzione normale teorica corrispondente ai prior, mentre la curva continua mostra la distribuzione empirica ricavata dalle simulazioni Monte Carlo. La sovrapposizione fra le due conferma che il procedimento sta funzionando come previsto.\n\n15.2.4 Come interpretare\nL’interpretazione dei controlli a priori segue una logica molto semplice: ci chiediamo se i dati simulati abbiano senso rispetto alla nostra conoscenza del problema. Se le repliche risultano sistematicamente più alte o più basse del range plausibile, allora il prior sulla media \\(\\mu\\) è mal calibrato. Se la variabilità appare eccessiva o troppo limitata, è necessario rivedere l’ampiezza del prior. L’obiettivo non è vincolare il modello a produrre dati “giusti”, ma evitare assunzioni così irrealistiche da rendere il modello inutilizzabile già prima di osservare i dati.\nIn breve, il controllo predittivo a priori è un test di buon senso: ci permette di accorgerci subito se i nostri prior stanno spingendo il modello verso scenari che sappiamo non avere alcuna plausibilità empirica. Meglio scoprirlo a questo stadio, piuttosto che dopo aver speso tempo e risorse in stime inutilmente complicate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_mcmc_prediction.html#riflessioni-conclusive",
    "href": "chapters/mcmc/05_mcmc_prediction.html#riflessioni-conclusive",
    "title": "15  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nI controlli predittivi a priori e a posteriori rappresentano due momenti distinti, ma complementari, nel processo di modellizzazione bayesiana. La distribuzione predittiva a priori ci permette di verificare se le assunzioni iniziali, tradotte nei prior, siano ragionevoli rispetto alla conoscenza di dominio. In questa fase, la domanda cruciale non riguarda la corrispondenza con i dati osservati, ma la plausibilità degli scenari generati: i valori simulati hanno senso? si collocano in un range realistico? riflettono un ordine di grandezza compatibile con il fenomeno?\nLa distribuzione predittiva a posteriori, invece, mette alla prova la capacità del modello di riprodurre le caratteristiche essenziali dei dati una volta incorporata l’evidenza empirica. Qui non si tratta più soltanto di buon senso, ma di valutare se il meccanismo probabilistico che abbiamo ipotizzato sia in grado di generare dati che assomigliano, nelle loro proprietà fondamentali, a quelli osservati. Un modello che fallisce sistematicamente in questa prova mostra i limiti delle proprie assunzioni e segnala la necessità di una revisione.\nEntrambe le procedure si basano sulla stessa idea operativa: generare dati simulati dal modello e confrontarli, in modo visivo e quantitativo, con i dati reali o con ciò che sappiamo del fenomeno. Non si tratta di una validazione definitiva — nessun modello può dirsi “vero” o “falso” sulla base di un singolo controllo grafico — ma di un passaggio essenziale per diagnosticare incoerenze macroscopiche e per orientare la costruzione di modelli più adeguati.\nIn questo senso, i controlli predittivi non vanno intesi come un’aggiunta opzionale, ma come una fase imprescindibile del workflow bayesiano. Solo dopo aver verificato la plausibilità dei prior e la coerenza predittiva del modello, ha senso procedere verso forme più raffinate di confronto, come la stima dell’ELPD o la cross-validazione LOO. I controlli predittivi costituiscono quindi una sorta di “porta di ingresso” alla valutazione del modello: un controllo immediato, intuitivo e al tempo stesso rigoroso, capace di rivelare a colpo d’occhio se siamo sulla strada giusta o se le nostre assunzioni necessitano di essere riconsiderate.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [82] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_mcmc_prediction.html#bibliografia",
    "href": "chapters/mcmc/05_mcmc_prediction.html#bibliografia",
    "title": "15  Controlli predittivi bayesiani (a priori e a posteriori) con cmdstanr",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Controlli predittivi bayesiani (a priori e a posteriori) con `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio_stan.html",
    "href": "chapters/mcmc/06_stan_odds_ratio_stan.html",
    "title": "16  Analisi bayesiana dell’odds ratio",
    "section": "",
    "text": "Introduzione\nAbbiamo già incontrato il problema dell’inferenza sulle proporzioni quando abbiamo discusso il modello Beta–Binomiale. In quel contesto, grazie alla coniugazione, era stato possibile ottenere una soluzione analitica della distribuzione a posteriori. Abbiamo anche visto come la stessa logica potesse essere approssimata con una griglia, rendendo trasparente la costruzione della distribuzione.\nOra vogliamo compiere un passo ulteriore. Nei capitoli precedenti abbiamo introdotto Stan come strumento generale per l’inferenza bayesiana tramite MCMC. È arrivato il momento di metterlo in pratica, partendo da un esempio che colleghi quanto già appreso con le potenzialità di questo nuovo ambiente: l’odds ratio.\nL’odds ratio è una misura largamente utilizzata nelle scienze sociali e psicologiche. Esprime quanto la probabilità di un certo esito differisca tra due gruppi. Ad esempio, può essere usato per quantificare se la probabilità di successo in un compito sperimentale sia maggiore in un gruppo sperimentale rispetto a un gruppo di controllo.\nQuesto esempio ha un duplice scopo. Da un lato, ci permette di vedere come tradurre in Stan un modello che conosciamo già, verificando che la logica bayesiana rimane invariata: si tratta sempre di combinare priori, verosimiglianza e dati per ottenere una distribuzione a posteriori. Dall’altro lato, ci offre un primo contatto concreto con la sintassi di Stan e con il modo in cui vengono eseguiti i campionamenti MCMC, che diventeranno il nostro strumento abituale per l’analisi di modelli più complessi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio_stan.html#introduzione",
    "href": "chapters/mcmc/06_stan_odds_ratio_stan.html#introduzione",
    "title": "16  Analisi bayesiana dell’odds ratio",
    "section": "",
    "text": "Panoramica del capitolo\n\nCome si definiscono probabilità, odds e odds ratio.\nCome si interpreta l’odds ratio in contesti psicologici.\n\nCome stimarlo in ottica bayesiana, implementando un modello in Stan.\n\nCome presentare i risultati con intervalli di credibilità.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nNozioni di base su Bernoulli/Binomiale, odds e odds ratio.\nConcetto di prior e posteriore.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, dplyr, tibble)\nconflicts_prefer(posterior::ess_bulk)\nconflicts_prefer(posterior::ess_tail)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio_stan.html#il-contesto-sperimentale",
    "href": "chapters/mcmc/06_stan_odds_ratio_stan.html#il-contesto-sperimentale",
    "title": "16  Analisi bayesiana dell’odds ratio",
    "section": "\n16.1 Il contesto sperimentale",
    "text": "16.1 Il contesto sperimentale\nPer introdurre l’analisi bayesiana dell’odds ratio, consideriamo il seguente esperimento. Nella prima metà del Novecento, Karl von Frisch si domandò se le api possedessero la visione dei colori. Per verificarlo, ideò una serie di esperimenti in cui le api potevano associare un colore a una ricompensa. Ispirandoci a una ricostruzione proposta da Hoffmann et al. (2022), possiamo immaginare una versione semplificata del disegno sperimentale:\n\n\nGruppo sperimentale: api addestrate ad associare un disco blu a una soluzione zuccherina.\n\nGruppo di controllo: api che non ricevono alcun addestramento.\n\nNella fase di test, la soluzione zuccherina viene rimossa, e si registra il numero di volte in cui le api si avvicinano al disco blu (evento critico).\nI risultati osservati sono riportati nella tabella seguente:\n\n\nGruppo\nSuccessi (scelta blu)\nTotale\n\n\n\nSperimentale\n130\n200\n\n\nControllo\n100\n200\n\n\n\nLa domanda di ricerca può essere così formulata: le api addestrate mostrano un odds maggiore di scegliere il disco blu rispetto alle api di controllo?\n\n16.1.1 Dalle probabilità agli odds\nLa probabilità di successo (scelta del blu) nel gruppo sperimentale è:\n\\[\np_1 = \\frac{130}{200} = 0.65.\n\\]\nI corrispondenti odds si calcolano come:\n\\[\n\\text{odds}_1 = \\frac{p_1}{1-p_1} = \\frac{0.65}{0.35} \\approx 1.86.\n\\]\nPer il gruppo di controllo:\n\\[\np_2 = \\frac{100}{200} = 0.50, \\quad \\text{odds}_2 = \\frac{0.50}{0.50} = 1.00.\n\\]\n\n16.1.2 Calcolo dell’odds ratio\nL’odds ratio (OR) confronta i due odds:\n\\[\n\\text{OR} = \\frac{\\text{odds}_1}{\\text{odds}_2} = \\frac{1.86}{1.00} \\approx 1.86.\n\\]\nInterpretazione: le api addestrate presentano odds circa 1.9 volte maggiori di scegliere il disco blu rispetto alle api non addestrate. Questo non implica che la loro probabilità sia raddoppiata, ma che il rapporto tra successi e insuccessi risulta quasi doppio.\nQuanto è affidabile questa stima? È a questo punto che l’approccio bayesiano mostra il suo valore: anziché limitarci a una stima puntuale, possiamo ottenere un’intera distribuzione a posteriori per l’OR, che esprime la nostra incertezza dopo aver osservato i dati.\n\n16.1.3 Approccio bayesiano\nNell’approccio frequentista, l’odds ratio viene stimato come rapporto tra stime puntuali, accompagnato da un intervallo di confidenza derivato da approssimazioni asintotiche. L’approccio bayesiano, al contrario, fornisce direttamente la distribuzione a posteriori dell’odds ratio, offrendo diversi vantaggi interpretativi:\n\n\nProbabilità diretta: possiamo calcolare la probabilità che l’OR sia maggiore di 1;\n\nValutazione di equivalenza: possiamo determinare la probabilità che l’OR ricada in un intervallo di equivalenza pratica (ROPE);\n\nIntervalli di credibilità: possiamo ottenere intervalli di credibilità esatti (ETI o HDI) senza ricorrere ad approssimazioni asintotiche.\n\nQuesto framework consente non solo una rappresentazione più intuitiva dei risultati, ma permette anche di rispondere direttamente a domande inferenziali in termini probabilistici. Ad esempio: qual è la probabilità che le api addestrate mostrino effettivamente una preferenza maggiore per il blu? O, più formalmente: qual è la probabilità che l’OR sia maggiore di 1?\n\n16.1.4 Relazione con la regressione logistica\nIl collegamento fondamentale emerge nell’ambito della regressione logistica. Modellando la probabilità di successo \\(p_i\\) mediante un modello logit:\n\\[\n\\text{logit}(p_i) = \\alpha + \\beta \\cdot x_i,\n\\] dove \\(x_i\\) è una variabile indicatrice (0 = gruppo di controllo, 1 = gruppo sperimentale), si ottiene che:\n\n\n\\(\\exp(\\beta)\\) corrisponde esattamente all’odds ratio tra il gruppo sperimentale e quello di controllo.\n\nCiò implica che la stima di un modello di regressione logistica binaria equivale alla stima dell’odds ratio, con il notevole vantaggio di poter estendere agevolmente il modello all’inclusione di ulteriori predittori, covariate o strutture gerarchiche.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio_stan.html#versione-con-modello-logistico",
    "href": "chapters/mcmc/06_stan_odds_ratio_stan.html#versione-con-modello-logistico",
    "title": "16  Analisi bayesiana dell’odds ratio",
    "section": "\n16.2 Versione con modello logistico",
    "text": "16.2 Versione con modello logistico\nI dati vengono rappresentati a livello individuale: ogni ape è codificata come 1 (ha scelto il blu) o 0 (non ha scelto il blu).\n\n# Dati individuali\ny &lt;- c(rep(1, 130), rep(0, 70),   # gruppo sperimentale: 130 successi, 70 insuccessi\n       rep(1, 100), rep(0, 100))  # gruppo di controllo: 100 successi, 100 insuccessi\nx &lt;- c(rep(1, 200), rep(0, 200))  # 1 = sperimentale, 0 = controllo\n\ndata_list &lt;- list(N = length(y), y = y, x = x)\nglimpse(data_list)\n#&gt; List of 3\n#&gt;  $ N: int 400\n#&gt;  $ y: num [1:400] 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ x: num [1:400] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n16.2.1 Specifica del modello in Stan\n\nstancode_or &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                  // numero totale di osservazioni\n  array[N] int&lt;lower=0,upper=1&gt; y; // esito binario (0/1)\n  vector[N] x;                     // variabile indicatrice del gruppo (0 = controllo, 1 = sperimentale)\n}\nparameters {\n  real alpha;    // intercetta (log-odds nel gruppo di controllo)\n  real beta;     // coefficiente (differenza in log-odds tra gruppo sperimentale e controllo)\n}\nmodel {\n  // Priors\n  alpha ~ normal(0, 5);\n  beta  ~ normal(0, 5);\n  \n  // Likelihood\n  y ~ bernoulli_logit(alpha + beta * x);\n}\ngenerated quantities {\n  real OR = exp(beta);  // odds ratio\n}\n\"\n\n\n16.2.1.1 Compilazione ed esecuzione del modello\n\nstanmod_or &lt;- cmdstanr::cmdstan_model(write_stan_file(stancode_or))\n\nfit_or &lt;- stanmod_or$sample(\n  data = data_list,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  seed = 123,\n  refresh = 0\n)\n\n\n16.2.1.2 Interpretazione dei risultati\nRiassunto dei parametri di interesse:\n\nprint(fit_or$summary(c(\"alpha\", \"beta\", \"OR\")), n = Inf)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    -0.004 -0.004 0.144 0.144 -0.240 0.232 1.001 5152.630 6997.882\n#&gt; 2 beta      0.628  0.626 0.208 0.208  0.288 0.970 1.000 5183.414 7043.458\n#&gt; 3 OR        1.914  1.870 0.403 0.386  1.333 2.638 1.000 5183.414 7043.458\n\n\n\nalpha: log-odds di successo nel gruppo di controllo\n\nbeta: differenza nei log-odds tra gruppo sperimentale e controllo\n\nOR: odds ratio (exp(beta))\n\nDistribuzione a posteriori dell’OR:\n\nposterior::summarise_draws(\n  fit_or$draws(\"OR\"),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n#&gt; # A tibble: 1 × 6\n#&gt;   variable  mean    sd `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 OR       1.914 0.403  1.254 1.870   2.816\n\nIl output mostra media, deviazione standard, mediana e intervallo di credibilità al 95% per l’odds ratio.\nVisualizzazione della distribuzione a posteriori:\n\nbayesplot::mcmc_hist(fit_or$draws(\"OR\")) +\n  xlab(\"Odds Ratio\") + ylab(\"Densità\")\n\n\n\n\n\n\n\n\nbayesplot::mcmc_areas(fit_or$draws(\"OR\"), prob = 0.95) +\n  xlab(\"Odds Ratio\")\n\n\n\n\n\n\n\nI grafici mostrano chiaramente che la distribuzione dell’odds ratio è concentrata su valori superiori a 1, con alta probabilità.\nInterpretazione: I risultati forniscono evidenza credibile che l’addestramento aumenta le probabilità che le api scelgano il disco blu rispetto al gruppo di controllo. La distribuzione a posteriori dell’OR indica che questo effetto è statisticamente credibile e praticamente significativo.\n\n16.2.1.3 Diagnostica essenziale\n\n# Indicatori numerici chiave: Rhat ~ 1, ESS adeguati\nposterior::summarize_draws(\n  fit_or$draws(c(\"alpha\",\"beta\",\"OR\")),\n  \"rhat\", \"ess_bulk\", \"ess_tail\"\n)\n#&gt; # A tibble: 3 × 4\n#&gt;   variable  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    1.001 5152.630 6997.882\n#&gt; 2 beta     1.000 5183.414 7043.458\n#&gt; 3 OR       1.000 5183.414 7043.458\n\n\n# Traceplot di controllo su OR\nbayesplot::mcmc_trace(fit_or$draws(\"OR\")) \n\n\n\n\n\n\n\nSe emergono problemi (Rhat &gt; 1.01, ESS basso, divergenze riportate in output), conviene aumentare iter_warmup/iter_sampling, alzare adapt_delta o, in ultima istanza, riconsiderare i prior se sono eccessivamente stretti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio_stan.html#versione-binomiale-con-prior-beta",
    "href": "chapters/mcmc/06_stan_odds_ratio_stan.html#versione-binomiale-con-prior-beta",
    "title": "16  Analisi bayesiana dell’odds ratio",
    "section": "\n16.3 Versione binomiale con prior Beta",
    "text": "16.3 Versione binomiale con prior Beta\nUn approccio alternativo alla stima dell’odds ratio consiste nel modellare separatamente le proporzioni di successo nei due gruppi utilizzando distribuzioni binomiali con prior Beta. Questo metodo risulta particolarmente intuitivo quando i dati sono naturalmente aggregabili in una tabella 2×2.\nL’odds ratio viene calcolato come trasformazione delle due probabilità stimate:\n\\[\n\\text{OR} = \\frac{\\theta_1/(1-\\theta_1)}{\\theta_2/(1-\\theta_2)} = \\exp\\left(\\operatorname{logit}(\\theta_1) - \\operatorname{logit}(\\theta_2)\\right)\n\\]\nQuesta formulazione offre una trasparenza didattica immediata: stimiamo separatamente le probabilità di successo nei due gruppi per poi derivare l’effetto di interesse. La scelta di prior Beta(2,2) per entrambi i parametri mantiene coerenza con le impostazioni del capitolo, utilizzando prior debolmente informative.\n\n16.3.1 Implementazione in Stan: modello Beta-Binomiale\n\nstancode_or_beta &lt;- \"\ndata {\n  int&lt;lower=0&gt; k1;  // numero di successi nel gruppo sperimentale\n  int&lt;lower=1&gt; n1;  // numero totale di prove nel gruppo sperimentale\n  int&lt;lower=0&gt; k2;  // numero di successi nel gruppo di controllo\n  int&lt;lower=1&gt; n2;  // numero totale di prove nel gruppo di controllo\n}\nparameters {\n  real&lt;lower=0,upper=1&gt; theta1;  // probabilità di successo nel gruppo sperimentale\n  real&lt;lower=0,upper=1&gt; theta2;  // probabilità di successo nel gruppo di controllo\n}\nmodel {\n  // Prior distributions\n  theta1 ~ beta(2, 2);\n  theta2 ~ beta(2, 2);\n  \n  // Likelihood\n  k1 ~ binomial(n1, theta1);\n  k2 ~ binomial(n2, theta2);\n}\ngenerated quantities {\n  real logOR = logit(theta1) - logit(theta2);  // log-odds ratio\n  real OR = exp(logOR);                        // odds ratio\n}\n\"\n\n\n# Dati aggregati per il modello binomiale\ndata_list_beta &lt;- list(\n  k1 = 130, n1 = 200,  # gruppo sperimentale: 130 successi su 200 prove\n  k2 = 100, n2 = 200   # gruppo di controllo: 100 successi su 200 prove\n)\n\n\n16.3.1.1 Compilazione ed esecuzione del modello\n\nstanmod_or_beta &lt;- cmdstanr::cmdstan_model(write_stan_file(stancode_or_beta))\n\nfit_or_beta &lt;- stanmod_or_beta$sample(\n  data = data_list_beta,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 123,\n  refresh = 0\n)\n\n\n16.3.1.2 Analisi comparativa dei risultati\nRiassunti posteriori per il modello Beta-Binomiale:\n\nposterior::summarise_draws(\n  fit_or_beta$draws(c(\"theta1\", \"theta2\", \"logOR\", \"OR\")),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n#&gt; # A tibble: 4 × 6\n#&gt;   variable  mean    sd `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 theta1   0.647 0.034  0.579 0.648   0.712\n#&gt; 2 theta2   0.500 0.035  0.432 0.500   0.569\n#&gt; 3 logOR    0.610 0.204  0.207 0.611   1.004\n#&gt; 4 OR       1.880 0.387  1.230 1.841   2.729\n\nConfronto degli intervalli di credibilità tra i due approcci:\n\nsumm_logit &lt;- posterior::summarise_draws(\n  fit_or$draws(\"OR\"),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\nsumm_beta &lt;- posterior::summarise_draws(\n  fit_or_beta$draws(\"OR\"),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n\nlist(Regressione_Logistica = summ_logit, Beta_Binomiale = summ_beta)\n#&gt; $Regressione_Logistica\n#&gt; # A tibble: 1 × 6\n#&gt;   variable  mean    sd `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 OR       1.914 0.403  1.254 1.870   2.816\n#&gt; \n#&gt; $Beta_Binomiale\n#&gt; # A tibble: 1 × 6\n#&gt;   variable  mean    sd `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 OR       1.880 0.387  1.230 1.841   2.729\n\nConfronto visivo delle distribuzioni posteriori:\n\nOR_logit &lt;- as.numeric(fit_or$draws(\"OR\"))\nOR_beta &lt;- as.numeric(fit_or_beta$draws(\"OR\"))\n\ntibble(\n  OR = c(OR_logit, OR_beta),\n  Modello = rep(c(\"Regressione Logistica\", \"Beta-Binomiale\"), \n                c(length(OR_logit), length(OR_beta)))\n) |&gt;\n  ggplot(aes(x = OR, fill = Modello)) +\n  geom_density(alpha = 0.4) +\n  labs(x = \"Odds Ratio\", y = \"Densità\")\n\n\n\n\n\n\n\nProbabilità a posteriori che l’OR sia maggiore di 1:\n\nc(\n  Regressione_Logistica = mean(OR_logit &gt; 1),\n  Beta_Binomiale = mean(OR_beta &gt; 1)\n)\n#&gt; Regressione_Logistica        Beta_Binomiale \n#&gt;                 0.999                 0.999",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio_stan.html#considerazioni-metodologiche",
    "href": "chapters/mcmc/06_stan_odds_ratio_stan.html#considerazioni-metodologiche",
    "title": "16  Analisi bayesiana dell’odds ratio",
    "section": "\n16.4 Considerazioni metodologiche",
    "text": "16.4 Considerazioni metodologiche\nI due approcci producono risultati sostanzialmente equivalenti, confermando la robustezza delle conclusioni inferenziali. La scelta tra le due specificazioni dipende da considerazioni pratiche e comunicative:\n\nRegressione logistica: Ideale per dati individuali e modelli che includono multiple covariate. Offre maggiore flessibilità per estensioni multivariate.\nModello Beta-Binomiale: Particolarmente adatto per dati aggregati in tabelle di contingenza. Risulta più intuitivo per comprendere il meccanismo di stima delle proporzioni sottostanti.\n\nEntrambi gli approcci conducono alle stesse conclusioni sostanziali riguardo all’effetto dell’addestramento sulla preferenza delle api per il disco blu, dimostrando la coerenza dei metodi bayesiani nella stima dell’odds ratio.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio_stan.html#riflessioni-conclusive",
    "href": "chapters/mcmc/06_stan_odds_ratio_stan.html#riflessioni-conclusive",
    "title": "16  Analisi bayesiana dell’odds ratio",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nQuesto capitolo ci ha mostrato come l’inferenza bayesiana sulle proporzioni, che inizialmente avevamo affrontato con soluzioni analitiche e metodi su griglia, possa essere espressa ed eseguita direttamente in Stan. L’uso dell’odds ratio come esempio ha evidenziato due aspetti fondamentali.\nPrimo, la continuità concettuale: Stan non cambia la logica dell’inferenza bayesiana. Il cuore rimane lo stesso – campionare dalla distribuzione a posteriori per descrivere la nostra incertezza sui parametri – ma la potenza computazionale consente di applicarlo a modelli più articolati senza dover ricorrere a soluzioni chiuse.\nSecondo, l’aspetto pratico: attraverso questo esempio abbiamo visto come Stan possa diventare uno strumento quotidiano per l’analisi dei dati psicologici, anche nei casi in cui i modelli sono relativamente semplici. In questo senso, l’odds ratio rappresenta un ponte: ci permette di acquisire familiarità con Stan su un terreno noto, preparandoci a utilizzarlo in contesti più complessi, come i modelli di Poisson o i modelli gerarchici.\nIn prospettiva, la lezione più importante di questo capitolo è che l’inferenza bayesiana non deve più essere limitata ai casi “risolvibili” a mano o con approssimazioni semplicistiche. Con Stan, la logica bayesiana diventa praticabile in modo sistematico e riproducibile, aprendo la strada a un uso più maturo e trasparente dei modelli statistici nella ricerca psicologica.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#&gt; [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [13] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] utf8_1.2.6            rmarkdown_2.29        ps_1.9.1             \n#&gt; [22] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [28] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [31] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [34] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [37] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [40] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [43] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [46] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [49] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [52] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [55] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [58] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [61] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [64] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [67] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [70] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [73] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [76] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [79] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [82] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [85] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio_stan.html#bibliografia",
    "href": "chapters/mcmc/06_stan_odds_ratio_stan.html#bibliografia",
    "title": "16  Analisi bayesiana dell’odds ratio",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoffmann, T., Hofman, A., & Wagenmakers, E.-J. (2022). Bayesian tests of two proportions: A tutorial with R and JASP. Methodology, 18(4), 239–277.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_two_means.html",
    "href": "chapters/mcmc/07_stan_two_means.html",
    "title": "17  Confrontare due medie",
    "section": "",
    "text": "Introduzione\nImmagina uno studio in cui confrontiamo il punteggio medio di affetto negativo settimanale tra un gruppo che segue un breve training di mindfulness e un gruppo di controllo. La domanda sostantiva non è “c’è qualche differenza?” ma “di quanto differiscono i gruppi e quanto siamo incerti su questa differenza?”. È questa la prospettiva che adottiamo qui: invece di ridurre il problema a un verdetto sì/no, stimiamo l’intera distribuzione a posteriori della differenza tra le medie e traduciamo tale distribuzione in affermazioni pratiche rilevanti per la psicologia.\nIn un confronto tra due gruppi, c’è anche un aspetto spesso trascurato ma cruciale: la variabilità. I due gruppi possono avere la stessa dispersione oppure no. Se, per esempio, il training riduce l’affetto negativo medio ma produce anche risposte più eterogenee (alcuni migliorano molto, altri poco), allora la differenza tra deviazioni standard è informativa tanto quanto la differenza tra medie. L’approccio bayesiano rende naturale stimare congiuntamente entrambe le quantità e la loro incertezza, offrendo un quadro più ricco di quello fornito dal t-test tradizionale (Kruschke, 2013).\nPer stabilizzare le stime e semplificare le scelte di prior, standardizziamo la variabile di esito \\(y\\) sull’intero campione (media 0, deviazione standard 1). La standardizzazione non altera le relazioni tra i gruppi, ma rende più trasparenti le ipotesi: a priori è ragionevole attendersi medie di gruppo non lontane da 0 e dispersioni dell’ordine dell’unità. Lavoreremo con due modelli semplici e didatticamente utili: un modello con varianza comune ai gruppi e un modello con varianze distinte. In entrambi useremo prior debolmente informative sulle medie (normali centrate in 0) e sulle deviazioni standard (esponenziali), coerenti con la variabile standardizzata.\nLa domanda metodologica non è quale ipotesi sia “vera”, ma quale modello predice meglio dati simili a quelli osservati mantenendo la massima parsimonia. Useremo quindi la densità predittiva logaritmica attesa (ELPD) stimata con PSIS-LOO per confrontare i due modelli: se il guadagno predittivo del modello più complesso (varianze distinte) è minimo rispetto alla sua incertezza, conviene preferire il modello con varianza comune; se invece il vantaggio è chiaro e stabile, scegliamo il modello più flessibile.\nIl cuore dell’analisi rimane comunque la distribuzione a posteriori della differenza tra le medie. È questa distribuzione che risponde alla domanda scientifica, ed è su di essa che riportiamo intervalli di credibilità e probabilità a posteriori di scenari di interesse (per esempio, la probabilità che la differenza sia inferiore a −0.2 SD, una soglia che potremmo considerare rilevante in termini clinici).\nRispetto al t-test di Student, l’approccio bayesiano offre tre vantaggi pratici per la ricerca psicologica. Primo, fornisce stima e incertezza di tutte le quantità rilevanti (differenza di medie, differenza di varianze, grandezza dell’effetto), invece di un unico p-value. Secondo, consente di valutare l’equivalenza pratica attraverso una region of practical equivalence (ROPE): se quasi tutta la posteriore ricade entro una piccola regione attorno a zero, possiamo accettare l’irrilevanza pratica dell’effetto, cosa che il t-test non permette in modo diretto. Terzo, l’impostazione è robusta ed estendibile: quando i dati mostrano code pesanti o outlier, possiamo descriverli con una distribuzione t e stimarne anche il grado di “normalità”, mantenendo una lettura sostantiva chiara delle differenze tra gruppi (Kruschke, 2013).\nIn sintesi, in questo capitolo useremo Stan per stimare due modelli semplici e confrontarli sul piano predittivo, ma terremo sempre lo sguardo sulle conclusioni sostantive: nel nostro esempio, “di quanto” il training modifica l’affetto negativo medio, “quanto” è plausibile una differenza nulla o trascurabile, e “come” cambia l’eterogeneità delle risposte tra i partecipanti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Confrontare due medie</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_two_means.html#introduzione",
    "href": "chapters/mcmc/07_stan_two_means.html#introduzione",
    "title": "17  Confrontare due medie",
    "section": "",
    "text": "Transizione al codice\nNei prossimi paragrafi genereremo un piccolo dataset simulato per il caso mindfulness vs controllo, standardizzeremo l’esito, specificheremo in Stan un modello con varianza comune e uno con varianze distinte, quindi confronteremo le due specificazioni con PSIS-LOO e riporteremo la posteriore della differenza tra le medie con intervallo di credibilità e, dove appropriato, una valutazione ROPE per l’equivalenza pratica. L’obiettivo didattico è duplice: dare un codice leggibile a chi non è esperto e mostrare come le scelte modellistiche si traducano in interpretazioni psicologiche chiare.\nPanoramica del capitolo\n\nComprendere il problema del confronto tra due medie in un’ottica bayesiana.\nMotivare la standardizzazione dei dati e la scelta di priors debolmente informative.\nImplementare in Stan un modello con varianza comune e uno con varianze distinte.\nValutare la capacità predittiva dei modelli attraverso PSIS-LOO.\nInterpretare la distribuzione a posteriori della differenza tra le medie e le verifiche predittive.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nNozioni di base su Bernoulli/Binomiale, odds e odds ratio.\nConcetto di prior e posteriore.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, dplyr, tibble, forcats)\nconflicts_prefer(posterior::ess_bulk)\nconflicts_prefer(posterior::ess_tail)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Confrontare due medie</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_two_means.html#codice-r",
    "href": "chapters/mcmc/07_stan_two_means.html#codice-r",
    "title": "17  Confrontare due medie",
    "section": "\n17.1 Codice R",
    "text": "17.1 Codice R\n\n# Simuliamo i dati di un piccolo studio psicologico\n# Gruppo A = controllo, Gruppo B = training mindfulness\n\nset.seed(123)  # per rendere i risultati riproducibili\n\nn_A &lt;- 80   # numero partecipanti controllo\nn_B &lt;- 90   # numero partecipanti training\n\n# Medie \"vere\" dei gruppi (in SD standardizzate)\ntrue_mean_A &lt;- 0.2   # controllo con affetto negativo leggermente più alto\ntrue_mean_B &lt;- -0.3   # training mindfulness riduce affetto negativo\n\n# Deviazioni standard \"vere\"\ntrue_sd_A &lt;- 1.0\ntrue_sd_B &lt;- 1.0   # prova a cambiare in 1.4 per simulare varianze diverse\n\n# Creiamo un data frame con le osservazioni\ndf &lt;- tibble(\n  score  = c(rnorm(n_A, true_mean_A, true_sd_A),\n             rnorm(n_B, true_mean_B, true_sd_B)),\n  group  = factor(c(rep(\"Controllo\", n_A), rep(\"Mindfulness\", n_B)))\n)\n\n# Standardizziamo la variabile di esito\ndf &lt;- df %&gt;%\n  mutate(\n    score_std = (score - mean(score)) / sd(score),\n    g = as.integer(group)   # Stan richiede indici numerici dei gruppi\n  )\n\n# Prepariamo la lista di dati per Stan\nstan_data &lt;- list(\n  N = nrow(df),             # numero totale osservazioni\n  J = 2L,                   # numero di gruppi\n  y = df$score_std,         # variabile risposta standardizzata\n  g = df$g                  # indice di gruppo\n)\n\nglimpse(stan_data)\n#&gt; List of 4\n#&gt;  $ N: int 170\n#&gt;  $ J: int 2\n#&gt;  $ y: num [1:170] -0.3016 0.0317 1.8369 0.3352 0.3945 ...\n#&gt;  $ g: int [1:170] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n17.1.1 Nota didattica\nIn questo esempio, la variabile score rappresenta il livello di affetto negativo. Abbiamo simulato una piccola differenza: in media, il gruppo mindfulness ha punteggi più bassi (cioè minore affetto negativo) rispetto al gruppo controllo. Standardizzando la variabile, lavoriamo sempre in “unità di deviazione standard”, semplificando l’interpretazione delle priors e delle stime.\n\n17.1.2 Differenza di medie e ROPE\nPrima ancora di stimare i modelli in Stan, possiamo calcolare la differenza empirica tra le medie e confrontarla con una regione di irrilevanza pratica (ROPE). Per esempio, supponiamo che differenze inferiori a 0.1 SD non abbiano rilevanza psicologica. Questo ci permette di introdurre un confronto diretto con il test t: il t-test risponde solo alla domanda “la differenza è zero?”, mentre l’approccio bayesiano ci consente di valutare “la differenza è psicologicamente importante?”.\n\n# Differenza empirica tra le medie\nmean_diff &lt;- mean(df$score_std[df$group == \"Mindfulness\"]) -\n             mean(df$score_std[df$group == \"Controllo\"])\n\nmean_diff\n#&gt; [1] -0.535\n\n# Definiamo una ROPE di ±0.1 SD\nrope_lower &lt;- -0.1\nrope_upper &lt;-  0.1\n\ncat(\"Differenza osservata =\", round(mean_diff, 3), \n    \" | ROPE = [\", rope_lower, \",\", rope_upper, \"]\\n\")\n#&gt; Differenza osservata = -0.535  | ROPE = [ -0.1 , 0.1 ]\n\nNaturalmente, la vera potenza del metodo bayesiano emergerà quando stimiamo la distribuzione a posteriori della differenza di medie. Allora potremo calcolare direttamente la probabilità a posteriori che la differenza ricada dentro o fuori dalla ROPE, ottenendo un’informazione più ricca e interpretabile rispetto al semplice p-value.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Confrontare due medie</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_two_means.html#modello-a-varianza-comune",
    "href": "chapters/mcmc/07_stan_two_means.html#modello-a-varianza-comune",
    "title": "17  Confrontare due medie",
    "section": "\n17.2 Modello a varianza comune",
    "text": "17.2 Modello a varianza comune\nL’ipotesi è che i due gruppi condividano la stessa dispersione attorno alle loro medie. Questa è spesso una buona approssimazione iniziale, riduce il numero di parametri e permette stime più stabili con campioni piccoli o moderati. Il punto centrale resta la differenza tra le medie: se il training mindfulness riduce l’affetto negativo, la media del gruppo “Mindfulness” sarà più bassa e la differenza “Mindfulness − Controllo” sarà negativa in unità di deviazione standard.\n\n# Salviamo il modello Stan con varianza comune\nstan_equal_var &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                      // numero di osservazioni\n  int&lt;lower=2&gt; J;                      // numero di gruppi (qui: 2)\n  vector[N] y;                         // esito standardizzato\n  array[N] int&lt;lower=1, upper=J&gt; g;    // indice di gruppo per ogni osservazione\n}\nparameters {\n  vector[J] mu;                        // medie dei due gruppi\n  real&lt;lower=0&gt; sigma;                 // deviazione standard comune\n}\nmodel {\n  // Priors debolmente informative, coerenti con y standardizzata\n  mu    ~ normal(0, 1.5);\n  sigma ~ exponential(1);\n\n  // Likelihood: ogni y appartiene al suo gruppo g[i]\n  for (i in 1:N)\n    y[i] ~ normal(mu[g[i]], sigma);\n}\ngenerated quantities {\n  vector[N] log_lik;                   // log-verosimiglianze per PSIS-LOO\n  vector[N] y_rep;                     // repliche per posterior predictive checks\n  real diff_mu;                        // differenza tra le medie (Gruppo 2 - Gruppo 1)\n\n  // calcolo log_lik e repliche\n  for (i in 1:N) {\n    log_lik[i] = normal_lpdf(y[i] | mu[g[i]], sigma);\n    y_rep[i]   = normal_rng(mu[g[i]], sigma);\n  }\n\n  // differenza di interesse sostantivo:\n  // attenzione: per coerenza didattica, assumiamo g=1 -&gt; Controllo, g=2 -&gt; Mindfulness\n  diff_mu = mu[2] - mu[1];\n}\n\"\n\n# Scrittura su disco e compilazione\nif (!dir.exists(here::here(\"stan\"))) dir.create(here::here(\"stan\"), recursive = TRUE)\nwriteLines(stan_equal_var, here::here(\"stan\", \"two_means_equal_var.stan\"))\n\nmod_eq &lt;- cmdstan_model(here::here(\"stan\", \"two_means_equal_var.stan\"))\n\n# Campionamento dalla posteriore\nfit_eq &lt;- mod_eq$sample(\n  data = stan_data,                    # creato nella sezione precedente\n  seed = 2025,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 1000,\n  refresh = 0\n)\n\nDopo l’esecuzione, verifichiamo a colpo d’occhio che i diagnostici principali siano buoni. Se R-hat è vicino a 1 e gli effective sample size sono adeguati, passiamo all’interpretazione. Usiamo direttamente le quantità generate nel blocco generated quantities, così lo studente vede continuità tra il modello e l’analisi a valle.\n\n# Differenza tra medie: estraiamo il vettore 'diff_mu'\ndiff_draws &lt;- fit_eq$draws(variables = \"diff_mu\", format = \"draws_matrix\")\n\n# Riassunto compatto della posteriore: media, sd e intervallo di credibilità al 95%\nq025 &lt;- function(x) posterior::quantile2(x, probs = 0.025)\nq975 &lt;- function(x) posterior::quantile2(x, probs = 0.975)\n\nposterior::summarize_draws(diff_draws, mean, sd, q025, q975)\n#&gt; # A tibble: 1 × 5\n#&gt;   variable   mean    sd   q2.5  q97.5\n#&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 diff_mu  -0.536 0.148 -0.817 -0.243\n\nL’oggetto diff_mu è la quantità sostantiva principale. Se nel nostro esempio è negativo, indica che il gruppo mindfulness ha, in media, affetto negativo più basso del controllo. Per rendere più esplicito il legame con l’interpretazione psicologica, calcoliamo la probabilità a posteriori che la differenza sia clinicamente rilevante secondo una ROPE scelta dal ricercatore. Per esemplificare, usiamo ±0.1 SD come regione di irrilevanza pratica; adattare questa soglia al contesto è parte del lavoro scientifico.\n\n# Calcolo ROPE: probabilità a posteriori dentro/fuori la regione\nrope_lower &lt;- -0.1\nrope_upper &lt;-  0.1\n\ndiff_vec &lt;- as.numeric(diff_draws[, \"diff_mu\"])\np_in_rope  &lt;- mean(diff_vec &gt; rope_lower & diff_vec &lt; rope_upper)\np_below    &lt;- mean(diff_vec &lt; rope_lower)\np_above    &lt;- mean(diff_vec &gt; rope_upper)\n\ntibble(\n  `P(diff in ROPE)`  = p_in_rope,\n  `P(diff &lt; lower)`  = p_below,\n  `P(diff &gt; upper)`  = p_above\n)\n#&gt; # A tibble: 1 × 3\n#&gt;   `P(diff in ROPE)` `P(diff &lt; lower)` `P(diff &gt; upper)`\n#&gt;               &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1            0.0025             0.998                 0\n\nQueste probabilità mostrano qualcosa che il t-test non fornisce: non solo se la differenza è “diversa da zero”, ma se è trascurabile, peggiorativa o migliorativa oltre una soglia ritenuta rilevante. In un report didattico, affiancherei a queste quantità un confronto predittivo e una verifica grafica della coerenza del modello con i dati.\nA questo punto abbiamo tutto ciò che serve per la lettura sostantiva: una distribuzione a posteriori della differenza tra le medie con intervallo di credibilità, una probabilità a posteriori di effetti rilevanti o trascurabili e un controllo predittivo che ci dice se il modello è in grado di generare dati verosimili. Nel passaggio successivo introdurremo il modello con varianze distinte e useremo PSIS-LOO per verificare se l’aumento di complessità offre un miglioramento predittivo stabile; se non lo offre, resteremo sul modello parsimonioso a varianza comune, senza perdere nulla sul piano interpretativo centrale.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Confrontare due medie</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_two_means.html#modello-a-varianze-distinte",
    "href": "chapters/mcmc/07_stan_two_means.html#modello-a-varianze-distinte",
    "title": "17  Confrontare due medie",
    "section": "\n17.3 Modello a varianze distinte",
    "text": "17.3 Modello a varianze distinte\nL’ipotesi qui è che i due gruppi possano avere eterogeneità diversa: ad esempio, il training di mindfulness potrebbe ridurre l’affetto negativo in media, ma con risposte più variabili tra i partecipanti rispetto al controllo. Stimiamo quindi \\(\\mu_1,\\mu_2\\) e \\(\\sigma_1,\\sigma_2\\). Come prima, lavoriamo su dati standardizzati: priors mu ~ Normal(0, 1.5) e sigma ~ Exponential(1).\n\n# Modello Stan: varianze distinte\nstan_unequal_var &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                      // numero di osservazioni\n  int&lt;lower=2&gt; J;                      // numero di gruppi (qui: 2)\n  vector[N] y;                         // esito standardizzato\n  array[N] int&lt;lower=1, upper=J&gt; g;    // indice di gruppo\n}\nparameters {\n  vector[J] mu;                        // medie per gruppo\n  vector&lt;lower=0&gt;[J] sigma;            // sd specifica di gruppo\n}\nmodel {\n  // Priors debolmente informative\n  mu    ~ normal(0, 1.5);\n  sigma ~ exponential(1);\n\n  // Likelihood con sd per gruppo\n  for (i in 1:N)\n    y[i] ~ normal(mu[g[i]], sigma[g[i]]);\n}\ngenerated quantities {\n  vector[N] log_lik;                   // per PSIS-LOO\n  vector[N] y_rep;                     // posterior predictive checks\n  real diff_mu;                        // mu[2] - mu[1], Mindfulness - Controllo\n  real diff_sigma;                     // sigma[2] - sigma[1]\n\n  for (i in 1:N) {\n    log_lik[i] = normal_lpdf(y[i] | mu[g[i]], sigma[g[i]]);\n    y_rep[i]   = normal_rng(mu[g[i]], sigma[g[i]]);\n  }\n\n  diff_mu    = mu[2]    - mu[1];\n  diff_sigma = sigma[2] - sigma[1];\n}\n\"\n\n# Scrittura su disco e compilazione\nif (!dir.exists(here::here(\"stan\"))) dir.create(here::here(\"stan\"), recursive = TRUE)\nwriteLines(stan_unequal_var, here::here(\"stan\", \"two_means_unequal_var.stan\"))\n\nmod_neq &lt;- cmdstan_model(here::here(\"stan\", \"two_means_unequal_var.stan\"))\n\n# Campionamento\nfit_neq &lt;- mod_neq$sample(\n  data = stan_data,    # come definito nella sezione precedente\n  seed = 2025,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 1000,\n  refresh = 0\n)\n\n\n17.3.1 Lettura sostantiva dei parametri\nCome prima, l’oggetto chiave è diff_mu = mu[2] − mu[1] (Mindfulness − Controllo). Qui però abbiamo anche diff_sigma = sigma[2] − sigma[1], utile per capire se il training modifica l’eterogeneità delle risposte.\n\n# Estraiamo le quantità principali\nneq_draws_mu     &lt;- fit_neq$draws(variables = c(\"mu[1]\", \"mu[2]\", \"diff_mu\"), format = \"draws_matrix\")\nneq_draws_sigma  &lt;- fit_neq$draws(variables = c(\"sigma[1]\", \"sigma[2]\", \"diff_sigma\"), format = \"draws_matrix\")\n\nq025 &lt;- function(x) posterior::quantile2(x, probs = 0.025)\nq975 &lt;- function(x) posterior::quantile2(x, probs = 0.975)\n\n# Riassunti posteriori\nposterior::summarize_draws(neq_draws_mu,    mean, sd, q025, q975)\n#&gt; # A tibble: 3 × 5\n#&gt;   variable   mean    sd   q2.5  q97.5\n#&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 mu[1]     0.282 0.102  0.082  0.483\n#&gt; 2 mu[2]    -0.254 0.108 -0.461 -0.041\n#&gt; 3 diff_mu  -0.536 0.148 -0.826 -0.249\n\n\nposterior::summarize_draws(neq_draws_sigma, mean, sd, q025, q975)\n#&gt; # A tibble: 3 × 5\n#&gt;   variable    mean    sd   q2.5 q97.5\n#&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 sigma[1]   0.940 0.076  0.804 1.105\n#&gt; 2 sigma[2]   1.003 0.076  0.871 1.165\n#&gt; 3 diff_sigma 0.063 0.107 -0.144 0.274\n\nSe diff_mu è negativo, il gruppo mindfulness ha in media affetto negativo più basso del controllo. Se diff_sigma è positivo, il gruppo mindfulness è più eterogeneo; se negativo, è più omogeneo. Questo secondo aspetto è spesso ignorato dal t-test, ma è scientificamente rilevante: un intervento può ridurre la media e cambiare la variabilità delle risposte.\nPer continuità con la sezione precedente, calcoliamo anche la ROPE sulla differenza di medie. La ROPE serve a rispondere alla domanda: l’effetto è praticamente trascurabile?\n\n# ROPE su diff_mu (stessa soglia di prima)\nrope_lower &lt;- -0.1\nrope_upper &lt;-  0.1\n\ndiff_mu_vec &lt;- as.numeric(neq_draws_mu[, \"diff_mu\"])\np_in_rope_neq &lt;- mean(diff_mu_vec &gt; rope_lower & diff_mu_vec &lt; rope_upper)\np_below_neq   &lt;- mean(diff_mu_vec &lt; rope_lower)\np_above_neq   &lt;- mean(diff_mu_vec &gt; rope_upper)\n\ntibble(\n  Model = \"Varianze distinte\",\n  `P(diff in ROPE)` = p_in_rope_neq,\n  `P(diff &lt; lower)` = p_below_neq,\n  `P(diff &gt; upper)` = p_above_neq\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   Model             `P(diff in ROPE)` `P(diff &lt; lower)` `P(diff &gt; upper)`\n#&gt;   &lt;chr&gt;                         &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Varianze distinte            0.0005             1.000                 0\n\n\n17.3.2 Confronto predittivo con PSIS-LOO\nOra confrontiamo modello a varianza comune (fit_eq) e modello a varianze distinte (fit_neq) usando ELPD (più alto è meglio). Guardiamo anche i diagnostici Pareto-k: idealmente &lt; 0.7. Se il vantaggio del modello più complesso è piccolo e incerto, restiamo sul modello parsimonioso; se è chiaro e stabile, accettiamo la maggiore complessità.\n\n# LOO per entrambi i modelli\nloo_eq  &lt;- fit_eq$loo()\nloo_neq &lt;- fit_neq$loo()\n\nprint(loo_eq)\n#&gt; \n#&gt; Computed from 4000 by 170 log-likelihood matrix.\n#&gt; \n#&gt;          Estimate   SE\n#&gt; elpd_loo   -237.5  9.8\n#&gt; p_loo         3.1  0.5\n#&gt; looic       474.9 19.5\n#&gt; ------\n#&gt; MCSE of elpd_loo is 0.0.\n#&gt; MCSE and ESS estimates assume MCMC draws (r_eff in [0.8, 1.1]).\n#&gt; \n#&gt; All Pareto k estimates are good (k &lt; 0.7).\n#&gt; See help('pareto-k-diagnostic') for details.\n\n\nprint(loo_neq)\n#&gt; \n#&gt; Computed from 4000 by 170 log-likelihood matrix.\n#&gt; \n#&gt;          Estimate   SE\n#&gt; elpd_loo   -238.3  9.8\n#&gt; p_loo         4.1  0.8\n#&gt; looic       476.6 19.6\n#&gt; ------\n#&gt; MCSE of elpd_loo is 0.0.\n#&gt; MCSE and ESS estimates assume MCMC draws (r_eff in [1.0, 1.3]).\n#&gt; \n#&gt; All Pareto k estimates are good (k &lt; 0.7).\n#&gt; See help('pareto-k-diagnostic') for details.\n\n\n# Confronto\ncomp &lt;- loo::loo_compare(list(equal_var = loo_eq, unequal_var = loo_neq))\ncomp_df &lt;- as.data.frame(comp)\ncomp_df\n#&gt;             elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic\n#&gt; equal_var       0.000    0.00     -237        9.76  3.05    0.539   475\n#&gt; unequal_var    -0.856    0.61     -238        9.81  4.06    0.780   477\n#&gt;             se_looic\n#&gt; equal_var       19.5\n#&gt; unequal_var     19.6\n\nPer una decisione didatticamente “manuale”, possiamo usare una regola semplice: se |ΔELPD| &lt; 2 × SE(Δ), consideriamo i modelli sostanzialmente equivalenti; in tal caso scegliamo il modello più semplice.\n\n# Piccolo helper decisionale\ndelta_elpd &lt;- comp_df$elpd_diff[1]     # per la riga in cima\nse_delta   &lt;- comp_df$se_diff[1]\n\ndecision &lt;- if (abs(delta_elpd) &lt; 2 * se_delta) {\n  \"Modelli predittivamente equivalenti: preferire la varianza comune per parsimonia.\"\n} else if (delta_elpd &gt; 0) {\n  \"Il modello a varianze distinte offre un vantaggio predittivo credibile: preferirlo.\"\n} else {\n  \"Il modello a varianza comune è migliore: preferirlo.\"\n}\n\ntibble(Delta_ELPD = delta_elpd, SE_Delta = se_delta, Decisione = decision)\n#&gt; # A tibble: 1 × 3\n#&gt;   Delta_ELPD SE_Delta Decisione                                           \n#&gt;        &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;                                               \n#&gt; 1          0        0 Il modello a varianza comune è migliore: preferirlo.\n\n\n17.3.3 Posterior predictive checks\nVerifichiamo che i due modelli riproducano la forma della distribuzione osservata. Se entrambi vanno bene, la scelta si gioca sull’ELPD; se uno mostra discrepanze sistematiche, quello è il segnale più forte.\n\n# Equal variance\nyrep_eq &lt;- fit_eq$draws(\"y_rep\", format = \"matrix\")\nbayesplot::ppc_dens_overlay(y = stan_data$y, yrep = yrep_eq[1:50, ])\n\n\n\n\n\n\n\n\n# Unequal variances\nyrep_neq &lt;- fit_neq$draws(\"y_rep\", format = \"matrix\")\nbayesplot::ppc_dens_overlay(y = stan_data$y, yrep = yrep_neq[1:50, ])",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Confrontare due medie</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_two_means.html#cosa-impariamo",
    "href": "chapters/mcmc/07_stan_two_means.html#cosa-impariamo",
    "title": "17  Confrontare due medie",
    "section": "\n17.4 Cosa impariamo",
    "text": "17.4 Cosa impariamo\n\nDifferenza tra le medie. La posteriore di diff_mu dice di quanto il training modifica l’affetto negativo medio, con intervallo di credibilità; la ROPE ci dice se l’effetto è praticamente trascurabile o rilevante. Questo è un vantaggio diretto rispetto al t-test, che non fornisce probabilità di “effetto rilevante” né gestisce l’equivalenza pratica in modo naturale.\nDifferenza tra varianze. La posteriore di diff_sigma chiarisce se l’intervento modifica l’eterogeneità delle risposte: informazione spesso ignorata, ma importante in psicologia applicata.\nCapacità predittiva. Il confronto PSIS-LOO ci guida nella scelta del livello di complessità. Se ΔELPD è piccolo e incerto, preferiamo la parsimonia (varianza comune); se il vantaggio è stabile e sostanziale, ha senso adottare il modello con varianze distinte.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Confrontare due medie</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_two_means.html#dalle-medie-di-gruppo-allanalisi-idiografica",
    "href": "chapters/mcmc/07_stan_two_means.html#dalle-medie-di-gruppo-allanalisi-idiografica",
    "title": "17  Confrontare due medie",
    "section": "\n17.5 Dalle medie di gruppo all’analisi idiografica",
    "text": "17.5 Dalle medie di gruppo all’analisi idiografica\nFinora ci siamo concentrati sulle medie di gruppo, chiedendoci quanto l’intervento mindfulness modifichi, in media, l’affetto negativo. Ma due gruppi con medie simili possono nascondere storie individuali molto diverse: c’è chi migliora nettamente, chi peggiora, chi non cambia. Per restituire queste differenze, spostiamo l’attenzione sul singolo partecipante.\nIn psicologia clinica, uno strumento tradizionale per valutare il cambiamento individuale è il Reliable Change Index (RCI): si guarda la differenza tra post e pre e la si rapporta all’errore atteso della differenza. Se la differenza “supera la soglia”, il cambiamento è detto affidabile (Jacobson & Truax, 1991). È un’idea semplice e utile, ma lascia fuori due elementi che per noi sono centrali: l’incertezza e la rilevanza pratica del cambiamento. In termini bayesiani, invece di un verdetto sì/no, vogliamo stimare quanto è plausibile che il cambiamento di un individuo sia nullo, trascurabile, o clinicamente rilevante.\nLavoreremo quindi con una piccola estensione bayesiana dell’RCI: per un singolo soggetto, consideriamo la differenza \\(\\Delta = \\text{post} - \\text{pre}\\) e, nota l’incertezza di misura del test (che riassumiamo tramite lo standard error of measurement, SEM), costruiamo la distribuzione a posteriori di \\(\\Delta\\). Da quella distribuzione potremo leggere quantità davvero utili: la probabilità che \\(\\Delta\\) sia trascurabile (dentro una ROPE) oppure rilevante (oltre una soglia clinica \\(\\tau\\)).\nLa logica è la stessa usata a livello di gruppo con la differenza tra medie: là guardavamo \\(\\mu_2 - \\mu_1\\) e una ROPE attorno a zero; qui guardiamo \\(\\Delta\\) per una persona, con una ROPE e una soglia \\(\\tau\\) espresse nella stessa metrica che abbiamo usato in precedenza in questo capitolo (unità di deviazione standard).\n\n17.5.1 Un modello bayesiano minimale per la stima del cambiamento individuale (RCI bayesiano)\nIl modello che presentiamo rappresenta una versione volutamente semplificata del reliable change index (RCI) in chiave bayesiana. L’obiettivo è introdurre lo studente a questi concetti attraverso un esempio trasparente e computazionalmente immediato. La scelta di un modello Normale–Normale in forma chiusa permette infatti di preservare la chiarezza espositiva senza rinunciare alla completezza concettuale.\n\n17.5.1.1 Struttura del modello\nL’input del modello è costituito dai punteggi pre-test e post-test del singolo partecipante, insieme alla deviazione standard e all’affidabilità dello strumento. L’output è la distribuzione a posteriori del cambiamento individuale Δ, dalla quale possiamo derivare tre probabilità clinicamente rilevanti. Tutti i calcoli vengono condotti nella stessa metrica standardizzata (unità di deviazione standard) adottata per le analisi di gruppo.\nLa specificazione è la seguente:\n\n\nVerosimiglianza: la differenza osservata tra post e pre (D) è distribuita come\n\\[\nD \\sim \\mathcal{N}(\\Delta, \\text{SEdiff}^2)\n\\] dove SEdiff è l’errore standard della differenza.\n\n\nPrior: il vero cambiamento Δ segue una distribuzione Normale centrata in 0 con deviazione standard pari a prior_sd_delta, a esprimere l’incertezza iniziale sulla sua entità:\n\\[\n\\Delta \\sim \\mathcal{N}(0, \\text{prior\\_sd\\_delta}^2).\n\\] Per combinazione coniugata, la distribuzione a posteriori di Δ risulta ancora Normale, con parametri calcolabili tramite le formule standard di aggiornamento bayesiano.\n\n\n17.5.1.2 Lo standard error della differenza\nElemento centrale del modello è il calcolo dello standard error della differenza (SEdiff), che riflette l’incertezza nella stima del cambiamento individuale tenendo conto dell’affidabilità del test. Si procede così:\n\n\nsi calcola l’errore standard di misura (SEM) come\n\\[\n\\text{SEM} = SD \\times \\sqrt{1 - \\text{reliability}},\n\\] dove SD è la deviazione standard del test;\n\n\nsi ottiene quindi\n\\[\n\\text{SEdiff} = \\sqrt{2} \\times \\text{SEM},\n\\] assumendo che pre e post abbiano la stessa metrica e affidabilità.\n\n\n17.5.1.3 Probabilità di interesse clinico\nDalla distribuzione a posteriori di Δ si ricavano tre probabilità sostantive:\n\nla probabilità che Δ cada nella ROPE (es. ±0.10 SD), cioè che il cambiamento sia trascurabile;\nla probabilità che Δ superi una soglia positiva τ (es. +0.30 SD), indicativa di un miglioramento clinicamente rilevante;\nla probabilità che Δ sia minore di –τ, indicativa di un peggioramento rilevante.\n\nQueste probabilità si ottengono integrando la distribuzione a posteriori sugli intervalli corrispondenti.\n\n17.5.1.4 Esempio numerico\nApplichiamo il modello a un soggetto del gruppo sperimentale in uno studio sull’intervento mindfulness. I suoi punteggi sono: pre = 0.40, post = 0.05 (espressi in SD). Assumiamo SD = valore campionario dell’intero dataset e un’affidabilità del test pari a 0.85.\n\n# ------------------------------------------------------------\n# RCI bayesiano (versione semplice, chiusa-forma)\n# ------------------------------------------------------------\n# Likelihood:  D = post - pre  ~ Normal(Delta, SEdiff^2)\n# Prior:       Delta ~ Normal(0, prior_sd_delta^2)\n# Posterior:   Delta | D ~ Normal(m_post, s_post^2)\n# ------------------------------------------------------------\n\nrci_bayes &lt;- function(pre, post,\n                      test_sd, reliability,\n                      rope_width = 0.10,   # ROPE ±0.10 SD (coerente con capitolo)\n                      tau_clin   = 0.30,   # soglia clinica 0.30 SD (esempio)\n                      prior_sd_delta = 0.60) {\n  # 1) Differenza osservata\n  D &lt;- post - pre\n  \n  # 2) SEM e SE della differenza\n  #    SEM = SD * sqrt(1 - reliability)\n  SEM    &lt;- test_sd * sqrt(max(0, 1 - reliability))\n  SEdiff &lt;- sqrt(SEM^2 + SEM^2)  # ipotesi: stessa metrica/affidabilità a pre e post\n  \n  # 3) Prior e posteriori (Normale–Normale)\n  s0 &lt;- prior_sd_delta\n  s  &lt;- SEdiff\n  \n  s2_post &lt;- 1 / (1/s0^2 + 1/s^2)\n  s_post  &lt;- sqrt(s2_post)\n  m_post  &lt;- (s2_post / s^2) * D\n  \n  # 4) Probabilità di interesse\n  p_in_rope   &lt;- pnorm( rope_width, mean = m_post, sd = s_post) -\n                 pnorm(-rope_width, mean = m_post, sd = s_post)\n  p_gt_tau    &lt;- 1 - pnorm(tau_clin,  mean = m_post, sd = s_post)\n  p_lt_neg_tau&lt;- pnorm(-tau_clin,     mean = m_post, sd = s_post)\n  \n  list(\n    observed_diff   = D,\n    SEM             = SEM,\n    SEdiff          = SEdiff,\n    prior_sd_delta  = s0,\n    post_mean       = m_post,\n    post_sd         = s_post,\n    rope            = c(-rope_width, rope_width),\n    tau_clin        = tau_clin,\n    probs = c(\n      P_in_ROPE         = p_in_rope,\n      P_diff_gt_tau     = p_gt_tau,\n      P_diff_lt_neg_tau = p_lt_neg_tau\n    )\n  )\n}\n\n\n# 'df' proviene dalle sezioni precedenti del capitolo (score in SD naturali)\ntest_sd &lt;- sd(df$score)\n\nres_demo &lt;- rci_bayes(\n  pre  = 0.40,\n  post = 0.05,\n  test_sd     = test_sd,\n  reliability = 0.85,\n  rope_width  = 0.10,  # ROPE ±0.10 SD (trascurabile)\n  tau_clin    = 0.30,  # soglia clinica 0.30 SD (rilevante)\n  prior_sd_delta = 0.60\n)\n\ncat(sprintf(\n  \"\\nRCI bayesiano (soggetto esempio)\\n---------------------------------\\nDiff. osservata (post-pre): %.3f\\nSEM: %.3f | SE diff: %.3f\\nPosterior Delta ~ Normal(%.3f, %.3f^2)\\nROPE: [%.2f, %.2f] | tau_clin: ±%.2f\\nP(Delta in ROPE)      = %.3f\\nP(Delta &gt;  tau_clin)  = %.3f\\nP(Delta &lt; -tau_clin)  = %.3f\\n\",\n  res_demo$observed_diff, res_demo$SEM, res_demo$SEdiff,\n  res_demo$post_mean, res_demo$post_sd,\n  res_demo$rope[1], res_demo$rope[2], res_demo$tau_clin,\n  res_demo$probs[\"P_in_ROPE\"], res_demo$probs[\"P_diff_gt_tau\"], res_demo$probs[\"P_diff_lt_neg_tau\"]\n))\n#&gt; \n#&gt; RCI bayesiano (soggetto esempio)\n#&gt; ---------------------------------\n#&gt; Diff. osservata (post-pre): -0.350\n#&gt; SEM: 0.384 | SE diff: 0.543\n#&gt; Posterior Delta ~ Normal(-0.192, 0.403^2)\n#&gt; ROPE: [-0.10, 0.10] | tau_clin: ±0.30\n#&gt; P(Delta in ROPE)      = 0.175\n#&gt; P(Delta &gt;  tau_clin)  = 0.111\n#&gt; P(Delta &lt; -tau_clin)  = 0.395\n\nIl modello produce:\n\ndifferenza osservata: –0.350 SD;\nSEM = 0.384, SEdiff = 0.543;\ndistribuzione a posteriori di Δ ~ Normal(–0.192, 0.403²).\n\nIn termini clinici:\n\nP(Δ in ROPE) = 0.175 → cambiamento probabilmente non trascurabile;\nP(Δ &gt; 0.30) = 0.111 → miglioramento poco plausibile;\nP(Δ &lt; –0.30) = 0.395 → peggioramento moderato plausibile.\n\n17.5.1.5 Interpretazione\nLa stima bayesiana attenua la differenza osservata, portandola da –0.350 a –0.192 SD: un effetto di regolarizzazione tipico dell’approccio bayesiano, che combina dati e informazione a priori. Le probabilità a posteriori rendono chiaro che il cambiamento del soggetto non è facilmente classificabile come miglioramento o stabilità: la possibilità di un peggioramento moderato risulta la più consistente, ma non esclusiva.\nQuesto esempio mette in evidenza il valore dell’approccio bayesiano: non un singolo verdetto, ma una mappa probabilistica delle ipotesi clinicamente rilevanti. La trasparenza del modello consente anche di riflettere criticamente sulla scelta dei parametri (affidabilità, SD, ampiezza della ROPE e soglia τ), che devono essere motivati in base a evidenze empiriche e convenzioni cliniche. In questo modo, lo stesso schema logico che abbiamo applicato ai gruppi diventa disponibile anche per l’analisi del singolo: non un verdetto dicotomico, ma una distribuzione di probabilità che rende esplicita l’incertezza e la rilevanza clinica del cambiamento.\n\n17.5.1.6 Prospettive\nLa versione proposta ha finalità introduttive. In un contesto di ricerca avanzato, il modello in forma chiusa può essere sostituito da implementazioni in linguaggio Stan, che consentono di modellare esplicitamente gli errori di misura e di passare a modelli gerarchici capaci di integrare stime individuali e differenze di gruppo. La coerenza concettuale dell’approccio bayesiano si manifesta così su più livelli: stimare differenze tra gruppi e stimare cambiamenti individuali seguono lo stesso schema logico, garantendo un quadro inferenziale unificato e potente per la ricerca psicologica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Confrontare due medie</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_two_means.html#riflessioni-conclusive",
    "href": "chapters/mcmc/07_stan_two_means.html#riflessioni-conclusive",
    "title": "17  Confrontare due medie",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’analisi sviluppata in questo capitolo mette in evidenza i punti di forza dell’approccio bayesiano al confronto tra gruppi e, più in generale, alla valutazione del cambiamento psicologico. La quantità centrale non è più un singolo numero o un p-value, ma l’intera distribuzione a posteriori delle differenze che ci interessano. È questa distribuzione che racconta la storia sostantiva: nel nostro esempio, di quanto il gruppo mindfulness differisce, in media, dal gruppo di controllo. Non otteniamo soltanto una stima puntuale, ma anche l’incertezza che accompagna ogni possibile valore della differenza. Questo ci consente di andare oltre il verdetto dicotomico “c’è / non c’è differenza” e di ragionare invece in termini di gradazioni di plausibilità.\nUn secondo aspetto riguarda la possibilità di valutare la rilevanza pratica degli effetti. Introdurre una region of practical equivalence (ROPE) ci permette di distinguere tra differenze che, pur statisticamente rilevabili, sono trascurabili dal punto di vista psicologico e differenze che invece hanno un impatto sostantivo. In questo modo possiamo rispondere a domande clinicamente significative, come “quanto è probabile che l’effetto sia non solo diverso da zero, ma anche sufficientemente grande da essere rilevante?”.\nIl confronto tra modelli con varianza comune e modelli con varianze distinte ci ha mostrato inoltre come ogni assunzione statistica vada valutata in termini predittivi. Grazie al criterio ELPD stimato con PSIS-LOO abbiamo potuto verificare se la maggiore complessità introdotta dal modello con varianze distinte migliorasse davvero la capacità di predire dati simili ai nostri. Quando il guadagno è minimo, la parsimonia suggerisce di mantenere il modello più semplice; quando invece il vantaggio predittivo è chiaro, si giustifica la maggiore complessità. Questo modo di ragionare è più trasparente e più vicino alla logica scientifica rispetto all’alternativa frequentista, in cui le scelte modellistiche sono spesso delegate a test poco interpretabili.\nIl passaggio all’analisi ideografica, con la versione bayesiana del Reliable Change Index, amplia ulteriormente la prospettiva. Se l’analisi di gruppo ci dice cosa accade in media, l’analisi del cambiamento individuale ci mostra quanto un intervento sia stato efficace per ciascun partecipante. Qui il vantaggio del ragionamento bayesiano è evidente: invece di un verdetto rigido (“cambiamento affidabile sì/no”), possiamo stimare la probabilità che un miglioramento sia trascurabile o clinicamente rilevante per il singolo individuo. In questo modo, i due livelli di analisi — collettivo e individuale — non sono più separati, ma si integrano in un quadro unitario.\nIn sintesi, l’approccio bayesiano ci insegna che l’inferenza non riguarda tanto il respingere o meno un’ipotesi nulla, quanto il descrivere la plausibilità di diversi scenari e collegarla al significato psicologico dei dati. Ciò vale tanto per le differenze tra gruppi quanto per i cambiamenti nei singoli individui. Questa prospettiva porta la statistica più vicina alle domande reali della psicologia: non solo “esiste un effetto?”, ma “quanto è grande?”, “quanto è incerto?”, “quanto è rilevante per la pratica clinica o applicativa?”, e perfino “quanto è plausibile che questo singolo paziente abbia beneficiato dell’intervento?”. È qui che l’approccio bayesiano mostra il suo valore aggiunto, trasformando l’analisi dei dati in uno strumento flessibile, trasparente e sostantivamente informativo.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] forcats_1.0.0         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Confrontare due medie</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_two_means.html#bibliografia",
    "href": "chapters/mcmc/07_stan_two_means.html#bibliografia",
    "title": "17  Confrontare due medie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJacobson, N. S., & Truax, P. (1991). Clinical significance: A statistical approach to defining meaningful change in psychotherapy research. Journal of Consulting and Clinical Psychology, 59(1), 12–19. https://doi.org/10.1037/0022-006X.59.1.12\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Confrontare due medie</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_poisson_model_1.html",
    "href": "chapters/mcmc/08_stan_poisson_model_1.html",
    "title": "18  Modello di Poisson",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto come utilizzare Stan per analizzare un problema familiare, quello delle proporzioni, introducendo l’odds ratio come primo esempio pratico. In questo capitolo allarghiamo l’orizzonte a un’altra classe di dati molto comune in psicologia: i conteggi.\nMolti fenomeni sperimentali e clinici si presentano sotto forma di conteggi. Pensiamo al numero di errori commessi in un compito di attenzione, al numero di risposte corrette in una sessione di apprendimento, o al numero di episodi sintomatici riportati in un diario clinico. In tutti questi casi, il modello probabilistico di riferimento è spesso la distribuzione di Poisson, che descrive il numero di eventi osservati in un dato intervallo di tempo o di prove, quando gli eventi hanno una probabilità media di verificarsi.\nIl modello di Poisson rappresenta quindi un banco di prova ideale per consolidare due aspetti fondamentali: da un lato, la generalità dell’inferenza bayesiana – la logica rimane la stessa, cambiano solo la forma della verosimiglianza e i parametri da stimare –; dall’altro, la potenza di Stan come strumento pratico per affrontare modelli che, pur essendo concettualmente semplici, diventano rapidamente complicati se implementati a mano.\nIn questo capitolo mostreremo come specificare e stimare un modello di Poisson in Stan, partendo da un esempio psicologico concreto. Questo ci consentirà di acquisire familiarità con un nuovo tipo di dati e di consolidare la logica bayesiana in un contesto diverso, preparandoci ad affrontare nei capitoli successivi modelli più articolati e multilivello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_poisson_model_1.html#introduzione",
    "href": "chapters/mcmc/08_stan_poisson_model_1.html#introduzione",
    "title": "18  Modello di Poisson",
    "section": "",
    "text": "Panoramica del capitolo\n\nCapire quando usare un modello di Poisson (conteggi non negativi, tendenzialmente rari, indipendenti dato il tasso).\nScrivere un modello in Stan con parametri su scala naturale (qui: lambda come tasso medio).\nImpostare prior debolmente informative su lambda o sul suo log (per mantenere positività e stabilità numerica).\nEseguire stima MCMC con cmdstanr e leggere i diagnostici di convergenza.\nFare posterior predictive checks (PPC) per valutare l’adeguatezza del modello.\n\n\n\n\n\n\n\nPerché questo esempio?\n\n\n\n\n\nIn questo capitolo non vogliamo solo calcolare una media dal campione, ma imparare a:\n\nstimare il tasso medio di occorrenza nella popolazione a partire dai dati osservati;\n\nesprimere anche la nostra incertezza su quel tasso, non solo un singolo numero;\n\ntradurre un modello teorico (Poisson con prior Gamma) in un modello computazionale in Stan;\n\nverificare che Stan fornisce gli stessi risultati della soluzione analitica, così da prendere confidenza con il workflow MCMC.\n\nQuesto esempio funziona come una “palestra”: semplice, ma ci prepara ad affrontare modelli più complessi in cui non avremo formule chiuse e l’uso di Stan diventerà indispensabile.\n\n\n\n\n\n\n\n\n\nPerché studiare il modello di Poisson?\n\n\n\n\n\n\nMolti dati psicologici si presentano come conteggi (episodi comportamentali, risposte corrette, eventi clinici).\n\nIl modello di Poisson è lo strumento naturale per stimare il tasso medio di occorrenza di questi eventi.\n\nL’approccio bayesiano ci permette non solo di stimare questo tasso, ma anche di esprimere in modo chiaro la nostra incertezza.\n\nIn questo capitolo usiamo il Poisson come primo esempio pratico per imparare a scrivere e stimare un modello in Stan.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, tidyverse, tibble)\nconflicts_prefer(posterior::ess_bulk)\nconflicts_prefer(posterior::ess_tail)\nconflicts_prefer(dplyr::count)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_poisson_model_1.html#dal-modello-teorico-al-modello-computazionale",
    "href": "chapters/mcmc/08_stan_poisson_model_1.html#dal-modello-teorico-al-modello-computazionale",
    "title": "18  Modello di Poisson",
    "section": "\n18.1 Dal modello teorico al modello computazionale",
    "text": "18.1 Dal modello teorico al modello computazionale\nQuando raccogliamo dati in psicologia, non ci interessa solo descrivere quello che è accaduto nel nostro campione, ma soprattutto stimare il processo che genera i dati nella popolazione.\nImmaginiamo di osservare, in otto finestre temporali di pari durata, quante volte si verifica un certo evento psicologico o comportamentale. Per esempio, il numero di compulsioni in otto momenti della giornata, oppure il numero di telefonate ricevute in otto turni orari.\nI dati raccolti sono:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nAbbiamo quindi \\(N = 8\\) osservazioni. Dal campione potremmo calcolare una semplice media (\\(\\bar y = 1.625\\)), ma questo ci dice solo quanto spesso l’evento è avvenuto nei nostri dati. La domanda più interessante è:\n\nqual è il tasso medio di occorrenza nella popolazione?\n\nChiamiamo questo tasso \\(\\lambda\\): il numero medio di eventi attesi in una finestra temporale.\n\n18.1.1 Perché serve un modello probabilistico?\nI dati osservati sono solo un piccolo campione e possono variare da una raccolta all’altra. Un modello probabilistico ci serve per due motivi principali:\n\n\nSeparare il segnale dal rumore: capire quanto dell’andamento osservato è dovuto al caso e quanto riflette una regolarità della popolazione.\n\nQuantificare l’incertezza: non ci basta stimare \\(\\lambda\\), vogliamo anche dire quanto siamo sicuri (o incerti) di quella stima.\n\n18.1.2 Il modello di Poisson\nPer i fenomeni di conteggio (quante volte un evento si verifica in un intervallo), il modello naturale è la distribuzione di Poisson:\n\\[\ny_i \\sim \\text{Poisson}(\\mu_i), \\qquad \\mu_i = \\lambda \\cdot t_i\n\\] dove:\n\n\n\\(y_i\\) è il numero osservato di eventi nella finestra \\(i\\),\n\n\\(t_i\\) è la durata della finestra,\n\n\\(\\lambda\\) è il tasso medio.\n\nNel nostro caso tutte le finestre hanno la stessa durata (\\(t_i = 1\\)), e quindi:\n\\[\nP(y_i \\mid \\lambda) = \\frac{\\lambda^{y_i} e^{-\\lambda}}{y_i!},\n\\qquad \\mathbb{E}[y_i]=\\lambda, \\quad \\mathrm{Var}(y_i)=\\lambda.\n\\] In parole semplici: \\(\\lambda\\) rappresenta quanti eventi in media ci aspettiamo per finestra.\n\n\n\n\n\n\nEsempi in psicologia\n\n\n\n\n\nModelli di questo tipo compaiono spesso anche nella ricerca psicologica.\nAlcuni esempi:\n\n\nClinica: numero di episodi compulsivi o attacchi di panico osservati in un certo periodo.\n\n\nPsicologia dello sviluppo: numero di parole nuove prodotte da un bambino in un giorno.\n\n\nPsicologia cognitiva: numero di risposte corrette in una serie di prove a tempo.\n\n\nPsicologia sociale: numero di interazioni tra membri di un gruppo osservate in una sessione.\n\nIn tutti questi casi, il modello di Poisson ci aiuta a stimare il tasso medio di occorrenza dell’evento di interesse e l’incertezza che accompagna tale stima.\n\n\n\n\n18.1.3 La distribuzione a priori\nNell’approccio bayesiano dobbiamo dichiarare che cosa riteniamo plausibile per \\(\\lambda\\) prima di osservare i dati. Per i modelli di Poisson la scelta naturale è la distribuzione Gamma. Ad esempio, una prior Gamma(9, 2) esprime l’idea che, prima di osservare i dati, ci aspettiamo circa 4–5 eventi per finestra, ma lasciamo spazio a una certa variabilità.\n\n18.1.4 Perché usiamo Stan?\nPotremmo calcolare la distribuzione a posteriori anche con formule chiuse (qui la posterior è ancora una Gamma). Ma usiamo Stan per due motivi didattici fondamentali:\n\n\nGeneralizzare: nella pratica incontreremo modelli per cui non esiste una soluzione analitica semplice. Con Stan impariamo un workflow valido in tutti i casi.\n\nQuantificare l’incertezza: Stan ci fornisce direttamente campioni dalla distribuzione a posteriori, che possiamo usare per costruire intervalli credibili, fare previsioni, confrontare modelli, ecc.\n\n\n\n\n\n\n\nUn caso semplice per allenarsi\n\n\n\n\n\nIn questo esempio l’uso di Stan può sembrare eccessivo, perché sappiamo già che la posterior è una Gamma e potremmo calcolarla con una formula.\nIl punto, però, è proprio esercitarsi: usiamo un caso semplice come “palestra” per imparare un workflow (specificare un modello, campionare con MCMC, analizzare la posterior) che ci sarà indispensabile quando i modelli diventeranno più realistici e complessi, e non avremo più scorciatoie analitiche.\n\n\n\n\n18.1.5 Obiettivi del modello in Stan\nCon questo primo esempio vogliamo:\n\nstimare \\(\\lambda\\), il tasso medio di occorrenza nella popolazione;\nottenere una misura della nostra incertezza su \\(\\lambda\\);\nverificare che i campioni generati da Stan coincidano con i risultati della formula analitica (dove è disponibile).\n\nIn questo modo ci abituiamo a un flusso di lavoro che useremo anche per modelli molto più complessi, in cui solo un approccio computazionale ci permette di fare inferenza bayesiana.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_poisson_model_1.html#scrivere-il-modello-in-stan",
    "href": "chapters/mcmc/08_stan_poisson_model_1.html#scrivere-il-modello-in-stan",
    "title": "18  Modello di Poisson",
    "section": "\n18.2 Scrivere il modello in Stan",
    "text": "18.2 Scrivere il modello in Stan\nUn modello Stan è diviso in blocchi: data (dati), parameters (incognite), model (priori + verosimiglianza). Aggiungiamo anche generated quantities per quantità derivate utili al confronto con la soluzione analitica (e, volendo, per LOO).\nPer evitare dipendenze da percorsi locali, creiamo e compiliamo il modello direttamente dalla stringa:\n\nstan_code &lt;- \"\ndata {\n  int&lt;lower=0&gt; N;\n  array[N] int&lt;lower=0&gt; y;\n  real&lt;lower=0&gt; alpha_prior;\n  real&lt;lower=0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0&gt; lambda;\n}\nmodel {\n  lambda ~ gamma(alpha_prior, beta_prior);\n  y ~ poisson(lambda);\n}\ngenerated quantities {\n  real alpha_post = alpha_prior + sum(y);\n  real beta_post  = beta_prior + N;\n  array[N] real log_lik;\n  for (i in 1:N) log_lik[i] = poisson_lpmf(y[i] | lambda);\n}\n\"\n\nCompiliamo:\n\nmod &lt;- cmdstan_model(write_stan_file(stan_code))\n\nPrepariamo i dati:\n\nN &lt;- length(y)\nalpha_prior &lt;- 9\nbeta_prior  &lt;- 2\n\nstan_data &lt;- list(N = N, y = y, alpha_prior = alpha_prior, beta_prior = beta_prior)\n\nUna volta preparati i dati, lanciamo il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 3000,\n  iter_warmup = 2000,\n  refresh = 0\n)\n\n\n18.2.1 Analizzare i risultati\nUna volta che Stan ha terminato il campionamento, otteniamo migliaia di valori possibili di \\(\\lambda\\), campionati dalla distribuzione a posteriori. Questi valori ci permettono di “vedere” la distribuzione a posteriori invece di calcolarla solo con una formula.\n\n18.2.1.1 Estraiamo i campioni di \\(\\lambda\\)\n\nEstraiamo i valori campionati di λ dalla posterior. L’oggetto draws restituisce tutti i campioni MCMC, noi qui selezioniamo solo il parametro lambda:\n\nposterior_draws &lt;- fit$draws(\"lambda\", format = \"df\")\n\nCreiamo un vettore con solo i valori di lambda:\n\nlambda_samples &lt;- posterior_draws$lambda\n\nOra lambda_samples contiene migliaia di valori di \\(\\lambda\\): possiamo usarli per calcolare media, intervalli credibili e per costruire grafici.\n\nlength(lambda_samples)\n#&gt; [1] 12000\nhead(lambda_samples)\n#&gt; [1] 1.68 1.52 1.48 2.83 2.84 3.01\n\n\n18.2.1.2 Calcoliamo i parametri della distribuzione posteriore teorica\nDato che in questo caso abbiamo una posterior coniugata, conosciamo la formula esatta della distribuzione a posteriori (Gamma). Ci serve per confrontarla con i campioni generati da Stan:\n\nalpha_post &lt;- alpha_prior + sum(y)   # nuovo parametro shape\nbeta_post  &lt;- beta_prior + N         # nuovo parametro rate\n\n\n18.2.1.3 Confrontiamo i due risultati (MCMC vs formula)\nCreiamo un grafico che mostri l’istogramma dei campioni ottenuti con Stan (in azzurro) e la curva della distribuzione Gamma calcolata analiticamente (in rosso).\n\nggplot(data.frame(lambda = lambda_samples), aes(x = lambda)) +\n  # Istogramma dei campioni posteriori\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 50,\n    alpha = 0.7\n  ) +\n  # Curva teorica Gamma con parametri aggiornati\n  stat_function(\n    fun = function(x) dgamma(x, shape = alpha_post, rate = beta_post),\n    linewidth = 1.2\n  ) +\n  labs(\n    x = \"λ (tasso medio di occorrenza)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nIl confronto visivo è molto utile:\n\nl’istogramma mostra la distribuzione stimata con Stan tramite campionamento MCMC,\nla curva rossa rappresenta la distribuzione teorica Gamma–Poisson che conosciamo già.\n\nSe le due coincidono (entro piccole fluttuazioni casuali), significa che Stan ha fatto un buon lavoro: il nostro workflow MCMC funziona!\n\n18.2.2 Intervallo di credibilità\nUn grande vantaggio dell’approccio bayesiano è che non otteniamo solo una stima puntuale di \\(\\lambda\\), ma una distribuzione completa dei valori plausibili. Da questa distribuzione possiamo ricavare un intervallo di credibilità: un intervallo che contiene, ad esempio, il 94% o il 95% della massa a posteriori.\n\n18.2.2.1 Calcoliamo i quantili della distribuzione\nCalcoliamo i quantili al 3%, 50% (mediana) e 97%:\n\ncred_interval &lt;- quantile(lambda_samples, probs = c(0.03, 0.5, 0.97))\ncred_interval\n#&gt;   3%  50%  97% \n#&gt; 1.42 2.17 3.18\n\n\nil valore al 50% è la mediana della distribuzione a posteriori,\ni valori al 3% e 97% delimitano un intervallo centrale che contiene il 94% della distribuzione.\n\n18.2.2.2 Interpretazione dei risultati\nI risultati ottenuti indicano che:\n\nil valore “tipico” di \\(\\lambda\\) (mediana) è circa 2.2 eventi per finestra,\nc’è un 94% di probabilità che \\(\\lambda\\) si trovi tra 1.42 e 3.20.\n\nL’informazione più importante non è tanto la stima puntuale (2.2), ma il fatto che possiamo quantificare la nostra incertezza: la posterior ci dice chiaramente quali valori di \\(\\lambda\\) sono più o meno plausibili.\n\n18.2.3 Diagnostica essenziale\nDopo il campionamento MCMC, è fondamentale verificare che le catene abbiano esplorato bene la distribuzione a posteriori. Per questo guardiamo due tipi di informazioni: indici numerici (come \\(\\hat{R}\\) e ESS) e grafici delle catene (traceplot).\nPossiamo ottenere una sintesi numerica della distribuzione a posteriore dei parametri con la funzione summarise_draws del pacchetto posterior:\n\nposterior::summarise_draws(fit$draws(\"lambda\"), rhat, ess_bulk, ess_tail)\n#&gt; # A tibble: 1 × 4\n#&gt;   variable  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lambda   1.002 4666.651 6265.973\n\n\n\\(\\hat{R}\\) (R-hat): misura la convergenza delle catene. Valori vicini a 1.00 indicano che le catene si sono mescolate bene; valori maggiori di 1.01 segnalano possibili problemi.\n\nESS (Effective Sample Size): indica quanti campioni “indipendenti” equivalenti abbiamo ottenuto.\n\n\ness_bulk valuta la precisione delle stime centrali (media, mediana).\n\ness_tail valuta la precisione nelle code della distribuzione (intervalli credibili). Più sono grandi, meglio è: in genere migliaia di campioni equivalenti sono più che sufficienti.\n\n\n\nPossiamo generare un traceplot con la funzione mcmc_trace di bayesplot:\n\nbayesplot::mcmc_trace(fit$draws(\"lambda\")) \n\n\n\n\n\n\n\nIl traceplot mostra l’andamento dei valori di \\(\\lambda\\) campionati dalle diverse catene. Se le catene:\n\noscillano liberamente attorno alla stessa regione,\nsenza trend sistematici o salti strani,\n\nallora possiamo concludere che il campionamento è avvenuto correttamente.\nIn sintesi: se \\(\\hat{R} \\approx 1\\), ESS è elevato e i traceplot sono ben mescolati, possiamo fidarci delle stime ottenute.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_poisson_model_1.html#sparatorie-mortali",
    "href": "chapters/mcmc/08_stan_poisson_model_1.html#sparatorie-mortali",
    "title": "18  Modello di Poisson",
    "section": "\n18.3 Sparatorie mortali",
    "text": "18.3 Sparatorie mortali\nNella sezione precedente abbiamo esaminato il processo di derivazione della distribuzione a posteriori per i parametri della distribuzione Gamma, la quale viene impiegata quando si adotta un prior Gamma per una verosimiglianza di Poisson. In questo esempio, useremo tale metodo per affrontare una questione relativa all’analisi di un set di dati reali.\n\n18.3.1 Domanda della ricerca\nCome spiegato qui, i dati che esamineremo sono raccolti dal Washington Post con lo scopo di registrare ogni sparatoria mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1° gennaio 2015. Il Washington Post ha adottato un approccio sistematico e accurato nella raccolta di queste informazioni, fornendo dati che possono essere utili per valutare i problemi legati alla violenza delle forze di polizia negli Stati Uniti.\nObiettivo. Stimare, per il periodo 2015–ultimo anno completo disponibile, il tasso medio annuo e l’incertezza associata. Poiché il 2025 è incompleto, lo escludiamo.\n\n18.3.2 Svolgimento con R\n\n18.3.2.1 Importazione e pre-processing dei dati\n\n# URL del dataset\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\n\n# Importa i dati\nfps_dat &lt;- read_csv(url, show_col_types = FALSE)\n\n# Conversione colonna date\nfps_dat &lt;- fps_dat %&gt;%\n  mutate(date = ymd(date),\n         year = year(date))\n\n# Esamina le colonne disponibili\ncolnames(fps_dat)\n#&gt;  [1] \"id\"                         \"date\"                      \n#&gt;  [3] \"threat_type\"                \"flee_status\"               \n#&gt;  [5] \"armed_with\"                 \"city\"                      \n#&gt;  [7] \"county\"                     \"state\"                     \n#&gt;  [9] \"latitude\"                   \"longitude\"                 \n#&gt; [11] \"location_precision\"         \"name\"                      \n#&gt; [13] \"age\"                        \"gender\"                    \n#&gt; [15] \"race\"                       \"race_source\"               \n#&gt; [17] \"was_mental_illness_related\" \"body_camera\"               \n#&gt; [19] \"agency_ids\"                 \"year\"\n\n# Filtra eliminando i casi con year == 2025\nfps &lt;- fps_dat %&gt;%\n  filter(year != 2025)\n\n# Conta le occorrenze per anno\nyear_counts &lt;- fps %&gt;%\n  count(year, name = \"events\")\n\n# Mostra i risultati\nprint(year_counts)\n#&gt; # A tibble: 10 × 2\n#&gt;     year events\n#&gt;    &lt;dbl&gt;  &lt;int&gt;\n#&gt;  1  2015    995\n#&gt;  2  2016    959\n#&gt;  3  2017    984\n#&gt;  4  2018    992\n#&gt;  5  2019    993\n#&gt;  6  2020   1021\n#&gt;  7  2021   1050\n#&gt;  8  2022   1097\n#&gt;  9  2023   1164\n#&gt; 10  2024   1175\n\n\n18.3.2.2 Modello di Poisson (pooling completo)\nAssumiamo \\(y_t \\sim \\text{Poisson}(\\lambda)\\) con \\(\\lambda\\) costante sul periodo:\n\\[\ny_t \\,\\sim\\, \\text{Poisson}(\\lambda), \\quad t=1,\\dots,n.\n\\]\nIl supporto di \\(\\lambda\\) è \\([0,\\infty)\\). Si noti che abbiamo considerato i dati come iid. Guardando la serie temporale, però, è ovvio che le cose non stanno così: i valori aumentano nel tempo.\n\n18.3.2.3 Prior\nUsiamo una prior coniugata Gamma su \\(\\lambda\\), scelta in modo debolmente informativo. Un’ipotesi ragionevole (da verificare e discutere in aula) è una media a priori di 600 eventi/anno, con deviazione standard 200. In termini Gamma(shape, rate):\n\\[\n\\alpha = (\\mu/\\sigma)^2,\\qquad \\beta = \\mu/\\sigma^2.\n\\]\nVisualizziamo la prior (campionando in R):\n\nmu    &lt;- 600\nsigma &lt;- 200\n\n# Parametrizzazione Gamma(shape = k, scale = theta) per la simulazione\ntheta &lt;- sigma^2 / mu\nk     &lt;- mu / theta\n\nset.seed(2)\nx_draws &lt;- rgamma(50000, shape = k, scale = theta)\n\nggplot(data.frame(x = x_draws), aes(x = x)) +\n  geom_histogram(bins = 30) +\n  labs(\n    x = \"Tasso (eventi/anno)\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\n\n18.3.2.4 Modello di Poisson con Stan\nQui stimiamo \\(\\lambda\\) assumendo lo stesso tasso per tutti gli anni (pooling completo). Con prior Gamma in parametrizzazione (shape, rate):\n\nstan_code &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;                 // numero di anni\n  array[N] int&lt;lower=0&gt; y;        // conteggi annuali\n  real&lt;lower=0&gt; alpha_prior;      // shape\n  real&lt;lower=0&gt; beta_prior;       // rate\n}\nparameters {\n  real&lt;lower=0&gt; lambda;           // tasso medio annuo\n}\nmodel {\n  lambda ~ gamma(alpha_prior, beta_prior); // prior Gamma(shape, rate)\n  y ~ poisson(lambda);                     // verosimiglianza\n}\ngenerated quantities {\n  real log_lik = poisson_lpmf(y | lambda);\n}\n\"\n\n\n# Dati (usa i conteggi 2015...2024 ordinati)\ny_vec &lt;- year_counts$events  # ordine per anno; per Poisson i.i.d. l'ordine non incide\n\n# Prior: coerente con la sezione precedente\nalpha_prior &lt;- (mu / sigma)^2\nbeta_prior  &lt;- mu / sigma^2\n\nstan_data &lt;- list(\n  N = length(y_vec),\n  y = as.integer(y_vec),\n  alpha_prior = alpha_prior,\n  beta_prior  = beta_prior\n)\nstan_data\n#&gt; $N\n#&gt; [1] 10\n#&gt; \n#&gt; $y\n#&gt;  [1]  995  959  984  992  993 1021 1050 1097 1164 1175\n#&gt; \n#&gt; $alpha_prior\n#&gt; [1] 9\n#&gt; \n#&gt; $beta_prior\n#&gt; [1] 0.015\n\nCompilazione ed esecuzione:\n\nmod &lt;- cmdstan_model(write_stan_file(stan_code))\n\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4,\n  seed = 123,\n  refresh = 0\n)\n\nRiassunto dei parametri:\n\nfit$summary(\"lambda\")\n#&gt; # A tibble: 1 × 10\n#&gt;   variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lambda   1042.414 1042.349 10.268 10.362 1025.691 1059.529 1.000 6110.780\n#&gt;   ess_tail\n#&gt;      &lt;dbl&gt;\n#&gt; 1 8233.184\n\n\nposterior::summarise_draws(\n  fit$draws(\"lambda\"),\n  mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n#&gt; # A tibble: 1 × 6\n#&gt;   variable     mean     sd   `2.5%`    `50%`  `97.5%`\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lambda   1042.414 10.268 1022.544 1042.349 1062.583\n\nVisualizzazione:\n\nbayesplot::mcmc_hist(fit$draws(\"lambda\")) \n\n\n\n\n\n\n\n\nbayesplot::mcmc_areas(fit$draws(\"lambda\"), prob = 0.95)\n\n\n\n\n\n\n\nIl grafico mostra che il tasso di sparatorie fatali ha una media annuale di 1042 con CI [1022, 1062].\nIn sintesi, analizzando i dati compresi tra il 2015 e il 2025 e basandoci su una distribuzione a priori che presuppone una sparatoria mortale al mese per stato, possiamo concludere con un grado di certezza soggettivo del 95% che il tasso stimato di sparatorie fatali da parte della polizia negli Stati Uniti sia di 1028 casi all’anno, con un intervallo di credibilità compreso tra 1022 e 1062.\nDiagnostica essenziale:\n\n# Indicatori numerici chiave: Rhat ~ 1, ESS adeguati\nposterior::summarize_draws(\n  fit$draws(c(\"lambda\")), \"rhat\", \"ess_bulk\", \"ess_tail\"\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   variable  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lambda   1.000 6110.780 8233.184\n\n\n# Traceplot di controllo su OR\nbayesplot::mcmc_trace(fit$draws(\"lambda\")) \n\n\n\n\n\n\n\n\n18.3.2.5 Derivazione analitica (Gamma–Poisson)\nCon prior \\(\\lambda \\sim \\text{Gamma}(\\alpha,\\beta)\\) e dati \\(y_1,\\dots,y_n\\) i.i.d. Poisson(\\(\\lambda\\)), il posteriore è:\n\\[\n\\lambda \\mid \\mathbf{y} \\;\\sim\\; \\text{Gamma}\\!\\left(\\alpha + \\sum_{t=1}^n y_t,\\;\\; \\beta + n\\right).\n\\] Quindi:\n\n\nmedia posteriore \\(\\mathbb{E}[\\lambda\\mid y] = \\dfrac{\\alpha + \\sum y_t}{\\beta + n}\\);\n\nICr 95% con i quantili Gamma al 2.5% e 97.5%.\n\n\n# Dati e prior come nella sezione Stan\ndata_vec &lt;- year_counts$events\nn        &lt;- length(data_vec)\nsum_y    &lt;- sum(data_vec)\n\nmu    &lt;- 600\nsigma &lt;- 200\nalpha_prior &lt;- (mu / sigma)^2\nbeta_prior  &lt;- mu / sigma^2\n\n# Posterior coniugato\nalpha_post &lt;- alpha_prior + sum_y\nbeta_post  &lt;- beta_prior  + n\n\npost_mean &lt;- alpha_post / beta_post\nci95      &lt;- qgamma(c(0.025, 0.975), shape = alpha_post, rate = beta_post)\n\ncat(\"Posterior mean λ:\", round(post_mean, 2), \"\\n\")\n#&gt; Posterior mean λ: 1042\ncat(\"95% CrI: [\", round(ci95[1], 2), \", \", round(ci95[2], 2), \"]\\n\")\n#&gt; 95% CrI: [ 1022 ,  1062 ]\n\nLa derivazione analitica e i risultati MCMC coincidono (entro l’errore Monte Carlo).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_poisson_model_1.html#riflessioni-conclusive",
    "href": "chapters/mcmc/08_stan_poisson_model_1.html#riflessioni-conclusive",
    "title": "18  Modello di Poisson",
    "section": "\n18.4 Riflessioni conclusive",
    "text": "18.4 Riflessioni conclusive\nL’esempio del modello di Poisson ci ha permesso di estendere l’inferenza bayesiana a un nuovo tipo di dati, mostrando la versatilità di Stan nel trattare situazioni diverse. Abbiamo visto che la logica rimane invariata: definiamo un prior, specifichiamo la verosimiglianza (in questo caso di Poisson) e otteniamo una distribuzione a posteriori che rappresenta la nostra incertezza sui parametri.\nDal punto di vista applicativo, questo esempio è particolarmente rilevante per la ricerca psicologica. I dati di conteggio sono onnipresenti, e spesso la loro analisi viene ridotta a modelli frequentisti standardizzati. Con l’approccio bayesiano, invece, possiamo esplicitare le nostre assunzioni, incorporare conoscenze pregresse e comunicare l’incertezza in modo più trasparente.\nIl valore didattico di questo capitolo sta nel mostrare la continuità: ciò che abbiamo imparato con le proporzioni e l’odds ratio si applica senza sforzo concettuale anche a contesti diversi. Al tempo stesso, l’uso di Stan ci ha reso evidente che, anche per modelli semplici, il supporto di un PPL è indispensabile quando vogliamo scalare verso situazioni più complesse.\nNei prossimi capitoli faremo proprio questo passo: passeremo da modelli semplici e univariati a strutture più articolate e gerarchiche, scoprendo come l’approccio bayesiano ci permetta di affrontare in modo sistematico la complessità della ricerca psicologica contemporanea.\n\n\n\n\n\n\nCosa abbiamo imparato?\n\n\n\n\n\n\nCome tradurre un modello teorico di conteggio (Poisson con prior Gamma) in un modello Stan.\n\nCome ottenere campioni dalla distribuzione a posteriori con il campionamento MCMC.\n\nCome confrontare i risultati con la soluzione analitica per verificare che il workflow funziona.\n\nPerché è utile partire da un caso semplice: per allenarsi con il workflow che useremo in modelli più complessi, dove formule chiuse non esistono.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] lubridate_1.9.4       forcats_1.0.0         stringr_1.5.1        \n#&gt;  [4] purrr_1.1.0           readr_2.1.5           tidyverse_2.0.0      \n#&gt;  [7] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt; [10] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [13] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [16] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [19] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [22] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [25] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [28] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [31] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#&gt; [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [13] crayon_1.5.3          pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] utf8_1.2.6            rmarkdown_2.29        tzdb_0.5.0           \n#&gt; [22] ps_1.9.1              ragg_1.5.0            bit_4.6.0            \n#&gt; [25] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [31] stringi_1.8.7         RColorBrewer_1.1-3    estimability_1.5.1   \n#&gt; [34] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [37] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [40] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [43] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [46] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [49] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [52] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [55] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [58] distributional_0.5.0  generics_0.1.4        vroom_1.6.5          \n#&gt; [61] rprojroot_2.1.1       hms_1.1.3             rstantools_2.5.0     \n#&gt; [64] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [67] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [70] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [73] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [76] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [79] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [82] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [85] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [88] bit64_4.6.0-1         MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_poisson_model_1.html#bibliografia",
    "href": "chapters/mcmc/08_stan_poisson_model_1.html#bibliografia",
    "title": "18  Modello di Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_gaussian_mixture.html",
    "href": "chapters/mcmc/09_stan_gaussian_mixture.html",
    "title": "19  Modelli Mistura Gaussiani",
    "section": "",
    "text": "Introduzione\nLa distribuzione gaussiana costituisce uno degli strumenti fondamentali della statistica, non solo perché molti fenomeni psicologici ed empirici possono approssimativamente seguirne l’andamento, ma anche perché essa funge da elemento costitutivo di modelli più complessi. Un esempio particolarmente rilevante è rappresentato dalle cosiddette misture di distribuzioni. Una mistura descrive una variabile casuale la cui distribuzione complessiva deriva dalla combinazione ponderata di più distribuzioni elementari, ciascuna delle quali rappresenta una possibile sottopopolazione dei dati osservati.\nNel caso delle variabili continue, una mistura di gaussiane è definita come la somma pesata di più densità normali. Ad esempio, una mistura di due distribuzioni normali può essere espressa come\n\\[\nf(x; \\pi_1, \\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = \\pi_1 \\, \\phi(x; \\mu_1, \\sigma_1) + \\pi_2 \\, \\phi(x; \\mu_2, \\sigma_2),\n\\] dove \\(\\pi_1\\) e \\(\\pi_2 = 1 - \\pi_1\\) rappresentano i pesi delle due componenti e \\(\\phi(x; \\mu, \\sigma)\\) è la densità di una distribuzione normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). In questo modo, la distribuzione osservata non coincide con una singola gaussiana, ma risulta dalla sovrapposizione di più curve normali che descrivono sottogruppi distinti della popolazione.\nUn’applicazione classica di questo approccio riguarda lo studio di popolazioni eterogenee. Se consideriamo, ad esempio, l’altezza di uomini e donne, possiamo assumere che ciascun gruppo segua una distribuzione normale con media e varianza proprie. La distribuzione complessiva dell’altezza nella popolazione generale sarà quindi una mistura di due gaussiane, che riflette la coesistenza di sottopopolazioni con caratteristiche differenti.\nL’idea alla base delle misture di gaussiane è dunque quella di fornire un modello flessibile capace di rappresentare situazioni in cui i dati provengono da più processi generativi sottostanti. Questo aspetto è particolarmente rilevante in psicologia, dove spesso i campioni includono soggetti appartenenti a sottogruppi differenti, non sempre immediatamente osservabili. L’utilizzo di modelli di mistura permette di identificare tali sottopopolazioni e di descriverne le proprietà con maggiore precisione, aprendo così la strada a interpretazioni più ricche e articolate dei fenomeni psicologici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_gaussian_mixture.html#introduzione",
    "href": "chapters/mcmc/09_stan_gaussian_mixture.html#introduzione",
    "title": "19  Modelli Mistura Gaussiani",
    "section": "",
    "text": "Panoramica del capitolo\n\nComprendere il ruolo dei modelli di mistura gaussiana nello studio di popolazioni eterogenee.\nSimulare dati che rappresentano due sottogruppi distinti (mindfulness e controllo).\nStimare i parametri del modello tramite inferenza bayesiana in Stan.\nValutare l’incertezza delle stime e interpretarne i risultati.\nVisualizzare la struttura latente dei dati per trarne implicazioni psicologiche.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Mindfulness and affect-network density: Does mindfulness facilitate disengagement from affective experiences in daily life? di Rowland & Wenzel (2020).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; source()\n\n# Carichiamo i pacchetti necessari\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, insight, bayesplot, ggplot2)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_gaussian_mixture.html#simulazione-dei-dati",
    "href": "chapters/mcmc/09_stan_gaussian_mixture.html#simulazione-dei-dati",
    "title": "19  Modelli Mistura Gaussiani",
    "section": "\n19.1 Simulazione dei Dati",
    "text": "19.1 Simulazione dei Dati\nPer illustrare l’uso dei modelli di mistura, ci basiamo su uno studio condotto da Rowland & Wenzel (2020), che ha indagato gli effetti di un training di mindfulness molto breve sulla consapevolezza e sull’autocontrollo percepito nella vita quotidiana. In quell’indagine i partecipanti erano suddivisi in due gruppi: il primo riceveva un addestramento alla mindfulness, mentre il secondo fungeva da gruppo di controllo. Le valutazioni erano raccolte tramite un protocollo di monitoraggio giornaliero, avviato subito dopo la prima sessione di laboratorio e protratto per quaranta giorni consecutivi.\nPer ragioni didattiche, qui non utilizziamo i dati originali, ma costruiamo una simulazione ispirata allo studio. Ci concentriamo in particolare su una delle dimensioni prese in esame, quella relativa al vissuto di tristezza (“sad”). Immaginiamo che i due gruppi mostrino distribuzioni differenti: il gruppo sottoposto a training mindfulness con una media più bassa nei giudizi di tristezza, e il gruppo di controllo con una media più elevata. Generiamo quindi due sottopopolazioni gaussiane, con la stessa deviazione standard ma con valori medi distinti, e un numero uguale di osservazioni.\nIl codice seguente crea i dati simulati, li organizza in un data frame e ne fornisce una prima esplorazione grafica tramite un istogramma dei valori standardizzati:\n\n# Parametri per le distribuzioni normali\n# Sad mindfulness\nmu_mindfulness &lt;- 20   # giudizi sad\nsigma_mindfulness &lt;- 10  # deviazione standard\n\n# Sad control\nmu_control &lt;- 60   # giudizi sad\nsigma_control &lt;- 10  # deviazione standard\n\n# Simulazione di 60 casi per ciascuna sottopopolazione\nset.seed(42)  # per la riproducibilità\nsad_mindfulness &lt;- rnorm(60, mean = mu_mindfulness, sd = sigma_mindfulness)\nsad_control &lt;- rnorm(60, mean = mu_control, sd = sigma_control)\n\n# Creazione del DataFrame per visualizzare i dati\ndati_sad &lt;- data.frame(\n  Sad = c(sad_mindfulness, sad_control),\n  Group = c(rep(\"Mindfulness\", 60), rep(\"Control\", 60))\n)\n\n# Mostra i primi e gli ultimi dati simulati\nhead(dati_sad)\n#&gt;    Sad       Group\n#&gt; 1 33.7 Mindfulness\n#&gt; 2 14.4 Mindfulness\n#&gt; 3 23.6 Mindfulness\n#&gt; 4 26.3 Mindfulness\n#&gt; 5 24.0 Mindfulness\n#&gt; 6 18.9 Mindfulness\ntail(dati_sad)\n#&gt;      Sad   Group\n#&gt; 115 43.4 Control\n#&gt; 116 56.2 Control\n#&gt; 117 54.9 Control\n#&gt; 118 87.0 Control\n#&gt; 119 46.4 Control\n#&gt; 120 61.4 Control\n\n\n# Parametri delle distribuzioni\nparametri_distribuzioni &lt;- data.frame(\n  Sottopopolazione = c(\"Mindfulness\", \"Control\"),\n  Media_mu = c(mu_mindfulness, mu_control),\n  Deviazione_Standard_sigma = c(sigma_mindfulness, sigma_control)\n)\n\nprint(parametri_distribuzioni)\n#&gt;   Sottopopolazione Media_mu Deviazione_Standard_sigma\n#&gt; 1      Mindfulness       20                        10\n#&gt; 2          Control       60                        10\n\n\n# Standardizzazione dei dati\ndati_sad$Sad_z &lt;- scale(dati_sad$Sad)\n\n# Creazione dell'istogramma per i dati standardizzati\nggplot(dati_sad, aes(x = Sad_z)) +\n  geom_histogram(\n    bins = 20\n  ) +\n  labs(\n    x = \"Giudizi 'Sad' Standardizzati\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\nL’istogramma mostra come i dati simulati non seguano una singola distribuzione normale, ma rivelino piuttosto la presenza di due sottopopolazioni sovrapposte, coerenti con la distinzione tra gruppo mindfulness e gruppo di controllo.\n\n19.1.1 Codice Stan\nIl seguente codice Stan è stato ripreso dallo studio di Michael Betancourt Identifying Bayesian Mixture Models e fornisce un’implementazione essenziale di un modello di mistura di due distribuzioni gaussiane:\n\n# Imposta il percorso al file Stan\nstan_file &lt;- file.path(here(\"stan\", \"bimodal_model.stan\"))\n\n# Compila il modello\nmodel &lt;- cmdstan_model(stan_file)\n\nLa struttura del modello segue la logica tipica di Stan, articolandosi nei blocchi di definizione dei dati, dei parametri e del modello vero e proprio. Nel blocco data vengono introdotte le osservazioni: il numero totale dei dati, indicato con \\(N\\), e il vettore \\(y\\), che raccoglie i valori osservati. Si tratta quindi dell’informazione empirica che vogliamo interpretare attraverso la mistura.\n\nmodel$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;\n#&gt;   vector[N] y;\n#&gt; }\n#&gt; parameters {\n#&gt;   ordered[2] mu;\n#&gt;   array[2] real&lt;lower=0&gt; sigma;\n#&gt;   real&lt;lower=0, upper=1&gt; theta;\n#&gt; }\n#&gt; model {\n#&gt;   sigma ~ normal(0, 2);\n#&gt;   mu ~ normal(0, 2);\n#&gt;   theta ~ beta(5, 5);\n#&gt;   for (n in 1 : N) \n#&gt;     target += log_mix(theta, normal_lpdf(y[n] | mu[1], sigma[1]),\n#&gt;                       normal_lpdf(y[n] | mu[2], sigma[2]));\n#&gt; }\n\nIl blocco parameters specifica le quantità ignote da stimare. In primo luogo compaiono le due medie \\(\\mu\\), dichiarate come vettore ordinato: questa scelta tecnica, che impone la condizione \\(\\mu_1 \\leq \\mu_2\\), evita problemi di identificabilità che potrebbero emergere se i due componenti della mistura fossero liberi di scambiarsi di posizione. Seguono le deviazioni standard \\(\\sigma\\), che devono assumere valori positivi, e infine il parametro \\(\\theta\\), vincolato all’intervallo compreso tra 0 e 1, che rappresenta la proporzione di osservazioni attribuibili al primo componente della mistura.\nIl cuore del modello si trova nel blocco model, dove vengono specificate le distribuzioni a priori e la funzione di verosimiglianza. Alle medie e alle deviazioni standard si assegna una distribuzione normale con media zero e deviazione standard pari a 2, che esprime aspettative flessibili ma non eccessivamente diffuse sui valori plausibili di questi parametri. Al parametro di mescolamento \\(\\theta\\) si assegna invece una distribuzione Beta(5,5), centrata su 0.5, che riflette un’aspettativa iniziale di equilibrio tra le due componenti senza però escludere altre configurazioni.\nPer ciascuna osservazione \\(y[n]\\), il modello calcola la log-verosimiglianza utilizzando la funzione log_mix. Questa funzione combina la probabilità che il dato provenga dalla prima distribuzione normale, pesata con \\(\\theta\\), e quella che provenga dalla seconda distribuzione, pesata con \\(1 - \\theta\\). In questo modo il modello traduce formalmente l’idea di mistura: ogni osservazione è considerata come proveniente da due sorgenti potenziali, con probabilità rispettivamente \\(\\theta\\) e \\(1 - \\theta\\).\nIn sintesi, il modello Stan implementa un meccanismo generativo in cui i dati osservati sono trattati come campioni provenienti da una distribuzione bimodale. L’obiettivo dell’inferenza bayesiana è stimare, a partire dai dati, le medie e le deviazioni standard delle due gaussiane che compongono la mistura, insieme alla proporzione \\(\\theta\\) che determina il peso relativo dei due componenti. Questo approccio, pur nella sua semplicità, consente di catturare in modo rigoroso la presenza di sottopopolazioni latenti nei dati psicologici.\nCreiamo il dizionario con i dati nel formato richiesto da Stan.\n\n# Creazione della lista di dati per Stan\nstan_data &lt;- list(\n  N = length(dati_sad$Sad_z),\n  y = as.numeric(dati_sad$Sad_z)  # vettore numerico\n)\nstan_data\n#&gt; $N\n#&gt; [1] 120\n#&gt; \n#&gt; $y\n#&gt;   [1] -0.28517 -1.12319 -0.72150 -0.60472 -0.70369 -0.92466 -0.22432 -0.91969\n#&gt;   [9] -0.00486 -0.90586 -0.31379  0.11126 -1.48000 -0.99941 -0.93643 -0.60338\n#&gt;  [17] -1.00177 -2.02879 -1.93528 -0.30719 -1.01147 -1.64991 -0.95314 -0.35283\n#&gt;  [25] -0.05821 -1.06508 -0.99009 -1.64205 -0.67952 -1.15579 -0.68153 -0.57356\n#&gt;  [33] -0.43058 -1.14234 -0.66010 -1.62207 -1.21833 -1.24710 -1.92391 -0.86307\n#&gt;  [41] -0.78953 -1.03503 -0.55047 -1.19333 -1.47109 -0.69133 -1.22999 -0.25351\n#&gt;  [49] -1.06550 -0.59486 -0.73934 -1.21806 -0.19652 -0.60038 -0.83985 -0.75898\n#&gt;  [57] -0.58462 -0.83982 -2.17453 -0.75537  0.69405  0.93323  1.10493  1.45903\n#&gt;  [65]  0.53816  1.41696  0.99844  1.30264  1.25165  1.16513  0.40143  0.81399\n#&gt;  [73]  1.12298  0.44022  0.61803  1.10457  1.18561  1.05382  0.46955  0.37690\n#&gt;  [81]  1.50794  0.96470  0.89133  0.80070  0.33597  1.11799  0.75903  0.77391\n#&gt;  [89]  1.25712  1.20881  1.45573  0.64688  1.13460  1.45530  0.37213  0.48037\n#&gt;  [97]  0.36306  0.22129  0.88766  1.13583  1.37298  1.30535  0.41871  1.65331\n#&gt; [105]  0.56437  0.89872  0.67023  0.80007  0.93451  0.90463  0.84217  0.89983\n#&gt; [113]  0.64287  0.63474  0.13389  0.68751  0.63109  2.02278  0.26333  0.91246\n\n\n19.1.2 Campionamento\nUna volta definito il modello, possiamo procedere all’inferenza bayesiana eseguendo il campionamento MCMC.\n\nfit &lt;- model$sample(\n  data = stan_data,\n  iter_warmup = 2000,\n  iter_sampling = 2000,\n  seed = 123,\n  refresh = 0   \n)\n\nIl campionamento produce migliaia di estrazioni dalla distribuzione a posteriori dei parametri. Un primo passo per la valutazione della bontà del modello consiste nell’ispezione delle catene MCMC, che consente di verificare la loro convergenza e la stabilità delle stime.\n\n# Traceplot per i parametri di interesse\nmcmc_trace(as_draws_array(fit$draws(c(\"mu\", \"sigma\", \"theta\"))))\n\n\n\n\n\n\n\n\n19.1.3 Risultati\nPossiamo poi riassumere le distribuzioni a posteriori dei parametri principali del modello, ovvero le medie, le deviazioni standard e la proporzione di mescolamento.\n\nfit$summary(variables = c(\"mu\", \"sigma\", \"theta\"))\n#&gt; # A tibble: 5 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu[1]    -0.858 -0.868 0.101 0.091 -1.001 -0.679 1.002 3141.500 2608.342\n#&gt; 2 mu[2]     0.883  0.886 0.070 0.066  0.766  0.996 1.000 6778.401 5781.664\n#&gt; 3 sigma[1]  0.550  0.539 0.082 0.074  0.439  0.699 1.001 3935.774 3249.503\n#&gt; 4 sigma[2]  0.425  0.420 0.054 0.052  0.346  0.521 1.000 4739.147 4983.220\n#&gt; 5 theta     0.507  0.505 0.054 0.052  0.422  0.599 1.000 4136.772 3356.066\n\nPer visualizzare meglio i risultati, possiamo rappresentare la distribuzione bimodale ricostruita a partire dai valori medi posteriori.\n\n# Posterior estimates (da output Stan, qui inseriti manualmente come nell’esempio Python)\nmu_0 &lt;- -0.859\nmu_1 &lt;-  0.942\nsigma_0 &lt;- 0.468\nsigma_1 &lt;- 0.390\ntheta &lt;- 0.520  # Probabilità del primo componente\n\n# Simulazione dati dalla distribuzione mista (per esempio 1000 campioni)\nset.seed(42)\ndata &lt;- c(\n  rnorm(1000 * theta, mean = mu_0, sd = sigma_0),\n  rnorm(1000 * (1 - theta), mean = mu_1, sd = sigma_1)\n)\n\n# Densità teorica della mixture\nx &lt;- seq(min(data), max(data), length.out = 1000)\nkde &lt;- theta * dnorm(x, mean = mu_0, sd = sigma_0) +\n       (1 - theta) * dnorm(x, mean = mu_1, sd = sigma_1)\n\n# Scala la densità per l’istogramma (conteggi, non densità)\nbinwidth &lt;- (max(data) - min(data)) / 50\nhist_area &lt;- length(data) * binwidth\nkde_scaled &lt;- kde * hist_area\n\n# Plot\nggplot(data.frame(x = data), aes(x)) +\n  geom_histogram(bins = 50, fill = \"skyblue\", alpha = 0.6, color = \"black\") +\n  geom_line(data = data.frame(x, y = kde_scaled), aes(x, y),\n            color = \"black\", size = 1) +\n  labs(\n    x = \"Sadness Score\", y = \"Counts\"\n  )\n\n\n\n\n\n\n\nIl confronto tra l’istogramma dei dati simulati e la curva della distribuzione stimata mostra una sovrapposizione molto convincente, segno che il modello è riuscito a cogliere correttamente la struttura bimodale dei dati.\nPoiché i dati erano stati standardizzati prima dell’analisi, possiamo ricondurre i parametri stimati alla scala originale dei punteggi per ottenere una lettura più intuitiva.\n\n# Media e deviazione standard della distribuzione originale\nmean_original &lt;- mean(dati_sad$Sad)\nstd_original  &lt;- sd(dati_sad$Sad)\n\n# Parametri posteriori delle distribuzioni standardizzate\nmu_0_standardized &lt;- -0.859\nmu_1_standardized &lt;-  0.942\nsigma_0_standardized &lt;- 0.468\nsigma_1_standardized &lt;- 0.390\n\n# Conversione dei parametri alla scala originale\nmu_0_original &lt;- mu_0_standardized * std_original + mean_original\nmu_1_original &lt;- mu_1_standardized * std_original + mean_original\nsigma_0_original &lt;- sigma_0_standardized * std_original\nsigma_1_original &lt;- sigma_1_standardized * std_original\n\n# Stampa dei risultati\ncat(\n  sprintf(\"Media a posteriori della prima sottopopolazione: %.2f\\n\", mu_0_original),\n  sprintf(\"Media a posteriori della seconda sottopopolazione: %.2f\\n\", mu_1_original),\n  sprintf(\"Deviazione standard a posteriori della prima sottopopolazione: %.2f\\n\", sigma_0_original),\n  sprintf(\"Deviazione standard a posteriori della seconda sottopopolazione: %.2f\\n\", sigma_1_original)\n)\n#&gt; Media a posteriori della prima sottopopolazione: 20.46\n#&gt;  Media a posteriori della seconda sottopopolazione: 62.05\n#&gt;  Deviazione standard a posteriori della prima sottopopolazione: 10.81\n#&gt;  Deviazione standard a posteriori della seconda sottopopolazione: 9.01\n\nIl confronto con i valori utilizzati per simulare i dati (\\(\\mu = 20\\) e \\(\\mu = 60\\), con \\(\\sigma = 10\\) in entrambi i gruppi) evidenzia una corrispondenza molto buona. Questo risultato è particolarmente significativo se si considera che il modello non riceveva alcuna informazione esplicita sull’appartenenza di ciascun individuo a un gruppo. In altre parole, è stato in grado di individuare autonomamente le due sottopopolazioni e di stimarne i parametri con precisione.\nDal punto di vista sostantivo, questo esempio didattico ci permette di riflettere sulla questione posta nello studio di Rowland & Wenzel (2020). Se in una popolazione eterogenea esistono gruppi che reagiscono in modo diverso a un intervento psicologico, come nel caso del training di mindfulness, i modelli di mistura offrono uno strumento potente per identificare tali differenze senza dover disporre a priori di una classificazione. Nel nostro caso, il modello ha permesso di distinguere chiaramente il gruppo sottoposto a mindfulness da quello di controllo sulla base dei punteggi di tristezza. Ciò illustra in termini concreti come le tecniche bayesiane di mistura possano contribuire a svelare strutture latenti nei dati psicologici, rendendo visibili effetti che altrimenti rischierebbero di rimanere nascosti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_gaussian_mixture.html#riflessioni-conlusive",
    "href": "chapters/mcmc/09_stan_gaussian_mixture.html#riflessioni-conlusive",
    "title": "19  Modelli Mistura Gaussiani",
    "section": "\n19.2 Riflessioni conlusive",
    "text": "19.2 Riflessioni conlusive\nIn questo capitolo abbiamo visto come i modelli di mistura gaussiana possano essere applicati con successo a dati psicologici che nascondono una struttura eterogenea. Partendo da una simulazione ispirata allo studio di Rowland & Wenzel (2020), abbiamo mostrato come l’approccio bayesiano consenta di stimare in modo accurato i parametri di due sottopopolazioni distinte sulla base dei giudizi di tristezza.\nIl risultato più rilevante è che il modello è stato in grado di distinguere i due gruppi senza alcuna informazione preventiva sulla loro appartenenza. Questo aspetto è cruciale in psicologia, dove spesso non si dispone di criteri netti per separare sottogruppi di individui, ma dove le differenze emergono come pattern latenti nei dati. L’inferenza bayesiana applicata ai modelli di mistura permette non solo di stimare questi pattern, ma anche di quantificare l’incertezza che li accompagna, fornendo quindi una base solida per le interpretazioni teoriche.\nDal punto di vista sostantivo, la lezione che possiamo trarre è che la variabilità osservata nei dati psicologici non deve essere considerata un semplice “rumore”, ma può riflettere la presenza di processi distinti che operano all’interno della popolazione. Proprio come nel nostro esempio, in cui il gruppo mindfulness mostrava livelli inferiori di tristezza rispetto al gruppo di controllo, i modelli di mistura offrono un mezzo per far emergere tali differenze anche in assenza di etichette esplicite.\nIn conclusione, i modelli di mistura gaussiana rappresentano uno strumento prezioso per lo psicologo che desidera andare oltre le analisi aggregate e indagare la complessità intrinseca dei fenomeni psicologici. Essi consentono di riconoscere la presenza di sottogruppi latenti, di stimarne le caratteristiche e di aprire così nuove prospettive interpretative sui dati, in linea con la crescente attenzione della ricerca contemporanea alla diversità interindividuale e alle dinamiche contestuali che influenzano l’esperienza umana.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_gaussian_mixture.html#bibliografia",
    "href": "chapters/mcmc/09_stan_gaussian_mixture.html#bibliografia",
    "title": "19  Modelli Mistura Gaussiani",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRowland, Z., & Wenzel, M. (2020). Mindfulness and affect-network density: Does mindfulness facilitate disengagement from affective experiences in daily life? Mindfulness, 11, 1253–1266.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_nuisance_parameters.html",
    "href": "chapters/mcmc/10_stan_nuisance_parameters.html",
    "title": "20  Modelli con più di un parametro",
    "section": "",
    "text": "Introduzione\nIn molte situazioni statistiche ci troviamo di fronte a modelli che includono più parametri incogniti. Tuttavia, non tutti questi parametri hanno lo stesso rilievo interpretativo: spesso l’interesse dell’analisi si concentra su uno o pochi di essi, mentre gli altri, pur essendo indispensabili per descrivere correttamente i dati, vengono considerati secondari. Questi ultimi prendono il nome di parametri di disturbo (nuisance parameters).\nL’obiettivo di un’analisi bayesiana è in genere quello di ottenere la distribuzione marginale a posteriori dei parametri di interesse. Per farlo, esistono due strategie. La prima consiste nel calcolare la distribuzione congiunta a posteriori di tutti i parametri e successivamente integrare, in modo analitico o numerico, rispetto a quelli di disturbo. Si tratta di un metodo formalmente corretto, ma spesso poco praticabile: nei modelli realistici l’integrazione può diventare estremamente complessa.\nLa seconda strategia, oggi la più diffusa, sfrutta le tecniche di simulazione. Attraverso il campionamento MCMC (Markov Chain Monte Carlo) è possibile generare campioni dalla distribuzione congiunta a posteriori e, in fase di analisi, focalizzarsi solo sui parametri di interesse, ignorando i campioni relativi a quelli di disturbo. Questo approccio ha il vantaggio di essere facilmente applicabile anche in modelli complessi, dove l’integrazione analitica sarebbe impraticabile.\nIn questo capitolo prenderemo in esame un esempio concreto che illustra il ruolo dei parametri di interesse e di quelli di disturbo. Immaginiamo uno studio che valuti l’efficacia di un intervento cognitivo, come un programma di training per la memoria di lavoro. Il nostro scopo sarà stimare la differenza nei punteggi medi di un test tra il gruppo che ha ricevuto l’intervento e quello di controllo. Le capacità cognitive di base dei partecipanti, pur influenzando i punteggi, non sono l’oggetto centrale dell’indagine: saranno dunque trattate come parametri di disturbo. Attraverso la marginalizzazione, potremo concentrare l’attenzione sull’effetto dell’intervento, mantenendo al tempo stesso la complessità necessaria per una descrizione realistica dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Modelli con più di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_nuisance_parameters.html#introduzione",
    "href": "chapters/mcmc/10_stan_nuisance_parameters.html#introduzione",
    "title": "20  Modelli con più di un parametro",
    "section": "",
    "text": "Panoramica del capitolo\n\nComprendere il concetto di parametri di disturbo e il loro ruolo nei modelli statistici.\nSimulare dati che includono sia parametri di interesse sia parametri di disturbo.\nSpecificare un modello bayesiano in Stan per stimare l’effetto di un intervento cognitivo.\nOttenere la distribuzione a posteriori del parametro di interesse marginalizzando i parametri di disturbo.\nInterpretare i risultati in termini psicologici, collegandoli all’efficacia dell’intervento.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nConsultare il terzo capitolo di Bayesian Data Analysis (Gelman et al., 2013).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; source()\n\n# Carichiamo i pacchetti necessari\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, insight, bayesplot, ggplot2)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Modelli con più di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_nuisance_parameters.html#stima-delleffetto-di-un-intervento-cognitivo-sui-punteggi-dei-test",
    "href": "chapters/mcmc/10_stan_nuisance_parameters.html#stima-delleffetto-di-un-intervento-cognitivo-sui-punteggi-dei-test",
    "title": "20  Modelli con più di un parametro",
    "section": "\n20.1 Stima dell’effetto di un intervento cognitivo sui punteggi dei test",
    "text": "20.1 Stima dell’effetto di un intervento cognitivo sui punteggi dei test\nImmaginiamo di voler valutare l’efficacia di un programma di potenziamento cognitivo, ad esempio un training progettato per migliorare la memoria di lavoro. Per testarne l’impatto, dividiamo i partecipanti in due gruppi: il primo riceve l’intervento, mentre il secondo funge da gruppo di controllo. L’obiettivo principale è stimare la differenza nei punteggi medi dei test tra i due gruppi dopo l’intervento.\nÈ chiaro, tuttavia, che i punteggi non dipendono unicamente dall’intervento. Essi riflettono anche le differenze individuali nelle capacità cognitive di base, i diversi livelli di motivazione e altri fattori casuali o di misurazione. Se ignorassimo questa complessità, rischieremmo di attribuire impropriamente all’intervento effetti che in realtà derivano da caratteristiche individuali.\nPer questo motivo, distinguiamo tra parametri di interesse e parametri di disturbo. La differenza tra le medie dei due gruppi, \\(\\delta = \\mu_1 - \\mu_2\\), rappresenta il cuore dell’analisi: è il parametro che quantifica l’effetto medio dell’intervento. Le abilità cognitive individuali dei partecipanti, indicate con \\(\\theta_j\\), e la variabilità residua dei punteggi, rappresentata da \\(\\sigma_y\\), vengono invece considerate parametri di disturbo. Pur non essendo oggetto diretto dell’indagine, essi sono indispensabili per costruire un modello realistico e per isolare correttamente l’effetto dell’intervento.\nIl modello assume che il punteggio di ciascun partecipante \\(y_{ij}\\) derivi dalla combinazione di due componenti: un effetto di gruppo, che riflette l’appartenenza al gruppo di intervento o di controllo, e un effetto individuale, che cattura le differenze nelle capacità cognitive di base. Formalmente, i punteggi sono distribuiti normalmente con media \\(\\mu_i + \\theta_j\\) e varianza \\(\\sigma_y^2\\). In questo quadro, \\(\\mu_1\\) e \\(\\mu_2\\) descrivono i punteggi medi dei due gruppi, \\(\\theta_j\\) rappresenta la deviazione di ciascun individuo rispetto al valore atteso in base al gruppo, mentre \\(\\sigma_y\\) esprime la variabilità residua non spiegata.\nIn Stan, questo modello viene implementato nel seguente modo:\n\n# Imposta il percorso al file Stan\nstan_file &lt;- file.path(here(\"stan\", \"nuisance_params_model.stan\"))\n\n# Compila il modello\nmodel &lt;- cmdstan_model(stan_file)\n\ndata {\n  int&lt;lower=0&gt; N1; // Number of participants in group 1 (intervention)\n  int&lt;lower=0&gt; N2; // Number of participants in group 2 (control)\n  array[N1] real y1; // Test scores for group 1\n  array[N2] real y2; // Test scores for group 2\n}\nparameters {\n  real mu1; // Mean test score for group 1\n  real mu2; // Mean test score for group 2\n  real&lt;lower=0&gt; sigma_y; // Standard deviation of test scores\n  real&lt;lower=0&gt; sigma_theta; // Standard deviation of baseline cognitive ability\n  array[N1 + N2] real theta; // Baseline cognitive abilities for all participants\n}\nmodel {\n  // Priors\n  mu1 ~ normal(0, 10);\n  mu2 ~ normal(0, 10);\n  sigma_y ~ normal(0, 5);\n  sigma_theta ~ normal(0, 5);\n  \n  for (j in 1 : (N1 + N2)) {\n    theta[j] ~ normal(0, sigma_theta); // Random effects for baseline abilities\n  }\n  \n  // Likelihood\n  for (j in 1 : N1) {\n    y1[j] ~ normal(mu1 + theta[j], sigma_y);\n  }\n  \n  for (j in 1 : N2) {\n    y2[j] ~ normal(mu2 + theta[N1 + j], sigma_y);\n  }\n}\ngenerated quantities {\n  real delta = mu1 - mu2; // Difference in means\n}\nLa specificazione del modello chiarisce quindi che il punteggio osservato di ciascun partecipante è la somma di un effetto comune al gruppo di appartenenza e di un effetto individuale. Il parametro di interesse, \\(\\delta\\), emerge come differenza tra le medie dei due gruppi, mentre i parametri individuali \\(\\theta_j\\) e la variabilità residua \\(\\sigma_y\\) fungono da variabili di supporto: non sono il focus dell’analisi, ma permettono di tener conto della complessità reale dei dati.\nEsaminiamo ora più da vicino la struttura del modello Stan, che traduce formalmente quanto discusso finora. I partecipanti sono suddivisi in due gruppi: il Gruppo 1 (intervento), che ha seguito il programma cognitivo, e il Gruppo 2 (controllo), che non lo ha ricevuto. Ognuno di essi fornisce un punteggio al test, e il modello assume che questo punteggio sia influenzato da due componenti principali: un effetto legato al gruppo di appartenenza e un effetto legato alle caratteristiche individuali.\nLa componente di gruppo descrive la tendenza media dei partecipanti a seconda del gruppo a cui appartengono. In Stan, essa viene rappresentata da due parametri, \\(\\mu_1\\) e \\(\\mu_2\\), che corrispondono rispettivamente alla media del gruppo di intervento e a quella del gruppo di controllo. La differenza tra queste due medie, \\(\\delta = \\mu_1 - \\mu_2\\), è il parametro di interesse, perché quantifica l’effetto medio dell’intervento cognitivo.\nAccanto a questo effetto, il modello include una componente individuale, che cattura le differenze tra i partecipanti. Ogni individuo possiede infatti abilità cognitive di base che non sono direttamente osservabili ma che influenzano le sue prestazioni. Queste abilità vengono modellate come effetti casuali, \\(\\theta_j\\), che rappresentano deviazioni individuali rispetto al valore atteso in base al gruppo. In Stan, i \\(\\theta_j\\) sono trattati come parametri distribuiti normalmente attorno a zero, con deviazione standard \\(\\sigma_\\theta\\), che misura la variabilità delle abilità cognitive di base nella popolazione.\nOltre a questi termini, il modello prevede anche un parametro \\(\\sigma_y\\), che rappresenta la variabilità residua nei punteggi dei test. Questo termine raccoglie tutte le fonti di variazione non spiegate dall’appartenenza al gruppo o dalle abilità cognitive individuali, come ad esempio errori di misurazione o fluttuazioni momentanee nella prestazione.\nDal punto di vista bayesiano, \\(\\theta_j\\) e \\(\\sigma_y\\) sono considerati parametri di disturbo: non sono il focus dell’analisi, ma sono necessari per rendere il modello realistico. La loro presenza ci consente di stimare in maniera corretta l’effetto dell’intervento, evitando di confondere differenze individuali o errori casuali con un effetto sistematico del trattamento.\nL’obiettivo finale è stimare la distribuzione a posteriori di \\(\\delta\\), la differenza tra le medie dei due gruppi. Per farlo, non occorre calcolare direttamente l’integrazione rispetto ai parametri di disturbo: grazie al campionamento MCMC, possiamo ottenere campioni dalla distribuzione congiunta di tutti i parametri e, in fase di analisi, concentrare l’attenzione solo su \\(\\delta\\). In questo senso, i parametri di disturbo vengono “marginalizzati” automaticamente, lasciandoci l’informazione essenziale sul parametro di interesse.\nIn sintesi, il modello Stan traduce in termini formali un’idea intuitiva: i punteggi dei partecipanti possono essere spiegati come la somma di un effetto di gruppo (dovuto all’intervento o al controllo) e di un effetto individuale (dovuto alle abilità cognitive di base). L’analisi bayesiana ci permette di isolare l’effetto dell’intervento tenendo conto di queste differenze individuali, e di quantificare l’incertezza associata alla stima.\n\n20.1.1 Dati\nPer comprendere meglio il funzionamento del modello, è utile partire da una simulazione. In questo modo possiamo controllare i parametri “veri” che generano i dati e verificare se il modello bayesiano è in grado di recuperarli in fase di stima. L’idea è quella di creare due gruppi di partecipanti, uno che ha ricevuto l’intervento e uno di controllo, attribuendo a ciascun gruppo un punteggio medio atteso diverso. A questi valori aggiungiamo sia la variabilità individuale, legata alle abilità cognitive di base, sia una componente di rumore residuo, che riflette errori di misurazione e altri fattori non osservati.\nNella simulazione, fissiamo la media “vera” dei punteggi a 10 per il gruppo di intervento e a 8 per il gruppo di controllo. Le abilità cognitive di base di ciascun partecipante vengono generate da una distribuzione normale centrata su zero, mentre la variabilità residua nei punteggi è controllata da una deviazione standard comune a entrambi i gruppi. In questo modo otteniamo un campione di dati che riflette sia le differenze tra i gruppi sia l’eterogeneità individuale dei partecipanti.\nIl codice seguente mostra come generare i dati e prepararli per l’analisi in Stan:\n\n# Imposta il seme per la riproducibilità\nset.seed(42)\n\n# Parametri della simulazione\nN1 &lt;- 50   # Numero di partecipanti nel gruppo 1 (intervento)\nN2 &lt;- 50   # Numero di partecipanti nel gruppo 2 (controllo)\n\nmu1_true &lt;- 10  # Media \"vera\" dei punteggi test per il gruppo 1\nmu2_true &lt;- 8   # Media \"vera\" dei punteggi test per il gruppo 2\nsigma_y_true &lt;- 2     # Deviazione standard \"vera\" dei punteggi test\nsigma_theta_true &lt;- 1 # Deviazione standard \"vera\" delle abilità cognitive di base\n\n# Simulazione delle abilità cognitive di base per tutti i partecipanti\ntheta &lt;- rnorm(N1 + N2, mean = 0, sd = sigma_theta_true)\n\n# Simulazione dei punteggi test per il gruppo 1 (intervento)\ny1 &lt;- rnorm(N1, mean = mu1_true + theta[1:N1], sd = sigma_y_true)\n\n# Simulazione dei punteggi test per il gruppo 2 (controllo)\ny2 &lt;- rnorm(N2, mean = mu2_true + theta[(N1 + 1):(N1 + N2)], sd = sigma_y_true)\n\n# Creazione della lista per Stan\nstan_data &lt;- list(\n  N1 = N1,\n  N2 = N2,\n  y1 = y1,\n  y2 = y2\n)\n\n# Output dei dati simulati per verifica\nglimpse(stan_data)\n#&gt; List of 4\n#&gt;  $ N1: num 50\n#&gt;  $ N2: num 50\n#&gt;  $ y1: num [1:50] 13.77 11.52 8.36 14.33 9.07 ...\n#&gt;  $ y2: num [1:50] 8.24 4.11 11.91 8.1 7.15 ...\n\nQuesti dati costituiscono la base su cui applicheremo il modello bayesiano: sappiamo in partenza che la differenza “vera” tra le medie dei due gruppi è pari a 2, e potremo verificare se l’inferenza basata sul campionamento MCMC riesce a recuperare questo valore entro la distribuzione a posteriori di \\(\\delta\\).\n\n20.1.2 Campionamento e Sintesi della Distribuzione a Posteriori\nUna volta simulati i dati e definito il modello in Stan, possiamo passare alla fase centrale dell’analisi: il campionamento dalla distribuzione a posteriori. Questo passaggio permette di stimare i parametri del modello non come singoli valori puntuali, ma come distribuzioni che riflettono l’incertezza delle nostre inferenze.\n\nfit &lt;- model$sample(\n  data = stan_data,\n  iter_warmup = 2000,\n  iter_sampling = 2000,\n  seed = 123,\n  refresh = 0   \n)\n\nL’algoritmo MCMC genera catene di valori simulati per ciascun parametro del modello. Per verificarne la qualità, una prima ispezione utile è il traceplot, che mostra l’andamento delle catene e permette di controllare la loro stabilità e la convergenza.\n\n# Traceplot per i parametri di interesse\nmcmc_trace(as_draws_array(fit$draws(c(\"delta\"))))\n\n\n\n\n\n\n\nUn traceplot ben miscelato, senza trend o pattern evidenti, indica che le catene stanno esplorando in maniera efficace lo spazio dei parametri. Nel nostro caso, ciò significa che stiamo ottenendo campioni affidabili della distribuzione a posteriori di \\(\\delta\\), cioè della differenza tra le medie dei due gruppi.\nDopo l’ispezione visiva, possiamo sintetizzare numericamente i risultati ottenuti.\n\nfit$summary(variables = c(\"delta\"))\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 delta    1.613  1.606 0.440 0.454 0.914 2.337 1.009  677.927 2598.255\n\nIl sommario restituisce alcune informazioni chiave: la media a posteriori, che rappresenta la stima centrale di \\(\\delta\\); gli intervalli di credibilità, che quantificano l’incertezza della stima; e gli indici diagnostici, che ci rassicurano sulla correttezza del campionamento.\nPoiché i dati sono stati simulati con una differenza reale tra i due gruppi pari a 2 punti, possiamo confrontare questo valore con la distribuzione a posteriori ottenuta. Se il modello funziona correttamente, la stima media di \\(\\delta\\) dovrebbe essere vicina a 2 e gli intervalli di credibilità dovrebbero includere questo valore. In questo modo, la simulazione conferma che l’approccio bayesiano è in grado di recuperare il parametro di interesse anche in presenza di variabilità individuale e di parametri di disturbo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Modelli con più di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_nuisance_parameters.html#riflessioni-conclusive",
    "href": "chapters/mcmc/10_stan_nuisance_parameters.html#riflessioni-conclusive",
    "title": "20  Modelli con più di un parametro",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’analisi svolta in questo capitolo ha mostrato come, in un contesto bayesiano, sia possibile distinguere tra parametri di interesse e parametri di disturbo, concentrandosi sui primi senza trascurare la complessità introdotta dai secondi. Nel nostro esempio, l’obiettivo era stimare l’effetto medio di un intervento cognitivo, espresso dalla differenza \\(\\delta\\) tra le medie dei due gruppi. Per farlo, abbiamo incluso nel modello anche le abilità cognitive individuali e la variabilità residua, che pur non essendo il fulcro dell’analisi, erano necessarie per rappresentare fedelmente la generazione dei dati.\nL’approccio seguito è strettamente legato a quello dei modelli gerarchici. Entrambi, infatti, riconoscono che le differenze individuali non sono un dettaglio trascurabile, ma una componente strutturale dei dati. Nei modelli gerarchici, questa visione è incorporata fin dall’inizio, attraverso una struttura che lega in modo esplicito i diversi livelli di variazione (tra gruppi, tra individui, entro individuo). La marginalizzazione, invece, mette in evidenza il processo attraverso cui i parametri di disturbo vengono “integrati via” a posteriori, lasciando al centro della scena solo il parametro di interesse.\nIn termini pratici, i due approcci conducono a risultati simili per quanto riguarda la stima di \\(\\delta\\), ma differiscono nella prospettiva: la marginalizzazione è una tecnica mirata a isolare il parametro di interesse, mentre i modelli gerarchici offrono un quadro più generale e flessibile, capace di estendersi facilmente a strutture di dati più complesse. Questo spiega perché, nella ricerca psicologica, i modelli gerarchici siano oggi particolarmente diffusi: permettono di incorporare nuove fonti di variazione, di modellare la dipendenza tra osservazioni e di affrontare in modo naturale dati annidati o longitudinali.\nIl messaggio principale è che l’approccio bayesiano ci consente di stimare parametri di interesse come l’effetto di un intervento cognitivo senza ignorare i fattori che contribuiscono alla variabilità dei dati. I parametri di disturbo non sono un ostacolo, ma parte integrante della modellizzazione: anche se non vengono interpretati direttamente, sono fondamentali per garantire che l’inferenza sul parametro centrale — in questo caso \\(\\delta\\) — sia solida e attendibile.\nPunti chiave\n\nNei modelli complessi non tutti i parametri hanno lo stesso rilievo: alcuni, come le abilità cognitive individuali, sono parametri di disturbo che servono a rendere il modello realistico ma non sono il focus dell’analisi.\nL’approccio bayesiano consente di stimare i parametri di interesse marginalizzando quelli di disturbo: la distribuzione a posteriori di \\(\\delta\\) tiene conto dell’incertezza complessiva senza bisogno di calcoli analitici complicati.\nI modelli gerarchici rappresentano un’estensione naturale di questa logica, poiché incorporano strutture multilivello che rendono l’analisi più flessibile e adatta a dati psicologici complessi.\nConsiderare esplicitamente la variabilità individuale permette di ottenere stime più attendibili dell’effetto di un intervento e di interpretare i dati con maggiore rigore.\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Modelli con più di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_nuisance_parameters.html#bibliografia",
    "href": "chapters/mcmc/10_stan_nuisance_parameters.html#bibliografia",
    "title": "20  Modelli con più di un parametro",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Modelli con più di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "",
    "text": "Introduzione\nIn molti compiti psicologici osserviamo, per ciascun partecipante, successi/insuccessi su un certo numero di prove. Vogliamo rispondere a tre domande:\nIl modello gerarchico beta–binomiale risponde a tutte e tre, introducendo un livello di popolazione che regolarizza le stime individuali (shrinkage) e quantifica la variabilità tra soggetti.\nIl modello si fonda su tre livelli. Al primo livello, i dati osservati sono modellati come variabili binomiali: per ogni partecipante osserviamo un certo numero di risposte corrette in un numero fissato di prove. Al secondo livello, ciascuna probabilità individuale di successo è considerata non come un valore fisso, ma come un’estrazione da una distribuzione Beta comune a tutti i partecipanti. Al terzo livello, i parametri della distribuzione Beta, che descrivono la tendenza centrale e la variabilità tra le probabilità individuali, sono essi stessi trattati come incerti e stimati dai dati attraverso delle distribuzioni a priori.\nUn modo intuitivo di interpretare questi iperparametri è attraverso la parametrizzazione in termini di media e concentrazione. La media rappresenta la probabilità di successo tipica nella popolazione, mentre la concentrazione descrive quanto le probabilità individuali tendono a essere simili tra loro oppure a differenziarsi. Valori alti della concentrazione implicano che le probabilità dei singoli partecipanti sono molto vicine alla media di popolazione; valori bassi indicano invece una maggiore eterogeneità. Questa riformulazione semplifica la scelta delle distribuzioni a priori e rende più immediata l’interpretazione psicologica dei risultati.\nDal punto di vista inferenziale, il modello consente di ottenere contemporaneamente stime individuali e stime di popolazione. Le prime beneficiano del fenomeno noto come shrinkage: le probabilità di successo di ciascun partecipante non vengono stimate isolatamente, ma vengono “attirate” verso la media di popolazione, con un’intensità che dipende dalla quantità di dati disponibili per quel partecipante. Questo meccanismo evita che pochi tentativi producano stime estreme e instabili, rendendo più robuste le conclusioni. Le seconde, cioè le stime di popolazione, forniscono una descrizione sintetica della distribuzione delle abilità e permettono di valutare se la prestazione media del gruppo si discosta da ciò che ci si attenderebbe dal puro caso.\nIn questo capitolo vedremo come costruire e stimare un modello gerarchico beta-binomiale con Stan, applicandolo a dati reali tratti dalla letteratura. L’analisi mostrerà non solo come implementare tecnicamente il modello, ma anche come interpretare i risultati a livello individuale e collettivo, evidenziando il ruolo centrale della struttura gerarchica nell’affrontare in maniera coerente la variabilità dei dati psicologici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html#introduzione",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html#introduzione",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "",
    "text": "(Q1) qual è la probabilità di successo per ogni individuo?\n(Q2) come variano queste probabilità nella popolazione (media e dispersione)?\n(Q3) date poche prove, come evitare stime estreme e instabili?\n\n\n\n\n\n\nPanoramica del capitolo\n\nSpecificare un modello beta–binomiale gerarchico.\nSpiegare il ruolo di media di popolazione (μ) e concentrazione (κ).\nInterpretare lo shrinkage e collegarlo al numero di prove per soggetto.\nLeggere le principali diagnostiche MCMC.\nConfrontare la prestazione media con un valore di riferimento (es. 0.5).\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, dplyr, tibble, stringr)\nconflicts_prefer(posterior::ess_bulk)\nconflicts_prefer(posterior::ess_tail)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html#motivazione-per-i-modelli-gerarchici-bayesiani",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html#motivazione-per-i-modelli-gerarchici-bayesiani",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "\n21.1 Motivazione per i modelli gerarchici bayesiani",
    "text": "21.1 Motivazione per i modelli gerarchici bayesiani\nQuando si lavora con dati psicologici raccolti da più individui, occorre bilanciare l’attenzione alle differenze individuali con la necessità di trarre conclusioni valide a livello di popolazione. I modelli gerarchici bayesiani offrono un quadro naturale per farlo, perché stimano simultaneamente i parametri dei singoli partecipanti e quelli che descrivono l’intera popolazione.\nL’idea di fondo è che ogni individuo fornisca informazioni non solo sul proprio comportamento, ma anche su come i comportamenti si distribuiscono in un gruppo più ampio. Così, ad esempio, se un partecipante ha poche prove, la stima della sua probabilità di successo non si basa soltanto sui suoi dati, ma viene informata anche dalle prestazioni degli altri. Questo meccanismo riduce il rischio di sovrainterpretare fluttuazioni casuali e produce stime più stabili. Allo stesso tempo, i dati di ciascun individuo migliorano la conoscenza dei parametri di popolazione, che a loro volta diventano un punto di riferimento per le inferenze sui singoli.\nDal punto di vista concettuale, i modelli gerarchici si distinguono dai modelli semplici perché la distribuzione a priori dei parametri individuali non è fissata una volta per tutte, ma è definita da iperparametri che descrivono l’intera popolazione. Si crea così una catena di inferenza: prima si apprende sui parametri di popolazione, poi si usano queste informazioni per affinare le stime individuali. La gerarchia riflette quindi una visione coerente con la realtà psicologica, in cui gli individui sono simili ma non identici, e le loro differenze sono interpretate alla luce di una struttura comune.\nQuesto duplice livello di inferenza è cruciale perché consente di distinguere tra variazioni casuali attribuibili al singolo partecipante e tendenze generali che riflettono caratteristiche della popolazione. Sapere, ad esempio, che le probabilità individuali di successo variano attorno a una media comune permette di collocare ogni individuo in un contesto più ampio, evitando interpretazioni basate solo sulle sue risposte.\nUn vantaggio decisivo dei modelli gerarchici è che l’inferenza a livello di popolazione va oltre i partecipanti effettivamente osservati: conoscere i parametri che governano la distribuzione delle abilità, preferenze o probabilità di risposta consente di prevedere nuovi soggetti non inclusi nello studio, ampliando la portata delle conclusioni. In questo senso, i parametri di popolazione diventano strumenti predittivi: indicano quale variabilità aspettarsi in futuri studi e offrono un quadro generale delle prestazioni nel dominio indagato.\nDal punto di vista pratico, questo approccio ha un valore evidente. I ricercatori sono spesso interessati non solo a “questi” partecipanti, ma alla popolazione di provenienza. Un modello gerarchico risponde a questa esigenza fornendo stime dei parametri superiori su cui basare generalizzazioni affidabili. In sintesi, la motivazione per l’uso dei modelli gerarchici bayesiani risiede nella loro capacità di sfruttare l’informazione condivisa tra individui, migliorare la precisione delle stime individuali, ridurre la sensibilità al rumore campionario e, allo stesso tempo, fornire una descrizione generale della popolazione di interesse—integrando in un unico quadro coerente informazione individuale e collettiva e arricchendo sia l’interpretazione teorica sia la rilevanza applicativa dei risultati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html#struttura-gerarchica-dei-dati",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html#struttura-gerarchica-dei-dati",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "\n21.2 Struttura gerarchica dei dati",
    "text": "21.2 Struttura gerarchica dei dati\nPer comprendere meglio il funzionamento di un modello gerarchico, è utile considerare come i dati psicologici siano spesso organizzati in più livelli. Prendiamo come esempio lo studio di Rosa e colleghi del 1998, dedicato alla cosiddetta “terapia tattile”. In quell’esperimento gli operatori erano chiamati a identificare, senza alcun contatto visivo, quale mano fosse stata “selezionata” da un esaminatore. Ogni operatore ha affrontato dieci prove e le risposte sono state registrate come corrette o errate.\nLa struttura dei dati emerge con immediatezza. Al livello più basso si trovano le singole prove, cioè le osservazioni binarie di ciascun operatore. Queste osservazioni sono naturalmente raggruppate per individuo, costituendo un livello intermedio che riflette le prestazioni di ciascun partecipante. Infine, tutti gli operatori appartengono a una popolazione più ampia di praticanti della terapia, che rappresenta il livello superiore della gerarchia.\nQuesta organizzazione a più livelli non è un artificio statistico, ma una caratteristica intrinseca della ricerca psicologica. L’analisi dei dati deve dunque tener conto sia delle differenze individuali sia di ciò che accomuna i partecipanti. Un modello gerarchico permette di descrivere entrambi gli aspetti contemporaneamente: da un lato fornisce stime delle abilità dei singoli operatori, dall’altro stima i parametri che governano la distribuzione complessiva delle abilità nella popolazione.\nGrazie a questa prospettiva multilivello, diventa possibile rispondere a domande che non riguardano solo la prestazione di un partecipante specifico, ma che coinvolgono l’intero gruppo. Ad esempio, possiamo chiederci se, nel complesso, gli operatori abbiano mostrato un’abilità superiore a quella attesa dal puro caso, e allo stesso tempo possiamo esplorare quanto le prestazioni differiscano da un individuo all’altro. In questo modo, la struttura gerarchica dei dati diventa la chiave per un’analisi capace di integrare differenze individuali e generalizzazioni di popolazione in un quadro coerente e informativo.\nAssunzione chiave – scambiabilità: trattiamo le probabilità individuali come scambiabili a priori (estrazioni dalla stessa Beta). È un’ipotesi sensata quando i partecipanti sono reclutati con criteri omogenei e non ci sono covariate che distinguono sottogruppi. Se emergono sottogruppi o predittori, il passo naturale è passare a un modello con predittori (logit-Beta o regressione logistica gerarchica).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html#modelli-gerarchici-bayesiani-una-panoramica-tecnica",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html#modelli-gerarchici-bayesiani-una-panoramica-tecnica",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "\n21.3 Modelli gerarchici bayesiani: una panoramica tecnica",
    "text": "21.3 Modelli gerarchici bayesiani: una panoramica tecnica\nDal punto di vista tecnico, un modello gerarchico bayesiano si distingue perché i parametri individuali non hanno una distribuzione a priori fissa e predeterminata, ma dipendono da parametri di livello superiore, detti iperparametri. In questo modo la struttura del modello riflette una catena di dipendenze: prima si apprendono i parametri che descrivono la popolazione, e successivamente queste informazioni vengono utilizzate per affinare le stime dei singoli partecipanti.\nSe consideriamo un modello semplice e non gerarchico, potremmo assegnare a ciascun parametro individuale una distribuzione a priori autonoma, ad esempio una Gaussiana con media e varianza fissate. Un approccio di questo tipo, però, tratta ogni individuo come completamente separato dagli altri, ignorando il fatto che tutti provengono dalla stessa popolazione e che quindi le loro prestazioni sono verosimilmente correlate. Al contrario, in un modello gerarchico i parametri individuali sono visti come estrazioni da una distribuzione comune, governata dagli iperparametri. Questi ultimi hanno a loro volta delle distribuzioni a priori, che rappresentano il livello più alto della gerarchia.\nFormalmente, possiamo pensare a tre passaggi. I dati osservati dipendono dai parametri individuali attraverso la verosimiglianza. I parametri individuali sono distribuiti secondo una legge che dipende dagli iperparametri. Infine, gli iperparametri sono regolati da distribuzioni a priori che esprimono le nostre conoscenze iniziali. Questa stratificazione permette di far dialogare i dati dei singoli con la conoscenza di gruppo, creando un meccanismo di inferenza che unisce livelli diversi di informazione.\nUn vantaggio importante di questa impostazione è che la variabilità individuale non viene ignorata, ma anzi modellata in modo esplicito. I parametri di popolazione agiscono come un collante che unisce le stime dei partecipanti, permettendo alle informazioni di fluire tra individui e migliorando la precisione complessiva. Dal punto di vista psicologico, ciò riflette l’idea che i soggetti siano tra loro simili ma non identici, e che le loro differenze possano essere comprese soltanto all’interno di una cornice condivisa.\nIn questo senso, i modelli gerarchici bayesiani offrono una prospettiva potente e flessibile. Consentono di trattare simultaneamente i dati individuali e collettivi, garantiscono inferenze più stabili soprattutto quando il numero di osservazioni è limitato e, soprattutto, rendono possibile generalizzare oltre il campione osservato, cogliendo l’essenza di un fenomeno a livello di popolazione senza perdere di vista la ricchezza delle differenze tra persone.\n\n\n\n\n\n\nParametrizzazioni equivalenti\n\n\n\nForma (α, β): \\(p_i \\sim \\text{Beta}(\\alpha,\\beta)\\). Forma (μ, κ): con \\(\\mu=\\alpha/(\\alpha+\\beta)\\) e \\(\\kappa=\\alpha+\\beta\\).\nCon (μ, κ) la media di popolazione è μ e la concentrazione è κ (più grande → meno eterogeneità).\nShrinkage (intuizione): se (α,β) fossero noti,\n\\[\n\\mathbb{E}[p_i \\mid y_i] \\;=\\; \\frac{\\alpha+y_i}{\\alpha+\\beta+n_i}\n\\;=\\; (1 - w_i)\\,\\mu \\;+\\; w_i\\,\\hat p_i,\\quad\nw_i = \\frac{n_i}{n_i+\\kappa},\\ \\ \\hat p_i=\\frac{y_i}{n_i}.\n\\] Cioè la stima a posteriori è una media pesata tra μ e la proporzione empirica \\(\\hat p_i\\).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html#analisi-bayesiana-della-terapia-tattile",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html#analisi-bayesiana-della-terapia-tattile",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "\n21.4 Analisi bayesiana della “terapia tattile”",
    "text": "21.4 Analisi bayesiana della “terapia tattile”\nPer rendere concreti i principi esposti finora, ci concentriamo su un esperimento che ha avuto un’ampia risonanza: lo studio di Rosa et al. (1998) sulla cosiddetta “terapia tattile”. In questa pratica, alcuni operatori sostenevano di percepire un presunto “campo energetico” attorno al corpo umano. L’esperimento mirava a verificare in maniera rigorosa questa capacità. Agli operatori veniva chiesto di identificare quale mano fosse stata selezionata da un esaminatore, senza alcun contatto visivo e senza possibilità di ricevere indizi sensoriali. Ogni operatore ha completato dieci prove, e per ciascuna la risposta è stata classificata come corretta oppure errata.\nIl nostro obiettivo è stimare, per ciascun operatore, la probabilità di dare una risposta corretta, confrontando queste stime con l’ipotesi nulla di puro caso, che corrisponde a una probabilità di successo del cinquanta per cento. Oltre a questo, vogliamo anche valutare se, a livello di gruppo, esistano prove credibili a favore di una prestazione superiore rispetto al caso e quanto varino le abilità tra i diversi operatori.\nPer affrontare queste domande, i dati vengono aggregati in modo da calcolare il numero di risposte corrette su dieci per ciascun partecipante. Si ottiene così, per ogni operatore, una coppia di valori che rappresenta il numero di successi e il numero totale di prove. Questa organizzazione dei dati riflette perfettamente la struttura del modello gerarchico: a livello individuale le osservazioni sono descritte da una distribuzione binomiale, mentre a livello di popolazione le probabilità di successo dei singoli sono modellate come estrazioni da una distribuzione Beta comune.\nGli iperparametri di questa Beta, che descrivono la tendenza centrale e la variabilità tra gli operatori, sono a loro volta trattati come incerti e stimati dai dati. Una volta eseguita l’analisi bayesiana, possiamo quindi ottenere non solo la stima della probabilità di successo per ogni operatore, ma anche la distribuzione a posteriori della probabilità media di successo nel gruppo. Questo permette di valutare se la prestazione collettiva differisce davvero da quella che ci aspetteremmo in condizioni di puro caso.\nL’analisi di questo esperimento diventa così un esempio paradigmatico dell’utilità dei modelli gerarchici. Da un lato mostra come sia possibile stimare e confrontare le prestazioni individuali, dall’altro evidenzia come l’approccio bayesiano consenta di integrare queste informazioni in un quadro più ampio, capace di descrivere la popolazione e di formulare previsioni per nuovi individui.\n\n21.4.1 I dati\nPer prima cosa importiamo i dati forniti da Kruschke (2014). È utile dare un’occhiata alle variabili disponibili e verificare che ogni operatore abbia lo stesso numero di prove.\n\n# Definisci l'URL del file CSV su GitHub\nurl &lt;- \"https://raw.githubusercontent.com/boboppie/kruschke-doing_bayesian_data_analysis/master/2e/TherapeuticTouchData.csv\"\n\n# Leggi direttamente il CSV dall'URL\ntt_dat &lt;- read.csv(url)\nglimpse(tt_dat)\n#&gt; Rows: 280\n#&gt; Columns: 2\n#&gt; $ y &lt;int&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n#&gt; $ s &lt;chr&gt; \"S01\", \"S01\", \"S01\", \"S01\", \"S01\", \"S01\", \"S01\", \"S01\", \"S01\", \"S01\"…\n\nNel dataset la colonna y codifica l’esito binario della prova, con 1 per risposta corretta e 0 per risposta errata; la colonna s identifica l’operatore. Prima di aggregare, conviene verificare che la numerosità di prove per operatore sia quella attesa e che non vi siano soggetti con un numero di osservazioni anomalo. Se l’esperimento prevede dieci prove per operatore, un controllo immediato chiarisce eventuali discrepanze.\n\nchecks &lt;- tt_dat %&gt;%\n  dplyr::count(s, name = \"n_trials\") %&gt;%\n  arrange(s)\n\nchecks\n#&gt;      s n_trials\n#&gt; 1  S01       10\n#&gt; 2  S02       10\n#&gt; 3  S03       10\n#&gt; 4  S04       10\n#&gt; 5  S05       10\n#&gt; 6  S06       10\n#&gt; 7  S07       10\n#&gt; 8  S08       10\n#&gt; 9  S09       10\n#&gt; 10 S10       10\n#&gt; 11 S11       10\n#&gt; 12 S12       10\n#&gt; 13 S13       10\n#&gt; 14 S14       10\n#&gt; 15 S15       10\n#&gt; 16 S16       10\n#&gt; 17 S17       10\n#&gt; 18 S18       10\n#&gt; 19 S19       10\n#&gt; 20 S20       10\n#&gt; 21 S21       10\n#&gt; 22 S22       10\n#&gt; 23 S23       10\n#&gt; 24 S24       10\n#&gt; 25 S25       10\n#&gt; 26 S26       10\n#&gt; 27 S27       10\n#&gt; 28 S28       10\n\nUna volta confermata la struttura, calcoliamo per ciascun operatore i successi totali e il numero di prove, ottenendo i sufficient statistics per la verosimiglianza binomiale. Da qui si ricava anche la proporzione empirica di risposte corrette, utile come benchmark descrittivo ma non ancora regolarizzata dal modello gerarchico.\n\nby_subject &lt;- tt_dat %&gt;%\n  group_by(s) %&gt;%\n  summarise(\n    y = sum(y),\n    n_trials = n(),\n    prop_emp = y / n_trials,\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(s)\n\nby_subject\n#&gt; # A tibble: 28 × 4\n#&gt;    s         y n_trials prop_emp\n#&gt;    &lt;chr&gt; &lt;int&gt;    &lt;int&gt;    &lt;dbl&gt;\n#&gt;  1 S01       1       10      0.1\n#&gt;  2 S02       2       10      0.2\n#&gt;  3 S03       3       10      0.3\n#&gt;  4 S04       3       10      0.3\n#&gt;  5 S05       3       10      0.3\n#&gt;  6 S06       3       10      0.3\n#&gt;  7 S07       3       10      0.3\n#&gt;  8 S08       3       10      0.3\n#&gt;  9 S09       3       10      0.3\n#&gt; 10 S10       3       10      0.3\n#&gt; # ℹ 18 more rows\n\nIl passo successivo è la specificazione del modello probabilistico. Per ogni operatore \\(i\\) denotiamo con \\(y_i\\) il numero di successi su \\(n_i\\) prove e con \\(p_i\\) la probabilità di successo. La verosimiglianza è binomiale, \\(y_i \\sim \\text{Binomiale}(n_i, p_i)\\). Le probabilità individuali non sono fissate a priori, ma modellate come estrazioni indipendenti e scambiabili da una stessa distribuzione Beta, \\(p_i \\sim \\text{Beta}(\\alpha,\\beta)\\). Questa scelta crea il livello di popolazione del modello: \\(\\alpha\\) e \\(\\beta\\) regolano, rispettivamente, la tendenza centrale e la dispersione delle \\(p_i\\) nella popolazione.\nQuando \\(\\alpha\\) e \\(\\beta\\) sono noti, la coniugatezza Beta–Binomiale implica che la distribuzione a posteriori di \\(p_i\\) è ancora Beta, \\(p_i \\mid y_i \\sim \\text{Beta}(\\alpha + y_i,\\, \\beta + n_i - y_i)\\). Nel caso realistico in cui \\(\\alpha\\) e \\(\\beta\\) siano incogniti, assegniamo dei prior anche a questi iperparametri. È importante essere espliciti sulla parametrizzazione della Gamma, poiché in letteratura compaiono sia convenzioni shape–rate sia shape–scale. Qui adotteremo la forma shape–rate, indicata come \\(\\text{Gamma}(k,\\ r)\\), dove \\(E[X]=k/r\\). Scelte ragionevoli e poco informative possono essere, ad esempio, \\(\\alpha \\sim \\text{Gamma}(2,\\,2)\\) e \\(\\beta \\sim \\text{Gamma}(2,\\,2)\\), che corrispondono a media uguale a 1 per ciascun iperparametro e varianza moderata; in alternativa, si può lavorare nella parametrizzazione \\((\\mu,\\kappa)\\), con \\(\\mu=\\alpha/(\\alpha+\\beta)\\) e \\(\\kappa=\\alpha+\\beta\\), scegliendo prior direttamente su media di popolazione e concentrazione. In ogni caso, la scelta dei prior va motivata rispetto al dominio psicologico e alla scala delle probabilità attese.\nPer passare alla stima con Stan, prepariamo una lista compatta con gli oggetti necessari. È pratica comune ordinare i soggetti, convertire in interi e verificare le lunghezze coerenti. La lista minima contiene il numero di soggetti \\(N\\), il vettore dei successi y e il vettore delle prove n_trials.\n\nstan_data &lt;- list(\n  N        = nrow(by_subject),\n  y        = as.integer(by_subject$y),\n  n_trials = as.integer(by_subject$n_trials)\n)\n\nstr(stan_data)\n#&gt; List of 3\n#&gt;  $ N       : int 28\n#&gt;  $ y       : int [1:28] 1 2 3 3 3 3 3 3 3 3 ...\n#&gt;  $ n_trials: int [1:28] 10 10 10 10 10 10 10 10 10 10 ...\n\nA questo punto i dati sono pronti per l’inferenza. La modellazione gerarchica introdurrà regolarizzazione sulle stime individuali \\(p_i\\), attenuando la variabilità spuriosa dovuta a pochi tentativi e consentendo, contemporaneamente, di apprendere la media e l’eterogeneità delle probabilità di successo a livello di popolazione. In seguito mostreremo come questa struttura si traduce in codice Stan e perché la scelta di prior su \\((\\alpha,\\beta)\\) oppure su \\((\\mu,\\kappa)\\) può incidere sulla stabilità computazionale e sulla leggibilità interpretativa dei risultati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html#modello-stan",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html#modello-stan",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "\n21.5 Modello Stan",
    "text": "21.5 Modello Stan\nArrivati a questo punto, i dati sono pronti per essere analizzati con un modello gerarchico in Stan. La struttura matematica che abbiamo descritto in precedenza si traduce in un programma che segue fedelmente la storia generativa dei dati. Per ogni operatore introduciamo una probabilità di successo \\(p_i\\), modellata come estrazione da una distribuzione Beta comune, mentre i conteggi osservati di risposte corrette vengono trattati come variabili binomiali condizionate su \\(p_i\\). Gli iperparametri della Beta, \\(\\alpha\\) e \\(\\beta\\), vengono stimati a loro volta, con distribuzioni a priori che riflettono le nostre assunzioni iniziali.\nIn Stan, il modello può essere scritto in questo modo:\ndata {\n  int&lt;lower=1&gt; N;                  // numero di operatori\n  int&lt;lower=0&gt; y[N];               // successi per operatore\n  int&lt;lower=1&gt; n_trials[N];        // prove per operatore\n}\nparameters {\n  real&lt;lower=0&gt; alpha;             // parametro della Beta\n  real&lt;lower=0&gt; beta;              // parametro della Beta\n  vector&lt;lower=0, upper=1&gt;[N] p;   // probabilità individuali\n}\nmodel {\n  alpha ~ gamma(2, 2);             // prior su alpha (shape-rate)\n  beta  ~ gamma(2, 2);             // prior su beta (shape-rate)\n  p     ~ beta(alpha, beta);       // distribuzione gerarchica delle p_i\n  y     ~ binomial(n_trials, p);   // verosimiglianza dei dati\n}\ngenerated quantities {\n  real overall_p = alpha / (alpha + beta); // media di popolazione\n}\nIl blocco data definisce le informazioni osservate: il numero di partecipanti, i successi e i tentativi per ciascun soggetto. Nel blocco parameters compaiono i parametri da stimare: gli iperparametri \\(\\alpha\\) e \\(\\beta\\), entrambi vincolati a valori positivi, e le probabilità individuali \\(p_i\\), che per costruzione devono trovarsi nell’intervallo compreso tra zero e uno.\nNel blocco model vengono specificate le distribuzioni a priori e la relazione tra parametri e dati. Le prior su \\(\\alpha\\) e \\(\\beta\\) sono state scelte come distribuzioni Gamma poco informative, capaci di lasciare spazio a un ampio spettro di configurazioni possibili. Le probabilità individuali vengono modellate come estrazioni da una Beta con parametri \\(\\alpha\\) e \\(\\beta\\). Infine, i conteggi di risposte corrette sono legati alle rispettive probabilità tramite la verosimiglianza binomiale.\nIl blocco generated quantities calcola la probabilità media di successo nella popolazione, che corrisponde al rapporto \\(\\alpha / (\\alpha+\\beta)\\). Questo valore è spesso di grande interesse, perché riassume la prestazione collettiva e consente di confrontarla con il valore teorico atteso in condizioni di puro caso.\nLa scrittura del modello in Stan non è solo una traduzione meccanica della teoria, ma un’occasione per riflettere sulle scelte modellistiche. Le distribuzioni a priori, la parametrizzazione degli iperparametri e la presenza del blocco generativo aggiuntivo non sono dettagli tecnici marginali: rappresentano decisioni che influiscono sulla stabilità dell’inferenza, sulla leggibilità dei risultati e sulla possibilità di formulare risposte precise alle domande psicologiche poste dallo studio.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html#compilazione-e-sampling",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html#compilazione-e-sampling",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "\n21.6 Compilazione e sampling",
    "text": "21.6 Compilazione e sampling\nUna volta definito il modello, il passo successivo consiste nel compilarlo e avviare il campionamento MCMC con cmdstanr. La compilazione traduce il codice Stan in un eseguibile ottimizzato; è un’operazione che si esegue una volta per modello, dopodiché il binario può essere riutilizzato. Conviene mantenere una struttura di progetto ordinata, salvando il file .stan in una cartella dedicata e richiamandolo tramite un percorso esplicito. L’oggetto CmdStanModel restituito dalla compilazione espone il metodo sample(), che gestisce l’intera esecuzione delle catene, il warmup, la fase di adattamento e la produzione dei draw posteriori.\n\n# Percorso del modello .stan (adatta al tuo progetto)\nstan_file &lt;- here::here(\"stan\", \"h_beta_binom_model.stan\")\n\n# Compilazione del modello\nmod &lt;- cmdstan_model(stan_file)\n\n# Impostazioni di sampling: scelte ragionevoli per un modello leggero come questo\nset.seed(84735)\nfit &lt;- mod$sample(\n  data = stan_data,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 2000,\n  adapt_delta = 0.9,\n  max_treedepth = 12,\n  refresh = 200\n)\n\nNel codice la scelta di quattro catene parallele velocizza l’esecuzione e facilita la diagnosi di convergenza. Una lunghezza totale di tremila iterazioni per catena, con un terzo destinato al warmup e due terzi al campionamento, è in genere adeguata per un modello beta–binomiale gerarchico con pochi parametri. Il controllo fine di adapt_delta e max_treedepth aiuta a prevenire divergenze e saturazioni dell’algoritmo di Hamiltonian Monte Carlo: un valore di adapt_delta pari a 0.9 è spesso un buon compromesso tra stabilità e velocità, mentre una profondità massima di dodici consente traiettorie sufficientemente lunghe senza penalizzare eccessivamente i tempi. Se dovessero comparire divergenze nei messaggi a schermo, aumentare gradualmente adapt_delta verso 0.95–0.99 è la prima mossa sensata; qualora il sampler segnalasse ripetutamente “maximum treedepth exceeded”, estendere max_treedepth può essere utile, sebbene la causa vada interpretata anche alla luce di possibili problemi di parametrizzazione o di prior troppo stretti.\nAl termine dell’esecuzione, l’oggetto fit contiene i draw posteriori, le metriche di adattamento e il riepilogo delle diagnostiche essenziali. È buona pratica iniziare con un controllo sintetico usando fit$summary() per esaminare R̂ e dimensione campionaria efficace; qualsiasi valore di R̂ distante da 1 indica problemi di mescolamento tra catene, mentre valori molto bassi di ESS suggeriscono autocorrelazione elevata e quindi una minore informazione campionaria di quanto il numero di iterazioni lasci intendere.\n\nsum_tbl &lt;- fit$summary()\nsum_tbl %&gt;% \n  dplyr::filter(variable %in% c(\"alpha\", \"beta\", \"overall_p\") | grepl(\"^p\\\\[\", variable)) %&gt;%\n  print(n = 10)\n#&gt; # A tibble: 31 × 10\n#&gt;    variable  mean median    sd   mad    q5   q95  rhat  ess_bulk ess_tail\n#&gt;    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 alpha    4.591  4.536 0.865 0.862 3.292 6.120 1.000  8127.678 6256.311\n#&gt;  2 beta     5.753  5.691 0.927 0.928 4.328 7.395 1.001 10179.787 6262.166\n#&gt;  3 p[1]     0.273  0.266 0.098 0.101 0.123 0.445 1.002 13832.020 5804.423\n#&gt;  4 p[2]     0.325  0.319 0.105 0.107 0.163 0.509 1.000 18248.354 5668.579\n#&gt;  5 p[3]     0.373  0.369 0.106 0.108 0.206 0.555 1.001 15178.133 5929.551\n#&gt;  6 p[4]     0.371  0.367 0.106 0.108 0.205 0.553 1.002 16205.868 5427.424\n#&gt;  7 p[5]     0.373  0.368 0.106 0.109 0.206 0.559 1.000 14469.777 6254.164\n#&gt;  8 p[6]     0.375  0.370 0.107 0.109 0.205 0.558 1.000 16662.048 5477.770\n#&gt;  9 p[7]     0.372  0.367 0.107 0.112 0.204 0.553 1.000 15713.602 6484.229\n#&gt; 10 p[8]     0.372  0.370 0.107 0.108 0.202 0.553 1.003 15450.860 4967.339\n#&gt; # ℹ 21 more rows\n\nUn’ispezione iniziale delle diagnostiche globali può essere condotta anche con le funzioni di posterior. La conversione a draws_array o draws_df permette di utilizzare strumenti flessibili per ulteriori controlli. Quando l’obiettivo è verificare rapidamente che non vi siano problemi sistematici, un’occhiata a R̂ e all’ESS dei parametri di popolazione e di un sottoinsieme di \\(p_i\\) è spesso sufficiente per decidere se proseguire con analisi più approfondite.\n\ndr &lt;- fit$draws(variables = c(\"alpha\",\"beta\",\"overall_p\",\"p[1]\",\"p[2]\",\"p[3]\"))\nposterior::summarise_draws(dr, \"mean\",\"sd\",\"rhat\",\"ess_bulk\",\"ess_tail\")\n#&gt; # A tibble: 6 × 6\n#&gt;   variable   mean    sd  rhat  ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha     4.591 0.865 1.000  8127.678 6256.311\n#&gt; 2 beta      5.753 0.927 1.001 10179.787 6262.166\n#&gt; 3 overall_p 0.443 0.037 1.000  9057.208 6343.897\n#&gt; 4 p[1]      0.273 0.098 1.002 13832.020 5804.423\n#&gt; 5 p[2]      0.325 0.105 1.000 18248.354 5668.579\n#&gt; 6 p[3]      0.373 0.106 1.001 15178.133 5929.551\n\nSe le diagnostiche confermano convergenza e buona esplorazione della posteriore, si può passare con tranquillità alle analisi substantive. In caso contrario, vale la pena considerare piccoli aggiustamenti mirati. Un aumento di adapt_delta tende a eliminare le divergenze al costo di un campionamento leggermente più lento; qualora persista autocorrelazione elevata, un incremento di iter_sampling migliora l’ESS, mentre problemi ostinati di geometria della posteriore spesso traggono beneficio da una parametrizzazione alternativa. In questo modello specifico, la riformulazione in termini di media di popolazione \\(\\mu\\) e concentrazione \\(\\kappa\\) è un’opzione pratica che può rendere più regolare la geometria, come verrà illustrato più avanti.\nChiusa questa fase, il modello è pronto per le esplorazioni posteriori e, soprattutto, per collegare le quantità di interesse psicologico—le probabilità individuali \\(p_i\\) e la media di popolazione—alle domande che motivano l’analisi. Nei passaggi successivi entreremo nel merito della lettura delle distribuzioni a posteriori, mostreremo come visualizzare lo shrinkage e come quantificare l’evidenza rispetto all’ipotesi di caso puro.\n\n21.6.1 Controlli predittivi essenziali\nPrior predictive. Prima di osservare i dati, i prior su (α,β) o (μ,κ) implicano una distribuzione plausibile delle \\(p_i\\) e dei conteggi \\(y_i\\)? Se i prior generano sistematicamente prestazioni “impossibili” (quasi 0 o quasi 1 con alta concentrazione), sono incoerenti col dominio psicologico.\nPosterior predictive. Dopo il fit, i dati replicati dal modello somigliano ai dati osservati (istogrammi delle proporzioni per soggetto, media di gruppo, varianza tra soggetti)? Divergenze sistematiche suggeriscono di rivedere la concentrazione κ o l’assunzione di scambiabilità.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html#shrinkage-bayesiano",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html#shrinkage-bayesiano",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "\n21.7 Shrinkage bayesiano",
    "text": "21.7 Shrinkage bayesiano\nLo shrinkage è esattamente la media pesata \\(\\mathbb{E}[p_i \\mid y_i]=(1-w_i)\\mu + w_i\\hat p_i\\), con \\(w_i=\\frac{n_i}{n_i+\\kappa}\\): più prove → \\(w_i\\) grande → la stima segue \\(\\hat p_i\\); κ grande → \\(w_i\\) piccolo → le stime collassano verso μ. I grafici che seguono mostrano proprio questo comportamento.\nPer comprendere l’idea, immaginiamo due operatori nello studio della therapeutic touch. Il primo ha ottenuto 9 risposte corrette su 10, il secondo soltanto 1 su 10. Se prendessimo queste proporzioni alla lettera, potremmo concludere che il primo è straordinariamente abile e il secondo del tutto incapace. Tuttavia, con soli dieci tentativi ciascuno, questi risultati estremi possono riflettere più la variabilità casuale che una reale differenza di abilità. Il modello gerarchico affronta questo problema facendo “dialogare” le stime individuali con la distribuzione di popolazione. Le probabilità di successo dei singoli non sono stimate in isolamento, ma vengono attratte verso la media collettiva.\nQuesto spostamento non è uguale per tutti. Chi ha molti dati fornisce un’evidenza solida, e quindi la sua probabilità stimata rimane più vicina al valore empirico osservato. Chi ha pochi dati, invece, viene corretto maggiormente e la sua stima viene spinta più decisamente verso la media del gruppo. In questo modo, i partecipanti con campioni piccoli o con esiti estremi non vengono interpretati in modo sproporzionato, ma ricevono una stima più prudente e credibile.\nLo shrinkage non è un difetto, bensì un vantaggio del modello. Esso riduce il rischio di sovrainterpretare il rumore dei dati, stabilizza le stime e consente di ottenere inferenze più robuste. In termini psicologici, riflette l’idea che gli individui siano diversi tra loro, ma comunque simili a sufficienza da condividere un contesto comune. L’effetto pratico è che le probabilità individuali stimate non ricalcano pedissequamente le proporzioni empiriche, ma si collocano in un punto intermedio tra l’esperienza del singolo e l’informazione collettiva.\nQuesto fenomeno diventa evidente quando si confrontano le proporzioni empiriche di successo con le stime bayesiane. In un grafico in cui per ciascun operatore si rappresentano entrambe le quantità, le proporzioni osservate tendono a variare in modo ampio, mentre le stime posteriori appaiono più contenute e ravvicinate tra loro. I valori estremi vengono moderati, e tutti gli operatori mostrano una certa attrazione verso la media di popolazione. È proprio in questa dinamica che si manifesta lo shrinkage, il cuore dell’approccio gerarchico bayesiano.\nPassiamo ora alla parte pratica su come visualizzare lo shrinkage nei dati della therapeutic touch. Iniziamo con il recuperare le stime a posteriori di alpha e beta.\n\n# Estrazione dei draw di p[i] e della media di popolazione\ndraws_p  &lt;- fit$draws(variables = \"p\")                 # draws_array\ndraws_mu &lt;- fit$draws(variables = \"overall_p\")         # draws_array\n\n# Riassunto con media, mediana, sd e diagnostiche\nsum_p &lt;- posterior::summarise_draws(\n  draws_p,\n  \"mean\", \"median\", \"sd\", \"rhat\", \"ess_bulk\", \"ess_tail\"\n) %&gt;%\n  mutate(s = as.integer(str_extract(variable, \"\\\\d+\"))) %&gt;%\n  arrange(s)\n\n# Calcolo dei quantili 5% e 95% a parte\nqs &lt;- posterior::summarise_draws(draws_p, ~ quantile2(.x, probs = c(0.05, 0.95))) %&gt;%\n  mutate(s = as.integer(str_extract(variable, \"\\\\d+\"))) %&gt;%\n  arrange(s)\n\n# Unione\nsum_p &lt;- sum_p %&gt;%\n  left_join(qs %&gt;% dplyr::select(s, q5 = `q5`, q95 = `q95`), by = \"s\")\n\nhead(sum_p)\n#&gt; # A tibble: 6 × 10\n#&gt;   variable  mean median    sd  rhat  ess_bulk ess_tail     s    q5   q95\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 p[1]     0.273  0.266 0.098 1.002 13832.020 5804.423 1.000 0.123 0.445\n#&gt; 2 p[2]     0.325  0.319 0.105 1.000 18248.354 5668.579 2.000 0.163 0.509\n#&gt; 3 p[3]     0.373  0.369 0.106 1.001 15178.133 5929.551 3.000 0.206 0.555\n#&gt; 4 p[4]     0.371  0.367 0.106 1.002 16205.868 5427.424 4.000 0.205 0.553\n#&gt; 5 p[5]     0.373  0.368 0.106 1.000 14469.777 6254.164 5.000 0.206 0.559\n#&gt; 6 p[6]     0.375  0.370 0.107 1.000 16662.048 5477.770 6.000 0.205 0.558\n\n\n# Riassunto per la media di popolazione\nsum_mu &lt;- posterior::summarise_draws(draws_mu)\n\n# Porta gli ID soggetto su un indice numerico coerente con p[1], p[2], ...\nby_subject &lt;- by_subject %&gt;%\n  mutate(s_idx = as.integer(stringr::str_extract(s, \"\\\\d+\"))) %&gt;%\n  arrange(s_idx)\n\n# Anche sum_p ha s come intero già pronto (estratto da \"p[i]\")\n# Se in sum_p la colonna si chiama 's', lasciamo così\n\n# Integrazione con le proporzioni empiriche usando l'indice numerico\ndf_shrink &lt;- by_subject %&gt;%\n  select(s, s_idx, prop_emp, n_trials) %&gt;%\n  inner_join(\n    sum_p %&gt;%\n      dplyr::select(s,              # questo è l'indice numerico 1..N\n                    post_mean = mean,\n                    post_med  = median,\n                    post_q05  = `q5`,\n                    post_q95  = `q95`),\n    by = join_by(s_idx == s)\n  ) %&gt;%\n  arrange(prop_emp) %&gt;%\n  mutate(s_ord = factor(s, levels = s))\n\n# Controllo rapido\ndplyr::glimpse(df_shrink)\n#&gt; Rows: 28\n#&gt; Columns: 9\n#&gt; $ s         &lt;chr&gt; \"S01\", \"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", \"S08\", \"S09…\n#&gt; $ s_idx     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n#&gt; $ prop_emp  &lt;dbl&gt; 0.1, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, …\n#&gt; $ n_trials  &lt;int&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, …\n#&gt; $ post_mean &lt;dbl&gt; 0.273, 0.325, 0.373, 0.371, 0.373, 0.375, 0.372, 0.372, 0.37…\n#&gt; $ post_med  &lt;dbl&gt; 0.266, 0.319, 0.369, 0.367, 0.368, 0.370, 0.367, 0.370, 0.36…\n#&gt; $ post_q05  &lt;dbl&gt; 0.123, 0.163, 0.206, 0.205, 0.206, 0.205, 0.204, 0.202, 0.20…\n#&gt; $ post_q95  &lt;dbl&gt; 0.445, 0.509, 0.555, 0.553, 0.559, 0.558, 0.553, 0.553, 0.55…\n#&gt; $ s_ord     &lt;fct&gt; S01, S02, S03, S04, S05, S06, S07, S08, S09, S10, S11, S12, …\n\nIl primo grafico mette in fila gli operatori ordinati per proporzione empirica e, per ciascuno, disegna un segmento che va dalla proporzione osservata alla stima a posteriori. Il segmento mostra visivamente la contrazione verso la media di popolazione, mentre la barra orizzontale rappresenta l’intervallo di credibilità della stima bayesiana.\n\n# Media di popolazione stimata (posterior mean)\nmu_hat &lt;- sum_mu$mean\n\n# Grafico “lollipop” di shrinkage con IC al 90%\ngg_shrink &lt;- ggplot(df_shrink, aes(x = s_ord)) +\n  geom_segment(aes(xend = s_ord, y = prop_emp, yend = post_mean), linewidth = 0.4, alpha = 0.7) +\n  geom_point(aes(y = prop_emp), size = 2, alpha = 0.8) +\n  geom_point(aes(y = post_mean), size = 2) +\n  geom_errorbar(aes(ymin = post_q05, ymax = post_q95), width = 0.15, alpha = 0.7) +\n  geom_hline(yintercept = mu_hat, linetype = \"dashed\") +\n  labs(\n    x = \"Operatore (ordinato per proporzione empirica)\",\n    y = \"Probabilità di successo\",\n    subtitle = sprintf(\"Linea tratteggiata = media di popolazione a posteriori ≈ %.3f\", mu_hat)\n  ) +\n  theme(panel.grid.minor = element_blank(),\n        axis.text.x = element_text(angle = 0, vjust = 0.5))\ngg_shrink\n\n\n\n\n\n\n\nPer una lettura complementare, un diagramma di dispersione mette a confronto, per ciascun operatore, la proporzione empirica con la stima a posteriori. La diagonale rappresenta l’assenza di contrazione; gli scostamenti verso il basso o verso l’alto visualizzano l’entità dello shrinkage. A parità di numero di prove per soggetto, la contrazione dipende soprattutto dalla dispersione di popolazione: intervalli posteriori stretti si traducono in una trazione più decisa verso la media.\n\ngg_scatter &lt;- ggplot(df_shrink, aes(x = prop_emp, y = post_mean)) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dotted\") +\n  geom_point(size = 2, alpha = 0.85) +\n  geom_errorbar(aes(ymin = post_q05, ymax = post_q95), width = 0.01, alpha = 0.6) +\n  geom_vline(xintercept = 0.5, linetype = \"dashed\") +\n  geom_hline(yintercept = mu_hat, linetype = \"dashed\") +\n  labs(\n    x = \"Proporzione empirica (successi / prove)\",\n    y = \"Stima bayesiana\\na posteriori di p_i\",\n    subtitle = \"Linea diagonale: nessuno shrinkage;\\nlinee tratteggiate: 0.5 e media di popolazione\"\n  ) +\n  coord_equal() +\n  theme(panel.grid.minor = element_blank())\ngg_scatter\n\n\n\n\n\n\n\nQuando tutti hanno lo stesso numero di prove, come nel dataset originale, l’effetto dipende poco dal campione per soggetto e molto dalla struttura gerarchica.\nLa stessa logica vale a livello di popolazione. La quantità overall_p sintetizza la probabilità media di successo nell’insieme degli operatori. È utile quantificare l’evidenza contro il puro caso calcolando la probabilità a posteriori che overall_p superi 0.5; allo stesso tempo, un intervallo di credibilità permette di valutare la compatibilità dei dati con la soglia del cinquanta per cento. La domanda di gruppo è: “la prestazione media supera il caso?”. Operazionalizziamo con \\(\\Pr(\\text{overall\\_p} &gt; 0.5 \\mid \\text{dati})\\). In contesti applicativi è possibile fissare una soglia decisionale (es. 0.95) per concludere a favore di “oltre il caso”.\n\nmu_draws &lt;- as_draws_df(draws_mu)$overall_p\nprob_mu_gt_half &lt;- mean(mu_draws &gt; 0.5)\nci_mu &lt;- quantile(mu_draws, c(0.025, 0.975))\n\nlist(\n  media_posteriori_di_popolazione = mean(mu_draws),\n  P_mu_maggiore_di_0_5 = prob_mu_gt_half,\n  CI95_mu = ci_mu\n)\n#&gt; $media_posteriori_di_popolazione\n#&gt; [1] 0.443\n#&gt; \n#&gt; $P_mu_maggiore_di_0_5\n#&gt; [1] 0.0595\n#&gt; \n#&gt; $CI95_mu\n#&gt;  2.5% 97.5% \n#&gt; 0.371 0.515\n\n\ndf_mu &lt;- tibble(mu = mu_draws)\n\ngg_mu &lt;- ggplot(df_mu, aes(x = mu)) +\n  geom_density(adjust = 1.2, linewidth = 0.6) +\n  geom_vline(xintercept = 0.5, linetype = \"dashed\") +\n  annotate(\"segment\", x = ci_mu[[1]], xend = ci_mu[[2]],\n           y = 0, yend = 0, linewidth = 2, alpha = 0.8) +\n  labs(\n    x = \"Probabilità media di successo (overall_p)\",\n    y = \"Densità a posteriori\",\n    subtitle = sprintf(\"P(overall_p &gt; 0.5) ≈ %.3f; CI95 ≈ [%.3f, %.3f]\",\n                       prob_mu_gt_half, ci_mu[[1]], ci_mu[[2]])\n  ) +\n  theme(panel.grid.minor = element_blank())\ngg_mu\n\n\n\n\n\n\n\nQueste visualizzazioni mostrano l’essenza dello shrinkage: le proporzioni individuali non vengono accettate acriticamente, ma regolarizzate verso una tendenza condivisa, con una forza che dipende dalla struttura gerarchica e, nei casi con numerosità diverse, dal numero di prove per soggetto. Negli esiti di gruppo, la distribuzione a posteriori della media consente di esprimere l’evidenza in termini probabilistici rispetto a una soglia teorica, evitando conclusioni basate su un unico punto stimato.\nIn sintesi, lo shrinkage ci ha permesso di ottenere stime più credibili delle probabilità individuali di successo, evitando di lasciarci ingannare da valori estremi che possono emergere quando il numero di prove è limitato. La distribuzione a posteriori della media di popolazione ha mostrato che la probabilità media di dare una risposta corretta si aggira attorno a 0.44, con un intervallo di credibilità al 95% [0.371, 0.515] che comprende il valore 0.5. Ciò significa che, collettivamente, le prestazioni degli operatori non forniscono evidenza credibile di un’abilità superiore a quella che ci si aspetterebbe dal puro caso.\nDal punto di vista inferenziale, non vi sono basi per concludere che gli operatori siano in grado di percepire il cosiddetto “campo energetico” meglio di quanto farebbe un soggetto che risponde casualmente. In altre parole, l’analisi bayesiana conferma che l’ipotesi nulla di prestazioni casuali rimane del tutto plausibile.\nL’esempio è istruttivo anche sul piano metodologico. Mostra infatti come un modello gerarchico non solo aiuti a stabilizzare le stime individuali, ma consenta anche di trarre conclusioni a livello di gruppo più solide e resistenti al rumore campionario. In un contesto controverso come quello della terapia tattile, questa forma di analisi permette di andare oltre le impressioni aneddotiche, fornendo un quadro quantitativo trasparente della compatibilità dei dati con le affermazioni oggetto di verifica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html#riflessioni-conclusive",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html#riflessioni-conclusive",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esplorato l’approccio gerarchico bayesiano come strumento per analizzare dati organizzati su più livelli. Per comprenderne l’utilità, può essere d’aiuto un’analogia semplice. Stimare la proporzione di palline blu in un’urna è un classico problema statistico. Ma la realtà psicologica è più complessa: spesso non abbiamo una sola urna, bensì molte urne più piccole contenute in un’urna grande, ciascuna con la propria proporzione di blu e rosse. Considerare ogni urna piccola come indipendente dalle altre significherebbe ignorare che appartengono a un contesto comune; al contrario, concentrarsi soltanto sull’urna grande farebbe perdere le peculiarità dei singoli contenitori.\nIl modello gerarchico supera questo falso dilemma. Permette infatti di stimare contemporaneamente le caratteristiche individuali e la distribuzione complessiva, integrando così informazione a livello micro e macro. Applicato al nostro esempio con verosimiglianza binomiale, questo approccio ha reso possibile stimare le probabilità di successo di ciascun operatore e, al tempo stesso, la probabilità media e la variabilità di popolazione.\nDal punto di vista pratico, i vantaggi sono evidenti. Le stime individuali risultano più stabili, perché informate anche dai dati degli altri; la variabilità tra operatori viene quantificata in modo trasparente; la distribuzione di popolazione fornisce un punto di partenza per predizioni su nuovi individui. L’analisi della therapeutic touch ha mostrato con chiarezza questo doppio guadagno: da un lato, lo shrinkage ha ridimensionato le proporzioni empiriche estreme, dall’altro, la distribuzione a posteriori della media ha permesso di valutare se le prestazioni collettive si discostassero dal caso. La risposta, in questo caso, è stata negativa: non vi sono evidenze credibili che gli operatori fossero in grado di percepire un “campo energetico”.\nPiù in generale, l’approccio gerarchico bayesiano rappresenta un pilastro dell’analisi moderna dei dati psicologici. Consente di modellare esplicitamente la struttura multilivello delle osservazioni, rafforzando la robustezza delle inferenze e migliorando la capacità di generalizzare oltre il campione osservato. Per questo motivo, costituisce uno strumento indispensabile per affrontare la complessità e la ricchezza dei dati reali nella ricerca psicologica contemporanea.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] stringr_1.5.1         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [13] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [16] utf8_1.2.6            rmarkdown_2.29        ps_1.9.1             \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [64] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [67] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [70] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [73] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [76] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [79] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_hier_beta_binom.html#bibliografia",
    "href": "chapters/mcmc/11_stan_hier_beta_binom.html#bibliografia",
    "title": "21  Modello gerarchico beta-binomiale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nRosa, L., Rosa, E., Sarner, L., & Barrett, S. (1998). A close look at therapeutic touch. Jama, 279(13), 1005–1010.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_parametrization.html",
    "href": "chapters/mcmc/12_stan_parametrization.html",
    "title": "22  Parametrizzazioni centered e non-centered",
    "section": "",
    "text": "Introduzione\nQuando si lavora con modelli gerarchici in Stan, una delle prime scelte riguarda il modo in cui vengono parametrizzate le variabili latenti. Questa decisione, che a prima vista può sembrare di natura puramente tecnica, ha invece conseguenze sostanziali sia sulla stabilità computazionale della stima sia sull’interpretazione dei risultati. In particolare, la distinzione tra parametrizzazione centrata e parametrizzazione non centrata rappresenta un passaggio cruciale per comprendere perché alcuni modelli convergono rapidamente mentre altri incontrano difficoltà anche su dataset apparentemente semplici.\nIl cuore della questione risiede nel modo in cui le variabili latenti vengono messe in relazione con i parametri iperpriors. Nella parametrizzazione centrata si assume che le osservazioni dipendano direttamente dalla distribuzione a priori, il che funziona bene quando i dati forniscono informazioni forti e coerenti. Tuttavia, in presenza di dati deboli o altamente variabili, questa scelta può produrre catene MCMC lente e autocorrelate. La parametrizzazione non centrata, al contrario, introduce una trasformazione che disaccoppia i livelli del modello e riduce la dipendenza diretta dai parametri iperpriors. Questa semplice modifica può rendere l’inferenza molto più efficiente, specialmente nei contesti in cui le informazioni empiriche non sono sufficienti a “guidare” l’algoritmo verso una stima stabile.\nPer comprendere appieno la differenza tra queste due strategie, è utile partire da un esempio elementare, quello di una singola media normale con varianza nota. Questo caso, apparentemente banale, permette di isolare i meccanismi in gioco e di mostrare come la scelta della parametrizzazione influenzi direttamente il comportamento del campionatore. Nei paragrafi che seguono analizzeremo dunque questo scenario, prima dal punto di vista teorico e poi con esempi numerici e implementazioni concrete in Stan.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Parametrizzazioni centered e non-centered</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_parametrization.html#introduzione",
    "href": "chapters/mcmc/12_stan_parametrization.html#introduzione",
    "title": "22  Parametrizzazioni centered e non-centered",
    "section": "",
    "text": "Prerequisiti\n\n\n\n\n\nSi veda il capitolo 13 “Models with memory” di Statistical rethinking (McElreath, 2020).\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayesplot, ggplot2, dplyr, tibble, forcats)\nconflicts_prefer(posterior::ess_bulk)\nconflicts_prefer(posterior::ess_tail)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Parametrizzazioni centered e non-centered</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_parametrization.html#il-caso-di-una-media-normale",
    "href": "chapters/mcmc/12_stan_parametrization.html#il-caso-di-una-media-normale",
    "title": "22  Parametrizzazioni centered e non-centered",
    "section": "\n22.1 Il caso di una media normale",
    "text": "22.1 Il caso di una media normale\nImmaginiamo di voler stimare la media di una distribuzione normale. Supponiamo che i dati \\(y_1, y_2, \\ldots, y_n\\) provengano da una distribuzione normale con varianza nota \\(\\sigma^2\\) e media incognita \\(\\mu\\). Questo è uno dei problemi più elementari dell’inferenza statistica, ma ci permette di illustrare con chiarezza la differenza tra parametrizzazione centrata e non centrata.\nIn un’impostazione bayesiana assegniamo a \\(\\mu\\) una distribuzione a priori, ad esempio una normale con media \\(\\mu_0\\) e deviazione standard \\(\\tau\\). La struttura gerarchica del modello è dunque molto semplice: a un primo livello si collocano i dati osservati, distribuiti come \\(\\mathcal{N}(\\mu, \\sigma^2)\\); a un secondo livello, la media \\(\\mu\\) è a sua volta distribuita come \\(\\mathcal{N}(\\mu_0, \\tau^2)\\).\nNella parametrizzazione centrata, \\(\\mu\\) viene campionato direttamente da questa distribuzione a priori. La relazione tra iperparametri e parametri è quindi immediata: si parte da \\(\\mu_0\\) e si aggiunge rumore gaussiano con deviazione standard \\(\\tau\\). Questa scelta appare naturale ed è perfettamente adeguata quando i dati sono molto informativi, cioè quando la varianza campionaria è piccola e il numero di osservazioni è grande. In tali condizioni, la distribuzione a posteriori di \\(\\mu\\) è ben identificata e il campionatore esplora rapidamente lo spazio dei parametri.\nLe difficoltà emergono quando i dati forniscono informazioni scarse o contraddittorie. In questi casi, la catena MCMC può soffrire di forti autocorrelazioni: il campionatore si muove lentamente, resta intrappolato in alcune regioni dello spazio dei parametri e richiede un numero molto elevato di iterazioni per ottenere stime affidabili.\nLa parametrizzazione non centrata affronta questo problema con un piccolo ma decisivo cambiamento. Invece di campionare \\(\\mu\\) direttamente, si introduce una variabile ausiliaria \\(z \\sim \\mathcal{N}(0,1)\\) e si definisce \\(\\mu = \\mu_0 + \\tau z\\). In questo modo, \\(\\mu\\) è ancora distribuita secondo \\(\\mathcal{N}(\\mu_0, \\tau^2)\\), ma la relazione con gli iperparametri è mediata dalla variabile standardizzata \\(z\\). Questa trasformazione spezza la dipendenza diretta tra i livelli del modello e consente al campionatore di esplorare lo spazio parametrico in maniera più efficiente, specialmente quando i dati sono poco informativi.\nIl caso della media normale rappresenta dunque un laboratorio ideale per osservare le implicazioni delle due strategie. Nelle sezioni successive mostreremo, attraverso esempi numerici e codici Stan, come queste differenze teoriche si traducano in prestazioni computazionali e qualità dell’inferenza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Parametrizzazioni centered e non-centered</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_parametrization.html#esempi-numerici",
    "href": "chapters/mcmc/12_stan_parametrization.html#esempi-numerici",
    "title": "22  Parametrizzazioni centered e non-centered",
    "section": "\n22.2 Esempi numerici",
    "text": "22.2 Esempi numerici\nPer rendere più concreta la distinzione tra parametrizzazione centrata e non centrata, consideriamo un semplice set di dati simulati. Supponiamo di avere cinque osservazioni generate da una distribuzione normale con media sconosciuta \\(\\mu\\) e varianza fissata a \\(\\sigma^2 = 1\\). Assegniamo a \\(\\mu\\) un prior gaussiano con media zero e deviazione standard pari a dieci. Questo scenario, volutamente essenziale, ci permette di osservare senza distrazioni gli effetti della scelta di parametrizzazione.\nNel caso centrato, il modello in Stan assume la forma più diretta: si dichiara il parametro \\(\\mu\\), lo si vincola a una distribuzione a priori \\(\\mathcal{N}(0, 10^2)\\) e si specifica la distribuzione dei dati come \\(\\mathcal{N}(\\mu, 1)\\). In altre parole, il campionatore deve muoversi nello spazio dei parametri partendo da un collegamento immediato tra la media a priori e le osservazioni.\nIl modello non centrato introduce invece una variabile ausiliaria \\(z\\), distribuita come \\(\\mathcal{N}(0,1)\\). La media diventa \\(\\mu = 0 + 10z\\), e i dati vengono modellati ancora come \\(\\mathcal{N}(\\mu, 1)\\). Sebbene i due modelli siano matematicamente equivalenti, dal punto di vista computazionale il secondo spesso si comporta meglio quando i dati non forniscono informazioni sufficienti per “ancorare” \\(\\mu\\).\nPer illustrare questa differenza possiamo confrontare i risultati delle due implementazioni. Con dati molto informativi — ad esempio con un numero elevato di osservazioni — i due approcci producono catene MCMC di qualità simile: le stime della media e l’esplorazione dello spazio dei parametri avvengono senza difficoltà. Quando però il numero di osservazioni è ridotto, oppure la varianza è elevata, la parametrizzazione centrata mostra spesso autocorrelazioni marcate e una scarsa efficienza campionaria. La parametrizzazione non centrata, al contrario, mantiene catene più stabili e riduce la necessità di un numero eccessivo di iterazioni.\nQuesti esempi, seppur elementari, mettono in evidenza un principio generale: la scelta della parametrizzazione non modifica la sostanza del modello, ma può determinare una differenza sostanziale nella sua resa pratica. Nei modelli gerarchici più complessi, la distinzione tra centrato e non centrato diventa cruciale per rendere l’inferenza non solo più efficiente, ma talvolta persino possibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Parametrizzazioni centered e non-centered</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_parametrization.html#codice-stan",
    "href": "chapters/mcmc/12_stan_parametrization.html#codice-stan",
    "title": "22  Parametrizzazioni centered e non-centered",
    "section": "\n22.3 Codice Stan",
    "text": "22.3 Codice Stan\nNel modello centrato la media \\(\\mu\\) è trattata direttamente come parametro, dotato di una distribuzione a priori normale; i dati sono condizionati su \\(\\mu\\) con varianza nota. Questa scrittura è la più naturale e, quando i dati sono informativi, conduce spesso a catene ben miscelate.\n// file: mean_centered.stan\ndata {\n  int&lt;lower=1&gt; N;            // numero di osservazioni\n  vector[N] y;               // dati osservati\n  real&lt;lower=0&gt; sigma;       // deviazione standard nota del likelihood\n  real mu0;                  // media del prior su mu\n  real&lt;lower=0&gt; tau;         // deviazione standard del prior su mu\n}\nparameters {\n  real mu;                   // media incognita (parametrizzazione centrata)\n}\nmodel {\n  mu ~ normal(mu0, tau);     // prior centrato\n  y  ~ normal(mu, sigma);    // modello di verosimiglianza\n}\ngenerated quantities {\n  vector[N] y_rep;           // repliche predittive\n  vector[N] log_lik;         // log-verosimiglianza punto-a-punto\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma);\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma);\n  }\n}\nLa versione non centrata introduce una variabile standardizzata \\(z \\sim \\mathcal{N}(0,1)\\) e definisce \\(\\mu = \\mu_0 + \\tau z\\). La distribuzione implicita di \\(\\mu\\) rimane identica a quella del modello centrato, ma la geometria dello spazio dei parametri cambia in modo decisivo: la dipendenza tra livelli gerarchici si allenta e, in scenari a bassa informatività, il campionatore può muoversi con maggiore efficienza.\n// file: mean_noncentered.stan\ndata {\n  int&lt;lower=1&gt; N;           \n  vector[N] y;              \n  real&lt;lower=0&gt; sigma;      \n  real mu0;                 \n  real&lt;lower=0&gt; tau;        \n}\nparameters {\n  real z;                   // variabile standardizzata (non centrata)\n}\ntransformed parameters {\n  real mu = mu0 + tau * z;  // ricostruzione della media sullo scale del prior\n}\nmodel {\n  z ~ normal(0, 1);         // prior equivalente su mu, espresso via z\n  y ~ normal(mu, sigma);    // verosimiglianza invariata\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma);\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma);\n  }\n}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Parametrizzazioni centered e non-centered</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_parametrization.html#esecuzione-con-cmdstanr-e-confronto-tra-centrato-e-non-centrato",
    "href": "chapters/mcmc/12_stan_parametrization.html#esecuzione-con-cmdstanr-e-confronto-tra-centrato-e-non-centrato",
    "title": "22  Parametrizzazioni centered e non-centered",
    "section": "\n22.4 Esecuzione con cmdstanr e confronto tra centrato e non centrato",
    "text": "22.4 Esecuzione con cmdstanr e confronto tra centrato e non centrato\nPer apprezzare le differenze tra le due parametrizzazioni, conviene fissare uno scenario leggermente “difficile” per il campionatore: pochi dati e un prior deliberatamente ampio sulla media. In questo modo la geometria della posterior risulta poco concentrata e gli effetti della scelta di parametrizzazione emergono con maggiore nettezza.\n\nset.seed(1234)\n\n# Dati simulati: pochi punti e varianza del likelihood modesta\nN     &lt;- 5\nsigma &lt;- 1.0\nmu_true &lt;- -0.5\ny &lt;- rnorm(N, mean = mu_true, sd = sigma)\n\n# Prior ampio sulla media\nmu0 &lt;- 0\ntau &lt;- 20\n\nstan_centered &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] y;\n  real&lt;lower=0&gt; sigma;\n  real mu0;\n  real&lt;lower=0&gt; tau;\n}\nparameters {\n  real mu;\n}\nmodel {\n  mu ~ normal(mu0, tau);\n  y  ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma);\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma);\n  }\n}\n'\n\nstan_noncentered &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] y;\n  real&lt;lower=0&gt; sigma;\n  real mu0;\n  real&lt;lower=0&gt; tau;\n}\nparameters {\n  real z;\n}\ntransformed parameters {\n  real mu = mu0 + tau * z;\n}\nmodel {\n  z ~ normal(0, 1);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma);\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma);\n  }\n}\n'\n\nwriteLines(stan_centered, here(\"stan\",\" mean_centered.stan\"))\nwriteLines(stan_noncentered, here(\"stan\", \"mean_noncentered.stan\"))\n\n# Compilazione\nmod_c  &lt;- cmdstan_model(here(\"stan\",\" mean_centered.stan\"))\nmod_nc &lt;- cmdstan_model(here(\"stan\", \"mean_noncentered.stan\"))\n\n# Dati per Stan\ndat &lt;- list(\n  N = N, \n  y = as.numeric(y), \n  sigma = sigma, \n  mu0 = mu0, \n  tau = tau\n  )\n\n# Scelte HMC caute, per evitare divergenze in scenari più spigolosi\nhmc_args &lt;- list(adapt_delta = 0.95, max_treedepth = 12)\n\nfit_c &lt;- mod_c$sample(\n  data = dat, seed = 6543, chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 1000,\n  refresh = 0, \n  adapt_delta = hmc_args$adapt_delta, max_treedepth = hmc_args$max_treedepth\n)\n\nfit_nc &lt;- mod_nc$sample(\n  data = dat, seed = 7654, chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 1000,\n  refresh = 0, \n  adapt_delta = hmc_args$adapt_delta, max_treedepth = hmc_args$max_treedepth\n)\n\n# Estratti posteriori in formato draws\ndraws_c  &lt;- fit_c$draws()\ndraws_nc &lt;- fit_nc$draws()\n\n# Riassunti diagnostici essenziali\n# Centered: esiste mu ma NON esiste z\nsum_c  &lt;- posterior::summarise_draws(fit_c$draws(variables = \"mu\"))\n\n# Non-centered: esiste z; mu esiste se lo hai definito nei transformed parameters\n# (nel nostro codice sì: `real mu = mu0 + tau * z;`)\nsum_nc &lt;- posterior::summarise_draws(fit_nc$draws(variables = c(\"mu\", \"z\")))\n\nL’output di summarise_draws fornisce, oltre alle stime a posteriori, lo \\(\\widehat{R}\\) e due misure di dimensione campionaria effettiva: ESS bulk ed ESS tail. La prima descrive la qualità della miscela nelle regioni centrali della distribuzione a posteriori; quando il campionatore esplora con facilità il cuore della distribuzione, l’ESS bulk tende a valori elevati. La seconda, l’ESS tail, quantifica la qualità della miscela nelle code; è sensibile a esplorazioni lente o a salti rari verso le regioni estreme, fenomeni che spesso accompagnano geometrie mal condizionate o curvature accentuate. Nella pratica interpretativa, si guarda a entrambe: una buona miscela nel bulk senza un’adeguata esplorazione delle code può indurre a sottostimare l’incertezza, mentre una buona copertura delle code con un bulk carente suggerisce lentezze diffuse e stime instabili anche in prossimità dei valori più plausibili. In condizioni regolari, ci si attende \\(\\widehat{R}\\) prossimo a 1 per tutti i parametri, ESS bulk e ESS tail di ordine almeno qualche centinaio con 4000 draw totali, e l’assenza di divergenze nelle diagnostiche di cmdstanr.\n\nsum_c\n#&gt; # A tibble: 1 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       -0.858 -0.858 0.445 0.439 -1.587 -0.148 1.002 1222.890 1215.074\n\n\nsum_nc\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       -0.864 -0.868 0.439 0.442 -1.569 -0.135 1.005 1341.017 1224.185\n#&gt; 2 z        -0.043 -0.043 0.022 0.022 -0.078 -0.007 1.005 1341.018 1224.185\n\nUn altro punto di osservazione utile riguarda la predizione. Le repliche posteriori, pur generate dalla stessa struttura del likelihood, possono risentire indirettamente dell’efficienza campionaria: quando la catena si muove con difficoltà, la variabilità predittiva ricostruita dai campioni è più rumorosa e meno stabile da una replica all’altra; quando invece la miscela è buona, gli stessi indici predittivi tendono a stabilizzarsi più rapidamente.\n\n# Estrazione delle repliche predittive\nyrep_c  &lt;- fit_c$draws(\"y_rep\",  format = \"matrix\")\nyrep_nc &lt;- fit_nc$draws(\"y_rep\", format = \"matrix\")\n\n# Un rapido overlay delle densità\np1 &lt;- bayesplot::ppc_dens_overlay(y, yrep_c[1:100, , drop = FALSE]) +\n  ggplot2::labs(title = \"PPC — CP\")\np2 &lt;- bayesplot::ppc_dens_overlay(y, yrep_nc[1:100, , drop = FALSE]) +\n  ggplot2::labs(title = \"PPC — NCP\")\n\np1\n\n\n\n\n\n\np2\n\n\n\n\n\n\n\nIn sintesi, a parità di specifica modellistica, la differenza che interessa è esclusivamente computazionale. Con pochi dati e prior larghi, la formulazione non centrata tende ad aumentare l’ESS, a ridurre l’autocorrelazione e a produrre catene più regolari. Se aumentiamo l’informatività dei dati, ampliando la numerosità campionaria o riducendo la varianza del likelihood, la situazione si riequilibra e la parametrizzazione centrata risulta spesso del tutto adeguata, talvolta persino leggermente più rapida da campionare per via della sua immediatezza geometrica.\nNel caso presente, di un modello estremamente semplice, i due approcci producono gli stessi risultati, anche con un campione estremamente ridotto. Nel caso di modelli più complessi, invece, la parametrizzazione non centrata può essere utile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Parametrizzazioni centered e non-centered</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_parametrization.html#riflessoni-conclusive",
    "href": "chapters/mcmc/12_stan_parametrization.html#riflessoni-conclusive",
    "title": "22  Parametrizzazioni centered e non-centered",
    "section": "\n22.5 Riflessoni conclusive",
    "text": "22.5 Riflessoni conclusive\nLa distinzione tra parametrizzazione centrata e non centrata non riguarda soltanto un dettaglio tecnico del codice Stan, ma tocca un aspetto fondamentale della modellazione gerarchica: il modo in cui rappresentiamo la relazione tra parametri a livello superiore e variabili latenti a livello inferiore. I due approcci sono matematicamente equivalenti, ma generano geometrie molto diverse nello spazio dei parametri, con conseguenze pratiche notevoli per l’efficienza del campionamento.\nLa parametrizzazione centrata è la più intuitiva. Essa esprime i parametri latenti come realizzazioni dirette della distribuzione a priori e funziona particolarmente bene quando i dati sono molto informativi. In questi casi la posterior è ben concentrata, il campionatore si muove agevolmente nello spazio parametrico e la semplicità della formulazione costituisce un vantaggio. Tuttavia, quando i dati sono scarsi o rumorosi, la dipendenza stretta tra i livelli gerarchici può rendere l’inferenza difficile: le catene diventano lente, autocorrelate e richiedono molte iterazioni per produrre stime affidabili.\nLa parametrizzazione non centrata affronta proprio questo problema. Introdurre una variabile standardizzata e ricostruire i parametri a partire da essa riduce la correlazione tra livelli, semplificando la geometria che il campionatore deve esplorare. In contesti a bassa informatività, ciò si traduce in un guadagno sostanziale di efficienza, con catene più stabili e un numero effettivo di campioni più elevato. È per questo motivo che, nella pratica quotidiana, i modelli non centrati sono spesso la scelta più sicura, soprattutto quando si lavora con strutture complesse o con dati limitati.\nÈ importante sottolineare che non esiste una regola assoluta: in scenari molto informativi, la parametrizzazione centrata può risultare persino più rapida, proprio grazie alla sua immediatezza. Per questo motivo, nelle applicazioni reali conviene spesso provare entrambe le formulazioni o ricorrere a strategie miste, note come “parametrizzazioni parzialmente centrate”, che combinano i vantaggi dei due approcci adattandosi alle caratteristiche dei dati.\nIl caso della media normale con varianza nota ha rappresentato un laboratorio ideale per illustrare i meccanismi di base. Nei capitoli successivi, la stessa logica tornerà in modelli più articolati — ad esempio nella regressione gerarchica e nei modelli a effetti misti — dove la scelta della parametrizzazione diventa ancora più cruciale. Ciò che qui abbiamo osservato in forma elementare si generalizza infatti a ogni contesto in cui esistono livelli multipli di variabilità e legami gerarchici tra parametri.\nIn sintesi, la distinzione tra parametrizzazioni centered e non-centered non riguarda la sostanza del modello, ma la sua implementazione computazionale. Comprendere questa differenza è cruciale per usare Stan in modo efficace, soprattutto nei modelli gerarchici psicologici, dove i dati individuali sono spesso scarsi e i prior giocano un ruolo importante.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] forcats_1.0.0         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Parametrizzazioni centered e non-centered</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_parametrization.html#bibliografia",
    "href": "chapters/mcmc/12_stan_parametrization.html#bibliografia",
    "title": "22  Parametrizzazioni centered e non-centered",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Parametrizzazioni centered e non-centered</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_bayesian_workflow.html",
    "href": "chapters/mcmc/13_bayesian_workflow.html",
    "title": "23  Flusso di lavoro bayesiano",
    "section": "",
    "text": "Introduzione\nAbbiamo ormai gli strumenti fondamentali per affrontare l’inferenza bayesiana in contesti realistici. Abbiamo visto che, nei casi semplici, l’aggiornamento può essere calcolato analiticamente, ma che già con pochi parametri questo diventa impraticabile. Abbiamo introdotto l’algoritmo di Metropolis, che ci ha mostrato come sia sempre possibile campionare dalla distribuzione a posteriori, e poi abbiamo visto come i linguaggi probabilistici – e in particolare Stan – rendano questa possibilità accessibile e utilizzabile nella ricerca psicologica.\nOra, però, dobbiamo fare un passo ulteriore. Avere strumenti di calcolo non basta: serve un metodo di lavoro. L’inferenza bayesiana non è soltanto una formula o un algoritmo, ma un processo che accompagna il ricercatore dall’ideazione del modello fino alla comunicazione dei risultati. Questo processo prende il nome di workflow bayesiano.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_bayesian_workflow.html#introduzione",
    "href": "chapters/mcmc/13_bayesian_workflow.html#introduzione",
    "title": "23  Flusso di lavoro bayesiano",
    "section": "",
    "text": "Prerequisiti\n\n\n\n\n\nPuò essere utile aver letto Bulbulia (2023) su workflow e inferenza causale.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_bayesian_workflow.html#un-processo-iterativo",
    "href": "chapters/mcmc/13_bayesian_workflow.html#un-processo-iterativo",
    "title": "23  Flusso di lavoro bayesiano",
    "section": "23.1 Un processo iterativo",
    "text": "23.1 Un processo iterativo\nIl workflow bayesiano non è lineare, ma iterativo. Inizia con la formulazione di un modello, procede con l’analisi dei dati e la valutazione dei risultati, ma spesso richiede di tornare indietro, rivedere le ipotesi e migliorare le specifiche. A differenza dell’approccio frequentista tradizionale, che tende a concentrarsi solo sull’output numerico finale (ad esempio un p-value), l’approccio bayesiano incoraggia una riflessione costante sul legame tra teoria, modello e dati.\nL’idea centrale è che ogni modello è un’ipotesi sul processo generativo che ha prodotto i dati. Il compito del ricercatore non è solo stimare parametri, ma verificare se il modello che li definisce è coerente con ciò che sappiamo e con ciò che osserviamo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_bayesian_workflow.html#le-fasi-del-workflow",
    "href": "chapters/mcmc/13_bayesian_workflow.html#le-fasi-del-workflow",
    "title": "23  Flusso di lavoro bayesiano",
    "section": "23.2 Le fasi del workflow",
    "text": "23.2 Le fasi del workflow\nIl workflow può essere schematizzato in tre momenti principali, che però nella pratica si intrecciano continuamente.\n1. Definizione del modello Il punto di partenza è sempre la teoria o l’ipotesi psicologica che vogliamo testare. In questa fase traduciamo le nostre idee in un modello probabilistico: definiamo i parametri, scegliamo i priori, specifichiamo la verosimiglianza. È il momento in cui ci chiediamo: quale processo potrebbe aver generato i dati che osserviamo?\n2. Inferenza e stima Una volta definito il modello, utilizziamo strumenti come Stan per ottenere campioni dalla distribuzione a posteriori. Questa fase include la verifica tecnica del campionamento (convergenza delle catene, numero effettivo di campioni indipendenti, diagnosi di autocorrelazione). È qui che la potenza degli algoritmi MCMC diventa essenziale, perché ci permette di trattare modelli complessi senza dover ricorrere a semplificazioni eccessive.\n3. Valutazione del modello Il passo successivo è chiederci se il modello “funziona”. Ciò significa, da un lato, confrontare le predizioni del modello con i dati osservati (posterior predictive checks) e, dall’altro, valutare la capacità del modello di generalizzare a nuovi dati (ad esempio tramite LOO-CV ed ELPD). La valutazione non è mai l’ultima parola, ma una guida per decidere se mantenere, modificare o sostituire il modello.\n\n\n\nFigura tratta da Blei (2014).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_bayesian_workflow.html#una-prospettiva-cumulativa",
    "href": "chapters/mcmc/13_bayesian_workflow.html#una-prospettiva-cumulativa",
    "title": "23  Flusso di lavoro bayesiano",
    "section": "23.3 Una prospettiva cumulativa",
    "text": "23.3 Una prospettiva cumulativa\nIl workflow bayesiano ci ricorda che la scienza non procede per verità definitive, ma per modelli progressivamente migliori. Ogni modello è un passo in un percorso cumulativo, in cui le ipotesi vengono testate, confrontate e, se necessario, abbandonate.\nDal punto di vista della psicologia, questo approccio rappresenta una risposta concreta alla crisi di replicazione. Non ci limitiamo a verificare associazioni statistiche, ma costruiamo modelli espliciti dei processi psicologici, li testiamo sui dati e li confrontiamo in termini di capacità predittiva. È un metodo che promuove trasparenza, apertura alla revisione e cumulatività, tutti elementi essenziali per rafforzare le basi empiriche della disciplina.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_bayesian_workflow.html#riflessioni-conclusive",
    "href": "chapters/mcmc/13_bayesian_workflow.html#riflessioni-conclusive",
    "title": "23  Flusso di lavoro bayesiano",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nCon il workflow bayesiano abbiamo completato il nostro percorso introduttivo all’inferenza bayesiana. Abbiamo visto che non si tratta solo di imparare un nuovo insieme di tecniche, ma di adottare una prospettiva diversa sul rapporto tra teoria, dati e analisi statistica.\nIl valore di questo approccio non sta soltanto nei dettagli tecnici, ma nel modo in cui ci spinge a pensare: ogni modello è un’ipotesi esplicita, ogni analisi è trasparente e riproducibile, ogni risultato è accompagnato da una valutazione critica della sua incertezza e della sua plausibilità.\nNei capitoli successivi vedremo come applicare questi principi a casi specifici e a modelli più articolati. Il workflow bayesiano rimarrà il filo conduttore: un metodo iterativo e riflessivo che ci guida nel costruire conoscenza scientifica solida, cumulativa e capace di rispondere alle sfide della psicologia contemporanea.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_bayesian_workflow.html#bibliografia",
    "href": "chapters/mcmc/13_bayesian_workflow.html#bibliografia",
    "title": "23  Flusso di lavoro bayesiano",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1(1), 203–232.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/conclusions_sec.html",
    "href": "chapters/mcmc/conclusions_sec.html",
    "title": "Riflessioni conclusive sulla sezione",
    "section": "",
    "text": "Principali acquisizioni concettuali e metodologiche\nIn questa sezione è stato illustrato come i metodi Monte Carlo basati su catene di Markov (MCMC) rendano fattibile l’inferenza bayesiana in contesti modellistici complessi, dove soluzioni analitiche risultano impraticabili. L’esposizione è stata strutturata secondo un approccio progressivo, partendo dai fondamenti concettuali – quali la simulazione stocastica e l’algoritmo di Metropolis – per giungere all’applicazione corrente mediante strumenti come Stan e l’algoritmo HMC-NUTS, passando attraverso stadi essenziali quali la diagnostica delle catene, la predizione e l’analisi di casi di studio via via più articolati. Tra questi, abbiamo esaminato modelli per la differenza tra medie e per l’odds ratio, modelli Poisson per dati di conteggio, misture gaussiane con problematiche di identificabilità, modelli con parametri di disturbo e modelli a struttura gerarchica.\nIl campionamento MCMC dalla distribuzione a posteriori costituisce l’oggetto primario dell’inferenza. Da esso è possibile derivare non solo stime puntuali e intervalli di credibilità, ma anche distribuzioni predittive posteriori per future replicazioni o nuove osservazioni, nonché qualsiasi funzione dei parametri di interesse, come ad esempio l’odds ratio.\nLa diagnostica delle catene rappresenta una fase imprescindibile. Affinché i risultati siano validi, è necessario verificare la convergenza e l’adeguatezza dell’esplorazione dello spazio dei parametri. A tal fine, è opportuno assicurarsi che l’indice R-hat sia prossimo a 1, che le dimensioni effettive del campione (ESS, sia nella parte centrale che nelle code) siano sufficienti, e che non siano presenti divergenze. Ulteriori indicatori da monitorare includono il treedepth massimo e l’E-BFMI. In caso di anomalie, strategie correttive possono comprendere la riparametrizzazione del modello (ad esempio in forma non-centered per modelli gerarchici), l’utilizzo di prior più informative, la riscalatura delle variabili, o l’aggiustamento di parametri come adapt_delta.\nLe distribuzioni a priori, spesso trascurate, svolgono un ruolo cruciale nella specificazione del modello. Prior debolmente informative possono favorire sia l’identificabilità numerica che quella sostantiva. Inoltre, la simulazione predittiva a priori (prior predictive check) consente di valutare se le assunzioni del modello generino dati plausibili, ancor prima di osservare i dati reali.\nLa verifica di adeguatezza del modello si avvale in modo essenziale della distribuzione predittiva a posteriori. I posterior predictive checks (PPC), che confrontano la distribuzione dei dati replicati con quelli osservati, permettono di identificare discrepanze strutturali in modo più efficace della sola valutazione di indici di adattamento.\nIl confronto tra modelli deve essere guidato dalla loro capacità predittiva. L’Expected Log Predictive Density (ELPD), stimabile mediante metodi come LOO o WAIC, fornisce un criterio solido per selezionare il modello che generalizza meglio, superando la mera aderenza ai dati osservati.\nDall’analisi di casi specifici è possibile trarre indicazioni generali. Nei modelli per la differenza tra medie, per l’odds ratio o per dati di conteggio (Poisson), la distribuzione a posteriori fornisce probabilità direttamente interpretabili (quali la probabilità che un effetto sia positivo) nonché predizioni per nuove unità. Le misture di distribuzioni, come le misture gaussiane, pongono sfide legate al label switching e all’identificabilità, che richiedono l’introduzione di vincoli, prior informative o un’appropriata post-elaborazione; al contempo, esse mostrano come gli MCMC possano esplorare spazi delle parametri multimodali. I parametri di disturbo possono essere gestiti in modo efficiente mediante marginalizzazione o attraverso un’impostazione gerarchica. I modelli gerarchici, come il modello beta-binomiale, permettono di ottenere stime per gruppi specifici (partial pooling) più robuste e al tempo stesso di compiere inferenze sulla popolazione sottostante.\nUn aspetto pratico cruciale riguarda l’efficienza computazionale. Più che il numero assoluto di iterazioni, conta l’ESS per unità di tempo di calcolo. L’operazione di thinning è generalmente superflua; è preferibile impiegare poche catene, sufficientemente lunghe e ben miscelate, piuttosto che molte catene corte e potenzialmente problematiche.",
    "crumbs": [
      "MCMC",
      "Riflessioni conclusive sulla sezione"
    ]
  },
  {
    "objectID": "chapters/mcmc/conclusions_sec.html#workflow-operativo-consolidato",
    "href": "chapters/mcmc/conclusions_sec.html#workflow-operativo-consolidato",
    "title": "Riflessioni conclusive sulla sezione",
    "section": "Workflow operativo consolidato",
    "text": "Workflow operativo consolidato\nLa trattazione si conclude proponendo una visione dell’inferenza bayesiana non come procedura meccanica, ma come processo iterativo e circolare. Tale processo si articola nelle seguenti fasi:\n\nSpecifica del modello, includendo prior sostantivamente giustificate;\nSimulazione predittiva (a priori e a posteriori) per comprendere le implicazioni del modello e verificarne la coerenza con la conoscenza di dominio;\nStima mediante MCMC e diagnostica accurata delle catene;\nValutazione della capacità predittiva del modello mediante strumenti come LOO o WAIC;\nAffinamento delle assunzioni, dei parametri, delle trasformazioni o della qualità dei dati, sulla base dei risultati delle fasi precedenti;\nComunicazione dei risultati in termini interpretabili, enfatizzando la quantificazione dell’incertezza attraverso probabilità, intervalli credibili e scenari predittivi.\n\nIn sintesi, i metodi MCMC non costituiscono un mero strumento numerico, ma rappresentano la vera e propria infrastruttura che abilita l’implementazione di modelli realistici e informativi. Grazie a pratiche rigorose di diagnostica, predizione e confronto, essi forniscono uno strumento essenziale per una psicologia quantitativa di tipo esplicativo, i cui esiti non si riducono a risposte dicotomiche, ma si esprimono attraverso distribuzioni di probabilità. Queste ultime quantificano coerentemente ciò che è stato appreso, il grado di incertezza associato e le previsioni su osservazioni future.",
    "crumbs": [
      "MCMC",
      "Riflessioni conclusive sulla sezione"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_sec.html",
    "href": "chapters/linear_models/introduction_sec.html",
    "title": "Introduzione alla sezione",
    "section": "",
    "text": "Nei capitoli precedenti abbiamo visto come sia possibile condurre l’inferenza statistica in situazioni semplici, come la stima di una media o il confronto tra due gruppi. In questa sezione estenderemo il discorso al modello di regressione lineare, nelle sue forme bivariata e multipla, applicato sia a predittori quantitativi sia a predittori qualitativi. La regressione non rappresenta un nuovo problema, ma piuttosto un ampliamento: l’inferenza su una o due medie, tradizionalmente affrontata con il t-test di Student, può infatti essere vista come un caso particolare del più generale modello lineare. Questo approccio unificato sarà presentato sia nella prospettiva frequentista sia in quella bayesiana.\nÈ importante, a questo punto, distinguere tra due grandi famiglie di modelli. I modelli fenomenologici descrivono i dati: offrono un riassunto matematico delle relazioni osservate, senza fare ipotesi esplicite sui processi che le hanno generate. I modelli meccanicistici, invece, mirano a rappresentare i meccanismi sottostanti, simulando i processi cognitivi o affettivi che producono le osservazioni. La regressione lineare appartiene chiaramente alla prima categoria: è uno strumento descrittivo, non esplicativo. La sua diffusione in psicologia deriva in larga misura dal successo dell’approccio frequentista, che ha imposto la logica dicotomica della verifica dell’ipotesi nulla (“c’è o non c’è un’associazione nella popolazione?”).\nTuttavia, sappiamo che questa domanda ha un valore scientifico limitato. In un certo senso, tutto è correlato con tutto il resto: ciò che conta non è stabilire se un’associazione esista, ma comprenderne l’entità e, più in profondità, i meccanismi che la determinano. La regressione lineare fornisce una descrizione accurata dell’associazione, ma non può dirci nulla sulle cause. Questo limite è condiviso dalla maggior parte dei modelli quantitativi utilizzati in psicologia, ancora oggi prevalentemente di tipo fenomenologico.\nCiononostante, studiare la regressione è indispensabile. Non tanto per la sua capacità esplicativa – che è ridotta – quanto perché costituisce lo strumento statistico più usato nella ricerca psicologica. Inoltre, l’adozione di una prospettiva bayesiana consente di reinterpretare la regressione in termini più maturi e scientificamente fecondi: non più come un test dicotomico dell’ipotesi nulla, ma come valutazione della plausibilità dei diversi valori dei parametri e confronto tra modelli alternativi. In questa prospettiva, la regressione lineare diventa un passaggio cruciale nel percorso che ci porterà, più avanti, verso modelli più ricchi e meccanicistici, capaci di rappresentare non solo le associazioni osservate ma anche i processi che le generano.",
    "crumbs": [
      "Regressione",
      "Introduzione alla sezione"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html",
    "href": "chapters/linear_models/01_reglin_frequentist.html",
    "title": "24  La regressione lineare bivariata",
    "section": "",
    "text": "Introduzione\nLa regressione lineare è uno degli strumenti più diffusi della statistica applicata. La sua funzione è descrivere come varia, in media, una variabile quantitativa — detta dipendente e indicata con \\(Y\\) — al variare di un’altra variabile quantitativa — detta indipendente e indicata con \\(X\\). Il modello esprime quindi una relazione media tra due grandezze, lasciando spazio a una quota di variabilità residua inevitabile nei dati psicologici e sociali.\nIn psicologia, la regressione lineare è stata adottata in modo estensivo per mettere in relazione costrutti teorici, per costruire previsioni empiricamente fondate, o per verificare ipotesi sulle dinamiche cognitive, emotive o sociali. Proprio per la sua pervasività, questo strumento rappresenta spesso la “lingua comune” della ricerca quantitativa.\nÈ importante, tuttavia, collocare la regressione nel giusto contesto epistemologico. Si tratta di un modello fenomenologico, che descrive associazioni tra variabili ma non fornisce di per sé spiegazioni sui meccanismi che le hanno generate. Inoltre, il modello si fonda su precise assunzioni matematiche e statistiche: comprenderle è fondamentale per utilizzare la regressione in modo consapevole e per riconoscerne i limiti. Solo così diventa possibile distinguere ciò che il modello ci dice davvero dai significati che rischiamo di attribuirgli indebitamente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "title": "24  La regressione lineare bivariata",
    "section": "",
    "text": "Panoramica del capitolo\n\nIl modello di regressione lineare secondo l’approccio frequentista.\nLa stima dei coefficienti del modello utilizzando il metodo dei minimi quadrati.\nL’interpretazione dei coefficienti dei minimi quadrati.\nIl calcolo e l’interpretazione dell’indice di determinazione (\\(R^2\\)).\nL’inferenza frequentista sui coefficienti dei minimi quadrati.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Basic Regression di Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (Second Edition).\nConsulta l’appendice Appendice O per un’introduzione alle funzioni lineari.\nLeggere Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code (Alter et al., 2025).\nLeggere il capitolo Linear Statistical Models (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(broom)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-relazione-tra-x-e-y",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-relazione-tra-x-e-y",
    "title": "24  La regressione lineare bivariata",
    "section": "\n24.1 La relazione tra \\(X\\) e \\(Y\\)\n",
    "text": "24.1 La relazione tra \\(X\\) e \\(Y\\)\n\nIl caso più semplice è il modello di regressione lineare bivariato, che descrive la relazione tra due variabili. L’idea di base è che, se \\(X\\) e \\(Y\\) sono associate, possiamo approssimare la loro relazione con una retta che indica come \\(Y\\) tende a variare al variare di \\(X\\).\nLa formulazione classica (frequentista) del modello è:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n,\n\\] dove:\n\n\n\\(a\\) (intercetta): valore atteso di \\(Y\\) quando \\(X = 0\\),\n\n\\(b\\) (pendenza): variazione attesa di \\(Y\\) per ogni unità di aumento in \\(X\\),\n\n\\(e_i\\) (errore residuo): differenza tra il valore osservato \\(y_i\\) e il valore previsto dal modello.\n\nGraficamente, questa equazione corrisponde a una retta di regressione che rappresenta la miglior approssimazione lineare dei dati secondo il criterio dei minimi quadrati. Nella realtà, i punti raramente giacciono tutti sulla retta: le differenze sono catturate dagli errori residui.\nLa regressione, quindi, non predice esattamente ogni osservazione, ma descrive la tendenza media nella popolazione. Ad esempio, se \\(b = 2\\), significa che — in media — un aumento di 1 unità in \\(X\\) è associato a un aumento di 2 unità in \\(Y\\). Ciò non implica che ogni caso segua la regola in modo perfetto, ma che l’andamento complessivo sia coerente con questa relazione.\nL’obiettivo dell’analisi è stimare i parametri \\(a\\), \\(b\\) e \\(\\sigma^2\\) (varianza residua) dai dati, utilizzando il metodo dei minimi quadrati (OLS) o, più in generale, il principio di massima verosimiglianza. Nel paradigma frequentista, questi parametri sono considerati quantità fisse ma sconosciute, e l’incertezza riguarda esclusivamente gli errori di misura o variabilità non spiegata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#a-cosa-serve-la-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#a-cosa-serve-la-regressione",
    "title": "24  La regressione lineare bivariata",
    "section": "\n24.2 A cosa serve la regressione?",
    "text": "24.2 A cosa serve la regressione?\nSecondo Gelman et al. (2021), la regressione lineare può essere applicata in almeno quattro contesti principali:\n\n\nPrevisione – Stimare valori futuri di una variabile di interesse o classificare casi in base a probabilità.\n\n\nEsempi: prevedere punteggi futuri a un test; monitorare il benessere psicologico in studi longitudinali; classificare individui in base alla probabilità di successo in un compito cognitivo.\n\n\n\nEsplorazione delle associazioni – Identificare e quantificare le relazioni tra predittori e risultato.\n\n\nEsempi: analizzare i tratti di personalità legati alla resilienza allo stress; studiare la relazione tra stili di attaccamento infantile e competenze relazionali adulte; valutare l’effetto di fattori socio-economici sullo sviluppo cognitivo.\n\n\n\nEstrapolazione – Estendere i risultati a contesti o popolazioni non direttamente osservati.\n\n\nEsempi: stimare l’efficacia di una terapia testata su studenti universitari nella popolazione generale; prevedere l’impatto di un intervento scolastico su un intero distretto a partire da dati di scuole pilota.\n\n\n\nInferenza causale – Stimare effetti di trattamenti o interventi, solo se supportata da un disegno di ricerca adeguato (ad es., randomizzazione).\n\n\nEsempi: valutare l’efficacia di un programma di mindfulness sull’ansia; stimare l’impatto di una psicoterapia sul disturbo post-traumatico da stress; determinare l’effetto di un intervento educativo su una popolazione diversificata.\n\n\n\nNota importante: in tutti i contesti, il modello deve includere tutte le variabili rilevanti per il fenomeno studiato. L’omissione di variabili confondenti può distorcere le stime — problema noto come errore di specificazione del modello. Ad esempio, in uno studio sull’efficacia di una psicoterapia per la depressione, fattori come età, condizioni di salute preesistenti e supporto sociale devono essere inclusi nell’analisi per evitare interpretazioni fuorvianti.\n\n24.2.1 Tipologie di regressione\nL’analisi di regressione può essere classificata in base al numero di variabili coinvolte, distinguendosi in tre principali categorie che riflettono diversi livelli di complessità.\nLa regressione bivariata rappresenta la forma più elementare, in cui viene analizzata la relazione tra un unico predittore e una sola variabile esito. La sua semplicità la rende un punto di partenza ideale per comprendere la logica fondamentale della regressione, poiché consente di apprendere i concetti di base senza l’onere di complicazioni matematiche eccessive.\nUn livello di complessità superiore è dato dalla regressione multipla, nella quale un unico esito viene modellato utilizzando molteplici predittori. Questo approccio permette di esaminare l’effetto simultaneo di diverse variabili indipendenti, richiedendo un’attenta interpretazione dei parametri stimati.\nInfine, la regressione multivariata costituisce il caso più generale, in cui più variabili esito vengono analizzate simultaneamente in relazione a uno o più predittori. Questo tipo di modellazione richiede calcoli statistici più articolati e rappresenta lo strumento più potente e complesso tra le tre tipologie.\nIl percorso di apprendimento ideale inizia dalla regressione bivariata, poiché fornisce le basi concettuali e metodologiche che possono successivamente essere estese verso modelli più sofisticati. La comprensione dei principi fondamentali acquisiti nel caso semplice è infatti un prerequisito essenziale per affrontare le sfide interpretative e computazionali poste dalle regressioni multiple e multivariate.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "title": "24  La regressione lineare bivariata",
    "section": "\n24.3 La predizione dell’intelligenza",
    "text": "24.3 La predizione dell’intelligenza\nPer illustrare il modello di regressione secondo l’approccio frequentista, utilizzeremo un dataset reale: i dati kidiq tratti dal National Longitudinal Survey of Youth (Gelman et al., 2021). Questi dati riguardano un campione di donne americane e i loro figli, con particolare attenzione a due variabili fondamentali per la nostra analisi: il punteggio cognitivo del bambino (kid_score) e il quoziente intellettivo della madre (mom_iq). L’obiettivo principale consiste nell’esaminare se - e in che misura - l’intelligenza materna possa essere considerata un fattore predittivo delle capacità cognitive del bambino.\n\n24.3.1 Esplorazione dei dati\nImportiamo i dati in R:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\nEsaminiamo le prime righe del data frame:\n\nhead(kidiq)\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1  121.1        4      27\n#&gt; 2        98      1   89.4        4      25\n#&gt; 3        85      1  115.4        4      27\n#&gt; 4        83      1   99.4        3      25\n#&gt; 5       115      1   92.7        4      27\n#&gt; 6        98      0  107.9        1      18\n\nUn diagramma a dispersione per i dati di questo campione suggerisce la presenza di un’associazione positiva tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq).\n\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.6) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Diagramma a dispersione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#il-modello-teorico",
    "href": "chapters/linear_models/01_reglin_frequentist.html#il-modello-teorico",
    "title": "24  La regressione lineare bivariata",
    "section": "\n24.4 Il modello teorico",
    "text": "24.4 Il modello teorico\nIl modello di regressione lineare bivariata è:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n\n\\] dove:\n\n\n\\(a\\): intercetta (valore atteso di \\(y\\) quando \\(x = 0\\));\n\n\\(b\\): pendenza (variazione attesa di \\(y\\) per +1 in \\(x\\));\n\n\\(e_i\\): errore residuo (scarto tra osservato e predetto).\n\nNel nostro caso:\n\n\n\\(y = \\text{`kid\\_score`}\\) (QI del bambino)\n\n\\(x = \\text{`mom\\_iq`}\\) (QI della madre)\n\nLa componente deterministica \\(\\hat{y}_i = a + b x_i\\) rappresenta la parte prevedibile di \\(y\\) in funzione di \\(x\\). La componente aleatoria \\(e_i = y_i - \\hat{y}_i\\) cattura ciò che il modello non spiega.\n\n\n\n\n\n\nIllustrazione\n\n\n\n\n\nIl campione è costituito da \\(n\\) coppie di osservazioni (\\(x, y\\)).\n\\[\n\\begin{array}{cc}\n\\hline\nx_1 & y_1 \\\\\nx_2 & y_2 \\\\\nx_3 & y_3 \\\\\n\\vdots & \\vdots \\\\\nx_n & y_n \\\\\n\\hline\n\\end{array}\n\\]\nPer ciascuna coppia di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione\n\\[\n\\mathbb{E}(y_i) = a + b x_i ,\n\\tag{24.1}\\]\n ovvero:\n\\[\n\\begin{array}{ccc}\n\\hline\nx_i & y_i & \\mathbb{E}(y_i) = a + b x_i \\\\\n\\hline\nx_1 & y_1 & a + b x_1 \\\\\nx_2 & y_2 & a + b x_2 \\\\\nx_3 & y_3 & a + b x_3 \\\\\n\\vdots & \\vdots & \\vdots \\\\\nx_n & y_n & a + b x_n \\\\\n\\hline\n\\end{array}\n\\]\nI valori \\(y_i\\) corrispondono, nell’esempio che stiamo discutendo, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti:\n\nkidiq$kid_score[0:10]\n#&gt;  [1]  65  98  85  83 115  98  69 106 102  95\n\nPer fare riferimento a ciascuna osservazione usiamo l’indice \\(i\\). Quindi, ad esempio, \\(y_2\\) è uguale a\n\nkidiq$kid_score[2]\n#&gt; [1] 98\n\n\n\n\n\n24.4.1 Stima del modello di regressione\nCalcoliamo i coefficienti della retta di regressione utilizzando la funzione lm.\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\nEsaminiamo i risultati:\n\n# Coefficienti stimati\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nIn generale, molte rette possono approssimare la nube di punti, ma il modello di regressione impone vincoli:\n\nla retta deve passare per il punto medio \\((\\bar{x}, \\bar{y})\\);\ndeve minimizzare la somma dei quadrati dei residui (SSE).\n\n\n# Calcola i valori medi\nmean_x &lt;- mean(kidiq$mom_iq, na.rm = TRUE)\nmean_y &lt;- mean(kidiq$kid_score, na.rm = TRUE)\n\n# Grafico nello stile \"manuscript\"\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.65, color = css_palette$text_primary) +\n  geom_smooth(\n    method = \"lm\", se = FALSE,\n    color = css_palette$accent_warm,\n    linewidth = 0.8\n  ) +\n  annotate(\n    \"point\", \n    x = mean_x, y = mean_y,\n    color = css_palette$illumination_blue,\n    size = 4.5, shape = 4, stroke = 2.2\n  ) +\n  labs(\n    x = \"QI della madre\",\n    y = \"QI del bambino\",\n    title = stringr::str_wrap(\"QI materno e QI del bambino\", width = 50),\n    subtitle = \"Con retta di regressione e punto medio\"\n  ) +\n  theme_manuscript()\n\n\n\n\n\n\n\n\n24.4.2 Interpretazione\nIl coefficiente \\(a\\) indica l’intercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non è di particolare interesse poiché corrisponde al valore della retta di regressione quando l’intelligenza della madre è pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come è possibile trasformare i dati per fornire un’interpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri è associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ciò significa che non è in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unità di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\nÈ importante comprendere che il modello statistico di regressione lineare non è in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima è basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\) è stato fornito in precedenza. Il diagramma presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). I valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.\n\n24.4.3 Centrare le variabili\nIn generale, per variabili a livello di scala ad intervalli, l’intercetta del modello di regressione lineare non ha un’interpretazione utile. Questo perché l’intercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore “0” di \\(x\\) è arbitrario e non corrisponde ad un “assenza” della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un’assenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre è 0 non è di alcun interesse.\nCentrando \\(x\\) attorno alla sua media otteniamo un’intercetta interpretabile: il valore medio di kid_score quando mom_iq è nella media del campione.\n\nkidiq &lt;- kidiq %&gt;%\n  mutate(xd = mom_iq - mean(mom_iq))\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n\n\n\n\n\n\n\nIn sostanza, abbiamo applicato una trasformazione ai dati, traslando tutti i punti del grafico lungo l’asse delle ascisse in modo che la media dei valori \\(x\\) risulti pari a zero. Questa operazione non ha alterato la distribuzione o la forma complessiva della nuvola di punti, ma ha semplicemente modificato l’origine del sistema di riferimento sull’asse \\(x\\).\nLa pendenza della retta di regressione che mette in relazione \\(x\\) e \\(y\\) rimane invariata, sia per i dati originali che per quelli trasformati. L’unico parametro che subisce una modifica è il valore dell’intercetta della retta di regressione, che acquisisce in questo modo un’interpretazione più intuitiva e significativa dal punto di vista sostanziale.\n\nmod1 &lt;- lm(kid_score ~ xd, data = kidiq)\ncoef(mod1)\n#&gt; (Intercept)          xd \n#&gt;       86.80        0.61\n\nNell’output del modello, l’intercetta rappresenta il valore predetto della variabile dipendente \\(y\\) quando la variabile indipendente \\(x\\) assume esattamente il suo valore medio campionario. Nel caso specifico dell’esempio, l’intercetta corrisponde al punteggio atteso del QI del bambino (kid_score) quando il quoziente intellettivo della madre (mom_iq) è pari alla media osservata nel campione di riferimento.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#metodo-dei-minimi-quadrati",
    "title": "24  La regressione lineare bivariata",
    "section": "\n24.5 Metodo dei minimi quadrati",
    "text": "24.5 Metodo dei minimi quadrati\nNel modello di regressione bivariata, i coefficienti \\(a\\) (intercetta) e \\(b\\) (pendenza) vengono stimati scegliendo la retta che minimizza la somma dei quadrati dei residui (Sum of Squared Errors, SSE):\n\\[\ne_i = y_i - (a + b x_i), \\quad SSE = \\sum_{i=1}^n e_i^2.\n\\] Questa scelta equivale, sotto l’assunzione di errori normali con media zero e varianza costante, alla stima di massima verosimiglianza.\nLa minimizzazione dell’SSE porta alle equazioni normali, la cui soluzione ha forma chiusa:\n\\[\nb = \\frac{\\mathrm{Cov}(x, y)}{\\mathrm{Var}(x)}, \\quad a = \\bar{y} - b \\,\\bar{x} ,\n\\] dove:\n\n\n\\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie campionarie;\n\n\\(\\mathrm{Cov}(x,y)\\) è la covarianza tra \\(x\\) e \\(y\\);\n\n\\(\\mathrm{Var}(x)\\) è la varianza di \\(x\\).\n\nQueste formule assicurano che:\n\nLa retta passa per il punto medio \\((\\bar{x}, \\bar{y})\\) della nube di punti.\nLa pendenza \\(b\\) quantifica la variazione media di \\(y\\) per un’unità di incremento di \\(x\\).\nL’intercetta \\(a\\) è il valore previsto di \\(y\\) quando \\(x=0\\) (interpretazione utile solo se \\(x=0\\) è significativo).\n\nEsempio in R\n\ncov_xy &lt;- cov(kidiq$kid_score, kidiq$xd)\nvar_x  &lt;- var(kidiq$xd)\nb &lt;- cov_xy / var_x\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$xd)\nc(intercetta = a, pendenza = b)\n#&gt; intercetta   pendenza \n#&gt;      86.80       0.61\n\nI risultati replicano quelli ottenuti in precedenza con lm().\n\n24.5.1 Residui\nIl residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nkidiq$kid_score[1]\n#&gt; [1] 65\n\nIl QI della madre è\n\nkidiq$mom_iq[1]\n#&gt; [1] 121\n\nPer questo bambino, il valore predetto dal modello di regressione è\n\na + b * kidiq$mom_iq[1]\n#&gt; [1] 161\n\nL’errore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) è\n\nkidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\n#&gt; [1] -95.7\n\nPer tutte le osservazioni abbiamo\n\nres &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\nÈ una proprietà del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nsum(res)\n#&gt; [1] -26473\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che è predicibile da \\(x_i\\), è data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, è dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\n# Creazione di un data frame con i valori calcolati\ndf &lt;- data.frame(\n  kid_score = kidiq$kid_score,\n  mom_iq = kidiq$mom_iq,\n  y_hat = a + b * kidiq$mom_iq,\n  e = kidiq$kid_score - (a + b * kidiq$mom_iq),\n  y_hat_plus_e = (a + b * kidiq$mom_iq) + (kidiq$kid_score - (a + b * kidiq$mom_iq))\n)\n\n# Visualizzazione dei primi 6 valori\nhead(df)\n#&gt;   kid_score mom_iq y_hat     e y_hat_plus_e\n#&gt; 1        65  121.1   161 -95.7           65\n#&gt; 2        98   89.4   141 -43.3           98\n#&gt; 3        85  115.4   157 -72.2           85\n#&gt; 4        83   99.4   147 -64.5           83\n#&gt; 5       115   92.7   143 -28.4          115\n#&gt; 6        98  107.9   153 -54.6           98\n\n\n24.5.2 Illustrazione del metodo dei minimi quadrati\nPer stimare i coefficienti \\(a\\) e \\(b\\), possiamo minimizzare la somma dei quadrati dei residui tra i valori osservati \\(y_i\\) e quelli previsti \\(a + b x_i\\).\nIniziamo con il creare una griglia per i valori di \\(b\\). Supponiamo che il valore di \\(a\\) sia noto (\\(a = 25.79978\\)). Usiamo R per creare una griglia di valori possibili per \\(b\\).\n\n# Griglia di valori per b\nb_grid &lt;- seq(0, 1, length.out = 1001)\na &lt;- 25.79978  # Intercetta nota\n\nDefiniamo ora una funzione che calcola la somma dei quadrati dei residui (\\(SSE\\)) per ciascun valore di \\(b\\).\n\n# Funzione per la somma dei quadrati dei residui\nsse &lt;- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\nApplichiamo la funzione sse alla griglia di valori \\(b\\) per calcolare la somma dei quadrati dei residui per ogni valore di \\(b\\).\n\n# Calcolo di SSE per ciascun valore di b\nsse_vals &lt;- sapply(\n  b_grid, \n  function(b) sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n)\n\n\n\nsapply:\n\nÈ una funzione di R che applica una funzione ad ogni elemento di un vettore (o lista) e restituisce i risultati in un vettore.\nQui, applica la funzione sse a ciascun valore di \\(b\\) contenuto in b_grid.\n\n\n\nfunction(b):\n\nÈ una funzione anonima definita al volo per specificare come calcolare \\(SSE\\) per ciascun valore di \\(b\\).\nAll’interno, viene chiamata la funzione sse(a, b, x, y) con i seguenti parametri:\n\n\na: il valore dell’intercetta (fissato in precedenza o noto).\n\nb: il valore corrente nella griglia b_grid.\n\nx: la variabile indipendente del dataset (kidiq$mom_iq).\n\ny: la variabile dipendente del dataset (kidiq$kid_score).\n\n\n\n\nIl risultato è un vettore, sse_vals, che contiene i valori di \\(SSE\\) corrispondenti a ciascun valore di \\(b\\) in b_grid.\n\nTracciamo un grafico che mostra la somma dei quadrati dei residui (\\(SSE\\)) in funzione dei valori di \\(b\\), evidenziando il minimo.\n\n# Identificazione del valore di b che minimizza SSE\nb_min &lt;- b_grid[which.min(sse_vals)]\n\n# Creazione del dataframe per ggplot\ndat &lt;- data.frame(b_grid = b_grid, sse_vals = sse_vals)\n\n# Genera il grafico\nggplot(dat, aes(x = b_grid, y = sse_vals)) +\n  geom_line(linewidth = 1) +  \n  annotate(\n    \"point\", x = b_min, y = min(sse_vals),\n    color = \"red\", size = 3\n  ) +  # Punto minimo\n  labs(\n    x = expression(paste(\"Possibili valori di \", hat(beta))),\n    y = \"Somma dei quadrati\\ndei residui\",\n    title = \"Residui quadratici\"\n  ) +\n  annotate(\n    \"text\", x = b_min, y = min(sse_vals), \n    label = expression(hat(beta)), color = \"red\", vjust = -1, hjust = 0.5\n  )\n\n\n\n\n\n\n\nInfine, identifichiamo il valore di \\(b\\) che minimizza la somma dei quadrati dei residui.\n\nb_min\n#&gt; [1] 0.61\n\nCon questa simulazione, abbiamo stimato il coefficiente \\(b\\) minimizzando la somma dei quadrati dei residui.\nQuesto approccio può essere esteso per stimare simultaneamente entrambi i coefficienti (\\(a\\) e \\(b\\)) utilizzando metodi di ottimizzazione più avanzati, come optim in R.\n\noptim_result &lt;- optim(\n  par = c(a = 25, b = 0.5),  # Valori iniziali\n  fn = function(params) {\n    a &lt;- params[1]\n    b &lt;- params[2]\n    sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n  }\n)\n\n# Coefficienti stimati\noptim_result$par\n#&gt;     a     b \n#&gt; 25.79  0.61\n\nQuesta simulazione illustra come, tramite il metodo dei minimi quadrati, sia possibile stimare i parametri di un modello bivariato di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "title": "24  La regressione lineare bivariata",
    "section": "\n24.6 L’errore standard della regressione",
    "text": "24.6 L’errore standard della regressione\nL’errore standard della stima \\(s_e\\) misura la deviazione media dei dati dalla retta:\n\\[\n\\sqrt{\\frac{1}{n-2} \\sum_{i=1}^n \\big(y_i - (\\hat{a} + \\hat{b}x_i)\\big)^2},\n\\tag{24.2}\\]\nL’indice \\(s_e\\) possiede la stessa unità di misura di \\(y\\) ed è una stima della deviazione standard dei residui nella popolazione.\nIn R:\n\n# Calcolo dei residui\ne &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n# Mostriamo i primi 10 residui\nhead(e, 10)\n#&gt;  [1] -34.68  17.69 -11.22  -3.46  32.63   6.38 -41.52   3.86  26.41  11.21\n\nCalcoliamo il valore medio assoluto dei residui per avere un’indicazione della deviazione media rispetto alla retta di regressione.\n\n# Media assoluta dei residui\nmean(abs(e))\n#&gt; [1] 14.5\n\nL’errore standard della stima \\(s_e\\) si calcola come la radice quadrata della somma dei quadrati dei residui divisa per \\(n-2\\):\n\n# Calcolo di s_e\nse &lt;- sqrt(sum(e^2) / (length(e) - 2))\nse\n#&gt; [1] 18.3\n\nNotiamo che il valore medio assoluto dei residui e l’errore standard \\(s_e\\) non sono identici, ma hanno lo stesso ordine di grandezza. \\(s_e\\) è una misura più rigorosa della deviazione standard dei residui.\nQuesta analisi dimostra come \\(s_e\\) consenta di valutare quanto le previsioni del modello si discostino (in media) dai dati osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#lindice-di-determinazione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#lindice-di-determinazione",
    "title": "24  La regressione lineare bivariata",
    "section": "\n24.7 L’indice di determinazione",
    "text": "24.7 L’indice di determinazione\nNell’approccio frequentista, la qualità dell’adattamento si apprezza osservando l’indice di determinazione \\(R^2\\), che indica quanta parte della varianza di \\(y\\) viene spiegata dal modello, e analizzando i residui: eventuali pattern sistematici nei residui possono segnalare che la struttura scelta non coglie tutte le caratteristiche dei dati o che esistono violazioni delle ipotesi (linearità, omoscedasticità, normalità degli errori). Un esame congiunto di \\(R^2\\) e residui aiuta a diagnosticare e, se necessario, migliorare il modello.\nL’indice di determinazione viene calcolato utilizzando un’importante proprietà del modello di regressione, ovvero la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) può quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\tag{24.3}\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. Questa scomposizione della devianza va sotto il nome di teorema della scomposizione della devianza.\nQuesta scomposizione viene utilizzata per calcolare l’indice di determinazione \\(R^2\\), che fornisce una misura della bontà di adattamento del modello ai dati del campione. L’indice di determinazione \\(R^2\\) è definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\tag{24.4}\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) è spiegata dalla variabile indipendente \\(x\\).\nPer l’esempio in discussione, possiamo calcolare la devianza totale, la devianza spiegata e l’indice di determinazione \\(R^2\\) come segue:\nLa devianza totale misura la variabilità complessiva dei punteggi osservati \\(y\\) rispetto alla loro media:\n\n# Devianza totale\ndev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#&gt; [1] 180386\n\nLa devianza spiegata misura la variabilità che il modello è in grado di spiegare, considerando i valori predetti \\(a + b x\\):\n\n# Devianza spiegata\ndev_r &lt;- sum(((a + b * kidiq$mom_iq) - mean(kidiq$kid_score))^2)\ndev_r\n#&gt; [1] 36249\n\nL’indice \\(R^2\\) è il rapporto tra la devianza spiegata e la devianza totale, e indica la frazione della variabilità totale che è spiegata dal modello di regressione:\n\n# Indice di determinazione\nR2 &lt;- dev_r / dev_t\nround(R2, 3)\n#&gt; [1] 0.201\n\nPer verificare i calcoli, utilizziamo il modello di regressione lineare in R e leggiamo \\(R^2\\) direttamente dal sommario del modello:\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Sommario del modello per leggere R^2\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nIl risultato mostra che circa il 20% della variabilità nei punteggi del QI dei bambini è spiegabile conoscendo il QI delle madri. Questo significa che il modello cattura una porzione rilevante della relazione, ma lascia anche spazio a fattori non inclusi nel modello che influenzano il QI dei bambini.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sui-coefficienti",
    "href": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sui-coefficienti",
    "title": "24  La regressione lineare bivariata",
    "section": "\n24.8 Inferenza sui coefficienti",
    "text": "24.8 Inferenza sui coefficienti\nL’inferenza statistica sui coefficienti di regressione richiede la definizione della distribuzione campionaria dei coefficienti di regressione. Il modello di regressione bivariata (o lineare semplice) è:\n\\[Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\\] dove \\(Y_i\\) è la variabile dipendente per l’osservazione \\(i\\), \\(X_i\\) è la variabile indipendente, \\(\\beta_0\\) è l’intercetta (parametro ignoto), \\(\\beta_1\\) è il coefficiente angolare (il parametro che ci interessa stimare), e \\(\\varepsilon_i\\) è il termine di errore per l’osservazione \\(i\\).\nNell’inferenza, il nostro obiettivo è stimare i parametri ignoti \\(\\beta_0\\) e \\(\\beta_1\\) usando i dati campionari disponibili. Il metodo più comune è quello dei Minimi Quadrati Ordinari (OLS), che ci fornisce gli stimatori \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) (spesso indicati semplicemente con \\(b_0\\) e \\(b_1\\)). Lo stimatore per il coefficiente angolare è dato dalla formula:\n\\[\\hat{\\beta}_1 = b_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}.\\]\n\n24.8.1 Cos’è la distribuzione campionaria di \\(b_1\\)?\nLo stimatore \\(b_1\\) è una variabile casuale. Perché? Perché il suo valore dipende dal campione casuale di dati \\((X_i, Y_i)\\) che abbiamo estratto dalla popolazione.\nImmaginiamo di poter ripetere il processo di campionamento e stima del modello infinite volte:\n\nEstraiamo un campione casuale di dimensione \\(n\\).\nCalcoliamo lo stimatore \\(b_1\\) per quel campione.\nRegistriamo il valore di \\(b_1\\).\nEstraiamo un nuovo campione casuale (indipendentemente dal primo).\nCalcoliamo il “nuovo” \\(b_1\\).\nRegistriamo il valore.\n… e così via, per infinite volte.\n\nLa distribuzione campionaria di \\(b_1\\) è la distribuzione di probabilità di tutti i valori di \\(b_1\\) che otterremmo da questi infiniti campioni casuali di dimensione \\(n\\) estratti dalla stessa popolazione.\n\n24.8.2 Assunzioni di Gauss–Markov e distribuzione campionaria della pendenza\nPer il modello di regressione bivariata\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\n\\] lo stimatore OLS della pendenza è\n\\[\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}.\n\\] Questo è una variabile casuale, perché il suo valore dipende dal campione estratto.\n\n24.8.2.1 1. Assunzioni di Gauss–Markov\nAffinché \\(\\hat{\\beta}_1\\) sia non distorto (unbiased) e BLUE (Best Linear Unbiased Estimator), devono valere:\n\nLinearità nei parametri La relazione media tra \\(Y\\) e \\(X\\) è lineare: \\(E(Y_i \\mid X_i) = \\beta_0 + \\beta_1 X_i\\).\nCampionamento casuale e indipendenza Le osservazioni \\((X_i,Y_i)\\) sono indipendenti e identicamente distribuite.\nEsogeneità Gli errori hanno media nulla condizionata a \\(X\\): \\(E(\\varepsilon_i \\mid X_i) = 0\\). Se violata, lo stimatore è distorto.\nOmoschedasticità Varianza costante degli errori: \\(\\mathrm{Var}(\\varepsilon_i \\mid X_i) = \\sigma^2\\).\nAssenza di collinearità perfetta La variabilità di \\(X\\) è positiva: \\(\\sum_{i=1}^n (X_i - \\bar{X})^2 &gt; 0\\).\n\nPer inferenza esatta in piccoli campioni si aggiunge l’assunzione di normalità: \\(\\varepsilon_i \\sim N(0,\\sigma^2)\\).\n\n24.8.2.2 2. Proprietà della distribuzione campionaria di \\(\\hat{\\beta}_1\\)\n\nSotto le assunzioni di Gauss–Markov:\n\nMedia (non distorsione) \\(E(\\hat{\\beta}_1) = \\beta_1\\) → in media, il processo di stima restituisce il vero coefficiente.\n\nVarianza\n\\[\n\\mathrm{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n\\]\ndove \\(\\sigma^2\\) è la varianza degli errori. In pratica si usa la stima:\n\\[\ns^2_e = \\frac{\\sum e_i^2}{n-2}, \\quad\nSE(\\hat{\\beta}_1) = \\sqrt{\\frac{s_e^2}{\\sum (X_i - \\bar{X})^2}}\n\\]\n\n\nForma della distribuzione\n\nCon normalità degli errori → distribuzione esatta normale per ogni \\(n\\).\nSenza normalità, per grandi \\(n\\) la distribuzione è approssimativamente normale (Teorema del Limite Centrale).\n\n\n\n24.8.2.3 3. Uso della distribuzione campionaria\nConoscere la distribuzione campionaria di \\(\\hat{\\beta}_1\\) serve per:\n\nTest d’ipotesi Es.: \\(H_0: \\beta_1 = 0\\), usando la statistica \\(t = \\hat{\\beta}_1 / SE(\\hat{\\beta}_1).\\)\nIntervalli di confidenza Es.: \\(\\hat{\\beta}_1 \\pm t_{n-2,\\,0.975} \\times SE(\\hat{\\beta}_1)\\), interpretati in termini di proprietà a lungo termine della procedura di campionamento.\n\nIn sintesi, la distribuzione campionaria di \\(b_1\\) descrive la variabilità attesa dello stimatore del coefficiente angolare attraverso diversi campioni casuali. Comprendere le sue proprietà (media, varianza, forma) è essenziale per interpretare correttamente i risultati di una regressione e trarre conclusioni affidabili sulla relazione nella popolazione.1\n\n24.8.3 Simulazione in R\nCalcoliamo la distribuzione campionaria di \\(\\hat{\\beta}_1\\). Iniziamo simulando un modello lineare bivariato con variabili standardizzate:\n\\[\nY_i = \\beta X_i + \\varepsilon_i, \\quad \\varepsilon_i \\sim N(0, \\sigma_\\varepsilon = 0.5),\n\\] con \\(\\beta = 1.5\\) e \\(n = 30\\) osservazioni.\nRipetiamo il campionamento \\(100{,}000\\) volte per approssimare la distribuzione campionaria di \\(\\hat{\\beta}_1\\).\n\n# Parametri\nbeta     &lt;- 1.5     # pendenza vera\nsigma_e  &lt;- 0.5     # deviazione standard errori\nn        &lt;- 30      # dimensione campione\nnrep     &lt;- 1e5     # numero repliche\n\n# X fissata una volta (come nelle assunzioni di Gauss-Markov)\nx &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Stime memorizzate\nb_hat &lt;- numeric(nrep)\n\n# Simulazione\nfor (i in 1:nrep) {\n  e &lt;- rnorm(n, mean = 0, sd = sigma_e) # errori\n  y &lt;- beta * x + e                     # risposta\n  b_hat[i] &lt;- cov(x, y) / var(x)        # formula OLS\n}\n\nEsaminiamo i risultati:\n\n# Statistiche empiriche\nmean_b_hat &lt;- mean(b_hat)  # media stimata\nsd_b_hat   &lt;- sd(b_hat)    # deviazione standard stimata\n\n# Errore standard teorico\nse_theo &lt;- sqrt(sigma_e^2 / sum((x - mean(x))^2))\n\nc(media_empirica = mean_b_hat,\n  sd_empirica    = sd_b_hat,\n  SE_teorico     = se_theo)\n#&gt; media_empirica    sd_empirica     SE_teorico \n#&gt;          1.500          0.101          0.101\n\nGeneriamo un grafico della distribuzione:\n\nggplot(data.frame(b_hat = b_hat), aes(x = b_hat)) +\n  geom_histogram(aes(y = after_stat(density)),\n                 bins = 50) +\n  stat_function(fun = dnorm,\n                args = list(mean = mean_b_hat, sd = sd_b_hat),\n                linewidth = 1) +\n  labs(\n    title = expression(\"Distribuzione campionaria di\" ~ hat(beta)[1]),\n    x = expression(hat(beta)[1]),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nL’analisi della distribuzione campionaria dello stimatore \\(\\hat{\\beta}_1\\) conferma tre proprietà statistiche fondamentali. In primo luogo, emerge la non distorsione dello stimatore: la media empirica calcolata si attesta approssimativamente a 1.5, valore che coincide con il parametro teorico \\(\\beta_1\\). Questo risultato fornisce una verifica empirica della proprietà per cui, sotto le assunzioni di Gauss-Markov, vale l’uguaglianza \\(E(\\hat{\\beta}_1) = \\beta_1\\), indicando che lo stimatore è corretto e non sistematicamente distorto.\nPer quanto riguarda la precisione dello stimatore, si osserva che la deviazione standard empirica risulta molto vicina all’errore standard teorico, definito come \\(SE(\\hat{\\beta}_1) = \\sqrt{\\sigma^2 / \\sum (X_i - \\bar{X})^2}\\). Questa corrispondenza suggerisce che la variabilità campionaria osservata è in linea con quanto previsto dal framework teorico, supportando l’affidabilità delle inferenze basate su questo stimatore.\nInfine, l’esame della forma della distribuzione rivela che l’istogramma dei valori stimati è ben approssimato da una curva normale. Questo risultato conferma la normalità asintotica dello stimatore anche per un campione di dimensione moderata (\\(n = 30\\)), avvallando l’utilizzo della distribuzione normale per la costruzione di intervalli di confidenza e test di ipotesi in questo contesto.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "href": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "title": "24  La regressione lineare bivariata",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo introdotto la regressione lineare bivariata nell’ottica frequentista, mostrando come il metodo dei minimi quadrati consenta di stimare i parametri della retta di regressione e di valutarne l’affidabilità attraverso strumenti inferenziali. Abbiamo chiarito il significato di intercetta, pendenza e varianza residua, discutendo anche le condizioni che rendono il modello un buon riassunto dei dati.\nQuesta impostazione, pur molto diffusa, presenta però limiti evidenti. L’inferenza si appoggia quasi esclusivamente ai p-value e agli intervalli di confidenza, non permette di incorporare conoscenza pregressa e richiede assunzioni rigide sulla distribuzione degli errori. Il risultato è un approccio potente per descrivere associazioni, ma poco flessibile e spesso riduttivo rispetto alle domande scientifiche più sostanziali.\nPer superare questi vincoli, nei prossimi capitoli esploreremo la regressione lineare da una prospettiva bayesiana. Qui vedremo come sia possibile integrare informazioni a priori, rappresentare l’incertezza in termini probabilistici e ottenere stime più trasparenti e interpretabili. Sarà il primo passo per trasformare la regressione da semplice strumento descrittivo a un modello inserito in un quadro inferenziale più ampio, capace di adattarsi meglio alla complessità della ricerca psicologica.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n1 – Definizione e scopi della regressione\nSecondo Gelman et al. (2021), quali sono i quattro principali utilizzi della regressione? Fornisci una breve descrizione di ciascuno.\n2 – Errore di specificazione\nCos’è l’“errore di specificazione” in un modello di regressione? Quali effetti ha sulle stime dei parametri?\n3 – Stima del modello con lm()\nUsando il data‑set kidiq (variabili kid_score e mom_iq):\n\n# carica i dati\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\nAdatta il modello kid_score ~ mom_iq e riporta intercetta e pendenza.\n4 – Interpretazione della pendenza\nInterpreta in parole la pendenza stimata al punto 3 nel contesto dei QI di madri e figli.\n5 – Indice R²\nCalcola l’R² del modello di cui al punto 3. Cosa indica il suo valore?\n6 – Centratura del predittore\nCrea la variabile centrata mom_iq_c = mom_iq - mean(mom_iq) e ri‑adatta il modello kid_score ~ mom_iq_c. Qual è la nuova intercetta e perché adesso è più interpretabile?\n7 – Calcolo manuale di \\(b\\)\nCalcola manualmente la pendenza con la formula\\(b = \\frac{\\text{Cov}(x,y)}{\\text{Var}(x)}\\)\ne confrontala col risultato di lm().\n8 – Confronto tra σ̂ (tradizionale) e σ_CV\n* (a) Calcola l’errore standard della regressione (σ̂) usando il modello completo.\n* (b) Esegui una validazione incrociata leave‑one‑out (LOOCV) e ottieni σ_CV.\n* (c) Spiega perché, in genere, σ_CV è ≥ σ̂.\n9 – Assunzioni di Gauss‑Markov\nElenca le cinque assunzioni di Gauss‑Markov per la regressione lineare semplice e indica quale, se violata, rende distorto lo stimatore OLS della pendenza.\n10 – Simulazione della distribuzione campionaria di \\(b\\)\nSimula 100 000 campioni (n = 30) dal modello\\(Y_i = 1.5\\,X_i + \\varepsilon_i,\\; X_i \\sim \\mathcal N(0,1),\\; \\varepsilon_i \\sim \\mathcal N(0,0.5^2)\\).\nPer ogni campione calcola \\(b̂\\). Rappresenta l’istogramma dei 100 000 \\(b̂\\), riporta media e deviazione standard empiriche e confrontale con l’errore standard teorico.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1 – Definizione e scopi\n1. Previsione – modellare / predire nuove osservazioni.\n2. Esplorazione delle associazioni – quantificare relazioni \\(X \\rightarrow Y\\).\n3. Estrapolazione – generalizzare dal campione alla popolazione.\n4. Inferenza causale – stimare l’effetto di un intervento quando il design lo consente.\n2 – Errore di specificazione\nOmettere un predittore rilevante ⇒ i residui assorbono la sua varianza ⇒ stime di \\(b\\) distorte (bias) e varianze sottostimate → inferenze non valide.\n3 – Stima del modello\n\nlibrary(rio); library(here)\nkidiq &lt;- import(here(\"data\",\"kidiq.dta\"))\n\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nEsempio di output\n(Intercept)     mom_iq \n 25.800        0.610 \n4 – Interpretazione della pendenza\nUn punto in più di QI materno è associato, in media, a 0.61 punti di QI del figlio.\n5 – Indice R²\n\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nOutput ≈ 0.20 ⇒ il 20 % della varianza di kid_score è spiegato da mom_iq.\n6 – Centratura\n\nkidiq$mom_iq_c &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\nmod_c &lt;- lm(kid_score ~ mom_iq_c, data = kidiq)\ncoef(mod_c)\n#&gt; (Intercept)    mom_iq_c \n#&gt;       86.80        0.61\n\nL’intercetta ora ≈ media del QI dei bambini quando il QI materno è medio.\nLa pendenza resta 0.61.\n7 – Calcolo manuale di b\n\nb_manual &lt;- cov(kidiq$mom_iq, kidiq$kid_score) / var(kidiq$mom_iq)\nall.equal(b_manual, coef(mod)[\"mom_iq\"])\n#&gt; [1] \"names for current but not for target\"\n\nTRUE → concordanza perfetta (salvo arrotondamenti).\n8 – σ̂ vs σ_CV\n\n# (a) σ̂\nsigma_hat &lt;- summary(mod)$sigma\n\n# (b) LOOCV\nn &lt;- nrow(kidiq)\nres_cv2 &lt;- numeric(n)\nfor (i in seq_len(n)){\n  fit_i &lt;- lm(kid_score ~ mom_iq, data = kidiq[-i,])\n  res_cv2[i] &lt;- (kidiq$kid_score[i] - predict(fit_i, kidiq[i,]))^2\n}\nsigma_CV &lt;- sqrt(mean(res_cv2))\n\nc(sigma_hat = sigma_hat, sigma_CV = sigma_CV)\n#&gt; sigma_hat  sigma_CV \n#&gt;      18.3      18.3\n\nσ_CV tende a superare σ̂ perché ogni predizione è fatta su dati che non hanno “visto” quell’osservazione → niente sovradimensionamento.\n9 – Assunzioni Gauss‑Markov\n1. Linearità nei parametri\n2. Campionamento casuale IID\n3. Esogeneità \\(E(\\varepsilon_i\\!\\mid X_i)=0\\) ← questa garantisce non‑distorsione\n4. Omoschedasticità\n5. Assenza di collinearità perfetta\n10 – Simulazione\n\nset.seed(123)\nbeta  &lt;- 1.5; sigma_e &lt;- 0.5; n  &lt;- 30; nrep &lt;- 1e5\nx &lt;- rnorm(n)\nb_hat &lt;- replicate(nrep, {\n  y &lt;- beta * x + rnorm(n, sd = sigma_e)\n  cov(x,y) / var(x)\n})\n\nmean_emp &lt;- mean(b_hat)\nsd_emp   &lt;- sd(b_hat)\nse_theo  &lt;- sqrt(sigma_e^2 / sum((x - mean(x))^2))\nc(media_empirica = mean_emp, sd_empirica = sd_emp, SE_teorico = se_theo)\n#&gt; media_empirica    sd_empirica     SE_teorico \n#&gt;         1.5001         0.0948         0.0946\n\nL’istogramma (codice sotto) mostra la forma quasi normale centrata su 1.5.\n\nhist(b_hat, breaks = 60, freq = FALSE, main = \"Distribuzione campionaria di b̂\",\n     xlab = \"b̂\"); curve(dnorm(x, mean_emp, sd_emp), add = TRUE, lwd = 2)\n\n\n\n\n\n\n\n- La media empirica ≈ 1.5 ⇒ unbiased.\n- La sd empirica ≈ SE teorico ⇒ formula varianza confermata.\n- Distribuzione simmetrica ≈ Normale ⇒ normalità asintotica verificata.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] broom_1.0.9           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        mgcv_1.9-3           \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] tzdb_0.5.0            haven_2.5.5           ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          R.utils_2.13.0        readr_2.1.5          \n#&gt; [37] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [40] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [43] codetools_0.2-20      curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       hms_1.1.3             rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           forcats_1.0.0        \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          R.methodsS3_1.8.2    \n#&gt; [79] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [82] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [85] R.oo_1.27.1           lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "href": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "title": "24  La regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "href": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "title": "24  La regressione lineare bivariata",
    "section": "",
    "text": "Per un approfondimento sull’approccio frequentista alla regressione, si veda, per esempio, Caudek & Luccio (2001).↩︎",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html",
    "href": "chapters/linear_models/02_regr_toward_mean.html",
    "title": "25  La regressione verso la media",
    "section": "",
    "text": "Introduzione\nIl concetto di regressione verso la media fu introdotto da Francis Galton alla fine dell’Ottocento, osservando la trasmissione ereditaria dell’altezza. Egli notò che i figli di padri eccezionalmente alti rimanevano in media sopra la statura generale, ma meno dei loro padri; e che lo stesso valeva, in direzione opposta, per i figli di padri molto bassi. Questo “ritorno parziale verso il centro” della distribuzione è il fenomeno che ancora oggi porta il nome di regressione verso la media.\nPerché avviene? Un valore estremo, come un’altezza particolarmente alta o bassa, è il risultato della combinazione di fattori genetici, ambientali e casuali. I figli ereditano solo una parte di questi fattori, e nuove influenze si aggiungono al quadro: il risultato è che le loro altezze tendono a essere meno estreme, più vicine alla media della popolazione. Non significa che il figlio di un padre altissimo diventi basso: rimane in media più alto degli altri, ma meno estremo.\nIl cuore statistico del fenomeno sta nella correlazione imperfetta tra le due variabili considerate (altezza del padre e del figlio). Se la correlazione fosse pari a 1, gli estremi si replicherebbero perfettamente. Ma quando \\(\\rho &lt; 1\\), i valori attesi dei figli risultano più vicini alla media rispetto a quelli dei padri. Galton stimò, nel suo esempio, una correlazione attorno a 0.5: segno che una parte importante, ma non totale, dell’estremità paterna si trasmette al figlio.\nStudiare la regressione verso la media ci permette di capire più a fondo la logica della regressione lineare bivariata. Si tratta infatti di un’applicazione concreta dell’idea di pendenza inferiore a 1 quando la correlazione non è perfetta. Questo fenomeno, apparentemente controintuitivo, è in realtà inevitabile nei dati psicologici e ha implicazioni profonde per l’interpretazione delle osservazioni e dei cambiamenti individuali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "title": "25  La regressione verso la media",
    "section": "",
    "text": "Panoramica del capitolo\n\nOrigine storica e intuizione del fenomeno (Galton).\nRegressione e correlazione: forme standardizzate e non standardizzate.\nVisualizzazione della RTM tramite retta di regressione.\nRTM ≠ causalità: errori di misura e artefatti di selezione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Basic Regression di Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (Second Edition).\nLeggere il capitolo Linear Statistical Models (Schervish & DeGroot, 2014).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(HistData)\n\n\n\n\n\n25.0.1 I dati di Galton\nEsaminiamo il fenomeno della regressione verso la media usando i dati di Galton. Nel pacchetto HistData di R sono disponibili i dati originali raccolti da Galton, che includono informazioni sull’altezza di padri, madri, figli maschi e femmine. Per semplificare l’analisi, possiamo creare un dataset che include solo l’altezza del padre e l’altezza di un figlio maschio scelto casualmente da ogni famiglia:\n\nset.seed(1234)\n\ngalton_heights &lt;- GaltonFamilies |&gt;\n  filter(gender == \"male\") |&gt;\n  group_by(family) |&gt;\n  sample_n(1) |&gt;\n  ungroup() |&gt;\n  select(father, childHeight) |&gt;\n  rename(son = childHeight)\n\nQuesto dataset contiene due colonne: father (altezza del padre) e son (altezza del figlio maschio). Calcolando la media e la deviazione standard delle altezze dei padri e dei figli, otteniamo:\n\ngalton_heights |&gt; \n  summarize(\n    mean_father = mean(father), \n    sd_father   = sd(father),\n    mean_son    = mean(son), \n    sd_son      = sd(son)\n  )\n#&gt; # A tibble: 1 × 4\n#&gt;   mean_father sd_father mean_son sd_son\n#&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1        69.1      2.55     69.1   2.62\n\nI risultati mostrano che, in media, i padri e i figli hanno altezze simili, anche se le distribuzioni non sono identiche. Un grafico di dispersione (scatterplot) evidenzia una chiara tendenza: padri più alti tendono ad avere figli più alti:\n\ngalton_heights |&gt;\n  ggplot(aes(father, son)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n25.0.2 Il coefficiente di correlazione\nLa forza e la direzione dell’associazione lineare tra le due variabili sono misurate dal coefficiente di correlazione di Pearson, definito come:\n\\[\n\\rho = \\frac{1}{n}\\sum_{i=1}^n\n\\left(\\frac{x_i - \\mu_x}{\\sigma_x}\\right)\n\\left(\\frac{y_i - \\mu_y}{\\sigma_y}\\right).\n\\]\ndove \\(\\mu_X, \\mu_Y\\) sono le medie e \\(\\sigma_X, \\sigma_Y\\) le deviazioni standard delle rispettive popolazioni. La sua stima campionaria, \\(r\\), è calcolata in R come:\n\ngalton_heights |&gt; \n  summarize(r = cor(father, son)) |&gt; \n  pull(r)\n#&gt; [1] 0.443\n\nUn coefficiente di 0.5 indica un’associazione lineare positiva di moderata intensità, implicando che l’altezza paterna spiega solo parzialmente la variabilità dell’altezza dei figli.\n\n25.0.3 L’aspettativa condizionata e l’emergenza del fenomeno di regressione\nUn obiettivo inferenziale comune è la stima del valore atteso dell’altezza del figlio (\\(Y\\)), condizionata a un specifico valore dell’altezza del padre (\\(X = x_0\\)), formalmente \\(\\mathbb{E}(Y \\mid X = x_0)\\).\nUn approccio intuitivo è stratificare i dati e calcolare la media campionaria del sottogruppo. Ad esempio, per \\(X = 72\\) pollici:\n\ngalton_heights |&gt; \n  filter(round(father) == 72) |&gt;\n  summarize(avg_son = mean(son))\n#&gt; # A tibble: 1 × 1\n#&gt;   avg_son\n#&gt;     &lt;dbl&gt;\n#&gt; 1    70.2\n\nTale stima risulta sistematicamente più vicina alla media generale di \\(Y\\) di quanto \\(x_0\\) non lo sia alla media di \\(X\\). Questo fenomeno è noto come regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-del-fenomeno-attraverso-la-stratificazione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-del-fenomeno-attraverso-la-stratificazione",
    "title": "25  La regressione verso la media",
    "section": "\n25.1 Visualizzare del fenomeno attraverso la stratificazione",
    "text": "25.1 Visualizzare del fenomeno attraverso la stratificazione\nIl fenomeno è generalizzabile visualizzando la media condizionata \\(\\mathbb{E}(Y \\mid X = x)\\) per diversi valori di \\(x\\), ottenuti tramite stratificazione:\n\ngalton_heights |&gt;\n  mutate(father_strata = factor(round(father))) |&gt;\n  group_by(father_strata) |&gt;\n  summarize(avg_son = mean(son)) |&gt;\n  ggplot(aes(x = father_strata, y = avg_son)) +\n  geom_point()\n\n\n\n\n\n\n\nLa nube di punti delle medie condizionate presenta una pendenza positiva ma inferiore a 45°, dimostrando visivamente la regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#modello-di-regressione-lineare-e-interpretazione-dei-parametri",
    "href": "chapters/linear_models/02_regr_toward_mean.html#modello-di-regressione-lineare-e-interpretazione-dei-parametri",
    "title": "25  La regressione verso la media",
    "section": "\n25.2 Modello di regressione lineare e interpretazione dei parametri",
    "text": "25.2 Modello di regressione lineare e interpretazione dei parametri\nIl modello statistico che formalizza questa relazione è la regressione lineare semplice:\n\\[\nY = \\beta_0 + \\beta_1 X + \\varepsilon ,\n\\]\ndove \\(\\epsilon\\) è un termine di errore stocastico con media zero.\nGli stimatori dei minimi quadrati ordinari (OLS) per i parametri \\(\\beta_0\\) (intercetta) e \\(\\beta_1\\) (pendenza) sono:\n\\[\n\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}, \\quad \\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}\n\\]\ndove \\(s_X\\), \\(s_Y\\) sono le deviazioni standard campionarie e \\(\\bar{X}\\), \\(\\bar{Y}\\) le medie campionarie.\nL’applicazione del modello ai dati di Galton fornisce:\n\nfit &lt;- lm(son ~ father, data = galton_heights)\ncoef(fit)\n#&gt; (Intercept)      father \n#&gt;      37.632       0.456\n\nLa pendenza stimata \\(\\hat{\\beta}_1 = 0.454\\) conferma che per ogni pollice in più del padre, l’altezza attesa del figlio aumenta di circa 0.454 pollici, un valore inferiore a 1 che è consistente con la regressione verso la media.\n\n25.2.0.1 Standardizzazione\nStandardizzando le variabili (\\(Z_X = (X - \\bar{X})/s_X\\), \\(Z_Y = (Y - \\bar{Y})/s_Y\\)), il modello di regressione assume la forma\n\\[\nZ_Y = \\rho\\, Z_X + \\varepsilon.\n\\]\nVediamo come si arriva a questo risultato. Consideriamo il modello lineare semplice\n\\[\nY = \\beta_0 + \\beta_1 X + \\varepsilon,\n\\qquad \\mathbb{E}[\\varepsilon] = 0,\n\\qquad \\mathrm{Cov}(X,\\varepsilon) = 0.\n\\]\nDalle equazioni normali dei minimi quadrati otteniamo, a livello di popolazione:\n\\[\n\\beta_1 = \\frac{\\mathrm{Cov}(X,Y)}{\\mathrm{Var}(X)},\n\\qquad\n\\beta_0 = \\mu_Y - \\beta_1 \\mu_X.\n\\]\nScrivendo la covarianza come \\(\\mathrm{Cov}(X,Y) = \\rho \\sigma_X \\sigma_Y\\), segue che\n\\[\n\\beta_1 = \\rho \\,\\frac{\\sigma_Y}{\\sigma_X}.\n\\]\nSe ora standardizziamo \\(X\\) e \\(Y\\), entrambe le deviazioni standard valgono 1, quindi la pendenza diventa\n\\[\n\\beta_1^* = \\rho.\n\\]\nInoltre, poiché le variabili standardizzate hanno media zero, anche l’intercetta scompare.\nIn conclusione, la regressione di \\(Z_Y\\) su \\(Z_X\\) ha sempre intercetta pari a 0 e coefficiente angolare pari alla correlazione \\(\\rho\\).\nInfatti, nei dati campionari:\n\nfit_standardized &lt;- lm(scale(son) ~ scale(father), data = galton_heights)\ncoef(fit_standardized)\n#&gt;   (Intercept) scale(father) \n#&gt;     -7.60e-15      4.43e-01\n\nLa pendenza è \\(0.4434\\), numericamente uguale alla correlazione \\(r\\) calcolata in precedenza (a meno di errori di arrotondamento). Poiché \\(|\\rho| &lt; 1\\), la previsione per un valore standardizzato \\(z_x\\) sarà \\(\\hat{z}_y = \\rho z_x\\), che è sempre, in valore assoluto, minore di \\(z_x\\). Questo spiega matematicamente il perché un valore estremo di \\(X\\) porta a una previsione per \\(Y\\) che è meno estrema, ossia più vicina alla sua media standardizzata (zero).\nIn sintesi, la correlazione imperfetta (\\(\\rho &lt; 1\\)) è la ragione principale per cui un valore estremo di \\(X\\) (ad esempio, un padre molto alto) porta a un valore \\(\\hat{Y}\\) che è sì superiore (o inferiore) alla media, ma meno estremo del padre. Questo “ritorno verso il centro” è ciò che chiamiamo regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "href": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "title": "25  La regressione verso la media",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa regressione verso la media è un fenomeno statistico inevitabile ogni volta che due misurazioni sono correlate, ma non perfettamente. In termini standardizzati, se \\(\\rho &lt; 1\\), il valore atteso di una variabile condizionata a un valore estremo dell’altra risulta più vicino alla media. Ciò significa che le osservazioni molto alte o molto basse tenderanno, in media, a “rientrare” verso il centro nelle rilevazioni successive.\nQuesto effetto non è un artefatto, ma la naturale conseguenza della variabilità residua e della presenza di errori di misura. In psicologia, le implicazioni sono notevoli: senza tener conto della regressione verso la media, si rischia di interpretare come cambiamento reale ciò che è in parte dovuto a fluttuazioni statistiche. È il caso, ad esempio, di studi pre–post senza gruppo di controllo, in cui miglioramenti apparenti possono riflettere semplicemente la tendenza dei valori estremi ad avvicinarsi alla media.\nComprendere questo fenomeno significa anche comprendere meglio il funzionamento del modello di regressione lineare bivariata: la regressione verso la media è, in fondo, l’espressione grafica e concettuale del fatto che la pendenza della retta di regressione sia inferiore a 1 quando la correlazione non è perfetta.\nQuesto ci ricorda che la regressione lineare, pur essendo un modello fenomenologico e descrittivo, può offrire intuizioni preziose sul comportamento dei dati psicologici e sui limiti delle nostre inferenze. Nei prossimi capitoli ci sposteremo dal quadro frequentista a quello bayesiano, per vedere come sia possibile affrontare queste stesse questioni in termini di probabilità sui parametri, incorporando conoscenze pregresse e ottenendo una rappresentazione più trasparente dell’incertezza.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HistData_0.9-3        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.5.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_7.0.0              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.3    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.5.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "href": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "title": "25  La regressione verso la media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html",
    "href": "chapters/linear_models/03_reglin_bayes.html",
    "title": "26  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto come la regressione lineare bivariata, nell’ottica frequentista, consenta di stimare la relazione tra due variabili attraverso il metodo dei minimi quadrati. Questo approccio, pur efficace, presenta limiti evidenti: si fonda su test d’ipotesi e p-value, non permette di integrare conoscenza pregressa e offre solo una descrizione indiretta dell’incertezza sui parametri.\nL’approccio bayesiano alla regressione propone una prospettiva diversa. L’idea centrale è la stessa che abbiamo incontrato in tutti i modelli precedenti: combiniamo un’informazione a priori con i dati osservati per ottenere una distribuzione a posteriori. In questo caso, i parametri della retta di regressione (intercetta, pendenza, varianza residua) non sono visti come valori fissi ma come quantità aleatorie, descritte da una distribuzione di probabilità.\nQuesta impostazione ci permette di:\nIn questo capitolo vedremo come specificare e stimare un modello bayesiano di regressione lineare bivariata, partendo da ipotesi semplici e confrontando i risultati con quelli ottenuti nell’approccio frequentista. Sarà l’occasione per evidenziare i punti di forza del quadro bayesiano e comprendere meglio come interpretare i coefficienti di regressione in termini probabilistici.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#introduzione",
    "href": "chapters/linear_models/03_reglin_bayes.html#introduzione",
    "title": "26  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "esprimere in modo esplicito le nostre convinzioni iniziali sui parametri;\naggiornare tali convinzioni alla luce dei dati;\nquantificare l’incertezza residua attraverso distribuzioni a posteriori, anziché affidarsi a intervalli di confidenza o a test dicotomici.\n\n\nPanoramica del capitolo\n\nComprendere il modello di regressione bayesiano e come si differenzia dall’approccio frequentista.\nInterpretare i parametri stimati in un contesto bayesiano e confrontarli con quelli frequentisti.\nFamiliarizzare con l’uso di brms nella regressione.\nInterpretare le previsioni del modello bayesiano e le verifiche predittive a posteriori.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere l’Appendice P.\nLeggere il capitolo Simple Normal Regression di Johnson et al. (2022).\nConsultare Regression and Other Stories (Gelman et al., 2021).\n\nIl pdf del libro è consultabile gratuitamente su questo sito.\nPrestare particolare attenzione ai capitoli 1 “Overeview, 6,”Background on Regression Modeling,” 7, “Linear Regression with a Single Predictor” e 8, “Fitting regression models”, che offrono una guida dettagliata al modello di regressione bivariato da una prospettiva bayesiana.\n\n\nPer utilizzare il pacchetto R brms, è necessario installare preliminarmente Stan o CmdStan sul proprio computer. Si consiglia di optare per CmdStan. Il metodo più semplice per installare CmdStan consiste nell’installare il pacchetto R cmdstanr e seguire le istruzioni fornite nella documentazione.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, see, brms)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#lapproccio-bayesiano",
    "href": "chapters/linear_models/03_reglin_bayes.html#lapproccio-bayesiano",
    "title": "26  Modello bayesiano di regressione lineare bivariata",
    "section": "\n26.1 L’approccio bayesiano",
    "text": "26.1 L’approccio bayesiano\nNella statistica frequentista, i parametri di un modello – come l’intercetta, la pendenza o la deviazione standard degli errori – vengono trattati come quantità fisse sebbene sconosciute. L’incertezza associata alle loro stime viene espressa indirettamente attraverso concetti quali intervalli di confidenza o valori-\\(p\\) nei test di ipotesi.\nL’approccio bayesiano propone una prospettiva radicalmente diversa: i parametri sono considerati variabili aleatorie, ciascuna descritta da una propria distribuzione di probabilità. Questo framework consente di rappresentare l’incertezza in modo esplicito e diretto. Il processo inferenziale bayesiano si articola fondamentalmente in tre fasi.\nLa prima fase riguarda la scelta delle distribuzioni a priori. Prima di osservare i dati, viene assegnata a ciascun parametro una distribuzione di probabilità iniziale, detta prior, che incorpora ogni conoscenza preesistente o ipotesi plausibili sul fenomeno in studio. Ad esempio, se la letteratura scientifica suggerisce consistentemente che l’ansia riduca la performance, è possibile specificare un prior informativo per il coefficiente di regressione corrispondente, come una distribuzione normale centrata su un valore negativo con deviazione standard moderata, formalmente indicata come \\(b \\sim \\mathcal{N}(-0.7, 0.3)\\). Al contrario, in assenza di informazioni preliminari solide, si può ricorrere a un prior debole o vago, che esprima una grande incertezza iniziale. Un prior di questo tipo, ad esempio \\(b \\sim \\mathcal{N}(0, 100)\\), assegna probabilità pressoché uniformi a un ampio spettro di valori, permettendo ai dati osservati di dominare completamente la stima finale, che risulterà quindi molto vicina a quella ottenuta con metodi frequentisti.\nLa seconda fase consiste nell’aggiornamento delle credenze attraverso i dati osservati. Applicando il teorema di Bayes, le distribuzioni a priori vengono combinate con la verosimiglianza dei dati, dando origine alla distribuzione a posteriori dei parametri. Formalmente, questo si esprime attraverso la proporzionalità:\n\\[\nP(a, b, \\sigma \\mid \\text{dati}) \\propto P(\\text{dati} \\mid a, b, \\sigma) \\cdot P(a, b, \\sigma).\n\\]\nIl risultato di questo aggiornamento bayesiano è una distribuzione di probabilità congiunta per i parametri, che quantifica in modo probabilistico la plausibilità dei loro diversi valori, alla luce sia dell’evidenza empirica sia delle assunzioni iniziali.\nLa terza fase è dedicata all’interpretazione della distribuzione a posteriori. In questo approccio, non si ottiene un’unica stima puntuale per la retta di regressione, bensì un’intera famiglia di rette plausibili, ciascuna associata a un differente grado di credibilità probabilistica. L’incertezza viene sintetizzata e comunicata attraverso intervalli di credibilità. A differenza degli intervalli di confidenza di impostazione frequentista, un intervallo di credibilità bayesiano del 95% ammette un’interpretazione probabilistica diretta: esiste una probabilità del 95% che il vero valore del parametro sia contenuto al suo interno, dato il modello, i prior specificati e i dati osservati.\nL’approccio bayesiano offre diversi vantaggi, sia di natura pratica che teorica. Permette l’integrazione formale di conoscenze pregresse, facilitando la cumulatività della ricerca, ad esempio attraverso l’incorporazione di risultati di meta-analisi in nuovi studi. Mostra una notevole robustezza in presenza di campioni di piccole dimensioni, poiché i prior svolgono una funzione di regolarizzazione che stabilizza le stime, mitigando il rischio di overfitting. Fornisce, infine, interpretazioni intuitive dell’incertezza, allineate al ragionamento probabilistico naturale. Per queste ragioni, la statistica bayesiana risulta particolarmente adatta alla ricerca psicologica, un campo che spesso deve operare con campioni limitati e nel quale i nuovi risultati devono essere costantemente integrati in un corpus di conoscenze in evoluzione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#il-modello-di-regressione-lineare-semplice",
    "href": "chapters/linear_models/03_reglin_bayes.html#il-modello-di-regressione-lineare-semplice",
    "title": "26  Modello bayesiano di regressione lineare bivariata",
    "section": "\n26.2 Il modello di regressione lineare semplice",
    "text": "26.2 Il modello di regressione lineare semplice\nPer illustrare concretamente il modello di regressione lineare semplice, consideriamo un esempio di comune interesse in psicologia: prevedere il livello di ansia di un individuo (indicato con \\(y\\)) in base al numero di ore di sonno (indicato con \\(x\\)) da egli riportate. La relazione lineare tra queste due variabili viene formalizzata attraverso il modello:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i,\n\\] dove \\(\\beta_0\\) rappresenta l’intercetta, ovvero il valore atteso della variabile ansia quando il numero di ore di sonno è pari a zero. Il parametro \\(\\beta_1\\) è il coefficiente di regressione, che quantifica la variazione attesa nel livello di ansia per ogni ora aggiuntiva di sonno. Il termine \\(\\varepsilon_i\\) costituisce l’errore casuale, capace di catturare la deviazione del punteggio osservato di ansia del singolo individuo rispetto al valore predetto dalla retta di regressione.\nUn’assunzione fondamentale del modello riguarda proprio il termine di errore. Si assume che gli errori \\(\\varepsilon_i\\) siano tra loro indipendenti e seguano una distribuzione normale con media zero e varianza costante \\(\\sigma^2\\). Questa assunzione implica a sua volta che, per un dato valore di \\(x\\), i valori osservati della variabile \\(y\\) siano distribuiti normalmente attorno alla media condizionata \\(\\mu_i\\). Formalmente:\n\\[\ny_i \\mid x_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2), \\quad \\text{dove} \\quad \\mu_i = \\beta_0 + \\beta_1 x_i.\n\\]\nIn termini sostanziali, il modello non presuppone che tutti gli individui con lo stesso numero di ore di sonno presentino un identico livello di ansia. Piuttosto, esso descrive come i loro punteggi si distribuiscano in modo aleatorio attorno a un valore medio, il quale è deterministicamente determinato dalla relazione lineare con la variabile esplicativa. La retta di regressione rappresenta dunque la tendenza centrale di questa relazione, mentre la variabilità residua attorno alla retta è attribuita a fattori non misurati o al caso.\n\n26.2.1 Cos’è la verosimiglianza?\nIl concetto di verosimiglianza rappresenta una misura fondamentale dell’adeguatezza di un insieme di parametri nel descrivere i dati osservati. Nel contesto della regressione lineare, la verosimiglianza dipende specificamente dai parametri β₀, β₁ e σ.\nPer ciascuna osservazione yᵢ, la probabilità di osservare quel particolare dato è espressa dalla funzione di densità di una distribuzione normale. Supponendo l’indipendenza delle osservazioni, la verosimiglianza congiunta per l’intero campione si ottiene attraverso il prodotto delle densità individuali:\n\\[\n\\mathcal{L}(\\beta_0, \\beta_1, \\sigma \\mid \\mathbf{y}, \\mathbf{x}) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\!\\left(-\\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2\\sigma^2}\\right).\n\\]\nData la complessità computazionale che deriva dal lavorare con prodotti di molteplici termini, nella pratica statistica si ricorre frequentemente alla log-verosimiglianza. Questa trasformazione, mantenendo le proprietà di ottimizzazione della funzione originale, converte il prodotto in una somma, semplificando notevolmente i calcoli:\n\\[\n\\log \\mathcal{L}(\\beta_0, \\beta_1, \\sigma \\mid \\mathbf{y}, \\mathbf{x}) = -\\frac{n}{2}\\log(2\\pi) - n\\log\\sigma - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i)^2.\n\\]\n\n26.2.1.1 Verosimiglianza: confronto tra approccio frequentista e bayesiano\nIl ruolo della verosimiglianza assume significati differenti nei due paradigmi statistici principali. Nell’approccio frequentista, la procedura di stima si basa sull’identificazione dei valori parametrici che massimizzano la funzione di verosimiglianza, dando origine al metodo della massima verosimiglianza. Questi valori costituiscono le stime puntuali considerate ottimali per i parametri del modello.\nNell’approccio bayesiano, la verosimiglianza rappresenta soltanto uno dei componenti del processo inferenziale. Essa viene integrata con le distribuzioni a priori assegnate ai parametri, attraverso l’applicazione del teorema di Bayes. Questa combinazione produce la distribuzione a posteriori, che costituisce la base per tutte le inferenze successive, fornendo una rappresentazione completa dell’incertezza associata ai parametri del modello.\n\n26.2.2 Le distribuzioni a priori\nUn elemento caratterizzante dell’approccio bayesiano risiede nella specificazione delle distribuzioni a priori. Queste distribuzioni formalizzano matematicamente le credenze iniziali riguardo ai parametri del modello, prima di prendere in considerazione i dati osservati. È possibile identificare tre categorie principali di distribuzioni a priori.\nLe distribuzioni non informative intendono rappresentare una situazione di massima ignoranza o neutralità iniziale. Il loro obiettivo è permettere ai dati osservati di determinare completamente le stime finali, senza esercitare alcuna influenza sostanziale. Un esempio tipico è una distribuzione normale con media zero e varianza molto ampia, come \\(\\mathcal{N}(0, 1000)\\).\nLe distribuzioni debolmente informative forniscono una regolarizzazione moderata, imponendo dei vincoli molto larghi ma in grado di evitare stime parametriche in regioni chiaramente implausibili o numericamente instabili. Questo tipo di prior può migliorare la stabilità delle stime, specialmente con campioni di piccole dimensioni, senza introdurre forti assunzioni sostanziali. Un esempio comune per un coefficiente di regressione potrebbe essere \\(\\mathcal{N}(0, 2.5)\\).\nLe distribuzioni informative incorporano in modo esplicito conoscenze provenienti da letteratura preesistente, teorie consolidate o esperienza empirica. Sono caratterizzate da una varianza ridotta, che riflette un grado di certezza iniziale più elevato. Il loro utilizzo può aumentare notevolmente l’efficienza dell’inferenza ma richiede una solida giustificazione teorica o empirica per la scelta dei loro iperparametri.\n\n26.2.3 Le distribuzioni a posteriori\nLa distribuzione a posteriori rappresenta il risultato fondamentale dell’inferenza bayesiana. Essa sorge dalla combinazione di due componenti: la verosimiglianza, che quantifica l’informazione contenuta nei dati osservati in relazione ai parametri, e le distribuzioni a priori, che esprimono le credenze iniziali.\nQuesta distribuzione congiunta a posteriori costituisce una rappresentazione probabilistica completa e aggiornata della nostra conoscenza riguardo ai parametri, condizionata all’evidenza empirica. A differenza delle tradizionali stime puntuali dell’approccio frequentista, il risultato bayesiano fornisce un’intera distribuzione di probabilità per ogni parametro. Questa ricchezza di informazione permette di quantificare l’incertezza in modo diretto e intuitivo, facilitando la costruzione di intervalli di credibilità e supportando un processo decisionale che integra coerentemente tutte le fonti di informazione disponibili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#implementazione-con-brms",
    "href": "chapters/linear_models/03_reglin_bayes.html#implementazione-con-brms",
    "title": "26  Modello bayesiano di regressione lineare bivariata",
    "section": "\n26.3 Implementazione con brms\n",
    "text": "26.3 Implementazione con brms\n\nNel pacchetto brms (che usa Stan come motore di calcolo), non è necessario scrivere la funzione di verosimiglianza a mano. Basta specificare il modello nella classica forma di Wilkinson:\nbrm(y ~ x, data = dati)\nQuesta notazione compatta definisce il modello di regressione, la verosimiglianza implicita e consente a brms di costruire automaticamente il modello bayesiano. Se non si specificano i prior, brms utilizza prior debolmente informativi di default.\n\n26.3.1 Come vengono stimate le distribuzioni a posteriori?\nPoiché la distribuzione a posteriori è spesso troppo complessa per essere calcolata esattamente, brms utilizza tecniche di campionamento numerico MCMC (Markov Chain Monte Carlo). In particolare, utilizza l’algoritmo NUTS (No-U-Turn Sampler), una variante evoluta dell’algoritmo di Metropolis-Hastings, che esplora lo spazio dei parametri in modo efficiente e adattivo. Grazie a questo, otteniamo campioni dalla distribuzione a posteriori, dai quali è possibile calcolare medie, intervalli di credibilità e fare previsioni.\nIn sintesi, il modello di regressione bayesiano consente di incorporare in modo trasparente incertezze, conoscenze pregresse e informazioni contenute nei dati. Rispetto all’approccio classico, non restituisce una singola stima puntuale ma un’intera distribuzione per ogni parametro. Questo permette inferenze più flessibili e più ricche di informazioni, particolarmente utili nelle scienze psicologiche, dove l’incertezza è la regola più che l’eccezione.\n\n26.3.2 Un esempio concreto\nDefiniamo i parametri e simuliamo i dati.\n\nset.seed(123)\n\n# Definizione delle variabili\nx &lt;- 1:100\nn &lt;- length(x)\na &lt;- 1.5\nb &lt;- 0.5\nsigma &lt;- 10\n\n# Generazione di y\ny &lt;- a + b * x + rnorm(n, 0, sigma)\n\n# Creazione del dataframe\nfake &lt;- tibble(x = x, y = y)\nhead(fake)\n#&gt; # A tibble: 6 × 2\n#&gt;       x      y\n#&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1     1 -3.60 \n#&gt; 2     2  0.198\n#&gt; 3     3 18.6  \n#&gt; 4     4  4.21 \n#&gt; 5     5  5.29 \n#&gt; 6     6 21.7\n\nIniziamo adattando ai dati un modello frequentista:\n\nfm1 &lt;- lm(y ~ x, data = fake)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = fake)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -24.536  -5.524  -0.346   6.485  20.949 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.1360     1.8429    0.62     0.54\n#&gt; x             0.5251     0.0317   16.57   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 9.15 on 98 degrees of freedom\n#&gt; Multiple R-squared:  0.737,  Adjusted R-squared:  0.734 \n#&gt; F-statistic:  275 on 1 and 98 DF,  p-value: &lt;2e-16\n\nPer ottenere l’intervallo di confidenza (nel senso frequentista) della stima dei parametri usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;              2.5 % 97.5 %\n#&gt; (Intercept) -2.521  4.793\n#&gt; x            0.462  0.588\n\nAdattiamo ora ai dati un modello di regressione bayesiano utilizzando brms. Si noti che, anche in questo caso, usiamo la sintassi di Wilkinson y ~ x, come per lm(). Eseguiamo il campionamento:\n\nfm2 &lt;- brm(\n  y ~ x, \n  data = fake,\n  backend = \"cmdstanr\"\n)\n\nCome discusso nell’analisi dell’algoritmo di Metropolis, il primo passo è esaminare le tracce dei parametri per verificare la convergenza dell’algoritmo. La convergenza può essere considerata raggiunta se le catene (nel caso di brm, sono 4 per impostazione predefinita) risultano ben mescolate. Questo si manifesta in un trace plot che mostra una distribuzione uniforme e casuale dei campioni attorno a un valore centrale, senza pattern evidenti o tendenze sistematiche.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fm2, \n  pars = c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nGli istogrammi delle distribuzioni a posteriori dei parametri si generano nel modo seguente:\n\nmcmc_hist(\n  fm2, \n  pars =c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nPer valutare l’autocorrelazione tra i campioni a posteriori del parametro beta, possiamo utilizzare il seguente comando:\n\nmcmc_acf(fm2, \"b_x\")\n\n\n\n\n\n\n\nL’autocorrelazione fornisce informazioni sulla dipendenza tra campioni successivi nella catena di Markov. È normale che i campioni successivi non siano completamente indipendenti, poiché le catene di Markov generano campioni correlati per costruzione. Tuttavia, se l’algoritmo ha raggiunto la convergenza, l’autocorrelazione dovrebbe diminuire rapidamente e diventare trascurabile dopo un numero relativamente piccolo di lag. Questo significa che, dopo un certo numero di passi, i campioni diventano progressivamente meno correlati tra loro, comportandosi in modo simile a campioni indipendenti estratti dalla distribuzione target.\nUn’elevata autocorrelazione su lag più lunghi potrebbe invece indicare problemi di mescolamento delle catene o una mancata convergenza, richiedendo ulteriori verifiche o aggiustamenti, come l’aumento del numero di iterazioni o una diversa parametrizzazione del modello.\nNel caso presente, notiamo una rapida diminuzione dell’autocorrelazione in funzione del numero di passi. Ciò è indicativo del fatto che la convergenza è stata raggiunta.\nUna sintesi numerica dei risultati si trova nel modo seguente:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: y ~ x \n#&gt;    Data: fake (Number of observations: 100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.17      1.79    -2.34     4.64 1.00     3981     2679\n#&gt; x             0.52      0.03     0.46     0.59 1.00     4004     2919\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     9.24      0.68     8.02    10.71 1.00     3848     2991\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nConfrontiamo le stime ottenute con i valori reali dei parametri simulati. L’intercetta è stata stimata attorno a 1.14, con un’incertezza al 95% che varia tra -2.4 e 4.8. Questo risultato rientra negli intervalli di credibilità previsti, confermando l’accuratezza del modello. Analogamente, per la pendenza \\(b\\), l’intervallo di credibilità al 95% include il valore reale simulato, dimostrando come le stime bayesiane riflettano accuratamente l’incertezza sui parametri.\nSe si utilizza la funzione conditional_effects() viene prodotto un grafico che rappresenta la relazione stimata tra il predittore \\(x\\) e la variabile di risposta \\(y\\).\n\nconditional_effects(fm2) |&gt;\n  plot(points = TRUE)\n\n\n\n\n\n\n\n\n\nLinea stimata (effetto medio):\n\nLa linea centrale del grafico rappresenta il valore medio previsto di \\(y\\) per ogni valore di \\(x\\), dato dalla relazione \\(y = \\alpha + \\beta x\\).\nQuesta linea è calcolata usando i valori medi a posteriori stimati per \\(\\alpha\\) e \\(\\beta\\).\n\n\n\nBande di incertezza (intervalli di credibilità):\n\nLe bande attorno alla linea rappresentano gli intervalli di credibilità (ad esempio, al 95%). Questi mostrano l’incertezza associata alle stime del modello per ogni valore di \\(x\\).\nPiù strette sono le bande, maggiore è la certezza del modello riguardo alla relazione stimata.\n\n\n\nDati osservati:\n\nI punti rappresentano i valori effettivi di \\(y\\) osservati nei dati. Questo consente di confrontare visivamente come i dati reali si allineano con le previsioni del modello.\n\n\n\nIl grafico consente\n\nuna verifica visiva della relazione stimata tra \\(y\\) e \\(x\\);\ndi identificazione di eventuali discrepanze tra i dati osservati e le previsioni del modello;\nuna rappresentazione dell’incertezza nelle stime.\n\nAd esempio, il grafico può mostrare se \\(x\\) ha un effetto credibile su \\(y\\) e con quale livello di incertezza. Se l’effetto di \\(x\\) è debole o nullo, la linea stimata sarà piatta (vicina a zero) e le bande di incertezza saranno ampie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "href": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "title": "26  Modello bayesiano di regressione lineare bivariata",
    "section": "\n26.4 Simulazione di livelli di copertura",
    "text": "26.4 Simulazione di livelli di copertura\nVerifichiamo la copertura degli intervalli di credibilità al 95% attraverso simulazioni ripetute.\n\nset.seed(42)\n# Parametri veri\na_true &lt;- 0.2\nb_true &lt;- 0.3\nsigma_true &lt;- 0.5\n# Numero di simulazioni\nnum_simulations &lt;- 100\n# Conteggio delle coperture\ncoverage_a &lt;- 0\ncoverage_b &lt;- 0\nfor (i in 1:num_simulations) {\n  # Generazione dei dati\n  x &lt;- 1:20\n  y &lt;- a_true + b_true * x + sigma_true * rnorm(length(x))\n  # Adattamento del modello\n  fit &lt;- lm(y ~ x)\n  ci &lt;- confint(fit) # Intervalli di confidenza\n  # Verifica delle coperture\n  if (ci[1,1] &lt;= a_true & ci[1, 2] &gt;= a_true) {\n    coverage_a &lt;- coverage_a + 1\n  }\n  if (ci[2,1] &lt;= b_true & ci[2, 2] &gt;= b_true) {\n    coverage_b &lt;- coverage_b + 1\n  }\n}\n\n\n# Risultati\ncat(\"Coverage for a:\", coverage_a / num_simulations, \"\\n\")\n#&gt; Coverage for a: 0.93\ncat(\"Coverage for b:\", coverage_b / num_simulations, \"\\n\")\n#&gt; Coverage for b: 0.96\n\nI risultati indicano che i livelli di copertura empirici ottenuti con l’approccio frequentista corrispondono strettamente ai livelli teorici attesi.\nPer proseguire, ripeteremo la simulazione adottando un approccio bayesiano. Useremo la funzione brm() del pacchetto brms al posto di lm().\n#| message: false\n#| warning: false\n#| output: false\n#| \nset.seed(23)\nn_fake   &lt;- 100\ncover_68 &lt;- logical(n_fake)\ncover_95 &lt;- logical(n_fake)\n\n# Veri parametri\na     &lt;- 0.2    # intercetta vera\nb     &lt;- 0.3    # pendenza vera\nsigma &lt;- 0.5    # deviazione standard vera\nx     &lt;- 1:20\nn     &lt;- length(x)\n\n# Priors con set_prior \npriors &lt;- c(\n  set_prior(\"normal(0, 2.5)\", class = \"Intercept\"),\n  set_prior(\"normal(0, 2.5)\", class = \"b\", coef = \"x\"),\n  set_prior(\"cauchy(0, 2.5)\", class = \"sigma\")\n)\n\nset.seed(23)\nn_fake   &lt;- 1000\ncover_68 &lt;- logical(n_fake)\ncover_95 &lt;- logical(n_fake)\n\na     &lt;- 0.2\nb     &lt;- 0.3\nsigma &lt;- 0.5\nx     &lt;- 1:20\nn     &lt;- length(x)\n\nfor (s in seq_len(n_fake)) {\n  y    &lt;- a + b * x + rnorm(n, 0, sigma)\n  fake &lt;- data.frame(x = x, y = y)\n\n  fit &lt;- brm(\n    y ~ 1 + x,\n    data    = fake,\n    family  = gaussian(),\n    prior   = priors,\n    iter    = 2000,\n    chains  = 2,\n    refresh = 0,\n    backend = \"cmdstanr\"\n  )\n\n  post &lt;- summary(fit)$fixed\n  b_hat &lt;- post[\"x\", \"Estimate\"]\n  b_se  &lt;- post[\"x\", \"Est.Error\"]\n\n  cover_68[s] &lt;- abs(b - b_hat) &lt; b_se\n  cover_95[s] &lt;- abs(b - b_hat) &lt; 2 * b_se\n}\n\ncat(\"Coverage 68%:\", mean(cover_68), \"\\n\")\ncat(\"Coverage 95%:\", mean(cover_95), \"\\n\")\nCon solo 100 iterazioni, i risultati sono i seguenti:\n&gt; cat(\"Coverage 68%:\", mean(cover_68), \"\\n\")\nCoverage 68%: 0.73 \n&gt; cat(\"Coverage 95%:\", mean(cover_95), \"\\n\")\nCoverage 95%: 0.953 \nQuesta seconda simulazione evidenzia che anche i livelli di copertura empirici ottenuti con l’approccio bayesiano si avvicinano ai valori teorici previsti.\nI risultati ottenuti confermano l’efficacia degli intervalli di confidenza e di credibilità stimati attraverso i modelli frequentisti e bayesiani.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "href": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "title": "26  Modello bayesiano di regressione lineare bivariata",
    "section": "\n26.5 Confronti, non effetti",
    "text": "26.5 Confronti, non effetti\nGelman et al. (2021) mettono in guardia contro un’interpretazione eccessivamente causale dei coefficienti di regressione. Sebbene nella pratica statistica sia comune riferirsi a questi coefficienti come “effetti”, tale terminologia può risultare fuorviante poiché suggerisce implicitamente l’esistenza di un nesso causale. In realtà, ciò che un modello di regressione stima rappresenta fondamentalmente un pattern osservazionale. Più precisamente, il coefficiente β₁ associato a una variabile esplicativa X cattura la differenza attesa nella media della variabile dipendente Y tra due sottopopolazioni che differiscono di un’unità nel valore di X.\nLa regressione lineare è essenzialmente uno strumento matematico progettato per analizzare associazioni e migliorare la capacità predittiva. I suoi coefficienti vanno interpretati primariamente come confronti medi tra gruppi definiti dai valori delle variabili esplicative. Un’interpretazione causale di questi coefficienti è legittima soltanto in contesti sperimentali specifici o quando il disegno di ricerca incorpora strategie identificative appropriate, come l’utilizzo di variabili strumentali, regression discontinuity design o altri metodi che mirano a controllare la confondazione. Tale interpretazione non può mai essere dedotta automaticamente dalla stima del modello statistico, ma deve essere giustificata da considerazioni metodologiche sostanziali relative al processo di generazione dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "href": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "title": "26  Modello bayesiano di regressione lineare bivariata",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo riformulato la regressione lineare bivariata in chiave bayesiana. Abbiamo visto come l’adozione di distribuzioni a priori per i parametri — intercetta, pendenza e varianza residua — permetta di combinare conoscenze pregresse con i dati osservati, producendo distribuzioni a posteriori che rappresentano in modo diretto l’incertezza sulle quantità di interesse.\nIl confronto con l’approccio frequentista mette in luce differenze sostanziali. Mentre il frequentismo si concentra su stime puntuali, intervalli di confidenza e test di ipotesi, il bayesianesimo restituisce l’intera distribuzione di probabilità dei parametri, consentendo affermazioni più trasparenti e interpretabili. In questo quadro, parlare della “plausibilità” di un coefficiente, o della probabilità che una pendenza sia positiva o negativa, non è più un abuso di linguaggio ma il cuore stesso dell’inferenza.\nNaturalmente, il prezzo da pagare è quello computazionale. Le soluzioni analitiche sono disponibili solo in casi semplici, come il modello qui discusso. Nei problemi reali, con più predittori o con strutture di dati complesse, dobbiamo ricorrere a metodi di approssimazione numerica. È qui che entrano in gioco i metodi di campionamento e gli strumenti software sviluppati negli ultimi decenni.\nNei prossimi capitoli introdurremo quindi Stan, un linguaggio di programmazione pensato per la stima di modelli bayesiani complessi, che automatizza i passaggi computazionali e rende accessibile l’inferenza anche in situazioni dove il calcolo diretto sarebbe impossibile. La regressione bivariata diventa così il banco di prova ideale per comprendere la logica bayesiana prima di affrontare modelli più ricchi e realistici.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nVerosimiglianza\nDefinire la funzione di verosimiglianza per il modello bayesiano di regressione lineare bivariata, esplicitando i parametri e la loro interpretazione.\nScelta dei prior\nProporre un set di prior debolmente informativi differenti da quelli riportati, motivando la scelta delle distribuzioni.\nSimulazione dati\nScrivere un blocco di codice in R/Quarto per simulare un dataset con \\(n=50\\), parametri \\(lpha=2\\), \\(eta=0.5\\), \\(\\sigma=1\\) e visualizzare un grafico dispersione con la retta di regressione vera.\nStima frequentista vs bayesiana\nUtilizzando i dati simulati, adattare un modello con lm() e uno con brm() (specificando i prior). Confrontare i risultati prodotti dai due approcci, riportando i valori stimati e gli intervalli di confidenza/credibilità.\nDiagnosi MCMC\nElencare e spiegare almeno tre controlli diagnostici da effettuare sulle catene MCMC per garantire la convergenza e un buon mescolamento.\nInterpretazione dei coefficienti\nIn un contesto osservazionale, discutere perché non è appropriato interpretare i coefficienti della regressione come effetti causali. Fare riferimento ai concetti di confondimento e disegno sperimentale.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nVerosimiglianza\n\\[\n\\mathcal{L}(\\alpha, \\beta, \\sigma \\mid y, x) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(y_i - (\\alpha + \\beta x_i))^2}{2\\sigma^2}\\right).\n\\]\n\n\nScelta dei prior\nAd esempio:\n\n\n\\(\\alpha \\sim \\mathcal{N}(0, 5)\\): consente maggiore variabilità iniziale;\n\n\n\\(\\beta \\sim \\text{Student-}t(3, 0, 2)\\): robuste alle code pesanti;\n\n\n\\(\\sigma \\sim \\text{Half-}Cauchy(0, 1)\\): prior leggermente più stretto sulle deviazioni.\n\n\n\nSimulazione dati\nset.seed(42)\nn &lt;- 50\nalpha &lt;- 2\nbeta  &lt;- 0.5\nsigma &lt;- 1\nx &lt;- rnorm(n, 0, 1)\ny &lt;- alpha + beta * x + rnorm(n, 0, sigma)\nplot(x, y, main = \"Dati simulati\", xlab = \"x\", ylab = \"y\")\nabline(a = alpha, b = beta, col = \"blue\", lwd = 2)\n\n\nStima frequentista vs bayesiana\n\n\nFrequentista (lm()):\nfm_f &lt;- lm(y ~ x)\nsummary(fm_f)\nconfint(fm_f, level = 0.95)\n\n\nBayesiano (brm()):\nfm_b &lt;- brm(y ~ x, data = data.frame(x, y),\n            prior = c(set_prior(\"normal(0,5)\", class=\"Intercept\"),\n                      set_prior(\"normal(0,5)\", class=\"b\"),\n                      set_prior(\"cauchy(0,1)\", class=\"sigma\")),\n            iter = 2000, chains = 2)\nsummary(fm_b)\nConfronto: i valori medi a posteriori e gli intervalli di credibilità dovrebbero includere quelli di confidenza di lm().\n\n\n\n\nDiagnosi MCMC\n\n\nTrace plots: verificare mescolamento e stazionarietà delle catene;\n\n\nR-hat: valore vicino a 1 indica convergenza;\n\n\nEffective Sample Size (ESS): numero di campioni indipendenti effettivi.\n\n\nInterpretazione dei coefficienti\nLa regressione osservazionale non controlla automaticamente i potenziali confondenti; senza randomizzazione o disegno sperimentale rigoroso, non si può inferire causalità. Bisogna considerare variabili confondenti e criteri di validità interna.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.11.0            cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [58] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [82] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "href": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "title": "26  Modello bayesiano di regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html",
    "title": "27  Zucchero sintattico",
    "section": "",
    "text": "Introduzione\nNel capitolo precedente abbiamo visto come formulare e stimare un modello bayesiano di regressione lineare bivariata utilizzando distribuzioni a priori semplici. Questo esercizio ci ha permesso di cogliere l’essenza dell’approccio: i parametri della retta di regressione non sono valori fissi, ma quantità descritte da distribuzioni di probabilità aggiornate alla luce dei dati.\nTuttavia, la scrittura esplicita di ogni dettaglio del modello può diventare rapidamente ingombrante, soprattutto quando si lavora con più predittori o con modelli più complessi. Per rendere l’analisi più agevole, possiamo introdurre alcune notazioni e funzioni che alleggeriscono il codice senza modificarne il significato statistico.\nIn questo capitolo presenteremo quindi quello che potremmo chiamare “zucchero sintattico”: strumenti che rendono la specificazione dei modelli in R più compatta e leggibile, pur mantenendo intatta la logica bayesiana sottostante. Sarà un passaggio intermedio utile, che ci permetterà di concentrarci sugli aspetti concettuali della modellazione senza appesantirci con dettagli tecnici ripetitivi. Nei capitoli successivi, quando introdurremo Stan, vedremo come questa stessa esigenza di sintesi e chiarezza diventi ancora più cruciale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#introduzione",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#introduzione",
    "title": "27  Zucchero sintattico",
    "section": "",
    "text": "Panoramica del capitolo\n\nCostruire e adattare modelli lineari con la funzione brm().\nInterpretare i risultati e confrontarli con quelli ottenuti da un approccio frequentista.\nVisualizzare le relazioni stimate e distinguere tra intervalli di credibilità e di predizione.\nSpecificare priors personalizzati e valutare l’impatto sui risultati.\nEseguire verifiche predittive a posteriori (posterior predictive checks).\nGestire la presenza di outlier tramite la regressione robusta.\nCalcolare e interpretare l’indice di determinazione bayesiano (Bayes R²).\nAccedere e manipolare la distribuzione a posteriori dei parametri.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code (Alter et al., 2025).\nConsultare The brms Book: Applied Bayesian Regression Modelling Using R and Stan.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, cmdstanr, tidybayes)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#interfaccia-brms",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#interfaccia-brms",
    "title": "27  Zucchero sintattico",
    "section": "\n27.1 Interfaccia brms\n",
    "text": "27.1 Interfaccia brms\n\nCome esempio, utilizzeremo un dataset che ci consente di stimare un modello lineare molto semplice. Il National Snow and Ice Data Center mette a disposizione numerosi dati pubblici, scaricabili ed esplorabili liberamente. Uno degli effetti più evidenti del cambiamento climatico riguarda la progressiva riduzione dell’estensione dei ghiacci marini nell’emisfero settentrionale. Qui analizzeremo come questa estensione è variata nel tempo.\nLa progressiva scomparsa di un elemento così iconico del nostro pianeta non è solo un dato fisico; agisce come un potente segnale psicologico. La percezione di perdite ambientali tangibili e su larga scala è un fattore chiave nel fenomeno dell’ansia climatica (climate anxiety), quella preoccupazione cronica e angoscia per gli impatti presenti e futuri del cambiamento climatico (Clayton, 2020).\nVisualizzare un trend discendente così chiaro, come quello che emergerà dalla nostra analisi, fornisce un contesto cruciale. Non si tratta di un’astratta previsione futura, ma della documentazione di una trasformazione in atto che sta già alterando ecosistemi, economie e, non da ultimo, il nostro benessere psicologico collettivo (APA, 2017). L’analisi dei dati diventa così uno strumento per comprendere e comunicare una delle fonti dello stress ambientale contemporaneo.\nI dati contenuti nel file N_08_extent_v4.0.csv riguardano le osservazioni del mese di agosto dal 1979 al 2024 e riportano i valori di extent. Con questo termine si indica la superficie marina totale in cui la concentrazione di ghiaccio è almeno del 15%. L’extent è considerato l’indicatore più robusto per monitorare le tendenze climatiche di lungo periodo, poiché risente meno delle fluttuazioni giornaliere dovute al vento (che può comprimere o disperdere il ghiaccio, modificandone la concentrazione ma non la sua estensione complessiva). Per questo motivo, quando si parla di “minimo storico dei ghiacci artici”, il riferimento è quasi sempre al valore di extent. La variabile extent è espressa in milioni di chilometri quadrati (ad esempio, 8.04 = 8.040.000 km²).\nCarichiamo i dati e diamo un’occhiata alle prime righe:\n\ndf &lt;- rio::import(here::here(\"data\", \"N_08_extent_v4.0.csv\"))\ndf |&gt; \n  head()\n#&gt;   year mo source_dataset region extent area\n#&gt; 1 1979  8     NSIDC-0051      N   8.04 5.06\n#&gt; 2 1980  8     NSIDC-0051      N   7.98 4.94\n#&gt; 3 1981  8     NSIDC-0051      N   7.84 4.48\n#&gt; 4 1982  8     NSIDC-0051      N   8.14 5.00\n#&gt; 5 1983  8     NSIDC-0051      N   8.19 4.97\n#&gt; 6 1984  8     NSIDC-0051      N   7.77 4.68\n\nVisualizziamo ora la relazione tra extent e year con un diagramma a dispersione:\n\nggplot(df, aes(x = year, y = extent)) +\n  geom_point() +  \n  labs(x = \"Anno\", y = \"Estensione (milioni km²)\") \n\n\n\n\n\n\n\nIl pacchetto brms si concentra sui modelli di regressione. Questa specializzazione consente di adottare una sintassi semplice e compatta, detta sintassi di Wilkinson (Wilkinson & Rogers, 1973).\nPer esempio, il modello lineare\n\\[\ny = \\alpha + \\beta x + \\varepsilon\n\\] può essere scritto in brms nel modo seguente:\na_model &lt;- brm(extent ∼ 1 + year, data = df)\nNella sintassi di Wilkinson:\n\nil simbolo ~ separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra);\n\n1 rappresenta l’intercetta, che in realtà è inclusa di default.\n\nQuindi il modello precedente può essere scritto in maniera equivalente come:\na_model &lt;- brm(extent ∼ year, data = df)\nSe desideriamo escludere l’intercetta dal modello, possiamo farlo così:\nno_intercept_model &lt;- brm(extent ∼ 0 + year, data = df)\noppure:\nno_intercept_model &lt;- brm(extent ∼ -1 + year, data = df)\nPer aggiungere altre variabili indipendenti, basta estendere la formula:\nmodel_2 &lt;- brm(extent ∼ year + z, data = df)\nbrms permette anche di stimare modelli gerarchici (a effetti misti). Ad esempio, se avessimo osservazioni raggruppate per area geografica g e volessimo stimare un effetto di year che varia da un gruppo all’altro, potremmo scrivere:\nmodel_h &lt;- brm(extent ∼ year + z + (year | g), data = df)\nÈ importante sottolineare che la sintassi di Wilkinson non specifica le distribuzioni a priori, ma soltanto come le variabili sono collegate tra loro. In assenza di istruzioni esplicite, brms assegna automaticamente delle prior debolmente informative, che permettono di stimare comunque il modello senza ulteriori interventi. Tuttavia, se desideriamo avere un controllo più preciso, possiamo definire manualmente le prior, come vedremo nelle sezioni successive.\n\n27.1.1 Centrare le variabili\nPer interpretare più facilmente l’intercetta, centriamo la variabile year rispetto alla sua media nel campione:\n\ndf$year_c &lt;- df$year - mean(df$year)\n\nIn questo modo, l’intercetta (\\(\\alpha\\)) del modello rappresenterà l’estensione media prevista (extent, in milioni di km²) nell’anno medio del campione (cioè l’anno medio tra 1979 e 2024).\nAdattiamo un modello lineare con year centrata ed esaminiamo i risultati:\n\nfit_1 &lt;- brm(\n  bf(extent ~ 1 + year_c, center = FALSE),\n  data = df,\n  backend = \"cmdstanr\",\n  silent = 0\n)\n\n\n\ncenter = FALSE nel bf(…) assicura che brms non applichi un centraggio automatico ai predittori numerici: così evitiamo il “doppio centraggio”, dato che abbiamo già centrato year a mano.\n\nbackend = \"cmdstanr\" indica a brms di usare CmdStan tramite l’interfaccia cmdstanr (anziché l’interfaccia rstan). In questo corso useremo cmdstanr, quindi è utile specificarlo esplicitamente.\n\nsilent = 0 lascia visibili alcuni messaggi informativi durante la compilazione e il campionamento (opzionale).\n\nLe tracce MCMC dei parametri si ottengono così:\n\nmcmc_trace(\n  fit_1,\n  pars = c(\"b_Intercept\", \"b_year_c\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nRiepilogo del modello:\n\nsummary(fit_1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: extent ~ 1 + year_c \n#&gt;    Data: df (Number of observations: 46) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     6.71      0.07     6.58     6.83 1.00     3383     2942\n#&gt; year_c       -0.07      0.01    -0.08    -0.06 1.00     4432     2887\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     0.45      0.05     0.37     0.56 1.00     3341     2803\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n27.1.1.1 Interpretazione\n\nL’intercetta \\(\\alpha\\) = b_Intercept è l’extent previsto (milioni di km²) nell’anno medio del campione (circa \\(\\text{mean(df\\$year)}\\)).\nLa pendenza \\(\\beta\\) = b_year_c quantifica la variazione media annua dell’extent: un valore negativo indica una diminuzione dell’estensione dei ghiacci nel tempo (trend atteso in questi dati).\n\nPer confronto, stimiamo lo stesso modello con l’approccio frequentista:\n\nfit_2 &lt;- lm(extent ~ 1 + year_c, data = df)\nsummary(fit_2)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = extent ~ 1 + year_c, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -1.2394 -0.2755  0.0204  0.3081  1.0768 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  6.71000    0.06537   102.6   &lt;2e-16\n#&gt; year_c      -0.07148    0.00492   -14.5   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 0.443 on 44 degrees of freedom\n#&gt; Multiple R-squared:  0.827,  Adjusted R-squared:  0.823 \n#&gt; F-statistic:  211 on 1 and 44 DF,  p-value: &lt;2e-16\n\nCon prior debolmente informativi, i risultati bayesiani e frequentisti tendono a essere molto simili (stesse quantità stimate, ma nel caso bayesiano abbiamo l’intera distribuzione a posteriori dei parametri, utile per inferenze e previsione).\n\n27.1.2 Visualizzazione dei risultati\nPer comprendere visivamente la relazione stimata tra anno ed estensione dei ghiacci artici nel nostro modello bayesiano, possiamo utilizzare la funzione conditional_effects:\n\nconditional_effects(fit_1, effects = \"year_c\")\n\n\n\n\n\n\n\nIl grafico generato fornisce una rappresentazione intuitiva della stima:\n\n\nLinea centrale (media posteriore): rappresenta il valore medio previsto di extent per ciascun valore di year_c.\n\nArea colorata (intervallo di credibilità): mostra l’intervallo di credibilità al 95% (Highest Density Interval, HDI), cioè l’intervallo in cui cade il 95% della distribuzione a posteriori delle previsioni.\n\nPossiamo modificare il livello di incertezza visualizzato regolando l’argomento prob:\n\n# Visualizzazione con intervallo di credibilità all'89%\nconditional_effects(fit_1, effects = \"year_c\", prob = 0.89)\n\n\n\n\n\n\n\n\nRiducendo prob (ad esempio a 0.80 o 0.50) otteniamo intervalli più stretti, che mostrano solo la parte più densa della distribuzione posteriore.\nAumentando prob (ad esempio a 0.99) otteniamo intervalli più ampi, che riflettono una maggiore incertezza.\n\n\n27.1.2.1 Interpretazione pratica del grafico\nNel grafico:\n\nil punto in cui la linea attraversa year_c = 0 corrisponde all’estensione prevista dei ghiacci nell’anno medio del campione (circa il 2001, dato che abbiamo centrato la variabile year);\nla pendenza della linea indica la variazione media di estensione dei ghiacci (in milioni di km²) per ogni anno in più: un valore negativo segnala una riduzione progressiva;\nla larghezza dell’intervallo di credibilità riflette il grado di incertezza delle stime: intervalli più stretti indicano maggiore precisione, intervalli più larghi indicano più incertezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#due-tipi-di-incertezza-nei-modelli-bayesiani",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#due-tipi-di-incertezza-nei-modelli-bayesiani",
    "title": "27  Zucchero sintattico",
    "section": "\n27.2 Due tipi di incertezza nei modelli bayesiani",
    "text": "27.2 Due tipi di incertezza nei modelli bayesiani\nImmaginiamo di voler capire come l’anno (X) sia collegato all’estensione dei ghiacci artici (Y). Con un modello bayesiano otteniamo due tipi distinti di incertezza, che corrispondono a due domande diverse:\n\n\n\n\n\n\n\nChe cosa stiamo stimando?\nCome si chiama l’incertezza?\nChe intervallo disegniamo?\n\n\n\n\nLa media “vera” dell’estensione dei ghiacci per un dato anno\n\nIncertezza del parametro (o dell’effetto medio)\n\nIntervallo di credibilità (credible interval)\n\n\n\nIl valore futuro di una nuova osservazione (quale sarà l’estensione dei ghiacci in un singolo anno come quello)\nIncertezza predittiva\n\nIntervallo di predizione (prediction interval)\n\n\n\n\n27.2.1 Incertezza del parametro – «Quanto stiamo sbagliando la linea media?»\n\nconditional_effects(fit_1, effects = \"year_c\")\n\n\n\n\n\n\n\n\nDisegna la linea di regressione (la media stimata dell’estensione per ogni anno centrato).\nAggiunge intorno una fascia stretta: l’intervallo di credibilità al 95%.\nCome leggerla: Se la fascia, per l’anno medio del campione, va ad esempio da 7.5 a 7.7 milioni di km², significa che “con il 95% di probabilità la vera media dell’estensione in quell’anno sta lì dentro”. Non dice nulla sulle singole osservazioni, che possono discostarsi anche molto dalla media.\n\nMetafora veloce. Pensa a tirare freccette: la media cade vicino al centro, ma ogni singola freccia può atterrare in punti diversi. L’intervallo di credibilità descrive solo dove cade il centro.\n\n27.2.2 Incertezza predittiva – «Quanto potrebbe variare la prossima osservazione?»\n\nconditional_effects(fit_1, effects = \"year_c\", method = \"predict\")\n\n\n\n\n\n\n\n\nRipropone la stessa linea media.\nDisegna però una fascia molto più larga: l’intervallo di predizione.\n\nL’intervallo predittivo include due fonti di variabilità:\n\n\nIncertezza sulla linea media (come sopra).\n\nVariabilità residua: le differenze naturali tra osservazioni nello stesso anno (fluttuazioni dovute a vento, condizioni meteorologiche, ecc.).\n\nMetafora veloce. Ora guardi non solo il centro del bersaglio, ma l’intero disco dove ogni freccia potrebbe cadere. L’area è molto più grande.\n\n27.2.3 Quando usare l’una o l’altra fascia?\n\n\n\n\n\n\n\nObiettivo della tua domanda\nFunzione da usare\nQuale fascia guardare\n\n\n\nCapire l’effetto medio (es. “quanto si riduce in media l’estensione ogni anno?”)\nconditional_effects(...)\nIntervallo di credibilità\n\n\nFare previsioni su un caso futuro (es. “quale sarà l’estensione osservata nell’agosto 2025?”)\nconditional_effects(..., method = \"predict\")\nIntervallo di predizione\n\n\n\n\n27.2.3.1 In sintesi\n\n\nCredibilità = incertezza sul parametro medio → fascia stretta (stima della retta).\n\nPredizione = incertezza su osservazioni future → fascia larga (linea + variabilità residua).\nLa scelta dipende dalla domanda: “qual è la media?” (credibilità) oppure “dove cadrà il prossimo dato?” (predizione).\n\nIn breve, la visualizzazione predittiva è più onesta quando vogliamo fare previsioni concrete su nuove osservazioni, mentre quella con l’intervallo di credibilità è più utile per capire la relazione generale tra anno ed estensione dei ghiacci.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#distribuzione-a-posteriori-dei-parametri",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#distribuzione-a-posteriori-dei-parametri",
    "title": "27  Zucchero sintattico",
    "section": "\n27.3 Distribuzione a posteriori dei parametri",
    "text": "27.3 Distribuzione a posteriori dei parametri\nPer esaminare la distribuzione a posteriori dei parametri del modello, possiamo utilizzare la funzione mcmc_plot():\n\nmcmc_plot(fit_1, type = \"dens\")\n\n\n\n\n\n\n\nQuesta funzione disegna la densità a posteriori dei parametri, mostrando graficamente quali valori sono più plausibili dato il modello, i dati e le scelte a priori.\nPer un’analisi numerica più dettagliata, trasformiamo l’oggetto fit_1 in un formato compatibile con il pacchetto posterior e poi calcoliamo le statistiche di sintesi:\n\ndraws &lt;- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable      mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  6.709 0.066     0.001   0.001\n#&gt; 2 b_year_c    -0.071 0.005     0.000   0.000\n\n\nLa funzione as_draws() converte l’oggetto in una struttura che rappresenta i campioni MCMC.\nGli argomenti variable = \"^b_\" e regex = TRUE selezionano solo i parametri che iniziano con b_, cioè i coefficienti del modello: l’intercetta e la pendenza.\nLa funzione summarise_draws() calcola statistiche riassuntive per la distribuzione a posteriori di questi parametri.\n\n\n27.3.1 Spiegazione di mcse_mean e mcse_sd\n\nOltre a media (mean) e deviazione standard (sd), summarise_draws() riporta anche due indici utili:\n\n\nmcse_mean = Monte Carlo Standard Error della media.\n\nIndica quanto la stima della media potrebbe variare semplicemente perché abbiamo un numero finito di campioni MCMC.\nSe è molto piccolo rispetto a sd, possiamo fidarci che la media stimata rappresenta bene la distribuzione a posteriori.\n\n\n\nmcse_sd = Monte Carlo Standard Error della deviazione standard.\n\nIndica quanto la stima della deviazione standard della distribuzione a posteriori potrebbe variare per lo stesso motivo.\nAnche qui, un valore molto piccolo rispetto alla sd è segno che il campionamento è stato sufficiente.\n\n\n\n27.3.2 Come interpretarli in pratica?\n\n\nRapporto rispetto a sd\n\n\nmcse_mean e mcse_sd dovrebbero essere almeno un ordine di grandezza più piccoli delle corrispondenti stime (mean e sd).\nAd esempio: se per b_Intercept abbiamo mcse_mean = 0.0044 e sd = 0.2695, il valore è più di 60 volte più piccolo → la stima è robusta.\n\n\n\nQualità del campionamento\n\n\nSe mcse_mean o mcse_sd fossero troppo grandi, questo indicherebbe che:\n\nil numero di iterazioni MCMC è insufficiente,\nle catene non hanno mescolato bene,\no ci sono problemi di convergenza.\n\n\n\n\n\n\n27.3.2.1 In sintesi\n\n\nmcse_mean e mcse_sd non descrivono l’incertezza statistica sui dati, ma la qualità del campionamento Monte Carlo.\nSe sono piccoli, significa che il numero di campioni è sufficiente e la distribuzione a posteriori è rappresentata in modo accurato.\nIn altre parole: ci dicono se possiamo fidarci che la “fotografia” ottenuta con l’MCMC rispecchi bene la vera distribuzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#specificare-i-priors",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#specificare-i-priors",
    "title": "27  Zucchero sintattico",
    "section": "\n27.4 Specificare i priors",
    "text": "27.4 Specificare i priors\nNei modelli bayesiani i priors rappresentano le nostre aspettative sui parametri prima di osservare i dati. Se non li specifichiamo, brms assegna dei prior debolmente informativi di default.\nPossiamo ispezionarli con la funzione get_prior:\n\nget_prior(extent ~ 1 + year_c, data = df)\n#&gt;                   prior     class   coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 6.8, 2.5) Intercept                                   \n#&gt;                  (flat)         b                                   \n#&gt;                  (flat)         b year_c                            \n#&gt;    student_t(3, 0, 2.5)     sigma                               0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\nL’output mostra quali prior vengono assegnati a ciascun parametro del modello. Per esempio:\n\n\nprior – indica il prior utilizzato.\n\n\nstudent_t(3, 6.8, 2.5): prior t di Student per l’intercetta, con 3 gradi di libertà, media 6.8 e scala 2.5.\n\n(flat): prior piatto (non informativo) per i coefficienti delle variabili predittive, come il coefficiente di year_c.\n\nstudent_t(3, 0, 2.5): prior t di Student per la deviazione standard residua (\\(\\sigma\\)), centrato su 0 con scala 2.5.\n\n\n\nclass – indica a quale tipo di parametro il prior si riferisce:\n\n\nIntercept: prior sull’intercetta (\\(\\alpha\\));\n\nb: prior sui coefficienti dei predittori (\\(\\beta\\));\n\nsigma: prior sulla deviazione standard residua (\\(\\sigma\\)).\n\n\n\ncoef – specifica a quale predittore si riferisce il prior.\n\nVuoto per l’intercetta (perché non dipende da un predittore specifico).\n\nyear_c per il coefficiente associato al predittore year_c.\n\n\n\nlb e ub – rappresentano i limiti inferiore (lower bound) e superiore (upper bound) del prior, se esistono.\n\nPer sigma, il limite inferiore è 0, poiché una deviazione standard non può essere negativa.\n\n\nsource – indica se il prior è stato impostato dall’utente o se è il valore predefinito (default).\n\n\n27.4.1 Specificare priors manualmente\nSe vogliamo rendere esplicite le nostre ipotesi, possiamo definire dei priors diversi da quelli di default. Ad esempio:\n\nprior_gaussian &lt;- \n  brms::prior(normal(7, 2), class = \"b\", coef = \"Intercept\") +    # Intercetta attorno a 7 (milioni km²)\n  brms::prior(normal(0, 0.5), class = \"b\", coef = \"year_c\") +  # Coefficiente di year_c\n  brms::prior(cauchy(0, 2), class = \"sigma\")          # Deviazione standard residua\n\n\nNota: usiamo brms::prior() per essere sicuri di richiamare la funzione del pacchetto brms ed evitare conflitti con funzioni omonime di altri pacchetti.\n\nAdattiamo ora il modello con i priors specificati:\n\nfit_2 &lt;- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nE otteniamo un sommario numerico delle distribuzioni a posteriori:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable      mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  6.711 0.068     0.001   0.001\n#&gt; 2 b_year_c    -0.072 0.005     0.000   0.000\n\n\n27.4.2 Confronto con i priors di default\nNel nostro caso, i priors esplicitamente definiti non cambiano in modo rilevante le distribuzioni a posteriori. Questo accade perché i dati disponibili sono numerosi e forniscono già informazioni molto forti: in pratica, le osservazioni “dominano” sulle ipotesi iniziali.\nDal punto di vista didattico è un aspetto cruciale da sottolineare:\n\n\nCon molti dati e alta informatività, i priors hanno un ruolo marginale: le stime finali saranno simili indipendentemente dalle ipotesi iniziali.\n\nCon pochi dati o dati molto rumorosi, invece, i priors diventano determinanti: le scelte iniziali possono influenzare in maniera sostanziale i risultati finali.\n\nIn altre parole, la forza relativa tra dati e priors dipende dalla quantità e dalla qualità dell’informazione empirica disponibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#predizioni-a-posteriori-posterior-predictive-checks",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#predizioni-a-posteriori-posterior-predictive-checks",
    "title": "27  Zucchero sintattico",
    "section": "\n27.5 Predizioni a posteriori (Posterior Predictive Checks)",
    "text": "27.5 Predizioni a posteriori (Posterior Predictive Checks)\nUn aspetto fondamentale nella valutazione di un modello statistico, sia frequentista che bayesiano, è verificare quanto bene le predizioni del modello rappresentino i dati osservati. La logica di fondo è simile nei due paradigmi, ma l’approccio e l’interpretazione sono diversi.\n\n27.5.1 Confronto frequentista\nNel caso frequentista, il confronto si basa sui valori stimati dal modello:\n\\[\n\\hat{y} = \\hat{\\alpha} + \\hat{\\beta}x\n\\]\nSi analizzano principalmente:\n\nla vicinanza della retta di regressione ai dati osservati;\nla presenza di eventuali pattern non lineari nei residui;\nla variazione della dispersione di \\(y\\) rispetto a \\(x\\) (per verificare l’ipotesi di omoschedasticità).\n\n27.5.2 Approccio bayesiano\nNell’approccio bayesiano eseguiamo le stesse verifiche di base, ma disponiamo di uno strumento in più: le Predizioni a Posteriori (Posterior Predictive Checks, PPCs).\nL’idea è semplice ma potente:\n\ninvece di confrontare i dati osservati solo con una linea di regressione “fissa”,\nli confrontiamo con dati simulati dal modello, generati utilizzando i campioni dalle distribuzioni a posteriori dei parametri.\n\nIn questo modo, nelle predizioni è incorporata anche l’incertezza sui parametri stimata dal modello.\n\n27.5.3 Come si costruiscono le predizioni a posteriori\nNel caso di un modello lineare semplice, il procedimento è:\n\nDati osservati: partiamo dalla distribuzione empirica della variabile risposta (\\(y\\)).\nEstrazione dei parametri: prendiamo un campione casuale \\(\\alpha'\\), \\(\\beta'\\), \\(\\sigma'\\) dalle distribuzioni a posteriori dei parametri.\n\nSimulazione dei dati: generiamo valori simulati da una normale:\n\\[\ny_{\\text{sim}} \\sim \\mathcal{N}(\\alpha' + \\beta' x, \\sigma')\n\\]\ndove \\(x\\) sono i predittori osservati.\n\nRipetizione: il processo viene ripetuto molte volte, producendo numerosi dataset simulati.\nConfronto: i dati simulati vengono confrontati con i dati reali (istogrammi, densità o residui).\n\n27.5.4 Interpretazione\n\n\nBuona corrispondenza: se la distribuzione dei dati simulati si sovrappone bene a quella osservata, il modello rappresenta adeguatamente i dati.\n\nDiscrepanze: differenze sistematiche (picchi mancanti, code sottostimate, ecc.) indicano che il modello non cattura tutti gli aspetti dei dati.\n\nIl vantaggio dei PPC è che:\n\nintegrano l’incertezza sui parametri;\npermettono di valutare non solo la bontà di adattamento media, ma anche dettagli della distribuzione;\nsono molto intuitivi e visivi, facilitando la diagnosi di problemi.\n\n\n27.5.4.1 Esempi con R\nVerifichiamo le predizioni del modello confrontandole con i dati osservati:\n\npp_check(fit_2)\n\n\n\n\n\n\n\nIn questo caso, il grafico mostra una buona corrispondenza tra i dati simulati e quelli reali.\nPossiamo poi analizzare i residui bayesiani con un grafico più specifico:\n\npp_check(fit_1, type = \"error_scatter_avg\")\n\n\n\n\n\n\n\nQuesto grafico rappresenta i residui (differenze tra osservato e predetto) rispetto ai valori predetti:\n\nse i residui appaiono distribuiti in modo uniforme, il modello descrive correttamente la relazione;\nse emergono pattern sistematici (ad esempio curvature o variazioni di dispersione), il modello potrebbe essere inadeguato.\n\n27.5.5 Commento sui residui\nNel grafico dei residui (\\(y\\) in funzione di \\(y - y_{\\text{rep}}\\)) si osserva un trend crescente: i residui non sono distribuiti in modo uniforme, ma mostrano una struttura sistematica. Questo pattern indica che il modello lineare bivariato non cattura pienamente le proprietà dei dati. In particolare, trattandosi di una serie temporale, è probabile che vi siano dipendenze tra osservazioni successive nel tempo: l’estensione dei ghiacci in un anno dipende anche dai valori degli anni immediatamente precedenti. Il modello lineare semplice, invece, assume che gli errori siano indipendenti e identicamente distribuiti, e non è quindi in grado di rappresentare questa dinamica temporale.\nQuesto esempio è didatticamente importante perché mostra che:\n\nanche un modello molto semplice può aiutare a evidenziare strutture nascoste nei dati (qui la dipendenza temporale);\ntuttavia, se compaiono incongruenze nei residui, significa che il modello non è adeguato e va migliorato o reso più complesso (ad esempio con modelli di regressione per serie temporali o modelli gerarchici dinamici).\n\nLa verifica dei residui è dunque un passaggio cruciale: non solo permette di valutare l’adattamento del modello, ma può suggerire nuove direzioni di modellizzazione per rappresentare meglio la complessità del fenomeno.\n\n27.5.5.1 In sintesi\nLe Predizioni a Posteriori forniscono un modo robusto per valutare l’adeguatezza di un modello bayesiano:\n\nse i dati simulati somigliano ai dati reali, il modello è plausibile per il campione analizzato;\nin caso contrario, è opportuno rivedere la struttura del modello (es. includendo effetti non lineari, variabili aggiuntive o priors più adeguati).\n\nIl PPC è una “prova del nove” del modello, che traduce la teoria in un confronto diretto e visivo con i dati osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#regressione-robusta",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#regressione-robusta",
    "title": "27  Zucchero sintattico",
    "section": "\n27.6 Regressione robusta",
    "text": "27.6 Regressione robusta\nIn questa sezione introduciamo la regressione robusta. L’obiettivo è mostrare quanto sia semplice modificare, in brm(), la distribuzione degli errori per rendere il modello meno sensibile agli outlier.\nQuesta flessibilità è un punto di forza dell’approccio bayesiano: nei modelli frequentisti standard, la distribuzione degli errori è quasi sempre fissata a priori (ad esempio normale/gaussiana) e non può essere facilmente modificata.\n\n27.6.1 Perché servono modelli robusti?\nGli outlier — valori molto distanti dal resto delle osservazioni — possono influenzare in modo marcato le stime di regressione. Ad esempio, aggiungiamo artificialmente un outlier nel dataset:\n\ndf_outlier &lt;- df\ndf_outlier$extent[1] &lt;- 20     # valore anomalo molto alto\ndf_outlier$year_c[1] &lt;- -25    # anno centrato \"estremo\"\n\nVisualizziamo i dati:\n\ndf_outlier |&gt; \n  ggplot(aes(x = year_c, y = extent)) +\n    geom_point() +  \n    labs(x = \"Anno centrato\", y = \"Estensione (milioni km²)\") \n\n\n\n\n\n\n\n\n27.6.2 Effetto dell’outlier su un modello gaussiano\nStimiamo un modello lineare gaussiano:\n\nfit_3 &lt;- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nEsaminiamo i parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable      mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  6.961 0.252     0.004   0.004\n#&gt; 2 b_year_c    -0.107 0.019     0.000   0.000\n\nRispetto al modello stimato senza outlier (dove la pendenza \\(\\beta\\) era intorno a –0.07), qui la stima è fortemente distorta. Un singolo punto anomalo può dunque trascinare la retta di regressione.\n\n27.6.3 Un modello robusto con distribuzione t\n\nPer ridurre la sensibilità agli outlier, possiamo sostituire la distribuzione gaussiana degli errori con una distribuzione t di Student, che ha code più pesanti:\n\nfit_4 &lt;- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  family = student(),   # distribuzione t di Student\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nI risultati mostrano che il modello t è meno influenzato dall’outlier rispetto al modello gaussiano:\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable      mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  6.740 0.068     0.001   0.001\n#&gt; 2 b_year_c    -0.072 0.005     0.000   0.000\n\n\n27.6.4 Il parametro \\(\\nu\\): quanto sono pesanti le code?\nIl modello con distribuzione t stima anche il parametro \\(\\nu\\), che controlla la pesantezza delle code:\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"nu\")\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 1 × 5\n#&gt;   variable  mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 nu       2.527 0.840     0.014   0.016\n\n\nCon valori alti di \\(\\nu\\) (es. &gt; 30), la distribuzione t si avvicina a una normale.\nCon valori bassi (es. \\(\\nu \\approx 4\\)), le code sono molto più pesanti: la distribuzione “accetta” più facilmente valori estremi, senza permettere che influenzino eccessivamente le stime.\n\nNel nostro caso, \\(\\nu \\approx 4\\) indica una distribuzione ben più robusta della normale, e il modello riesce a ignorare in buona parte l’effetto dell’outlier.\n\n27.6.5 In sintesi\nLa regressione robusta con distribuzione t è uno strumento essenziale quando sospettiamo che i dati possano contenere valori anomali. A differenza del modello gaussiano, non lascia che pochi outlier distorcano in modo significativo le stime dei parametri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#indice-di-determinazione-bayesiano",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#indice-di-determinazione-bayesiano",
    "title": "27  Zucchero sintattico",
    "section": "\n27.7 Indice di determinazione bayesiano",
    "text": "27.7 Indice di determinazione bayesiano\nCon il pacchetto brms possiamo calcolare il Bayes \\(R^2\\), l’equivalente bayesiano del classico indice di determinazione \\(R^2\\). Questo indice misura la proporzione di varianza spiegata dal modello, ma a differenza dell’approccio frequentista, tiene conto dell’incertezza associata alle stime dei parametri.\nIl comando per calcolarlo è:\n\nbayes_R2(fit_2)\n#&gt;    Estimate Est.Error  Q2.5 Q97.5\n#&gt; R2    0.822     0.023 0.764 0.851\n\n\n27.7.1 Interpretazione dell’output\nIl risultato è un tibble (una tabella ordinata) che riporta:\n\n\nEstimate: la media della distribuzione a posteriori del Bayes \\(R^2\\), cioè la proporzione di varianza spiegata dal modello;\n\nEst.Error: l’errore standard associato alla stima;\n\nQ2.5 e Q97.5: i limiti inferiore e superiore dell’intervallo di credibilità al 95% per il Bayes \\(R^2\\).\n\nEsempio (con valori ipotetici coerenti col nostro modello):\n\n\nStima media: il modello spiega circa il 57% della varianza osservata;\n\nErrore standard: l’incertezza sulla stima è bassa (± 0.02);\n\nIntervallo di credibilità: con il 95% di probabilità, il vero valore del Bayes \\(R^2\\) si trova tra 0.52 e 0.61.\n\n27.7.2 Differenze rispetto al \\(R^2\\) frequentista\n\n\nIncertezza esplicita\n\nIl Bayes \\(R^2\\) non è una stima puntuale, ma una distribuzione a posteriori: possiamo quindi rappresentare l’incertezza con intervalli di credibilità.\nNel caso frequentista, invece, il \\(R^2\\) è un singolo numero senza misura diretta di incertezza.\n\n\n\nInfluenza dei priors\n\nNel Bayes \\(R^2\\), i priors scelti per i parametri influiscono sulla stima finale.\nQuesto consente di incorporare conoscenze precedenti e rende la misura più flessibile e adattabile al contesto di ricerca.\n\n\n\n27.7.3 Distribuzione a posteriori del Bayes \\(R^2\\)\n\nPossiamo anche visualizzare la distribuzione completa dei valori simulati di \\(R^2\\):\n\nr2_draws &lt;- bayes_R2(fit_2, summary = FALSE)\nr2_df &lt;- data.frame(R2 = as.numeric(r2_draws))\n\nggplot(r2_df, aes(x = R2)) +\n  geom_density() +\n  geom_rug(alpha = 0.4) +\n  labs(\n    x = expression(R^2),\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nCalcoliamo anche i quantili:\n\nround(quantile(r2_df$R2, probs = c(.025, .5, .975)), 3)\n#&gt;  2.5%   50% 97.5% \n#&gt; 0.764 0.827 0.851\n\nIn alternativa, con bayesplot possiamo ottenere una visualizzazione immediata e compatta:\n\nmcmc_areas(r2_draws, prob = 0.95) \n\n\n\n\n\n\n\n\n27.7.3.1 In sintesi\nIl Bayes \\(R^2\\) è uno strumento potente perché combina l’intuitività del \\(R^2\\) classico con la ricchezza informativa dell’approccio bayesiano, permettendo di valutare non solo quanta varianza il modello spiega, ma anche quanto siamo sicuri di questa stima.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#approfondimento-manipolare-la-distribuzione-a-posteriori-con-brms",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#approfondimento-manipolare-la-distribuzione-a-posteriori-con-brms",
    "title": "27  Zucchero sintattico",
    "section": "\n27.8 Approfondimento: manipolare la distribuzione a posteriori con brms\n",
    "text": "27.8 Approfondimento: manipolare la distribuzione a posteriori con brms\n\nVediamo ora come accedere e manipolare i campioni della distribuzione a posteriori generati da un modello stimato con brms.\nSupponiamo di aver costruito un modello lineare semplice, in cui vogliamo predire l’estensione dei ghiacci (extent) a partire dall’anno centrato (year_c):\nfit_2 &lt;- brm(\n  bf(extent ~ 1 + year_c, center = FALSE), \n  prior = prior_gaussian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\n27.8.1 Estrarre i campioni\nUna volta stimato il modello, possiamo ottenere i campioni MCMC della distribuzione a posteriori con as_draws():\n\nposterior_2 &lt;- as_draws(fit_2)\n\nL’oggetto posterior_2 è di tipo draws, definito dal pacchetto posterior. Al suo interno troviamo i campioni prodotti dall’algoritmo MCMC, organizzati come un array o una lista:\n\nstr(posterior_2)\n#&gt; List of 4\n#&gt;  $ 1:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 6.74 6.72 6.75 6.65 6.79 ...\n#&gt;   ..$ b_year_c   : num [1:1000] -0.075 -0.0721 -0.0757 -0.0717 -0.0745 ...\n#&gt;   ..$ sigma      : num [1:1000] 0.43 0.427 0.494 0.493 0.413 ...\n#&gt;   ..$ lprior     : num [1:1000] -3.05 -3.05 -3.06 -3.07 -3.04 ...\n#&gt;   ..$ lp__       : num [1:1000] -31.1 -30.8 -31.8 -31.7 -31.9 ...\n#&gt;  $ 2:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 6.75 6.75 6.69 6.73 6.53 ...\n#&gt;   ..$ b_year_c   : num [1:1000] -0.0714 -0.0711 -0.0695 -0.0789 -0.0687 ...\n#&gt;   ..$ sigma      : num [1:1000] 0.458 0.473 0.388 0.515 0.468 ...\n#&gt;   ..$ lprior     : num [1:1000] -3.05 -3.05 -3.04 -3.07 -3.07 ...\n#&gt;   ..$ lp__       : num [1:1000] -31 -31.1 -31.6 -32.6 -34.3 ...\n#&gt;  $ 3:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 6.65 6.83 6.65 6.76 6.63 ...\n#&gt;   ..$ b_year_c   : num [1:1000] -0.0703 -0.0642 -0.0752 -0.0688 -0.077 ...\n#&gt;   ..$ sigma      : num [1:1000] 0.399 0.424 0.428 0.403 0.41 ...\n#&gt;   ..$ lprior     : num [1:1000] -3.05 -3.04 -3.05 -3.04 -3.05 ...\n#&gt;   ..$ lp__       : num [1:1000] -31.7 -33.8 -31.5 -31.5 -32.4 ...\n#&gt;  $ 4:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 6.68 6.66 6.76 6.73 6.78 ...\n#&gt;   ..$ b_year_c   : num [1:1000] -0.0625 -0.0729 -0.0661 -0.0708 -0.0711 ...\n#&gt;   ..$ sigma      : num [1:1000] 0.44 0.423 0.465 0.451 0.414 ...\n#&gt;   ..$ lprior     : num [1:1000] -3.05 -3.05 -3.05 -3.05 -3.04 ...\n#&gt;   ..$ lp__       : num [1:1000] -32.5 -31.2 -31.7 -30.8 -31.5 ...\n#&gt;  - attr(*, \"class\")= chr [1:3] \"draws_list\" \"draws\" \"list\"\n\n\n27.8.2 Parametri del modello\nPer vedere i nomi dei parametri campionati (intercetta, slope, deviazione standard, ecc.) usiamo:\n\nvariables(fit_2)\n#&gt; [1] \"b_Intercept\" \"b_year_c\"    \"sigma\"       \"lprior\"      \"lp__\"\n\nNel nostro caso, siamo interessati al coefficiente di regressione associato a year_c, che in brms è etichettato come b_year_c.\n\n27.8.3 Estrarre e riorganizzare i campioni\nPer lavorare più comodamente con i campioni, possiamo usare tidybayes, che fornisce funzioni per trasformare gli output bayesiani in formato tidy.\n\nb_slope_draws &lt;- posterior_2 |&gt; \n  spread_draws(b_year_c)\n\nLa funzione spread_draws() “srotola” i campioni in un tibble:\n\nhead(b_slope_draws)\n#&gt; # A tibble: 6 × 4\n#&gt;   .chain .iteration .draw b_year_c\n#&gt;    &lt;int&gt;      &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;\n#&gt; 1      1          1     1  -0.0750\n#&gt; 2      1          2     2  -0.0721\n#&gt; 3      1          3     3  -0.0757\n#&gt; 4      1          4     4  -0.0717\n#&gt; 5      1          5     5  -0.0745\n#&gt; 6      1          6     6  -0.0682\n\nOgni riga rappresenta un singolo campione della catena MCMC per quel parametro.\n\n27.8.4 Calcolare statistiche di sintesi\nUna volta estratti i campioni di b_year_c, possiamo calcolare facilmente mediana, media e quantili:\n\nquantile(b_slope_draws$b_year_c, probs = c(0.03, 0.50, 0.97))\n#&gt;      3%     50%     97% \n#&gt; -0.0814 -0.0714 -0.0621\nmean(b_slope_draws$b_year_c)\n#&gt; [1] -0.0715\n\n\nI quantili a 0.03 e 0.97 definiscono un intervallo di credibilità al 94%.\nIl quantile a 0.50 corrisponde alla mediana a posteriori.\nLa media a posteriori fornisce un’altra stima puntuale utile.\n\n27.8.5 Visualizzare la distribuzione a posteriori\nPer capire meglio la forma della distribuzione a posteriori, possiamo tracciarne la densità. Con tidyverse e tidybayes bastano poche righe:\n\ntibble(beta = b_slope_draws$b_year_c) %&gt;%\n  ggplot(aes(x = beta)) +\n  stat_halfeye() +\n  labs(\n    x = \"Valore di β\",\n    y = \"Densità a posteriori\"\n  )\n\n\n\n\n\n\n\n\n\nstat_halfeye() mostra la densità stimata e mette in evidenza i valori più probabili.\nLa banda orizzontale rappresenta un intervallo di credibilità centrale.\n\n\n27.8.5.1 In sintesi\nGrazie a as_draws() di posterior e alle funzioni di tidybayes, possiamo:\n\nestrarre i campioni MCMC della distribuzione a posteriori,\ncalcolare statistiche di sintesi (media, mediana, quantili),\nvisualizzare in modo intuitivo la forma e l’incertezza della distribuzione di un parametro.\n\nLa combinazione di posterior, tidybayes e tidyverse rende il flusso di lavoro con i modelli stimati da brms semplice, potente e flessibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#riflessioni-conclusive",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#riflessioni-conclusive",
    "title": "27  Zucchero sintattico",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come la scrittura di un modello possa essere resa più chiara e compatta attraverso l’uso di scorciatoie sintattiche. Lo scopo non è cambiare la sostanza del modello, ma alleggerire la sua formulazione, così da concentrare l’attenzione sugli aspetti concettuali e interpretativi piuttosto che sui dettagli tecnici ripetitivi.\nQuesta operazione di “pulizia” del codice ha un valore didattico importante: permette di visualizzare con maggiore immediatezza la struttura del modello e di cogliere più facilmente il legame tra le formule statistiche e la loro implementazione. Inoltre, anticipa una sfida che incontreremo sempre più spesso man mano che i modelli diventeranno complessi: la necessità di strumenti che automatizzino i calcoli senza oscurare la logica sottostante.\nNei prossimi capitoli vedremo come Stan risponda a questa esigenza su scala molto più ampia, fornendo un linguaggio di programmazione che combina rigore statistico e potenza computazionale. In questo senso, lo “zucchero sintattico” non è solo una comodità, ma un passo preparatorio per abituarci a pensare ai modelli in modo modulare, leggibile e scalabile.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nModello base\nImporta il dataset Howell_18.csv, filtra gli individui di età ≥ 18 anni e adatta un modello bayesiano lineare height ∼ weight usando brm(). Visualizza il sommario.\nCentraggio del predittore\nCalcola la variabile centrata weight_c e adatta il modello height ∼ weight_c. Confronta l’intercetta (b_Intercept) con quella del modello non centrato. Spiega la differenza.\n\nSpecificazione dei prior\nUsa get_prior() per recuperare i prior di default, poi definisci manualmente prior debolmente informativi:\n\nIntercept ∼ Normal(150, 20)\nweight_c ∼ Normal(0, 10)\nsigma ∼ Cauchy(0, 5)\n\nAdatta il modello con questi prior e confronta le stime a posteriori con quelle del modello con prior di default.\n\n\nPredizioni predittive a posteriori\nPer il modello con prior personalizzati:\n\nEsegui pp_check() per la densità e per l’errore medio (type = \"error_scatter_avg\").\nDescrivi brevemente cosa mostrano i due grafici.\n\n\n\nModello robusto\nIntroduci un outlier modificando il primo record: imposta height = 400.\n\nAdatta prima un modello gaussiano e poi uno robusto con family = student().\nConfronta le stime di b_weight_c nei due modelli e discuti l’impatto dell’outlier.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nModello base\nlibrary(brms)\ndf &lt;- rio::import(\"data/Howell_18.csv\")\ndf_adults &lt;- subset(df, age &gt;= 18)\nfit_base &lt;- brm(height ~ weight, data = df_adults, backend = \"cmdstanr\")\nsummary(fit_base)\n\n\nCentraggio del predittore\ndf_adults$weight_c &lt;- df_adults$weight - mean(df_adults$weight)\nfit_centered &lt;- brm(height ~ weight_c, data = df_adults, backend = \"cmdstanr\")\nsummary(fit_centered)\n\nIl b_Intercept nel modello non centrato è l’altezza prevista per peso = 0 (non interpretabile realisticamente).\n\nNel modello centrato, l’intercetta rappresenta l’altezza media alla media del peso del campione.\n\n\n\nSpecificazione dei prior\nget_prior(height ~ weight_c, data = df_adults)\n\npriors_custom &lt;- c(\n  prior(normal(150, 20), class = \"b\", coef = \"Intercept\"),\n  prior(normal(0, 10), class = \"b\", coef = \"weight_c\"),\n  prior(cauchy(0, 5), class = \"sigma\")\n)\nfit_priors &lt;- brm(\n  height ~ weight_c,\n  data = df_adults,\n  prior = priors_custom,\n  backend = \"cmdstanr\"\n)\nsummary(fit_priors)\n\nLe stime a posteriori rimangono simili, ma i prior personalizzati influenzano leggermente l’incertezza.\n\n\n\nPredizioni predittive a posteriori\npp_check(fit_priors)\npp_check(fit_priors, type = \"error_scatter_avg\")\n\nIl grafico di densità mostra se la distribuzione simulata riproduce quella osservata.\n\nIl grafico degli errori media evidenzia eventuali pattern sistematici nei residui.\n\n\n\nModello robusto\ndf_out &lt;- df_adults\ndf_out$height[1] &lt;- 400\nfit_gauss &lt;- brm(height ~ weight_c, data = df_out, backend = \"cmdstanr\")\nfit_student &lt;- brm(height ~ weight_c, family = student(),\n                   data = df_out, backend = \"cmdstanr\")\nsummary(fit_gauss)$fixed[\"weight_c\", ]\nsummary(fit_student)$fixed[\"weight_c\", ]\n\nIl modello gaussiano vede una variazione marcata di b_weight_c a causa dell’outlier.\n\nIl modello Student stima un coefficiente più vicino al valore senza outlier, dimostrando robustezza.\n\n\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#&gt; [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [13] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] utf8_1.2.6            rmarkdown_2.29        ps_1.9.1             \n#&gt; [22] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [28] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [31] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [34] knitr_1.50            zoo_1.8-14            R.utils_2.13.0       \n#&gt; [37] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [40] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [43] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [46] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#&gt; [49] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [52] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [55] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [58] stats4_4.5.1          distributional_0.5.0  generics_0.1.4       \n#&gt; [61] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         \n#&gt; [64] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [67] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [70] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [73] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [76] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [79] gtable_0.3.6          R.methodsS3_1.8.2     digest_0.6.37        \n#&gt; [82] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [85] R.oo_1.27.1           memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [88] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar_sea_ice.html#bibliografia",
    "href": "chapters/linear_models/04_synt_sugar_sea_ice.html#bibliografia",
    "title": "27  Zucchero sintattico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nClayton, S. (2020). Climate anxiety: Psychological responses to climate change. Journal of anxiety disorders, 74, 102263.\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html",
    "href": "chapters/linear_models/05_stan_regression.html",
    "title": "28  Regressione lineare in Stan",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo formulato la regressione lineare bivariata sia in chiave frequentista sia in chiave bayesiana, lavorando con modelli semplici e utilizzando notazioni compatte per facilitarne l’implementazione in R. Questi esercizi ci hanno permesso di cogliere la logica dell’approccio bayesiano, ma hanno anche mostrato i limiti delle soluzioni analitiche: sono praticabili solo in casi elementari e non si estendono facilmente a modelli con più predittori, variabili categoriali o strutture gerarchiche.\nPer affrontare problemi realistici è necessario un linguaggio che ci permetta di specificare modelli generali e di stimarli in modo efficiente con algoritmi di campionamento moderni. Questo linguaggio è Stan. Con Stan possiamo tradurre direttamente le nostre ipotesi in codice, lasciando al software il compito di eseguire il campionamento dalla distribuzione a posteriori.\nIn questo capitolo vedremo come implementare il modello di regressione lineare in Stan. Partiremo dalla traduzione della formulazione matematica in codice, per poi esaminare come i diversi blocchi del linguaggio (data, parameters, model, generated quantities) contribuiscano a definire e stimare il modello. Lo scopo non è solo imparare a scrivere un programma funzionante, ma soprattutto comprendere il legame stretto tra teoria statistica, specificazione del modello e calcolo computazionale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#introduzione",
    "href": "chapters/linear_models/05_stan_regression.html#introduzione",
    "title": "28  Regressione lineare in Stan",
    "section": "",
    "text": "28.0.1 Perché usare Stan per la regressione?\nScrivere la regressione in Stan significa specificare un modello generativo completo:\n\\[\ny_n \\sim \\mathcal{N}(\\alpha + \\mathbf{x}_n^\\top \\boldsymbol{\\beta},\\, \\sigma),\n\\] con priors espliciti per \\(\\alpha\\), \\(\\boldsymbol{\\beta}\\) e \\(\\sigma\\). Questo approccio offre tre vantaggi immediati:\n\n\nTrasparenza — la struttura del modello (likelihood e priors) è dichiarata in modo chiaro.\n\nCoerenza — l’inferenza è interamente bayesiana: non ci sono p-value né “soglie di significatività”.\n\nFlessibilità — lo stesso schema si estende facilmente a GLM (esiti Bernoulli, Poisson, ecc.) e a modelli multilivello, semplicemente cambiando la famiglia di distribuzione o la struttura gerarchica.\n\n28.0.2 Idee guida del capitolo\n\n\nNotazione matriciale: la scrittura compatta \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\\) si traduce in Stan in matrix[N,K] X; e vector[K] beta;, con previsioni calcolate come X * beta.\n\nVettorializzazione: scrivere y ~ normal(X * beta + alpha, sigma); è più elegante ed efficiente che iterare su ogni osservazione.\n\nCoefficiente parziale vs bivariato: in presenza di correlazione tra predittori, il coefficiente bivariato può risultare distorto o addirittura invertire segno. I coefficienti del modello multiplo misurano invece l’associazione condizionata.\n\nPriors su scala naturale: formulare i priors nelle unità originali (per esempio, punteggi da 0 a 10 o da 0 a 100) rende le ipotesi più interpretabili e comunicabili.\n\n28.0.3 Una prima finestra sugli errori di specificazione\nIl capitolo affronterà anche alcuni casi frequenti di specificazione errata, con esempi concreti tratti dalla ricerca psicologica:\n\n\nVariabili omesse: trascurare un predittore rilevante e correlato introduce bias nei coefficienti.\n\nForma funzionale errata: trattare relazioni non lineari come lineari semplici produce stime ingannevoli.\n\nVarianza non costante e outlier: assumere residui gaussiani omoschedastici può essere inadeguato; i posterior predictive checks aiutano a diagnosticarlo e a considerare likelihood più robuste.\n\nIn sintesi, la regressione lineare in Stan non è solo un esercizio di calcolo, ma un’occasione per apprendere un metodo: partire da un modello teorico, tradurlo in linguaggio probabilistico, implementarlo in codice, e valutarne la capacità di rappresentare i dati psicologici in modo critico e trasparente.\nPanoramica del capitolo\n\nIl modello di regressione multipla in notazione matriciale.\n\nFormulazione del modello in codice Stan.\n\nStima e interpretazione dei coefficienti parziali e confronto con quelli di modelli bivariati.\n\nEffetto della correlazione tra predittori sulle stime e errore di specificazione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\nPer seguire al meglio questo capitolo è utile avere:\n\nuna conoscenza di base della regressione lineare semplice e del concetto di coefficiente di regressione;\n\nun’idea generale della notazione vettoriale/matriciale, anche solo a livello concettuale;\nnozioni introduttive di statistica bayesiana: cosa sono i prior, la likelihood e il posterior;\nfamiliarità minima con R per la simulazione di dati e con il flusso di lavoro di Stan.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, cmdstanr, tidybayes, loo, patchwork)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#regressione-lineare-con-un-solo-predittore",
    "href": "chapters/linear_models/05_stan_regression.html#regressione-lineare-con-un-solo-predittore",
    "title": "28  Regressione lineare in Stan",
    "section": "\n28.1 Regressione lineare con un solo predittore",
    "text": "28.1 Regressione lineare con un solo predittore\nConsideriamo una regressione lineare con un solo predittore, un’intercetta \\(\\alpha\\), un coefficiente \\(\\beta\\) e un errore gaussiano \\(\\sigma\\):\n\\[\ny_n = \\alpha + \\beta\\,x_n + \\varepsilon_n,\\qquad \\varepsilon_n \\sim \\mathcal{N}(0,\\sigma).\n\\]\nIn Stan con priors espliciti e debolmente informativi:\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;               // predittore (consigliato centrare in R)\n  vector[N] y;               // risposta continua\n}\nparameters {\n  real alpha;                // intercetta (valore di y al centro di x)\n  real beta;                 // coefficiente\n  real&lt;lower=0&gt; sigma;       // DS dell'errore\n}\nmodel {\n  // Priors debolmente informativi (propri)\n  alpha ~ normal(0, 10);\n  beta  ~ normal(0, 5);\n  sigma ~ student_t(4, 0, 10);  // half-Student-t implicita grazie al vincolo &lt;lower=0&gt;\n\n  // Likelihood (vettorializzata)\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  vector[N] mu = alpha + beta * x;\n  vector[N] y_rep;\n  for (n in 1:N) y_rep[n] = normal_rng(mu[n], sigma);\n\n  // R^2 \"bayesiano\" (Gelman et al.)\n  real R2 = variance(mu) / (variance(mu) + square(sigma));\n}\nIn questo modello:\n\n\nN è il numero di osservazioni;\nper ogni osservazione abbiamo un valore di x (predittore) e un valore di y (variabile risposta);\n\nalpha ~ normal(0, 10) e beta ~ normal(0, 5) sono priors propri, debolmente informativi sulla scala della variabile y;\n\nsigma ~ student_t(4, 0, 10) è una half-Student-t implicita (perché sigma è vincolata \\(&gt;0\\)); è un prior robusto e poco informativo sulla scala di \\(\\sigma\\).\n\nSe venissero rimosse tutte le righe di prior, Stan non aggiungerebbe priors di default:\n\n\nalpha e beta avrebbero di fatto un prior piatto improprio su \\((-\\infty, +\\infty)\\);\n\nsigma avrebbe un prior piatto improprio su \\((0, +\\infty)\\).\n\nCon likelihood gaussiane questi priors possono talvolta produrre una posteriore propria, ma non è una buona pratica: meglio usare priors (anche deboli) e fare prior predictive checks.\n\n\n\n\n\n\nCentrare i predittori\n\n\n\nConsigliato centrare x in R (x_c &lt;- x - mean(x)) e passare x_c al modello: rende alpha interpretabile (valore atteso di \\(y\\) al centro dei predittori) e migliora la geometria posteriore (minore correlazione tra \\(\\alpha\\) e \\(\\beta\\)).\n\n\n\n28.1.1 Notazione matriciale e vettorializzazione\nLa riga seguente è vettorializzata, cioè calcola la probabilità di tutte le osservazioni in un’unica istruzione:\ny ~ normal(alpha + beta * x, sigma);\nÈ equivalente a scrivere:\nfor (n in 1:N) {\n  y[n] ~ normal(alpha + beta * x[n], sigma);\n}\nLa forma vettorializzata è più compatta e molto più veloce da eseguire. In Stan, quando un argomento di una distribuzione è un vettore, anche gli altri argomenti possono esserlo (purché abbiano la stessa dimensione) oppure possono essere scalari (in tal caso vengono “riciclati” per tutte le osservazioni).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#notazione-matriciale-regressione-multipla",
    "href": "chapters/linear_models/05_stan_regression.html#notazione-matriciale-regressione-multipla",
    "title": "28  Regressione lineare in Stan",
    "section": "\n28.2 Notazione matriciale: regressione multipla",
    "text": "28.2 Notazione matriciale: regressione multipla\nOra estendiamo il ragionamento al caso in cui i predittori siano più di uno, così da introdurre il concetto di effetto parziale.\nQuando abbiamo più predittori per ciascuna osservazione, possiamo scrivere il modello di regressione in forma vettoriale/matriciale (Caudek & Luccio, 2001). Con più predittori per osservazione, in forma compatta il modello è:\n\\[\n\\mathbf{y} = \\mathbf{X} \\, \\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\n\\] dove:\n\n\n\\(\\mathbf{y}\\) è un vettore colonna di dimensione \\(N \\times 1\\), che contiene la variabile risposta per le \\(N\\) osservazioni;\n\n\\(\\mathbf{X}\\) è una matrice \\(N \\times K\\), dove ogni riga corrisponde a un’osservazione e ogni colonna a un predittore (la prima colonna, se presente, è di 1 e serve per l’intercetta);\n\n\\(\\boldsymbol{\\beta}\\) è un vettore colonna di dimensione \\(K \\times 1\\), che contiene i coefficienti del modello (inclusa l’intercetta se la colonna di 1 è presente in \\(\\mathbf{X}\\));\n\n\\(\\boldsymbol{\\varepsilon}\\) è un vettore \\(N \\times 1\\) di errori casuali, che assumiamo distribuiti come \\(\\mathcal{N}(0, \\sigma^2)\\).\n\n\n\n\n\n\n\n\n\nNotazione matematica\nSignificato\nOggetto in Stan\nDichiarazione Stan\n\n\n\n\\(\\mathbf{y}\\)\nVettore colonna degli esiti (variabile risposta)\ny\nvector[N] y;\n\n\n\\(\\mathbf{X}\\)\nMatrice dei predittori (N osservazioni × K predittori)\nx\nmatrix[N, K] x;\n\n\n\\(\\boldsymbol{\\beta}\\)\nVettore colonna dei coefficienti di regressione\nbeta\nvector[K] beta;\n\n\n\\(\\beta_0\\)\nIntercetta\nalpha\nreal alpha;\n\n\n\\(\\sigma\\)\nDeviazione standard dell’errore\nsigma\nreal&lt;lower=0&gt; sigma;\n\n\n\\(\\hat{\\mathbf{y}} = \\mathbf{X} \\boldsymbol{\\beta} + \\beta_0\\)\nVettore delle predizioni lineari\nx * beta + alpha\nEspressione all’interno del modello Stan\n\n\n\\(\\boldsymbol{\\varepsilon}\\)\nVettore degli errori casuali\n—\nImplicito nella distribuzione normal(..., sigma)\n\n\n\n\n\n28.2.1 Sviluppo riga per riga\nScrivendo esplicitamente il contenuto della moltiplicazione \\(\\boldsymbol{X} \\, \\boldsymbol{\\beta}\\), otteniamo:\n\\[\n\\begin{bmatrix}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{N}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & x_{11} & x_{12} & \\dots & x_{1,K-1} \\\\\n1 & x_{21} & x_{22} & \\dots & x_{2,K-1} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{N1} & x_{N2} & \\dots & x_{N,K-1}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_{0} \\\\\n\\beta_{1} \\\\\n\\beta_{2} \\\\\n\\vdots \\\\\n\\beta_{K-1}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\varepsilon_{1} \\\\\n\\varepsilon_{2} \\\\\n\\vdots \\\\\n\\varepsilon_{N}\n\\end{bmatrix}\n\\]\n\n28.2.2 Interpretazione\n\n\nOgni riga della matrice \\(\\mathbf{X}\\) contiene i valori dei predittori per una singola osservazione.\n\nLa stessa colonna di \\(\\boldsymbol{\\beta}\\) (cioè lo stesso coefficiente) si applica a tutte le righe, moltiplicando il rispettivo valore del predittore.\nIl termine \\(\\beta_0\\) è l’intercetta: è costante e si applica a tutte le osservazioni.\nLa moltiplicazione \\(\\mathbf{X} \\, \\boldsymbol{\\beta}\\) produce un vettore \\(N \\times 1\\) di valori previsti (\\(\\hat{y}\\)), uno per ogni osservazione.\nGli errori \\(\\boldsymbol{\\varepsilon}\\) rappresentano la differenza tra il valore osservato \\(y_i\\) e il valore previsto \\(\\hat{y}_i\\).\n\n28.2.3 Esempio con due variabili indipendenti\nSe \\(N=3\\) e \\(K=3\\) (intercetta + 2 predittori), abbiamo:\n\\[\n\\underbrace{\\begin{bmatrix}\ny_{1} \\\\ y_{2} \\\\ y_{3}\n\\end{bmatrix}}_{y}\n=\n\\underbrace{\\begin{bmatrix}\n1 & x_{11} & x_{12} \\\\\n1 & x_{21} & x_{22} \\\\\n1 & x_{31} & x_{32}\n\\end{bmatrix}}_{X}\n\\underbrace{\\begin{bmatrix}\n\\beta_{0} \\\\ \\beta_{1} \\\\ \\beta_{2}\n\\end{bmatrix}}_{\\beta}\n+\n\\underbrace{\\begin{bmatrix}\n\\varepsilon_{1} \\\\ \\varepsilon_{2} \\\\ \\varepsilon_{3}\n\\end{bmatrix}}_{\\varepsilon}\n\\] Il che equivale a:\n\\[\n\\begin{cases}\ny_{1} = \\beta_0 + \\beta_1 x_{11} + \\beta_2 x_{12} + \\varepsilon_{1} \\\\\ny_{2} = \\beta_0 + \\beta_1 x_{21} + \\beta_2 x_{22} + \\varepsilon_{2} \\\\\ny_{3} = \\beta_0 + \\beta_1 x_{31} + \\beta_2 x_{32} + \\varepsilon_{3}\n\\end{cases}\n\\]\n\n28.2.4 Interpretazione dei coefficienti parziali di regressione\nIn un modello di regressione multipla ogni coefficiente \\(\\beta_j\\) rappresenta l’effetto parziale del predittore \\(x_j\\) sulla variabile risposta \\(y\\), tenendo costanti (cioè controllando per) gli altri predittori inclusi nel modello.\n\n\nEffetto parziale: \\(\\beta_j\\) indica di quanto ci si attende che cambi \\(y\\) in media se \\(x_j\\) aumenta di una unità, mentre tutti gli altri predittori del modello restano invariati.\n\nUnità di misura: l’interpretazione è sempre nella scala originale di \\(y\\) e \\(x_j\\) (se non abbiamo standardizzato).\n\nSegno: positivo se, a parità degli altri predittori, un aumento di \\(x_j\\) è associato a un aumento di \\(y\\); negativo se associato a una diminuzione.\n\n\n28.2.4.1 Differenza con la regressione bivariata\nSe stimiamo un modello bivariato (cioè con un solo predittore per volta), il coefficiente di regressione di \\(x_j\\) rappresenta l’associazione totale tra \\(x_j\\) e \\(y\\), senza tenere conto di altri fattori. Questo può essere fuorviante quando i predittori sono correlati tra loro e/o esiste un predittore \\(x_k\\) che spiega parte della stessa varianza di \\(y\\) che spiega \\(x_j\\).\nIn questi casi:\n\n\nModello bivariato: il coefficiente di \\(x_j\\) include anche l’effetto “indiretto” dovuto alla sua correlazione con altri predittori.\n\nModello multiplo: il coefficiente di \\(x_j\\) è “depurato” dagli effetti degli altri predittori, cioè riflette l’associazione residua unica di \\(x_j\\) con \\(y\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#esempio-numerico",
    "href": "chapters/linear_models/05_stan_regression.html#esempio-numerico",
    "title": "28  Regressione lineare in Stan",
    "section": "\n28.3 Esempio numerico",
    "text": "28.3 Esempio numerico\nPer chiarire concretamente la differenza tra l’effetto totale (o grezzo) di un predittore e il suo effetto parziale (o netto), simuliamo uno scenario realistico ipotizzando che l’esito \\(y\\) sia un punteggio di stress su scala 0–10. I due predittori sono:\n\n\n\\(x_1\\): affetto negativo istantaneo su scala 0–10 (più alto = più negativo);\n\n\\(x_2\\): ore di sonno nell’ultima notte su scala 0–10.\n\nSupponiamo che:\n\na parità di altre condizioni, aumentare l’affetto negativo di 1 punto (su 0–10) faccia crescere lo stress di qualche punto (effetto positivo);\n\ndormire di più riduca lo stress (effetto negativo);\nil livello medio di stress a affetto negativo medio e sonno medio sia moderato.\n\n\nset.seed(42)\n\nN &lt;- 2000\nrho &lt;- 0.8\n\nx1 &lt;- rnorm(N, 0, 1)\nz  &lt;- rnorm(N, 0, 1)\nx2 &lt;- rho * x1 + sqrt(1 - rho^2) * z  # cor(x1, x2) ~ 0.8\n\nbeta1_true &lt;-  1\nbeta2_true &lt;- -2\nsigma_true &lt;-  0.5\n\ny &lt;- beta1_true * x1 + beta2_true * x2 + rnorm(N, 0, sigma_true)\n\ndati &lt;- tibble(y = y + abs(min(y)), x1 = x1 + abs(min(x1)), x2 = x2 + abs(min(x2)))\nsummary(dati)\n#&gt;        y              x1             x2      \n#&gt;  Min.   :0.00   Min.   :0.00   Min.   :0.00  \n#&gt;  1st Qu.:3.26   1st Qu.:2.70   1st Qu.:2.73  \n#&gt;  Median :4.23   Median :3.36   Median :3.38  \n#&gt;  Mean   :4.23   Mean   :3.36   Mean   :3.38  \n#&gt;  3rd Qu.:5.21   3rd Qu.:4.03   3rd Qu.:4.06  \n#&gt;  Max.   :9.03   Max.   :6.96   Max.   :6.70\n\nSe i due predittori \\(x_1\\) e \\(x_2\\) sono correlati (ad esempio: chi dorme poco tende anche a percepire più stress):\n\ncor(dati$x1, dati$x2)\n#&gt; [1] 0.8\n\nallora i coefficienti stimati assumono significati diversi a seconda del modello:\n\nNel modello bivariato \\(y \\sim x_1\\), il coefficiente di \\(x_1\\) riflette non solo l’effetto diretto dello stress sull’ansia, ma anche l’effetto indiretto mediato dalla correlazione con il sonno (più stress → meno sonno → più ansia).\nNel modello multiplo \\(y \\sim x_1 + x_2\\), il coefficiente di \\(x_1\\) isola invece l’effetto unico dello stress, cioè la variazione di ansia associata a un incremento di stress a parità di ore di sonno.\n\nIn sintesi:\n\ni coefficienti bivariati misurano l’associazione totale tra predittore e risposta,\ni coefficienti parziali misurano l’associazione unica, controllando per gli altri predittori,\nla differenza tra i due diventa rilevante quando i predittori sono correlati.\n\nPer rendere chiara la differenza, usiamo i dati simulati (y, x1, x2) e stimiamo i coefficienti di regressione in due modi diversi:\n– usando un predittore alla volta (y ~ x1 e y ~ x2); – usando entrambi i predittori insieme (y ~ x1 + x2).\nPer semplicità, iniziamo a stimare i coefficienti con lm() (poi useremo Stan):\n\n# Modelli bivariati\nfit_biv_x1 &lt;- lm(y ~ x1, data = dati)\nfit_biv_x2 &lt;- lm(y ~ x2, data = dati)\n\n# Modello multiplo\nfit_mult &lt;- lm(y ~ x1 + x2, data = dati)\n\n# Confronto dei coefficienti\ncoefs &lt;- data.frame(\n  Modello = c(\"Bivariato x1\", \"Bivariato x2\", \"Multiplo\"),\n  beta_x1 = c(coef(fit_biv_x1)[\"x1\"], NA, coef(fit_mult)[\"x1\"]),\n  beta_x2 = c(NA, coef(fit_biv_x2)[\"x2\"], coef(fit_mult)[\"x2\"])\n)\ncoefs\n#&gt;        Modello beta_x1 beta_x2\n#&gt; 1 Bivariato x1  -0.618      NA\n#&gt; 2 Bivariato x2      NA   -1.22\n#&gt; 3     Multiplo   1.017   -2.02\n\nI valori veri dei coefficienti erano:\n\nbeta1_true &lt;-  1\nbeta2_true &lt;- -2\n\nCosa osserviamo:\n\nnel modello bivariato y ~ x1, il coefficiente di x1 è negativo (≈ −0.6), anche se il vero effetto è positivo (+1);\nnel modello multiplo y ~ x1 + x2, i coefficienti si avvicinano ai valori veri (≈ +1 per x1, ≈ −2 per x2): qui leggiamo gli effetti parziali, cioè ciascun predittore “a parità” dell’altro.\n\nIl cambio di segno nel bivariato è un chiaro esempio di bias da variabile omessa: se escludiamo x2 (sonno), l’effetto stimato di x1 (affetto negativo) assorbe anche parte dell’influenza del sonno, arrivando persino a invertirne il segno.\nMatematicamente, l’atteso del coefficiente bivariato è:\n\\[\n\\mathbb{E}\\!\\left[\\hat\\beta^{(biv)}_{x1}\\right] \\;=\\;\n\\beta_1 \\;+\\; \\beta_2 \\frac{\\operatorname{Cov}(x_1, x_2)}{\\operatorname{Var}(x_1)} .\n\\]\nQuando \\(\\beta_2\\) e \\(\\operatorname{Cov}(x_1, x_2)\\) hanno segni opposti e grande ampiezza, la correzione può superare \\(\\beta_1\\) e invertire il segno.\n\n\n\n\n\n\nMessaggio didattico:\n\nI coefficienti bivariati misurano l’associazione totale tra un predittore e la risposta.\nI coefficienti parziali del modello multiplo misurano l’associazione unica, condizionata agli altri predittori.\nIn psicologia (e non solo), questo è cruciale: includere o escludere variabili di controllo — ad esempio livello socioeconomico, sonno o supporto sociale — può cambiare radicalmente la stima di un effetto.\n\n\n\n\n\n28.3.1 La regressione multipla in Stan\nOra ripetiamo l’analisi precedente usando Stan. Prima però ci rinfreschiamo la memoria relativamente alle operazioni di algebra matriciale necessarie per capire il codice Stan.\n\n\n\n\n\n\nCome funziona la moltiplicazione tra matrici (ripasso essenziale)\n\n\n\n\n\nConformabilità. Due matrici si possono moltiplicare solo se il numero di colonne della prima coincide con il numero di righe della seconda. Se \\(A\\) è \\(m \\times k\\) e \\(B\\) è \\(k \\times n\\), allora il prodotto \\(C = A B\\) esiste ed è una matrice di dimensione \\(m \\times n\\).\nElemento \\(c_{ij}\\). L’elemento sulla riga \\(i\\) e colonna \\(j\\) di \\(C\\) si ottiene come prodotto scalare tra:\n\nla riga \\(i\\)-esima di \\(A\\) e\nla colonna \\(j\\)-esima di \\(B\\).\n\nPer prodotto scalare intendiamo: somma dei prodotti degli elementi corrispondenti.\nFormalmente,\n\\[\nc_{ij} \\;=\\; \\sum_{t=1}^{k} a_{i t}\\, b_{t j}.\n\\]\nEsempio numerico.\nSiano\n\\[\nA=\\begin{bmatrix}\n1 & 2 & 3\\\\\n4 & 5 & 6\n\\end{bmatrix}\n\\quad (2\\times 3), \\qquad\nB=\\begin{bmatrix}\n1 & 0\\\\\n-1 & 2\\\\\n2 & 1\n\\end{bmatrix}\n\\quad (3\\times 2).\n\\]\nSono conformabili (3 colonne di \\(A\\) = 3 righe di \\(B\\)). Il prodotto \\(C=AB\\) sarà \\(2\\times 2\\).\nCalcoliamo i singoli elementi:\n\n\\(c_{11} = [1,2,3]\\cdot[1,-1,2]^\\top = 1\\cdot 1 + 2\\cdot(-1) + 3\\cdot 2 = 1 - 2 + 6 = 5\\)\n\\(c_{12} = [1,2,3]\\cdot[0,2,1]^\\top = 1\\cdot 0 + 2\\cdot 2 + 3\\cdot 1 = 0 + 4 + 3 = 7\\)\n\\(c_{21} = [4,5,6]\\cdot[1,-1,2]^\\top = 4\\cdot 1 + 5\\cdot(-1) + 6\\cdot 2 = 4 - 5 + 12 = 11\\)\n\\(c_{22} = [4,5,6]\\cdot[0,2,1]^\\top = 4\\cdot 0 + 5\\cdot 2 + 6\\cdot 1 = 0 + 10 + 6 = 16\\)\n\nQuindi\n\\[\nC=AB=\\begin{bmatrix}\n5 & 7\\\\\n11 & 16\n\\end{bmatrix}.\n\\]\nVerifica in R.\n\nA &lt;- matrix(c(1,2,3, 4,5,6), nrow = 2, byrow = TRUE)\nB &lt;- matrix(c(1,0, -1,2, 2,1), nrow = 3, byrow = TRUE)\nA %*% B\n#&gt;      [,1] [,2]\n#&gt; [1,]    5    7\n#&gt; [2,]   11   16\n\n\n\n\nCon più predittori, anche in Stan possiamo usare la notazione matriciale:\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; K;\n  matrix[N, K] X;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  vector[K] beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  alpha ~ normal(0, 10);\n  beta  ~ normal(0, 5);\n  sigma ~ student_t(4, 0, 10);\n\n  y ~ normal(X * beta + alpha, sigma);\n}\ngenerated quantities {\n  vector[N] mu = alpha + X * beta;\n  vector[N] y_rep;\n  for (n in 1:N) y_rep[n] = normal_rng(mu[n], sigma);\n  real R2 = variance(mu) / (variance(mu) + square(sigma));\n}\nQui:\n\n\nx è una matrice N × K di predittori;\n\nbeta è un vettore con K coefficienti;\n\nx * beta produce un vettore di N valori predetti;\naggiungendo alpha otteniamo la previsione completa per ogni osservazione.\n\nAnche in questo caso la forma vettorializzata è equivalente a:\nfor (n in 1:N) {\n  y[n] ~ normal(x[n] * beta + alpha, sigma);\n}\n\n28.3.2 Intercetta come colonna della matrice dei predittori\nSe preferiamo non dichiarare un parametro separato per l’intercetta (alpha), possiamo inserire una colonna di 1 come prima colonna della matrice x. In questo caso il primo elemento di beta (beta[1]) fungerà da intercetta.\nSe però vogliamo assegnare un prior diverso all’intercetta rispetto agli altri coefficienti, è meglio dichiarare alpha come parametro separato. Questo è anche leggermente più efficiente, ma la differenza di velocità è trascurabile: la scelta va fatta per chiarezza del codice.\nScriviamo dunque il modello Stan per i dati dell’esempio in discussione.\n\nstancode &lt;- write_stan_file(\"\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; K;\n  matrix[N, K] X;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  vector[K] beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  alpha ~ normal(0, 10);\n  beta  ~ normal(0, 5);\n  sigma ~ student_t(4, 0, 10);\n\n  y ~ normal(X * beta + alpha, sigma);\n}\ngenerated quantities {\n  vector[N] mu = alpha + X * beta;\n  vector[N] y_rep;\n  for (n in 1:N) y_rep[n] = normal_rng(mu[n], sigma);\n  real R2 = variance(mu) / (variance(mu) + square(sigma));\n}\n\")\n\nNotiamo la scelta dei prior nel modello Stan:\nalpha ~ normal(0, 10);\nbeta  ~ normal(0, 5);\nsigma ~ student_t(4, 0, 10);\n\nIntercetta alpha: prior normal(0,10). È un prior debole e poco informativo: ammette con alta probabilità valori compresi tra circa −20 e +20. È adatto se i dati sono centrati (così l’intercetta rappresenta il valore medio di \\(y\\)). Se invece \\(y\\) ha una scala diversa, conviene adeguare la deviazione standard del prior alla variabilità attesa dei dati.\nCoefficienti beta: prior normal(0,5). Indica che, a priori, ci aspettiamo effetti di ampiezza moderata (nell’ordine di qualche unità di \\(y\\) per uno scarto unitario di \\(x\\)), ma lasciamo aperta la possibilità a effetti anche più grandi. Se i predittori vengono standardizzati, un prior ancora più stretto come normal(0,1) diventa naturale, perché corrisponde all’ipotesi che la maggior parte degli effetti sia inferiore a ±2 deviazioni standard di \\(y\\).\nDeviazione standard sigma: prior student_t(4, 0, 10). È una distribuzione half-Student-t (positiva per vincolo &lt;lower=0&gt;), con code più pesanti della normale: questo rende il prior robusto, permettendo valori piccoli ma anche occasionalmente molto grandi per \\(\\sigma\\). In pratica, evita che il modello “forzi” troppo la variabilità residua, ma previene anche valori assurdi.\n\nMessaggio didattico: questi prior sono propri e debolmente informativi: non costringono il modello a soluzioni arbitrarie, ma al tempo stesso evitano i problemi dei prior impropri (che Stan non assegna mai di default).\nIn generale, conviene:\n\ncentrare e, se possibile, standardizzare i predittori;\nscegliere prior compatibili con la scala dei dati;\nverificare le implicazioni con un prior predictive check (simulando \\(y\\) dai soli prior).\n\nCompiliamo:\n\nmod &lt;- cmdstan_model(stancode, compile = TRUE)\n\n\n28.3.2.1 Un solo predittore\nIniziamo stimando il modello con un solo predittore. Costruiamo la matrice \\(X\\) di dimensione \\(N \\times 1\\) (una sola colonna) e centriamo i dati per rendere l’intercetta più interpretabile:\n\n# Scegliamo il predittore (qui x1; per usare x2 basta sostituire \"x1\")\nx1_c &lt;- dati$x1 - mean(dati$x1)  # centratura rispetto alla media\n\n# Creiamo una matrice N×1 (attenzione: non usare as.numeric, che schiaccia la matrice)\nX &lt;- matrix(x1_c, ncol = 1)\nK &lt;- ncol(X)  # qui sarà 1\n\nPrepariamo i dati per Stan:\n\nstan_data &lt;- list(\n  N = nrow(dati),\n  K = K,   # numero di predittori: 1\n  X = X,   # matrice N×1\n  y = dati$y\n)\nglimpse(stan_data)  # controllo rapido della lista\n#&gt; List of 4\n#&gt;  $ N: int 2000\n#&gt;  $ K: int 1\n#&gt;  $ X: num [1:2000, 1] 1.387 -0.549 0.379 0.648 0.42 ...\n#&gt;  $ y: num [1:2000] 3.01 4.47 5.9 6.42 4.52 ...\n\nEseguiamo il campionamento MCMC:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 2025,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 2000\n)\n\nSintesi delle stime a posteriori:\n\nsumm &lt;- fit$summary(variables = c(\"alpha\", \"beta\", \"sigma\", \"R2\"))\nsumm\n#&gt; # A tibble: 4 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha     4.233  4.234 0.030 0.030  4.184  4.282 1.001 9428.401 6239.711\n#&gt; 2 beta[1]  -0.618 -0.619 0.030 0.029 -0.667 -0.570 1.003 8381.228 6196.084\n#&gt; 3 sigma     1.326  1.326 0.021 0.020  1.293  1.362 1.000 9120.684 5505.744\n#&gt; 4 R2        0.177  0.177 0.015 0.015  0.153  0.202 1.003 8432.253 5653.883\n\nCon un solo predittore, osserviamo lo stesso bias da variabile omessa che avevamo trovato con lm(): il coefficiente stimato per x1 è distorto perché il modello non tiene conto dell’influenza di x2.\n\n28.3.2.2 Due predittori\nOra estendiamo il modello includendo entrambi i predittori. Creiamo una matrice \\(X\\) di dimensione \\(N \\times 2\\), centrando entrambe le colonne:\n\n# Matrice con due predittori centrati\nX &lt;- cbind(dati$x1, dati$x2)\nX &lt;- scale(X, center = TRUE, scale = FALSE)\nK &lt;- ncol(X)  # ora K = 2\n\nPrepariamo i dati per Stan:\n\nstan2_data &lt;- list(\n  N = nrow(dati), \n  K = K, \n  X = X, \n  y = dati$y\n)\nglimpse(stan2_data)\n#&gt; List of 4\n#&gt;  $ N: int 2000\n#&gt;  $ K: int 2\n#&gt;  $ X: num [1:2000, 1:2] 1.387 -0.549 0.379 0.648 0.42 ...\n#&gt;   ..- attr(*, \"scaled:center\")= num [1:2] 3.36 3.38\n#&gt;  $ y: num [1:2000] 3.01 4.47 5.9 6.42 4.52 ...\n\nCampionamento:\n\nfit2 &lt;- mod$sample(\n  data = stan2_data,\n  seed = 2025, \n  chains = 4, \n  parallel_chains = 4,\n  iter_warmup = 1000, \n  iter_sampling = 2000\n)\n\nSintesi delle stime:\n\nsumm &lt;- fit2$summary(variables = c(\"alpha\", \"beta\", \"sigma\", \"R2\"))\nsumm\n#&gt; # A tibble: 5 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha     4.233  4.233 0.012 0.012  4.214  4.253 1.000 6567.012 5247.360\n#&gt; 2 beta[1]   1.016  1.017 0.019 0.019  0.986  1.047 1.001 4515.829 4602.377\n#&gt; 3 beta[2]  -2.017 -2.017 0.018 0.018 -2.047 -1.986 1.001 4308.570 4405.765\n#&gt; 4 sigma     0.515  0.515 0.008 0.008  0.502  0.528 1.000 6678.973 5652.335\n#&gt; 5 R2        0.876  0.876 0.004 0.004  0.869  0.882 1.001 6445.047 5823.024\n\nInterpretazione\n\nI posterior mean di beta[1] e beta[2] sono vicini ai valori veri della simulazione (+1 e −2), e gli intervalli di credibilità li comprendono.\nQuesto conferma che il modello multiplo riesce a recuperare gli effetti “puliti”, eliminando il bias da variabile omessa.\n\nLavorando su scala grezza, i coefficienti sono immediatamente leggibili:\n\n\nbeta[1]: +1 punto di affetto negativo → +1 punto di stress,\n\nbeta[2]: +1 ora di sonno → −2 punti di stress.\n\n28.3.3 Diagnostica\n\nfit2$cmdstan_diagnose()\n#&gt; Checking sampler transitions treedepth.\n#&gt; Treedepth satisfactory for all transitions.\n#&gt; \n#&gt; Checking sampler transitions for divergences.\n#&gt; No divergent transitions found.\n#&gt; \n#&gt; Checking E-BFMI - sampler transitions HMC potential energy.\n#&gt; E-BFMI satisfactory.\n#&gt; \n#&gt; Rank-normalized split effective sample size satisfactory for all parameters.\n#&gt; \n#&gt; Rank-normalized split R-hat values satisfactory for all parameters.\n#&gt; \n#&gt; Processing complete, no problems detected.\n\n\n28.3.4 Controllo predittivo posteriore\n\ndraws &lt;- fit2$draws()\n# Estrazione sicura dei draw per mu e y_rep\n# (uso 'variables =' e imposto l'ordine esplicito 1..N per y_rep)\nmu_draws   &lt;- posterior::as_draws_matrix(fit2$draws(variables = \"mu\"))\nyrep_draws &lt;- posterior::as_draws_matrix(\n  fit2$draws(variables = paste0(\"y_rep[\", 1:N, \"]\"))\n)\n\n# Controllo di coerenza dimensioni (opzionale ma utile)\nstopifnot(ncol(yrep_draws) == length(dati$y))\n\n# PPC: uso 100 repliche (righe = draw, colonne = osservazioni)\nns &lt;- min(100, nrow(yrep_draws))\nbayesplot::ppc_dens_overlay(dati$y, yrep_draws[1:ns, ])\n\n\n\n\n\n\n\nSe le curve replicate si sovrappongono bene alla distribuzione osservata di \\(y\\), il modello ha una buona calibrazione predittiva.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#robustezza-agli-outlier-regressione-t-di-student",
    "href": "chapters/linear_models/05_stan_regression.html#robustezza-agli-outlier-regressione-t-di-student",
    "title": "28  Regressione lineare in Stan",
    "section": "\n28.4 Robustezza agli outlier: regressione t di Student",
    "text": "28.4 Robustezza agli outlier: regressione t di Student\nLa regressione lineare classica assume che gli errori siano gaussiani, cioè distribuiti come \\(\\mathcal{N}(0,\\sigma)\\). Questa ipotesi funziona bene quando la distribuzione dei residui è “ben comportata”. Tuttavia, in psicologia capita spesso di avere osservazioni estreme (outlier) che non si adattano a questa ipotesi: pochi valori anomali possono “tirare” la retta e distorcere molto le stime.\nUn rimedio è sostituire la normale con la distribuzione t di Student, che ha code più pesanti. Questo significa che gli outlier ricevono meno peso: la stima è più robusta, perché non si lascia influenzare eccessivamente da poche osservazioni estreme.\n\n28.4.1 Il modello in Stan\nEcco la versione “robusta” della regressione multipla:\n// file: lm_multiple_t.stan\ndata {\n  int&lt;lower=1&gt; N;          // numero osservazioni\n  int&lt;lower=1&gt; K;          // numero predittori\n  matrix[N, K] X;          // matrice dei predittori\n  vector[N] y;             // variabile risposta\n}\nparameters {\n  real alpha;              // intercetta\n  vector[K] beta;          // coefficienti di regressione\n  real&lt;lower=0&gt; sigma;     // scala residui\n  real&lt;lower=2&gt; nu;        // gradi di libertà (&gt;=2 per varianza finita)\n}\nmodel {\n  // Priors\n  alpha ~ normal(0, 10);\n  beta  ~ normal(0, 5);\n  sigma ~ student_t(4, 0, 10);\n  nu    ~ exponential(0.1);   // media ≈ 10, lascia aperta la possibilità a valori piccoli\n\n  // Likelihood: regressione t (GLM)\n  target += student_t_id_glm_lpdf(y | nu, X, alpha, beta, sigma);\n}\ngenerated quantities {\n  vector[N] mu = alpha + X * beta;\n  vector[N] y_rep;\n  for (n in 1:N)\n    y_rep[n] = student_t_rng(nu, mu[n], sigma);\n\n  real R2 = variance(mu) / (variance(mu) + square(sigma));\n}\n\n28.4.2 Interpretazione dei parametri\n\n\nnu controlla lo “spessore delle code”:\n\nvalori grandi (es. \\(\\nu &gt; 30\\)) rendono la t praticamente indistinguibile da una normale,\nvalori piccoli (es. \\(\\nu \\approx 3\\)–\\(5\\)) producono code pesanti e quindi maggiore robustezza.\n\n\nsigma misura la dispersione residua, ma ora è separata dalla robustezza delle code.\n\nMessaggio didattico: con la t di Student il modello “capisce” che ci sono dati un po’ anomali e li tratta con cautela, senza lasciarsi dominare da essi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#non-linearità-errore-di-specificazione-e-ppc",
    "href": "chapters/linear_models/05_stan_regression.html#non-linearità-errore-di-specificazione-e-ppc",
    "title": "28  Regressione lineare in Stan",
    "section": "\n28.5 Non linearità (errore di specificazione) e PPC",
    "text": "28.5 Non linearità (errore di specificazione) e PPC\nUn altro caso frequente di errore di specificazione si ha quando forziamo un modello lineare su dati che in realtà hanno una curvatura (per esempio quadratica). Anche se i residui sembrano gaussiani, il modello sbaglia sistematicamente le previsioni.\n\n28.5.1 Simuliamo dati non lineari\n\nset.seed(11)\nN &lt;- 300\nx &lt;- rnorm(N)\ny_true &lt;- 1 + 2*x + 1.5*x^2         # relazione quadratica\ny &lt;- y_true + rnorm(N, 0, 1.5)\n\nX &lt;- cbind(x)                       # modello lineare \"sbagliato\"\nK &lt;- 1\n\n\n28.5.2 Fittiamo un modello lineare\n\nfit_lin &lt;- mod$sample(\n  data = list(N = N, K = K, X = scale(X, center = TRUE, scale = FALSE), y = y),\n  seed = 2025, chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 2000\n)\n\n\n28.5.3 Controllo predittivo posteriore\n\nyrep_lin &lt;- as_draws_matrix(fit_lin$draws(\"y_rep\"))\nbayesplot::ppc_scatter_avg(y = y, yrep = yrep_lin[1:200, ])\n\n\n\n\n\n\n\n\n28.5.4 Cosa osserviamo?\nIl PPC mostra un mismatch sistematico: le previsioni lineari non seguono la curvatura dei dati veri. Il modello sta sbagliando in maniera strutturale, non solo per rumore.\n\n28.5.5 Come rimediare?\n\nAggiungere un termine quadratico (\\(x^2\\)) come nuovo predittore;\nUsare polinomi di grado superiore;\nOppure usare modelli flessibili (spline, funzioni base, Gaussian process).\n\nMessaggio didattico: i PPC non servono solo a “validare” un modello, ma soprattutto a diagnosticare quando la forma funzionale è troppo rigida. In questo caso, il PPC rivela l’esigenza di un modello più flessibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#riflessioni-conclusive",
    "href": "chapters/linear_models/05_stan_regression.html#riflessioni-conclusive",
    "title": "28  Regressione lineare in Stan",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo tradotto il modello di regressione lineare nel linguaggio Stan, facendo un passo importante verso la pratica della modellazione bayesiana. Abbiamo visto come i diversi blocchi del programma permettano di dichiarare i dati, definire i parametri, specificare la struttura del modello e produrre quantità derivate utili all’analisi.\nIl passaggio a Stan non è solo tecnico. Significa collocarsi in un quadro in cui possiamo esprimere modelli molto più flessibili e realistici rispetto ai casi semplici affrontati in precedenza. La regressione lineare diventa così il punto di partenza per una modellazione che può includere predittori multipli, effetti gerarchici e specificazioni personalizzate, mantenendo intatta la logica dell’aggiornamento bayesiano.\nNaturalmente, questa maggiore potenza comporta anche nuove responsabilità. Scrivere un modello in Stan richiede di essere consapevoli delle assunzioni fatte, di controllare la qualità del campionamento e di interpretare i risultati alla luce di ciò che il modello può — e non può — dirci. In questo senso, Stan non sostituisce la comprensione statistica: la rende anzi ancora più necessaria.\nNei capitoli successivi discuteremo due aspetti cruciali che emergono quando si applica la regressione ai dati reali: l’errore di specificazione del modello e il bias da variabile omessa. Saranno esempi concreti per riflettere sui limiti intrinseci del modello lineare e sull’importanza di formulare ipotesi che siano non solo eleganti matematicamente, ma anche sostantivamente adeguate alla complessità dei fenomeni psicologici.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_stan_regression.html#bibliografia",
    "href": "chapters/linear_models/05_stan_regression.html#bibliografia",
    "title": "28  Regressione lineare in Stan",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_specification_error.html",
    "href": "chapters/linear_models/06_specification_error.html",
    "title": "29  Errore di specificazione e bias da variabile omessa",
    "section": "",
    "text": "Introduzione\nFinora abbiamo presentato la regressione lineare come uno strumento potente e flessibile per descrivere relazioni tra variabili. Abbiamo visto come stimarne i parametri, come interpretarli e come implementarli sia in R che in Stan. Ma in tutte queste applicazioni abbiamo dato per scontato un punto cruciale: che il modello fosse specificato correttamente.\nNella pratica, questa condizione è raramente soddisfatta. Può accadere che una variabile rilevante non sia stata inclusa nel modello, oppure che la forma funzionale ipotizzata non descriva adeguatamente la relazione reale. In questi casi parliamo di errore di specificazione del modello.\nUna delle conseguenze più importanti è il cosiddetto bias da variabile omessa: quando trascuriamo un predittore correlato sia con la variabile dipendente sia con altri predittori inclusi, le stime dei coefficienti risultano distorte. Questo non è un dettaglio tecnico, ma un problema sostanziale: potremmo attribuire a un predittore un effetto che in realtà appartiene a un altro, fraintendendo così i meccanismi che hanno generato i dati.\nIn questo capitolo analizzeremo cosa significa errore di specificazione, mostreremo matematicamente come nasce il bias da variabile omessa e discuteremo le sue implicazioni nella ricerca psicologica. Comprendere questi limiti è fondamentale non solo per interpretare in modo corretto i risultati della regressione, ma anche per formulare modelli più adeguati e consapevoli.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Errore di specificazione e bias da variabile omessa</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_specification_error.html#introduzione",
    "href": "chapters/linear_models/06_specification_error.html#introduzione",
    "title": "29  Errore di specificazione e bias da variabile omessa",
    "section": "",
    "text": "Panoramica del capitolo\n\nBias da variabile omessa: escludere una variabile rilevante altera sistematicamente i coefficienti.\nCondizioni del bias.\nImplicazioni: i coefficienti OLS non sono interpretabili in chiave causale; la regressione è fenomenologica.\nProspettiva: privilegiare modelli meccanicistici (es., Rescorla–Wagner, DDM, dinamici EMA).\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\nPer seguire al meglio questo capitolo è utile avere:\n\nuna conoscenza di base della regressione lineare semplice e del concetto di coefficiente di regressione.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, cmdstanr, tidybayes, loo, patchwork)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Errore di specificazione e bias da variabile omessa</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_specification_error.html#sec-ovb",
    "href": "chapters/linear_models/06_specification_error.html#sec-ovb",
    "title": "29  Errore di specificazione e bias da variabile omessa",
    "section": "\n29.1 Errore di specificazione e bias da variabile omessa",
    "text": "29.1 Errore di specificazione e bias da variabile omessa\n\n29.1.1 Idea chiave\nSe il vero modello è\n\\[\nY=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\varepsilon,\\qquad \\mathbb{E}[\\varepsilon\\mid X_1,X_2]=0,\n\\] ma stimiamo erroneamente il modello che omette \\(X_2\\),\n\\[\nY=\\alpha_0+\\alpha_1X_1+u,\n\\] allora il coefficiente su \\(X_1\\) risulta distorto quando:\n\n\n\\(X_2\\) ha effetto diretto su \\(Y\\) (\\(\\beta_2\\neq 0\\));\n\n\\(X_2\\) è correlata con \\(X_1\\) (\\(\\mathrm{Corr}(X_1,X_2)\\neq 0\\)).\n\n29.1.2 Dimostrazione (via standardizzazione)\n\n29.1.2.1 Passo 1 — Standardizza le variabili\nDefiniamo medie \\(\\mu_1,\\mu_2,\\mu_Y\\) e deviazioni standard \\(\\sigma_1,\\sigma_2,\\sigma_Y\\). Poniamo\n\\[\nZ_1=\\frac{X_1-\\mu_1}{\\sigma_1},\\qquad\nZ_2=\\frac{X_2-\\mu_2}{\\sigma_2},\\qquad\nZ_Y=\\frac{Y-\\mu_Y}{\\sigma_Y}.\n\\]\nPer costruzione:\n\n\n\\(\\mathrm{Var}(Z_1)=\\mathrm{Var}(Z_2)=1\\),\n\n\\(\\mathrm{Cov}(Z_1,Z_2)=\\rho_{12}=\\mathrm{Corr}(X_1,X_2)\\).\n\nIl modello vero standardizzato è\n\\[\nZ_Y=\\gamma_1 Z_1+\\gamma_2 Z_2+\\varepsilon_z,\\qquad \\mathbb{E}[\\varepsilon_z\\mid Z_1,Z_2]=0,\n\\] con beta standardizzati\n\\[\n\\gamma_1=\\beta_1\\,\\frac{\\sigma_1}{\\sigma_Y},\\qquad\n\\gamma_2=\\beta_2\\,\\frac{\\sigma_2}{\\sigma_Y}.\n\\]\n\n29.1.2.2 Passo 2 — Stima (erronea) che omette \\(Z_2\\)\n\nStimiamo la regressione univariata\n\\[\nZ_Y=\\delta_1 Z_1 + \\text{errore}.\n\\]\nPer OLS,\n\\[\n\\hat\\delta_1=\\frac{\\mathrm{Cov}(Z_1,Z_Y)}{\\mathrm{Var}(Z_1)}=\\mathrm{Cov}(Z_1,Z_Y),\n\\] dato che \\(\\mathrm{Var}(Z_1)=1\\).\nUsiamo il modello vero standardizzato:\n\\[\n\\begin{align}\n\\mathrm{Cov}(Z_1,Z_Y)\n&=\\mathrm{Cov}\\big(Z_1,\\gamma_1Z_1+\\gamma_2Z_2+\\varepsilon_z\\big)\\notag\\\\\n&=\\gamma_1\\underbrace{\\mathrm{Var}(Z_1)}_{=1}\n+\\gamma_2\\,\\mathrm{Cov}(Z_1,Z_2)\n+\\underbrace{\\mathrm{Cov}(Z_1,\\varepsilon_z)}_{=0}.\n\\end{align}\n\\]\nQuindi\n\\[\n\\boxed{\\;\\hat\\delta_1=\\gamma_1+\\gamma_2\\,\\rho_{12}\\;}.\n\\]\nLettura immediata: il coefficiente stimato univariato mescola l’effetto diretto standardizzato di \\(X_1\\) (\\(\\gamma_1\\)) con un termine spurio \\(\\gamma_2\\rho_{12}\\) dovuto all’omissione di \\(X_2\\).\n\n29.1.3 Ritraduzione ai coefficienti non standardizzati\nTra i coefficienti vale\n\\[\n\\hat\\delta_1=\\frac{\\sigma_1}{\\sigma_Y}\\,\\hat\\alpha_1,\\qquad\n\\gamma_1=\\beta_1\\,\\frac{\\sigma_1}{\\sigma_Y},\\qquad\n\\gamma_2=\\beta_2\\,\\frac{\\sigma_2}{\\sigma_Y}.\n\\]\nDalla formula standardizzata\n\\[\n\\hat\\delta_1=\\gamma_1+\\gamma_2\\rho_{12}\n\\] segue\n\\[\n\\frac{\\sigma_1}{\\sigma_Y}\\,\\hat\\alpha_1\n=\\beta_1\\frac{\\sigma_1}{\\sigma_Y}\n+\\beta_2\\frac{\\sigma_2}{\\sigma_Y}\\rho_{12}.\n\\]\nMoltiplicando per \\(\\sigma_Y/\\sigma_1\\) e ricordando che \\(\\rho_{12}=\\dfrac{\\mathrm{Cov}(X_1,X_2)}{\\sigma_1\\sigma_2}\\), ottieniamo la forma non standardizzata:\n\\[\n\\boxed{\\;\\hat\\alpha_1=\\beta_1+\\beta_2\\,\\frac{\\mathrm{Cov}(X_1,X_2)}{\\mathrm{Var}(X_1)}\\;}.\n\\]\nBias (in media):\n\\[\n\\boxed{\\;\\mathbb{E}[\\hat\\alpha_1]-\\beta_1\n=\\beta_2\\,\\frac{\\mathrm{Cov}(X_1,X_2)}{\\mathrm{Var}(X_1)}\\;}\n\\quad\\Longleftrightarrow\\quad\n\\boxed{\\;\\mathbb{E}[\\hat\\delta_1]-\\gamma_1=\\gamma_2\\rho_{12}\\;}.\n\\]\n\n29.1.4 Interpretazione didattica\n\n\nCondizioni per il bias: serve sia \\(\\beta_2\\neq 0\\) (l’omessa \\(X_2\\) conta davvero su \\(Y\\)) sia \\(\\rho_{12}\\neq 0\\) (l’omessa \\(X_2\\) è correlata con \\(X_1\\)). Se una condizione manca, il bias svanisce.\n\nSegno del bias (scala standardizzata): \\(\\mathrm{Bias}(\\hat\\delta_1)=\\gamma_2\\rho_{12}\\).\n\n\n\\(\\gamma_2&gt;0\\) e \\(\\rho_{12}&gt;0\\) ⇒ sovrastima;\n\n\\(\\gamma_2&gt;0\\) e \\(\\rho_{12}&lt;0\\) ⇒ sottostima.\n\n\n\n29.1.5 Perché conta in psicologia\nLa regressione multipla è un modello fenomenologico: fotografa associazioni tra variabili, non i meccanismi che le generano. In contesti psicologici, l’omissione di variabili rilevanti è spesso inevitabile: non conosciamo o non misuriamo tutti i determinanti di \\(Y\\). Ne segue che i coefficienti parziali possono essere sistematicamente distorti e, dunque, fuorvianti.\n\n29.1.6 Oltre la regressione: modelli formali dei processi\nPer queste ragioni, i modelli di regressione multipla dovrebbero avere un ruolo limitato in psicologia. Molto più promettente è l’uso di modelli formali che cercano di rappresentare i meccanismi psicologici sottostanti. Esempi discussi in questa dispensa sono:\n\nil modello di apprendimento di Rescorla–Wagner, che spiega come gli individui aggiornano le loro aspettative sulla base del feedback;\n\nil Drift Diffusion Model (DDM), che descrive i processi decisionali come un accumulo di evidenza nel tempo;\n\ni modelli dinamici per dati EMA, che mostrano come l’umore e altre variabili psicologiche cambiano nel tempo.\n\nQuesti modelli non si limitano a descrivere correlazioni, ma cercano di catturare i processi causali che generano i dati osservati.\n\n\n\n\n\n\nMappa del bias: variazione di \\(\\rho_{12}\\) e \\(\\beta_2\\)\n\n\n\n\n\nEsaminiamo come segno e magnitudo del bias cambino al variare della correlazione tra regressori (\\(\\rho_{12}\\)) e dell’effetto dell’omessa (\\(\\beta_2\\)). La heatmap visualizza \\(\\hat\\alpha_1-\\beta_1\\).\n\nset.seed(1)\nn &lt;- 3000; beta1 &lt;- 1; sig &lt;- 1\nrho_seq &lt;- seq(-.9,.9,length=19); b2_seq &lt;- seq(-1.5,1.5,length=19)\n\ngrid &lt;- expand.grid(rho=rho_seq, b2=b2_seq)\n\nsim_once &lt;- function(rho, beta2){\n  X1 &lt;- rnorm(n)\n  X2 &lt;- rho*X1 + sqrt(1-rho^2)*rnorm(n)   # Corr(X1,X2)=rho\n  Y  &lt;- beta1*X1 + beta2*X2 + rnorm(n,0,sig)\n  coef(lm(Y ~ X1))[2] - beta1             # ritorna uno scalare, senza nome\n}\n\ngrid$bias &lt;- mapply(sim_once, grid$rho, grid$b2)  # &lt;-- niente t(), niente [, \"bias\"]\n\nggplot(grid, aes(x=rho, y=b2, fill=bias)) +\n  geom_tile() + scale_fill_gradient2() +\n  labs(x=expression(rho[12]), y=expression(beta[2]), fill=\"Bias\",\n       title=\"Bias da variabile omessa al variare di ρ12 e β2\")\n\n\n\n\n\n\n\nCommento e interpretazione. L’asse orizzontale riporta la correlazione tra i regressori \\(\\rho_{12}=\\mathrm{Corr}(X_1,X_2)\\); l’asse verticale l’effetto dell’omessa \\(X_2\\) su \\(Y\\) (\\(\\beta_2\\)). Il riempimento (“Bias”) è \\(\\hat\\alpha_1-\\beta_1\\), cioè di quanto il coefficiente sul regressore incluso \\(X_1\\) sovrastima (valori &gt; 0) o sottostima (valori &lt; 0) il suo valore vero.\n\n\nSegno del bias. Il bias è (in media) \\(\\beta_2\\,\\rho_{12}\\). Quadranti:\n\n\n\\(\\beta_2&gt;0,\\ \\rho_{12}&gt;0\\) → positivo (sovrastima);\n\n\\(\\beta_2&gt;0,\\ \\rho_{12}&lt;0\\) → negativo (sottostima);\n\n\\(\\beta_2&lt;0,\\ \\rho_{12}&gt;0\\) → negativo;\n\n\\(\\beta_2&lt;0,\\ \\rho_{12}&lt;0\\) → positivo.\n\nLe bande di colore cambiano segno attraversando le linee \\(\\rho_{12}=0\\) o \\(\\beta_2=0\\), dove il bias si annulla (zona chiara).\n\nMagnitudo. Aumenta con \\(|\\beta_2|\\) e \\(|\\rho_{12}|\\): gli angoli (|ρ|≈0.9, |β₂|≈1.5) mostrano i bias maggiori. La diagonale basso-sinistra → alto-destra evidenzia bias positivo; l’altra diagonale bias negativo.\nSimmetria e teoria. La mappa è sostanzialmente simmetrica perché il bias teorico è \\(\\beta_2\\rho_{12}\\). Le piccole irregolarità dipendono dal rumore Monte Carlo della simulazione (con \\(n\\) finito).\nLettura pratica. Se anche solo una tra correlazione tra regressori (\\(\\rho_{12}\\)) o effetto dell’omessa (\\(\\beta_2\\)) è prossima a zero, il bias è trascurabile (aree chiare lungo gli assi). Quando entrambi sono lontani da zero, l’OLS nel modello omesso è fuorviante.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Errore di specificazione e bias da variabile omessa</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_specification_error.html#riflessioni-conclusive",
    "href": "chapters/linear_models/06_specification_error.html#riflessioni-conclusive",
    "title": "29  Errore di specificazione e bias da variabile omessa",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come la validità delle stime di regressione dipenda in modo cruciale dalla corretta specificazione del modello. Abbiamo discusso in particolare il bias da variabile omessa, mostrando che trascurare un predittore rilevante può distorcere i coefficienti degli altri, inducendo interpretazioni fuorvianti.\nQuesto non è un problema marginale: nella ricerca psicologica capita spesso di lavorare con costrutti complessi, difficili da misurare, e di non poter includere tutte le variabili rilevanti. In queste condizioni, le stime di regressione rischiano di riflettere relazioni spurie piuttosto che effetti reali. Essere consapevoli di questi limiti è quindi essenziale per interpretare i risultati con cautela e per progettare studi che riducano al minimo il rischio di specificare modelli inadeguati.\nLa lezione più importante è che la regressione, come ogni modello fenomenologico, non deve essere scambiata per una spiegazione causale: è un modo per descrivere associazioni nei dati, che può però facilmente indurre in errore se non viene accompagnato da una riflessione critica sulla struttura del modello.\nNel prossimi capitolo vedremo come l’ANOVA a una via possa essere interpretata come un caso particolare del modello lineare. Sarà l’occasione per consolidare ulteriormente la visione unificata che guida questa sezione: regressione e confronto tra gruppi non sono strumenti separati, ma facce diverse dello stesso impianto metodologico.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        rmarkdown_2.29        ps_1.9.1             \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           mvtnorm_1.3-3        \n#&gt; [64] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [67] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Errore di specificazione e bias da variabile omessa</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_specification_error.html#bibliografia",
    "href": "chapters/linear_models/06_specification_error.html#bibliografia",
    "title": "29  Errore di specificazione e bias da variabile omessa",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Errore di specificazione e bias da variabile omessa</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html",
    "href": "chapters/linear_models/07_one_mean.html",
    "title": "30  Inferenza bayesiana su una media",
    "section": "",
    "text": "Introduzione\nIn questo capitolo affrontiamo uno dei problemi più elementari — e al tempo stesso fondamentali — della statistica: stimare la media di una popolazione a partire da un campione di osservazioni. È una situazione ricorrente nella ricerca psicologica: possiamo chiederci qual è l’altezza media in un gruppo di adolescenti, il livello medio di ansia in un campione clinico, oppure la soddisfazione media di studenti che hanno seguito un determinato corso.\nTradizionalmente, questo problema è stato affrontato nell’ottica frequentista, che porta a costruire intervalli di confidenza o a testare ipotesi sulla media. In questa prospettiva, la media della popolazione è un valore fisso ma sconosciuto, e il ragionamento si concentra sul comportamento dei campioni che avremmo potuto osservare “se ripetessimo l’esperimento molte volte”.\nL’approccio bayesiano rovescia la prospettiva: la media non è un’entità misteriosa e fissa, ma una quantità sulla quale formuliamo delle credenze incerte, che possiamo aggiornare alla luce dei dati raccolti. Non stimiamo quindi “la media” in senso assoluto, ma descriviamo la distribuzione delle nostre convinzioni plausibili su di essa.\nQuesto cambiamento concettuale ha conseguenze profonde. Significa che l’analisi non si riduce a un verdetto dicotomico, ma diventa una rappresentazione sfumata dell’incertezza. Significa anche che possiamo integrare conoscenze pregresse tramite distribuzioni a priori, e che ogni inferenza riguarda direttamente i valori del parametro, non campioni ipotetici mai osservati.\nIn questo capitolo vedremo come costruire e interpretare una distribuzione a posteriori per la media di una popolazione, utilizzando esempi psicologici concreti. Sarà il primo passo per estendere il ragionamento bayesiano a situazioni più articolate, come il confronto tra due gruppi o la valutazione della grandezza di un effetto.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#introduzione",
    "href": "chapters/linear_models/07_one_mean.html#introduzione",
    "title": "30  Inferenza bayesiana su una media",
    "section": "",
    "text": "Panoramica del capitolo\n\nCome fare inferenza sulla media di un campione.\nCome trovare le distribuzioni a posteriori usando brms.\nVerificare il modello usando i pp-check plots.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Geocentric models di Statistical rethinking (McElreath, 2020).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, ggdist)\n\nconflicts_prefer(stats::sd)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#la-variabilità-come-punto-di-partenza",
    "href": "chapters/linear_models/07_one_mean.html#la-variabilità-come-punto-di-partenza",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.1 La variabilità come punto di partenza",
    "text": "30.1 La variabilità come punto di partenza\nOgni volta che raccogliamo dati psicologici, ci confrontiamo inevitabilmente con la variabilità. Alcune differenze sono tra individui:\nVariabilità inter-individuale: ad esempio, quanto differiscono tra loro le altezze, i tempi di reazione o i livelli di benessere soggettivo?\nAltre differenze sono all’interno dello stesso individuo, anche se meno visibili in un singolo rilevamento:\nVariabilità intra-individuale: quanto potrebbe variare la risposta della stessa persona se la misurassimo in momenti diversi della giornata, o in giorni diversi? Anche quando non la osserviamo direttamente, la variabilità intra-individuale è sempre una componente latente del dato psicologico, e ci invita a riflettere sulle fonti di instabilità e fluttuazione nei comportamenti e negli stati mentali.\n\n30.1.1 L’incertezza come oggetto dell’inferenza\nA partire da questa variabilità, vogliamo formulare inferenze sul valore medio di un certo parametro (come l’altezza media in una popolazione). Ma ogni inferenza è anche un atto di stima incerta: nessun campione ci dà la verità, ma solo una gamma di possibilità più o meno plausibili.\nIn questo capitolo affronteremo quindi il problema dell’inferenza sulla media da due prospettive complementari:\n\n\nApproccio frequentista: basato sull’idea di ripetizione del campionamento e sul calcolo di un intervallo di confidenza;\n\nApproccio bayesiano: che assume esplicitamente l’incertezza e la rappresenta attraverso una distribuzione di probabilità (la distribuzione a posteriori).\n\n30.1.2 Perché usare brms?\nInvece di derivare la distribuzione a posteriori della media in modo analitico (come nei modelli con prior coniugati), useremo il pacchetto brms, che si basa su un potente algoritmo di campionamento chiamato NUTS (No-U-Turn Sampler). Questo ci permetterà di stimare numericamente l’intera distribuzione a posteriori della media e della variabilità, anche in casi in cui il calcolo analitico sarebbe difficile o impossibile. In questo modo, potremo:\n\nquantificare l’incertezza su ciò che ci interessa (ad esempio: qual è l’altezza media? con quanta certezza lo possiamo dire?);\nvisualizzare in modo intuitivo l’effetto dei dati e dei priori sulle nostre stime;\navvicinarci a un modo di pensare statistico più adatto alla complessità della psicologia, dove ogni dato è il risultato di molte fonti di variabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#il-modello-normale-un-primo-passo-nella-descrizione-della-variabilità",
    "href": "chapters/linear_models/07_one_mean.html#il-modello-normale-un-primo-passo-nella-descrizione-della-variabilità",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.2 Il modello Normale: un primo passo nella descrizione della variabilità",
    "text": "30.2 Il modello Normale: un primo passo nella descrizione della variabilità\nQuando parliamo di altezza, ansia, tempo di reazione o qualsiasi altra variabile psicologica continua, un punto di partenza comune è il modello Normale. Questo modello assume che le osservazioni siano distribuite attorno a un valore medio, con una certa dispersione. In termini formali, diciamo che ogni osservazione \\(y_n\\) è generata da una distribuzione Normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\):\n\\[\ny_n \\;\\sim\\; \\mathcal N\\bigl(\\mu, \\sigma\\bigr).\n\\]\nNel linguaggio dell’inferenza, \\(\\mu\\) rappresenta il valore centrale che vogliamo stimare, mentre \\(\\sigma\\) quantifica la variabilità delle osservazioni rispetto a quel centro. Entrambi i parametri sono ignoti, e l’obiettivo dell’inferenza è proprio descrivere l’incertezza che abbiamo su di essi.\nNel capitolo precedente abbiamo visto come calcolare la distribuzione a posteriori di questi parametri in modo analitico, quando si utilizzano prior coniugati. In questo capitolo, invece, riprendiamo lo stesso problema, ma adottiamo un approccio più generale e flessibile: stimiamo il modello usando il pacchetto brms, che utilizza metodi MCMC per approssimare la distribuzione a posteriori, anche quando non esistono soluzioni chiuse.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#un-esempio-concreto-la-variabilità-dellaltezza-nei-kung-san",
    "href": "chapters/linear_models/07_one_mean.html#un-esempio-concreto-la-variabilità-dellaltezza-nei-kung-san",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.3 Un esempio concreto: la variabilità dell’altezza nei !Kung San",
    "text": "30.3 Un esempio concreto: la variabilità dell’altezza nei !Kung San\nPer rendere più concreto il problema, useremo un dataset storico: i dati raccolti da Nancy Howell tra la fine degli anni ’60 presso i !Kung San, una popolazione del deserto del Kalahari con uno stile di vita basato su caccia e raccolta.\nI dati che utilizzeremo riportano le altezze di individui adulti (con età superiore ai 18 anni). Questo esempio è tratto da McElreath (2020), ed è ideale per iniziare a riflettere sulla variabilità inter-individuale.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\ndf |&gt; head()\n#&gt;   height weight age male\n#&gt; 1    152   47.8  63    1\n#&gt; 2    140   36.5  63    0\n#&gt; 3    137   31.9  65    0\n#&gt; 4    157   53.0  41    1\n#&gt; 5    145   41.3  51    0\n#&gt; 6    164   63.0  35    1\n\nIl campione è composto da 352 osservazioni:\n\nlength(df$height)\n#&gt; [1] 352\n\n\n30.3.1 Distribuzione osservata dell’altezza\nUna prima esplorazione visiva ci aiuta a capire la forma della distribuzione osservata. L’istogramma seguente mostra come si distribuiscono le altezze nel campione:\n\nggplot(df, aes(x = height)) +\n  geom_histogram(binwidth = 5) +\n  labs(x = \"Altezza\", y = \"Frequenza\") \n\n\n\n\n\n\n\nLa forma appare compatibile con una distribuzione Normale. Ma quanto bene si adatta?\n\ndf |&gt;\n  ggplot(aes(sample = height)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  labs(x = \"Quantili teorici\", y = \"Valori osservati\") \n\n\n\n\n\n\n\nIl Q-Q plot mostra un leggero scostamento: la curva empirica è un po’ più piatta rispetto alla linea teorica, segno che la variabilità osservata è leggermente inferiore a quella attesa da una Normale standard (code meno pesanti). Tuttavia, la discrepanza è modesta, e possiamo comunque usare il modello gaussiano come prima approssimazione della distribuzione dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#specifica-del-modello-una-distribuzione-per-descrivere-lincertezza",
    "href": "chapters/linear_models/07_one_mean.html#specifica-del-modello-una-distribuzione-per-descrivere-lincertezza",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.4 Specifica del modello: una distribuzione per descrivere l’incertezza",
    "text": "30.4 Specifica del modello: una distribuzione per descrivere l’incertezza\nNel modello bayesiano, ipotizziamo che ogni osservazione \\(y_n\\) sia indipendente e identicamente distribuita (iid):\n\\[\ny_n \\sim \\mathcal N(\\mu, \\sigma),\n\\]\n\n\n\\(\\mu\\): la media vera (ignota) della popolazione.\n\n\\(\\sigma\\): la deviazione standard vera, che misura quanta variabilità c’è tra gli individui.\n\n\nL’assunzione di indipendenza implica che conoscere l’errore commesso su un individuo non ci dice nulla sull’errore commesso su un altro. L’assunzione di identica distribuzione implica che tutti gli individui provengano dalla stessa popolazione.\n\nScrivere \\(y_n \\sim \\mathcal N(\\mu, \\sigma)\\) è quindi un modo compatto per dire che ogni osservazione è un’espressione della variabilità inter-individuale, distribuita attorno a un valore centrale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#stime-preliminari-una-fotografia-della-variabilità",
    "href": "chapters/linear_models/07_one_mean.html#stime-preliminari-una-fotografia-della-variabilità",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.5 Stime preliminari: una fotografia della variabilità",
    "text": "30.5 Stime preliminari: una fotografia della variabilità\nPrima di definire i priori o stimare la distribuzione a posteriori, è utile esplorare alcune statistiche descrittive:\n\nmean(df$height)   # media campionaria\n#&gt; [1] 155\nsd(df$height)     # deviazione standard campionaria\n#&gt; [1] 7.74\n\nQueste due quantità ci offrono una prima “fotografia” della variabilità nel campione:\n\nLa media campionaria è una stima iniziale di \\(\\mu\\), che potrà guidarci nella scelta di una prior realistica.\nLa deviazione standard campionaria è una misura iniziale di \\(\\sigma\\), e descrive quanto le osservazioni si discostano, in media, dalla media.\n\nAnche se queste statistiche non riflettono ancora in modo completo l’incertezza che abbiamo, sono molto utili per:\n\n\nGuidare la scelta dei priors in un’ottica informata;\n\nIndividuare possibili outlier o anomalie, che potrebbero influenzare sia l’inferenza frequentista sia quella bayesiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#il-modello-frequentista-stimare-la-media-come-punto-fisso",
    "href": "chapters/linear_models/07_one_mean.html#il-modello-frequentista-stimare-la-media-come-punto-fisso",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.6 Il modello frequentista: stimare la media come punto fisso",
    "text": "30.6 Il modello frequentista: stimare la media come punto fisso\nNel contesto dell’inferenza classica, uno dei modi più semplici per stimare la media di una popolazione consiste nell’adottare un modello lineare senza predittori: un modello che si limita a stimare un’unica quantità, chiamata intercetta. In pratica, questo corrisponde a stimare la media campionaria dei dati osservati.\nIn R, questo modello si specifica in modo molto compatto:\nheight ~ 1\nIl simbolo 1 indica che vogliamo stimare solo l’intercetta, senza nessuna variabile esplicativa. In termini pratici, l’intercetta rappresenta qui la media dell’altezza nel campione.\n\n30.6.1 Specifica e stima del modello\nPossiamo stimare il modello con la funzione lm():\n\nfm1 &lt;- lm(\n  formula = height ~ 1, \n  data = df\n)\n\nQuesto comando applica il metodo della minima somma dei quadrati, producendo una stima puntuale della media, assieme a una misura della sua variabilità.\n\n30.6.2 Interpretare i risultati\nL’output del modello si ottiene con:\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -18.072  -6.007  -0.292   6.058  24.473 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.413     375   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 7.74 on 351 degrees of freedom\n\nIl riassunto mostra diverse informazioni, ma le più rilevanti in questo contesto sono:\n\n\nLa stima dell’intercetta \\(\\hat{\\alpha}\\): coincide con la media campionaria delle altezze.\n\nL’errore standard: misura la variabilità attesa della stima \\(\\hat{\\alpha}\\) se ripetessimo il campionamento molte volte.\n\nIl p-value: quantifica la probabilità di osservare un valore della statistica test così estremo (o più) se la media vera fosse 0. In questo caso ha scarso interesse pratico, perché il valore di riferimento (0 cm) non è plausibile.\n\nIl R²: che in assenza di predittori non è interpretabile in modo utile.\n\n30.6.3 Intervallo di confidenza al 95%: una misura indiretta dell’incertezza\nIl modello frequentista non descrive la nostra incertezza come una distribuzione su \\(\\mu\\), ma fornisce invece un intervallo di confidenza, che ha un’interpretazione indiretta: se ripetessimo l’esperimento un numero molto elevato di volte, in circa il 95% dei casi l’intervallo conterrebbe il vero valore della media.\nPossiamo calcolarlo con:\n\nconfint(fm1, level = 0.95)\n#&gt;             2.5 % 97.5 %\n#&gt; (Intercept)   154    155\n\nQuesto intervallo si basa sulla formula classica:\n\\[\n\\hat{\\alpha} \\pm t_{\\text{df}} \\cdot \\text{SE}(\\hat{\\alpha})\n\\]\ndove:\n\n\n\\(\\hat{\\alpha}\\) è la stima puntuale della media,\n\n\\(t_{\\text{df}}\\) è il quantile della distribuzione t di Student (con \\(n - 1\\) gradi di libertà),\n\n\\(\\text{SE}(\\hat{\\alpha})\\) è l’errore standard della stima.\n\n30.6.4 Calcolo manuale (opzionale)\nSe vogliamo calcolare l’intervallo “a mano”, possiamo scrivere:\n\ncoef(fm1) + c(-1, 1) * qt(0.975, df.residual(fm1)) * 0.413\n#&gt; [1] 154 155\n\n\n\ncoef(fm1) restituisce la stima dell’intercetta,\n\nqt(0.975, df.residual(fm1)) fornisce il valore critico t,\n\n0.413 è l’errore standard (da sostituire con quello esatto, se disponibile).\n\n30.6.5 Riflessione: cos’è l’incertezza, per davvero?\nNel modello frequentista, l’incertezza sulla media è descritta in termini di variabilità potenziale tra campioni, non come incertezza su un valore specifico. Il parametro \\(\\mu\\) è trattato come fisso ma ignoto, e tutta l’incertezza risiede nella stima che otteniamo da un singolo campione.\nIn questo senso, l’approccio frequentista non fornisce una distribuzione sul parametro: non possiamo dire “la probabilità che la media sia tra 153 e 155 cm è del 95%”, ma solo che “se ripetessimo l’esperimento molte volte, l’intervallo conterrebbe la media vera nel 95% dei casi”.\nNel prossimo paragrafo vedremo come un modello bayesiano offra un’alternativa: trattare \\(\\mu\\) come una variabile aleatoria su cui esprimere direttamente l’incertezza, permettendoci di formulare affermazioni probabilistiche esplicite sui valori possibili del parametro.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#il-modello-bayesiano-descrivere-lincertezza-con-distribuzioni",
    "href": "chapters/linear_models/07_one_mean.html#il-modello-bayesiano-descrivere-lincertezza-con-distribuzioni",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.7 Il modello Bayesiano: descrivere l’incertezza con distribuzioni",
    "text": "30.7 Il modello Bayesiano: descrivere l’incertezza con distribuzioni\nDopo aver stimato la media dell’altezza con il modello frequentista, possiamo affrontare lo stesso problema con un approccio bayesiano, usando il pacchetto brms. Questo ci consente di rappresentare in modo più diretto l’incertezza che abbiamo sui parametri del modello.\nNel framework bayesiano, tutti i parametri sono trattati come variabili aleatorie: invece di stimare un singolo valore per la media, stimiamo una distribuzione a posteriori, che riflette l’incertezza residua dopo aver osservato i dati.\n\n30.7.1 Priori debolmente informativi: quando “non sappiamo molto”\nOgni modello bayesiano richiede la specifica di distribuzioni a priori. Tuttavia, quando non abbiamo conoscenze forti da inserire, possiamo affidarci ai priori debolmente informativi: distribuzioni ampie, generiche e poco vincolanti, che permettono ai dati di “parlare da soli”.\nSe non specifichiamo nulla, brms userà questi prior di default. È un buon punto di partenza, soprattutto per modelli semplici e dataset abbastanza ricchi.\n\n30.7.2 Specifica del modello in brms\n\nIl codice è simile a quello usato con lm():\n\nfm2 &lt;- brm(\n  formula = height ~ 1,       # stima solo l'intercetta (media dell’altezza)\n  family = gaussian(),        # assunzione di distribuzione normale\n  data = df,                  # dataset\n  chains = 4,                 # numero di catene MCMC\n  iter = 2000,                # iterazioni per catena\n  warmup = 1000,              # periodo di adattamento\n  backend = \"cmdstanr\"        # motore di calcolo efficiente\n)\n\nQui stiamo stimando due parametri:\n\n\n\\(\\mu\\) → media dell’altezza nella popolazione;\n\n\\(\\sigma\\) → deviazione standard, che rappresenta quanta variabilità inter-individuale osserviamo.\n\nIn termini formali, il modello è scritto come:\n\\[\ny_i = \\alpha + \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma).\n\\]\n\n30.7.3 Interpretare l’output: incertezza esplicitata\nUna volta che il modello è stato stimato, possiamo esaminarne l’output:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.40   153.79   155.38 1.00     3342     2620\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.76      0.29     7.23     8.35 1.00     3158     2486\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nNel risultato troveremo:\n\n\nMedia della distribuzione a posteriori per \\(\\alpha\\), che è la stima centrale di \\(\\mu\\);\n\nErrore standard a posteriori, cioè quanto fluttua \\(\\mu\\) nei campioni simulati;\n\nIntervallo di credibilità al 95%: l’intervallo in cui cade il 95% della distribuzione a posteriori di \\(\\mu\\).\n\nA differenza dell’intervallo di confidenza frequentista, qui possiamo davvero dire:\n\nC’è il 95% di probabilità che la media dell’altezza si trovi in questo intervallo, dati il modello e i dati osservati.\n\n\n30.7.4 Riportare i risultati: due linguaggi per lo stesso fenomeno\n\n\n\n\n\n\nApproccio\nRisultato\n\n\n\nFrequentista\n“La media stimata è 154.6, con un intervallo di confidenza al 95% tra 153.8 e 155.4.”\n\n\nBayesiano\n“La media stimata a posteriori è 154.6, con un intervallo di credibilità al 95% tra 153.8 e 155.4.”\n\n\n\nNumericamente possono coincidere, ma la logica inferenziale è diversa: nel caso bayesiano, l’intervallo descrive ciò che crediamo plausibile; nel frequentista, ciò che la procedura catturerebbe nella maggior parte dei campioni ripetuti.\n\n30.7.5 Esplorare i campioni a posteriori: guardare l’incertezza in faccia\nDopo aver stimato il modello, possiamo accedere direttamente ai campioni generati dall’algoritmo NUTS:\n\nas_draws_df(fm2) %&gt;% head(3)\n#&gt; # A draws_df: 3 iterations, 1 chains, and 5 variables\n#&gt;   b_Intercept sigma Intercept lprior  lp__\n#&gt; 1         155   7.6       155   -6.1 -1224\n#&gt; 2         155   7.6       155   -6.1 -1224\n#&gt; 3         155   7.6       155   -6.1 -1224\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\nOgni riga della colonna b_Intercept rappresenta un valore plausibile per \\(\\mu\\), estratto dalla sua distribuzione a posteriori. Questi campioni sono il cuore dell’inferenza bayesiana: ci permettono di costruire grafici, intervalli e ragionamenti probabilistici.\n\n30.7.6 Calcoli riassuntivi sui campioni\nPossiamo usare i campioni per calcolare:\n\n# Media a posteriori\nmean(as_draws_df(fm2)$b_Intercept)\n#&gt; [1] 155\n\n# Deviazione standard a posteriori\nsd(as_draws_df(fm2)$b_Intercept)\n#&gt; [1] 0.4\n\n# Intervallo di credibilità al 95%\nquantile(as_draws_df(fm2)$b_Intercept, probs = c(0.025, 0.975))\n#&gt;  2.5% 97.5% \n#&gt;   154   155\n\n\nQuesti valori sintetizzano l’incertezza associata alla nostra stima della media: non un singolo punto, ma una nuvola di possibilità, tutte compatibili con i dati osservati.\n\n\n30.7.7 Conclusioni intermedie\nAbbiamo visto come:\n\nL’approccio frequentista fornisca una stima puntuale e un intervallo ipotetico di copertura.\nL’approccio bayesiano fornisca una distribuzione completa a posteriori, da cui possiamo derivare medie, intervalli, probabilità e visualizzazioni.\n\nEntrambi gli approcci descrivono la variabilità tra individui, ma il metodo bayesiano offre strumenti più trasparenti per rappresentare l’incertezza sui parametri.\n\nQuesto è particolarmente utile in psicologia, dove campioni ridotti, contesti variabili e differenze individuali richiedono modelli che sappiano dire “quanto (non) sappiamo”.\n\nNel prossimo paragrafo vedremo come possiamo personalizzare i priori, incorporando informazioni pregresse (da studi precedenti, teoria, esperienza clinica…), e come questo possa influenzare l’inferenza nei casi in cui i dati da soli non siano sufficientemente informativi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#uso-dei-prior-nel-modello-bayesiano-rendere-esplicite-le-ipotesi-sullincertezza",
    "href": "chapters/linear_models/07_one_mean.html#uso-dei-prior-nel-modello-bayesiano-rendere-esplicite-le-ipotesi-sullincertezza",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.8 Uso dei Prior nel Modello Bayesiano: rendere esplicite le ipotesi sull’incertezza",
    "text": "30.8 Uso dei Prior nel Modello Bayesiano: rendere esplicite le ipotesi sull’incertezza\nFinora abbiamo visto che è possibile stimare un modello bayesiano anche senza specificare esplicitamente i prior: in tal caso, brms utilizza prior debolmente informativi, lasciando che siano i dati a guidare l’inferenza.\nMa il cuore dell’approccio bayesiano sta proprio qui: nella possibilità di incorporare conoscenze precedenti, aspettative, risultati di studi precedenti — insomma, di modellare in modo esplicito e trasparente l’incertezza che abbiamo prima di vedere i dati.\n\n30.8.1 Tre domande chiave prima di stimare\nPrima di usare un modello bayesiano, è utile porsi alcune domande fondamentali:\n\nCosa sappiamo già del fenomeno?\nCome possiamo esprimere questa conoscenza sotto forma di distribuzioni?\nQuanto vogliamo che questa conoscenza influenzi l’inferenza?\n\nLa risposta a queste domande guida la scelta dei prior. Nei passaggi che seguono, vedremo come un modello informato da prior realistici possa non solo migliorare la stima, ma anche aumentare la coerenza tra teoria e dati.\n\n30.8.2 Specificare i prior: un esempio concreto\nRiprendiamo il nostro esempio sull’altezza nella popolazione dei !Kung San. Supponiamo di avere un’idea ragionevole su quanto potrebbe essere la media e la variabilità delle altezze.\nPossiamo tradurre questa conoscenza nel linguaggio delle distribuzioni:\n\nPer \\(\\mu\\) (la media), ipotizziamo: \\(\\mu \\sim \\mathcal{N}(181, 30)\\) — una media attesa intorno a 181 cm, con ampio margine di incertezza.\nPer \\(\\sigma\\) (la deviazione standard), ipotizziamo: \\(\\sigma \\sim \\mathcal{N}^+(0, 20)\\) — una normale troncata a destra, che garantisce valori positivi.\n\nQuesti prior sono informativi ma ampi: riflettono aspettative plausibili, senza imporre vincoli troppo rigidi.\n\nMcElreath scherza dicendo di usare come prior la propria altezza. L’ironia nasconde un principio importante: ogni ipotesi è valida, purché dichiarata. Un buon modello bayesiano non finge oggettività, ma esplicita l’incertezza iniziale.\n\n\n30.8.3 Forma del modello con prior espliciti\nIl modello completo si scrive così:\n\\[\n\\begin{aligned}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\\\\\\\\n\\mu &\\sim \\mathcal{N}(181,\\ 30) \\\\\\\\\n\\sigma &\\sim \\mathcal{N}^+(0,\\ 20)\n\\end{aligned}\n\\]\nQui, sia la media sia la variabilità della popolazione sono trattate come quantità soggette a incertezza. La stima diventa un aggiornamento: partiamo da un’opinione iniziale e la modifichiamo alla luce dei dati.\n\n30.8.4 Implementazione in brms\n\n\nfm3 &lt;- brm(\n  formula = height ~ 1,\n  data    = df,\n  family  = gaussian(),\n  prior   = c(\n    prior(normal(181, 30), class = \"Intercept\"),\n    prior(normal(0, 20), class = \"sigma\")\n  ),\n  chains  = 4, iter = 2000,\n  seed    = 1234,\n  backend = \"cmdstanr\"\n)\n\n\n30.8.5 Analisi dell’output\nUna volta stimato il modello, possiamo esaminarlo come sempre con:\n\nsummary(fm3)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.80   155.41 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.20     8.38 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSe i dati sono informativi (come in questo caso), l’effetto dei prior sarà contenuto: la distribuzione a posteriori sarà molto simile a quella ottenuta con prior deboli. Questo è un comportamento desiderabile: il prior non deve forzare i risultati, ma integrarsi con essi.\n\n30.8.6 Scegliere il livello dell’intervallo di credibilità\nPossiamo modificare la probabilità coperta dall’intervallo credibile, ad esempio scegliendo un intervallo all’89% anziché al 95%:\n\nsummary(fm3, prob = 0.89)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.94   155.27 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.32     8.25 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nQuesta scelta è proposta da McElreath come default per motivi pedagogici: evitare che l’intervallo venga interpretato come test di significatività.\n\n“Why 89%? Because it’s prime.” — è un invito a pensare criticamente alle convenzioni statistiche, e a riflettere su cosa stiamo cercando davvero di comunicare quando riportiamo un intervallo.\n\n\n30.8.7 Cosa otteniamo con prior espliciti?\nUsare prior informativi consente di:\n\nIncorporare conoscenze teoriche, esperienze passate, dati precedenti.\nRendere il modello più robusto quando i dati sono scarsi o rumorosi.\nEvitare stime irrealistiche in contesti con alta incertezza.\nEsplicitare le nostre ipotesi, invece di nasconderle dietro un’apparente neutralità.\n\n30.8.8 Conclusione\nIn un modello bayesiano, ogni assunzione è chiara e trattabile. I risultati non sono semplici numeri, ma distribuzioni di credibilità che raccontano ciò che è plausibile, dato ciò che sapevamo prima e ciò che abbiamo osservato ora.\n\nQuesto rende l’approccio bayesiano particolarmente adatto alla psicologia: un campo dove l’incertezza è la norma, la variabilità è parte del fenomeno da spiegare, e la trasparenza delle assunzioni è fondamentale.\n\nNel prossimo paragrafo, ci concentreremo su come visualizzare e valutare queste distribuzioni a posteriori, usando strumenti diagnostici e grafici che ci aiutano a comprendere — e comunicare — la variabilità residua stimata dal modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#visualizzare-lincertezza-con-bayesplot",
    "href": "chapters/linear_models/07_one_mean.html#visualizzare-lincertezza-con-bayesplot",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.9 Visualizzare l’incertezza con bayesplot\n",
    "text": "30.9 Visualizzare l’incertezza con bayesplot\n\nIl pacchetto bayesplot è uno strumento prezioso per ogni analisi bayesiana: permette di esplorare visivamente la variabilità delle stime a posteriori, di diagnosticare l’efficienza del campionamento MCMC e di verificare se il modello riesce a riprodurre i dati osservati.\nIn un contesto psicologico, dove spesso i dati sono rumorosi e le inferenze complesse, poter visualizzare dove e quanto il modello è incerto è fondamentale.\n\n30.9.1 Traceplot: osservare le catene in azione\nIl traceplot mostra l’evoluzione dei campioni per ogni parametro nel corso delle iterazioni MCMC. Serve a controllare:\n\nche le catene siano stazionarie (nessuna deriva sistematica),\nche si mescolino bene (assenza di autocorrelazione),\nche ci sia convergenza (tutte le catene esplorano la stessa distribuzione).\n\n\nmcmc_trace(fm3, pars = c(\"Intercept\", \"sigma\"), facet_args = list(nrow = 2))\n\n\n\n\n\n\n\nUn buon traceplot mostra bande dense, senza tendenze crescenti o oscillazioni lente: questo suggerisce che il campionamento stia catturando in modo affidabile la distribuzione a posteriori.\n\n30.9.2 Densità a posteriori: cosa crediamo dopo aver visto i dati\nPer visualizzare la distribuzione di probabilità di un parametro stimato, possiamo usare:\n\nmcmc_areas(fm3, regex_pars = \"b_Intercept\", prob = 0.89)\n\n\n\n\n\n\n\nQuesta funzione evidenzia l’intervallo credibile in cui cade, ad esempio, l’89% della densità a posteriori per la media dell’altezza.\n\nA differenza dell’intervallo di confidenza, qui possiamo davvero dire che c’è l’89% di probabilità che la media vera sia compresa in quell’intervallo.\n\n\n30.9.3 Distribuzione congiunta di due parametri: incrociare incertezze\nQuando vogliamo esplorare la relazione tra due parametri (ad esempio, media e deviazione standard), possiamo usare:\n\nmcmc_scatter(fm3, pars = c(\"Intercept\", \"sigma\"))\n\n\n\n\n\n\n\nQuesto tipo di visualizzazione è utile per valutare dipendenze tra parametri: ad esempio, se i campioni sono inclinati lungo una diagonale, significa che c’è correlazione a posteriori tra i due.\n\n30.9.4 Posterior Predictive Check: il modello spiega davvero i dati?\nUna delle forze dell’approccio bayesiano è che i modelli sono generativi: possiamo simulare nuovi dati partendo dalle distribuzioni a posteriori e confrontarli con quelli osservati.\n\npp_check(fm3)\n\n\n\n\n\n\n\nLa funzione pp_check() mostra:\n\nin nero: la distribuzione dei dati osservati,\nin colore: più repliche simulate dal modello.\n\nSe le simulazioni coprono bene i dati reali, il modello è coerente con le osservazioni. Se invece ci sono scostamenti sistematici, questo può indicare che:\n\nla distribuzione scelta non è adatta,\nci sono outlier non gestiti,\nmancano variabili esplicative nel modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#lapproccio-tradizionale-il-test-t-di-student",
    "href": "chapters/linear_models/07_one_mean.html#lapproccio-tradizionale-il-test-t-di-student",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.10 L’approccio tradizionale: il test t di Student",
    "text": "30.10 L’approccio tradizionale: il test t di Student\nPrima dell’adozione diffusa dei metodi bayesiani, l’inferenza sulla media veniva solitamente effettuata con il test t. Questo approccio assume che la variabilità osservata nel campione (stimata con la deviazione standard campionaria) sia sufficiente a rappresentare l’incertezza sul parametro d’interesse.\nIl calcolo si basa sulla statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}.\n\\]\nIl test permette di costruire un intervallo di confidenza, ma non di fare affermazioni probabilistiche sui parametri. Il valore \\(\\mu\\) è considerato fisso ma sconosciuto, e l’incertezza è attribuita unicamente al campionamento.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#confronto-tra-approcci-stesso-dato-epistemologie-diverse",
    "href": "chapters/linear_models/07_one_mean.html#confronto-tra-approcci-stesso-dato-epistemologie-diverse",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.11 Confronto tra approcci: stesso dato, epistemologie diverse",
    "text": "30.11 Confronto tra approcci: stesso dato, epistemologie diverse\n\n\n\n\n\n\n\nElemento\nFrequentista\nBayesiano\n\n\n\nConcetto di parametro\nFisso ma ignoto\nVariabile aleatoria\n\n\nIncertezza\nTra campioni\nNei parametri\n\n\nIntervallo (95%)\nProcedura che copre nel 95% dei casi\nCredibilità del 95% sul valore vero\n\n\nEstensione a modelli complessi\nLimitata\nFlessibile\n\n\nTrasparenza delle assunzioni\nImplicita\nEsplicita",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#replicare-lanalisi-con-cmdstanr",
    "href": "chapters/linear_models/07_one_mean.html#replicare-lanalisi-con-cmdstanr",
    "title": "30  Inferenza bayesiana su una media",
    "section": "\n30.12 Replicare l’analisi con cmdstanr\n",
    "text": "30.12 Replicare l’analisi con cmdstanr\n\nOra replichiamo con cmdstanr (Stan esplicito) l’analisi ottenuta con brm e salvata nell’oggetto fm3.\nIl modello è:\n\\[\ny_i \\sim \\mathrm{Normal}(\\mu,\\sigma), \\qquad\n\\mu \\sim \\mathcal{N}(181, 30), \\qquad\n\\sigma \\sim \\mathcal{N}^+(0, 20),\n\\]\ndove \\(\\mathcal{N}^+\\) indica la normale troncata ai valori positivi.\nIl modello Stan equivalente è\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // Priors equivalenti a brms:\n  mu    ~ normal(181, 30);\n  sigma ~ normal(0, 20); // con &lt;lower=0&gt; diventa automaticamente Half-Normal(0,20)\n\n  // Likelihood\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (n in 1:N) y_rep[n] = normal_rng(mu, sigma);\n}\n\"\n\nCompiliamo:\n\nstan_file &lt;- write_stan_file(stancode, dir = \"stan\", basename = \"one_mean_fm3.stan\")\nmod       &lt;- cmdstan_model(stan_file)\n\nPrepariamo i dati:\n\nstan_data &lt;- list(N = nrow(df), y = as.numeric(df$height))\nglimpse(stan_data)\n#&gt; List of 2\n#&gt;  $ N: int 352\n#&gt;  $ y: num [1:352] 152 140 137 157 145 ...\n\nEseguiamo il campionamento:\n\nfit_stan &lt;- mod$sample(\n  data = stan_data,\n  seed = 1234,\n  chains = 4, \n  iter_warmup = 1000, \n  iter_sampling = 4000, \n  parallel_chains = 4,\n  adapt_delta = 0.95\n)\n\nEsaminiamo i risultati:\n\nfit_stan$summary(variables = c(\"mu\",\"sigma\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median    sd   mad      q5     q95  rhat  ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       154.601 154.602 0.413 0.406 153.918 155.285 1.000 10185.459 8086.662\n#&gt; 2 sigma      7.767   7.757 0.290 0.288   7.303   8.259 1.000 10043.384 8612.693\n\n\n30.12.1 Confronto delle posterior (brms vs Stan)\n\ndraws_brm  &lt;- as_draws_df(fm3) |&gt;\n  transmute(mu = b_Intercept, sigma = sigma)\ndraws_stan &lt;- as_draws_df(fit_stan$draws(variables = c(\"mu\",\"sigma\")))\n\nsumm_brm  &lt;- posterior::summarise_draws(draws_brm)  |&gt; mutate(modello = \"brms\")\nsumm_stan &lt;- posterior::summarise_draws(draws_stan) |&gt; mutate(modello = \"stan\")\n\ndplyr::bind_rows(summ_brm, summ_stan) |&gt;\n  dplyr::select(modello, variable, mean, sd, q5, q95, rhat, ess_bulk) |&gt;\n  dplyr::arrange(variable, modello)\n#&gt; # A tibble: 4 × 8\n#&gt;   modello variable    mean    sd      q5     q95  rhat  ess_bulk\n#&gt;   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 brms    mu       154.603 0.414 153.924 155.281 1.000  3150.751\n#&gt; 2 stan    mu       154.601 0.413 153.918 155.285 1.000 10185.459\n#&gt; 3 brms    sigma      7.771 0.294   7.305   8.264 1.000  3220.370\n#&gt; 4 stan    sigma      7.767 0.290   7.303   8.259 1.000 10043.384\n\n\n30.12.2 Visualizzazione delle densità posteriori\n\n\n\n\n\n\n\n\nSe le aree colorate e le linee dei due modelli si sovrappongono quasi perfettamente in ciascun pannello, le posterior coincidono entro il rumore Monte Carlo.\n\n30.12.3 Posterior predictive check\n\ndraws_yrep &lt;- fit_stan$draws(\"y_rep\")\narr &lt;- posterior::as_draws_array(draws_yrep)\nM &lt;- dim(arr)[1] * dim(arr)[2]\nN &lt;- dim(arr)[3]\n\nyrep_df  &lt;- as.data.frame(matrix(arr, nrow = M, ncol = N))\nobs_mean &lt;- mean(df$height)\nyrep_mean &lt;- rowMeans(as.matrix(yrep_df))\n\nppc_df &lt;- data.frame(stat = yrep_mean)\n\nbase_col  &lt;- \"#56B4E9\"\nline_col  &lt;- \"#D55E00\"\n\nggplot(ppc_df, aes(x = stat)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, color = \"white\", fill = base_col) +\n  geom_vline(xintercept = obs_mean, color = line_col, linewidth = 1) +\n  labs(x = \"Media(y_rep)\", y = \"Densità\")\n\n\n\n\n\n\n\n\n30.12.4 Nota sulle prior\nCon il vincolo \\(\\sigma&gt;0\\) in Stan, la specifica sigma ~ normal(0, 20); implementa automaticamente una Half-Normal con scala 20, coerente con prior(normal(0, 20), class = \"sigma\") in brms. Questa equivalenza assicura che i risultati dei due approcci coincidano entro l’errore Monte Carlo, a parità di dati e impostazioni MCMC.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07_one_mean.html#riflessioni-conclusive",
    "title": "30  Inferenza bayesiana su una media",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo riformulato un problema classico — la stima della media di una popolazione — nella prospettiva bayesiana. Abbiamo visto che ciò che otteniamo non è un singolo numero, ma una distribuzione a posteriori che descrive in modo esplicito le nostre credenze aggiornate sul parametro. Questa distribuzione ci dice quanto sono plausibili diversi valori della media, integrando insieme l’informazione a priori e i dati osservati.\nIl passaggio dall’approccio frequentista a quello bayesiano segna un cambiamento concettuale profondo. Non ci limitiamo più a calcolare un intervallo di confidenza o a verificare un’ipotesi nulla, ma costruiamo una rappresentazione diretta dell’incertezza sui parametri che ci interessano. In questo modo, l’inferenza diventa non solo più intuitiva, ma anche più trasparente e coerente con il modo in cui gli psicologi ragionano sui fenomeni: sempre con un certo margine di dubbio, ma anche con la possibilità di pesare scenari alternativi.\nNaturalmente, la stima di una media è solo il punto di partenza. Nella ricerca psicologica siamo spesso interessati a confrontare due gruppi, per capire se una popolazione differisce da un’altra, e se sì di quanto. Nei prossimi capitoli vedremo come estendere il ragionamento bayesiano a questi casi, collegando la stima della media al confronto tra condizioni sperimentali e alla valutazione della grandezza dell’effetto.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nObiettivo: Utilizzare i dati dello studio di Tarrats-Pons et al. (2025) per replicare i risultati riportati nella Figura 2 , applicando sia l’approccio frequentista che il framework bayesiano. Calcolare inoltre la grandezza dell’effetto nel contesto bayesiano (Cohen’s \\(d\\)) e generare un grafico che visualizzi la distribuzione a posteriori della grandezza dell’effetto ottenuta.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(brms)\nlibrary(posterior)\nlibrary(bayestestR)\n\ndf &lt;- read_excel(\n  here::here(\n    \"data\",\n    \"Tarrats-Pons.xlsx\"\n  ),\n  sheet = 3\n)\n\ndf |&gt;\n  group_by(Sample) |&gt;\n  summarize(\n    avg = mean(`CESS-D`),\n    n = n()\n  )\n\ndf_wide &lt;- df %&gt;%\n  select(IdentificationNumber, Sample, CESS_D = `CESS-D`) %&gt;%\n  pivot_wider(\n    names_from = Sample, # da POST/PRE\n    values_from = CESS_D, # i valori da mettere nelle colonne\n    names_prefix = \"CESSD_\" # opzionale, per nominare CESSD_POST, CESSD_PRE\n  )\n\n# Controlla il risultato\nhead(df_wide)\n\ndf_wide$diff &lt;- df_wide$CESSD_PRE - df_wide$CESSD_POST\n\nhist(df_wide$diff)\n\nt.test(df_wide$diff)\n\n# t-test sulle differenze\nres &lt;- t.test(df_wide$diff)\n\n# Numero di soggetti\nn &lt;- length(df_wide$diff)\n\n# Calcolo di Cohen's d\nd_t &lt;- as.numeric(res$statistic) / sqrt(n)\n\n# Mostro risultato\nd_t\n\nfm1 &lt;- brm(\n  formula = diff ~ 1, # Modello con sola intercetta (mu)\n  data = df_wide,\n  family = gaussian(), # Distribuzione Normale\n  prior = c(\n    brms::prior(normal(0, 10), class = \"Intercept\"), # Prior su mu\n    brms::prior(normal(0, 10), class = \"sigma\") # Prior su sigma\n  ),\n  chains = 4,\n  iter = 2000,\n  seed = 1234,\n  backend = \"cmdstanr\"\n)\nsummary(fm1)\npp_check(fm1)\n\nfm2 &lt;- brm(\n  formula = diff ~ 1, # Modello con sola intercetta (mu)\n  data = df_wide,\n  family = student(), # Distribuzione Normale\n  prior = c(\n    brms::prior(normal(0, 10), class = \"Intercept\"), # Prior su mu\n    brms::prior(normal(0, 10), class = \"sigma\") # Prior su sigma\n  ),\n  chains = 4,\n  iter = 2000,\n  seed = 1234,\n  backend = \"cmdstanr\"\n)\nsummary(fm2)\npp_check(fm2)\n\npost_samples &lt;- posterior::as_draws_df(fm1)\nhead(post_samples)\n\npost_samples$effect_size &lt;- post_samples$b_Intercept / post_samples$sigma\n\n# Calcolo diretto delle statistiche dell'effect size\nmean_effect_size &lt;- mean(post_samples$effect_size)\nsd_effect_size &lt;- sd(post_samples$effect_size)\nci_effect_size &lt;- quantile(post_samples$effect_size, probs = c(0.025, 0.975))\n\n# Stampa dei risultati\ncat(\"=== Statistiche dell'Effect Size Bayesiano ===\\n\")\ncat(\"Effect size medio:\", round(mean_effect_size, 2), \"\\n\")\ncat(\"SD dell'effect size:\", round(sd_effect_size, 2), \"\\n\")\ncat(\n  \"Intervallo di credibilità al 95%:\",\n  round(ci_effect_size[1], 2),\n  \"-\",\n  round(ci_effect_size[2], 2),\n  \"\\n\\n\"\n)\n\n# Interpretazione dell'effect size secondo le convenzioni di Cohen\nif (abs(mean_effect_size) &lt; 0.2) {\n  interpretation &lt;- \"piccolo\"\n} else if (abs(mean_effect_size) &lt; 0.5) {\n  interpretation &lt;- \"medio-piccolo\"\n} else if (abs(mean_effect_size) &lt; 0.8) {\n  interpretation &lt;- \"medio\"\n} else {\n  interpretation &lt;- \"grande\"\n}\ncat(\"Interpretazione (Cohen):\", interpretation, \"\\n\")\n\n# Calcola la probabilità che l'effect size sia maggiore di zero\nprob_positive &lt;- mean(post_samples$effect_size &gt; 0)\ncat(\n  \"Probabilità che l'effect size sia positivo:\",\n  round(prob_positive * 100, 2),\n  \"%\\n\"\n)\n\n# Se necessario, calcola probabilità per altre soglie\nprob_medium &lt;- mean(post_samples$effect_size &gt; 0.5)\ncat(\n  \"Probabilità che l'effect size sia &gt; 0.5 (medio):\",\n  round(prob_medium * 100, 2),\n  \"%\\n\"\n)\nprob_large &lt;- mean(post_samples$effect_size &gt; 0.8)\ncat(\n  \"Probabilità che l'effect size sia &gt; 0.8 (grande):\",\n  round(prob_large * 100, 2),\n  \"%\\n\"\n)\n\n# Visualizzazione della distribuzione posteriore dell'effect size\n# (Per eseguire questo blocco, devi avere ggplot2 installato e caricato)\n# library(ggplot2)\nggplot(post_samples, aes(x = effect_size)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  geom_vline(\n    xintercept = mean_effect_size,\n    color = \"red\",\n    linetype = \"dashed\"\n  ) +\n  geom_vline(\n    xintercept = ci_effect_size[1],\n    color = \"darkblue\",\n    linetype = \"dotted\"\n  ) +\n  geom_vline(\n    xintercept = ci_effect_size[2],\n    color = \"darkblue\",\n    linetype = \"dotted\"\n  ) +\n  labs(\n    x = \"Effect Size (Cohen's d)\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] readxl_1.4.5          lubridate_1.9.4       forcats_1.0.0        \n#&gt;  [4] stringr_1.5.1         purrr_1.1.0           readr_2.1.5          \n#&gt;  [7] tidyverse_2.0.0       bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt; [10] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt; [13] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [16] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [19] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [22] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [25] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [28] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [31] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [34] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] RColorBrewer_1.1-3    tensorA_0.36.2.1      jsonlite_2.0.0       \n#&gt;  [4] magrittr_2.0.3        TH.data_1.1-4         estimability_1.5.1   \n#&gt;  [7] farver_2.1.2          rmarkdown_2.29        ragg_1.5.0           \n#&gt; [10] vctrs_0.6.5           memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [13] distributional_0.5.0  curl_7.0.0            broom_1.0.9          \n#&gt; [16] cellranger_1.1.0      htmlwidgets_1.6.4     plyr_1.8.9           \n#&gt; [19] sandwich_3.1-1        emmeans_1.11.2-8      zoo_1.8-14           \n#&gt; [22] cachem_1.1.0          lifecycle_1.0.4       pkgconfig_2.0.3      \n#&gt; [25] Matrix_1.7-4          R6_2.6.1              fastmap_1.2.0        \n#&gt; [28] snakecase_0.11.1      digest_0.6.37         colorspace_2.1-1     \n#&gt; [31] ps_1.9.1              rprojroot_2.1.1       textshaping_1.0.3    \n#&gt; [34] labeling_0.4.3        timechange_0.3.0      abind_1.4-8          \n#&gt; [37] compiler_4.5.1        withr_3.0.2           backports_1.5.0      \n#&gt; [40] inline_0.3.21         QuickJSR_1.8.0        pkgbuild_1.4.8       \n#&gt; [43] R.utils_2.13.0        MASS_7.3-65           tools_4.5.1          \n#&gt; [46] R.oo_1.27.1           glue_1.8.0            nlme_3.1-168         \n#&gt; [49] grid_4.5.1            checkmate_2.3.3       reshape2_1.4.4       \n#&gt; [52] generics_0.1.4        gtable_0.3.6          tzdb_0.5.0           \n#&gt; [55] R.methodsS3_1.8.2     data.table_1.17.8     hms_1.1.3            \n#&gt; [58] utf8_1.2.6            splines_4.5.1         lattice_0.22-7       \n#&gt; [61] survival_3.8-3        tidyselect_1.2.1      knitr_1.50           \n#&gt; [64] arrayhelpers_1.1-0    gridExtra_2.3         V8_7.0.0             \n#&gt; [67] stats4_4.5.1          xfun_0.53             bridgesampling_1.1-2 \n#&gt; [70] stringi_1.8.7         yaml_2.3.10           pacman_0.5.1         \n#&gt; [73] evaluate_1.0.5        codetools_0.2-20      cli_3.6.5            \n#&gt; [76] RcppParallel_5.1.11-1 xtable_1.8-4          systemfonts_1.2.3    \n#&gt; [79] processx_3.8.6        coda_0.19-4.1         svUnit_1.0.8         \n#&gt; [82] parallel_4.5.1        rstantools_2.5.0      Brobdingnag_1.2-9    \n#&gt; [85] mvtnorm_1.3-3         scales_1.4.0          ggridges_0.5.7       \n#&gt; [88] insight_1.4.2         rlang_1.1.6           multcomp_1.4-28",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_one_mean.html#bibliografia",
    "href": "chapters/linear_models/07_one_mean.html#bibliografia",
    "title": "30  Inferenza bayesiana su una media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nTarrats-Pons, E., Mussons-Torras, M., & Jiménez-Pérez, Y. (2025). Efficacy of a Positive Psychology Intervention in Enhancing Optimism and Reducing Depression Among University Students: A Quasi-Experimental Study. Behavioral Sciences, 15(5), 571.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html",
    "href": "chapters/linear_models/08_two_means.html",
    "title": "31  Confronto tra le medie di due gruppi",
    "section": "",
    "text": "Introduzione\nUno dei problemi di ricerca più frequenti in psicologia riguarda il confronto tra due gruppi o condizioni. Ci chiediamo, ad esempio, se un gruppo di trattamento ottenga risultati migliori di un gruppo di controllo, o se un campione clinico differisca da un campione non clinico in una certa misura psicologica. In questi casi, la questione cruciale non è soltanto se esista una differenza, ma anche quanto grande essa sia e con quale grado di incertezza possiamo descriverla.\nIn questo capitolo affrontiamo il problema con un approccio bayesiano. Immaginiamo di avere una variabile continua di esito, indicata con \\(y_{ig}\\), che misura l’osservazione \\(i\\) nel gruppo \\(g\\) (dove \\(g\\) può assumere valore 0 oppure 1). Un modello semplice e naturale assume che i punteggi in ciascun gruppo seguano una distribuzione normale con la propria media:\n\\[\ny_{ig}\\sim\\mathcal N(\\mu_g,\\ \\sigma),\n\\qquad \\Delta=\\mu_1-\\mu_0 .\n\\]\nLa quantità di interesse centrale è \\(\\Delta\\), la differenza tra le due medie.\nQuesto stesso modello può essere scritto in forma equivalente come un modello di regressione lineare semplice, utilizzando una variabile indicatrice \\(x_i\\) che codifica l’appartenenza al gruppo (0 = gruppo di riferimento, 1 = gruppo sperimentale):\n\\[\ny_i \\sim \\mathcal N(\\alpha+\\beta x_i,\\ \\sigma).\n\\]\nIn questa formulazione, l’intercetta \\(\\alpha\\) rappresenta la media del gruppo di riferimento (\\(\\mu_0\\)), mentre il coefficiente \\(\\beta\\) coincide con la differenza tra le due medie (\\(\\Delta\\)). Quando necessario, considereremo anche la versione standardizzata di questo effetto, definita come \\(d = \\Delta / \\sigma\\), che fornisce una misura della dimensione dell’effetto indipendente dalla scala di misura utilizzata.\nRispetto all’approccio frequentista tradizionale, che si concentra principalmente sul calcolo di un p-value per l’ipotesi nulla di uguaglianza delle medie, l’inferenza bayesiana offre una prospettiva più ricca e informativa. Essa fornisce una distribuzione a posteriori completa per \\(\\Delta\\), che quantifica direttamente la nostra incertezza sulla differenza dopo aver osservato i dati. Da questa distribuzione possiamo calcolare probabilità con un significato immediato, come:\nInoltre, il quadro bayesiano rende trasparente l’integrazione di conoscenze pregresse tramite le distribuzioni a priori e obbliga a esplicitare tutte le assunzioni su cui il modello si basa. Questo rende il processo inferenziale non solo più flessibile, ma anche più rigoroso e interpretabile dal punto di vista scientifico.\nIl percorso che seguiremo in questo capitolo è semplice e strutturato. Inizieremo specificando il modello bayesiano per il confronto tra due medie, esplorandone anche varianti più robuste nel caso in cui l’assunzione di normalità risulti troppo restrittiva. Sceglieremo poi delle prior debolmente informative, che siano coerenti con la scala di misura della nostra variabile risultato e che permettano ai dati di “parlare” in modo predominante. Una volta stimato il modello, il focus sarà sul riportare le quantità di interesse—la differenza \\(\\Delta\\) e l’eventuale dimensione dell’effetto standardizzata \\(d\\)—accompagnate dalle loro distribuzioni a posteriori e dalle probabilità rilevanti. Infine, valuteremo l’adeguatezza del nostro modello attraverso verifiche predittive, per assicurarci che sia in grado di generare dati simili a quelli osservati, e, se necessario, confronteremo modelli con assunzioni diverse per scegliere quello che meglio cattura la struttura dei nostri dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#introduzione",
    "href": "chapters/linear_models/08_two_means.html#introduzione",
    "title": "31  Confronto tra le medie di due gruppi",
    "section": "",
    "text": "la probabilità che la differenza sia positiva, \\(\\Pr(\\Delta&gt;0 \\mid \\text{dati})\\);\nla probabilità che l’effetto superi una soglia di rilevanza pratica predefinita, \\(\\Pr(|\\Delta|&gt;\\text{SESOI}\\mid\\text{dati})\\).\n\n\n\n\n\n\n\n\nLe assunzioni del modello base\n\n\n\nCome ogni modello statistico, anche questo semplice confronto tra medie si basa su alcune assunzioni fondamentali che è importante tenere a mente. Le osservazioni sono assumed to be indipendenti tra loro, una volta tenuto conto dell’effetto del gruppo. I residui del modello, cioè la parte di variabilità non spiegata dalla gruppo appartenenza, dovrebbero seguire una distribuzione approssimativamente normale. Il modello presentato qui assume anche che la variabilità dei dati (la \\(\\sigma\\)) sia la stessa nei due gruppi; si tratta di un’ipotesi semplificatrice, ma il modello può essere esteso per accomodare il caso più generale in cui le varianze siano diverse (eteroscedasticità).\n\n\n\n\n\n\n\n\nL’importanza di una Soglia di Rilevanza (SESOI)\n\n\n\nPer evitare di sovrainterpretare differenze statisticamente significative ma trivialmente piccole, è una buona pratica metodologica definire a priori una Soglia di Rilevanza Scientificamente Significativa (SESOI). Stabilire, ad esempio, che una differenza di almeno 5 punti in un test cognitivo abbia un reale significato pratico, permette di ancorare le conclusioni alla sostanza del fenomeno studiato, andando oltre la semplice significatività statistica. È quindi utile riportare non solo la probabilità che l’effetto sia diverso da zero, ma anche la probabilità che superi questa soglia di rilevanza.\n\n\n\nPanoramica del capitolo\n\nLe basi concettuali e statistiche che sottendono la modellazione della differenza tra medie nell’ambito del modello di regressione lineare bayesiana.\nLe diverse strategie di codifica del predittore categoriale (dummy, centrata, a medie di cella).\nLe strategie più efficaci per comunicare i risultati attraverso intervalli credibili e previsioni probabilistiche.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nConsultare l’articolo “Bayesian estimation supersedes the t test” (Kruschke, 2013).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, brms, bayestestR, insight)\nconflicts_prefer(loo::loo)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#il-modello-a-indicatore-e-le-quantità-di-interesse",
    "href": "chapters/linear_models/08_two_means.html#il-modello-a-indicatore-e-le-quantità-di-interesse",
    "title": "31  Confronto tra le medie di due gruppi",
    "section": "\n31.1 Il modello a indicatore e le quantità di interesse",
    "text": "31.1 Il modello a indicatore e le quantità di interesse\nPer confrontare due gruppi in modo rigoroso, utilizziamo un modello statistico che incorpora un predittore binario, \\(x_i\\), il cui valore (0 o 1) indica l’appartenenza a uno dei due gruppi. Il modello lineare che proponiamo è il seguente:\n\\[\ny_i = \\alpha + \\beta x_i + \\varepsilon_i, \\qquad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma),\n\\]\ndove il termine \\(\\varepsilon_i\\) rappresenta l’errore residuo, la parte di variabilità del punteggio \\(y_i\\) che il modello non riesce a spiegare. Un’assunzione fondamentale di questo modello base è che la dispersione di questi residui, misurata dalla deviazione standard \\(\\sigma\\), sia la stessa per entrambi i gruppi. Questa condizione è nota come ipotesi di omoschedasticità.\nLe quantità centrali che vogliamo stimare—le medie dei due gruppi—sono ricavabili direttamente dai parametri del modello. Sostituendo i valori dell’indicatore, otteniamo:\n\nL’attesa per il gruppo di riferimento (quando \\(x_i = 0\\)) è: \\(\\mathbb{E}[y \\mid x=0] = \\alpha\\). Chiamiamo questo valore \\(\\mu_0\\).\nL’attesa per il gruppo di confronto (quando \\(x_i = 1\\)) è: \\(\\mathbb{E}[y \\mid x=1] = \\alpha + \\beta\\). Chiamiamo questo valore \\(\\mu_1\\).\n\nLa differenza tra le due medie, che è la quantità di interesse primaria, risulta quindi essere esattamente il coefficiente \\(\\beta\\):\n\\[\n\\Delta = \\mu_1 - \\mu_0 = (\\alpha + \\beta) - \\alpha = \\beta.\n\\]\nIn sintesi, l’interpretazione dei parametri è molto intuitiva:\n\nIl parametro \\(\\alpha\\) (l’intercetta) rappresenta la media del gruppo di riferimento.\nIl parametro \\(\\beta\\) (la pendenza) rappresenta la differenza media tra il gruppo di confronto e il gruppo di riferimento.\nIl parametro \\(\\sigma\\) rappresenta la variabilità residua comune all’interno di ciascun gruppo, assumendo che sia omogenea.\n\nUna prospettiva alternativa: il modello a medie di cella\nLo stesso modello può essere formulato in un modo che rende ancora più esplicite le medie di gruppo. Invece di esprimerlo come una funzione lineare, possiamo scriverlo direttamente specificando la media per ogni cella:\n\\[\ny_i \\sim \\mathcal{N}(\\mu_{x_i},\\, \\sigma),\n\\]\ndove \\(\\mu_{x_i}\\) è semplicemente la media del gruppo a cui l’osservazione \\(i\\)-esima appartiene. In pratica, questo significa che se \\(x_i = 0\\), allora \\(y_i \\sim \\mathcal{N}(\\mu_0, \\sigma)\\), e se \\(x_i = 1\\), allora \\(y_i \\sim \\mathcal{N}(\\mu_1, \\sigma)\\).\nQuesta parametrizzazione è del tutto equivalente a quella con \\(\\alpha\\) e \\(\\beta\\), con la semplice corrispondenza \\(\\mu_0 = \\alpha\\) e \\(\\mu_1 = \\alpha + \\beta\\). La sua utilità risiede nel fatto che rende immediatamente visibili i parametri di interesse diretto (\\(\\mu_0\\) e \\(\\mu_1\\)) ed è spesso più semplice da comprendere concettualmente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#la-codifica-centrata-dellindicatore",
    "href": "chapters/linear_models/08_two_means.html#la-codifica-centrata-dellindicatore",
    "title": "31  Confronto tra le medie di due gruppi",
    "section": "\n31.2 La codifica centrata dell’indicatore",
    "text": "31.2 La codifica centrata dell’indicatore\nUn’accortezza tecnica ma molto utile nella modellazione consiste nel centrare la variabile indicatrice. Invece di usare i valori 0 e 1, possiamo ridefinirla sottraendo 0.5, ottenendo così:\n\\[\nx_c = x - \\tfrac12 \\in \\left\\{-\\tfrac12,\\ +\\tfrac12\\right\\}.\n\\]\nIl modello di regressione viene quindi riscritto utilizzando questo predittore centrato:\n\\[\ny_i = \\alpha_c + \\beta_c \\, x_{c,i} + \\varepsilon_i.\n\\]\nQuesta piccola modifica altera in modo vantaggioso l’interpretazione dei coefficienti:\n\nIl parametro \\(\\alpha_c\\) (l’intercetta) non è più la media del gruppo di riferimento, bensì la media generale (o grand mean) dei due gruppi, calcolata come \\((\\mu_0 + \\mu_1)/2\\).\nIl parametro \\(\\beta_c\\) (la pendenza) rimane invece esattamente la differenza tra le due medie (\\(\\mu_1 - \\mu_0\\)), proprio come nel caso della codifica non centrata.\n\n\n31.2.1 Vantaggi pratici della codifica centrata\nQuesta parametrizzazione alternativa offre diversi vantaggi pratici:\n\n\nInterpretazione immediata dell’intercetta: L’intercetta \\(\\alpha_c\\) rappresenta direttamente la media complessiva del campione, una quantità spesso utile da riportare.\n\nSemplicità nella specifica delle prior: Risulta più intuitivo e diretto specificare distribuzioni a priori per i parametri. Possiamo scegliere una prior per \\(\\alpha_c\\) basata sulla nostra conoscenza del livello medio generale della variabile \\(y\\) nella popolazione, e una prior separata per \\(\\beta_c\\) basata sull’ampiezza dell’effetto che ci aspettiamo o che riteniamo rilevante.\n\nStima più efficiente in modelli complessi: Nei modelli gerarchici più avanzati, la centratura può spesso ridurre la correlazione tra le stime dei parametri, migliorando l’efficienza del campionatore MCMC e facilitando la convergenza.\n\nSuggerimento operativo: La scelta tra la codifica standard (0/1) e quella centrata dipende dagli obiettivi dell’analisi.\n\nUtilizza la codifica centrata quando l’attenzione è primariamente sulla differenza \\(\\beta\\) e quando vuoi riportare in modo trasparente la media complessiva.\nUtilizza la forma a “medie di cella” (o la codifica 0/1) quando è più conveniente o interpretabile stimare direttamente i livelli medi \\(\\mu_0\\) e \\(\\mu_1\\) per ciascun gruppo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#stima-con-brms",
    "href": "chapters/linear_models/08_two_means.html#stima-con-brms",
    "title": "31  Confronto tra le medie di due gruppi",
    "section": "\n31.3 Stima con brms\n",
    "text": "31.3 Stima con brms\n\nDi seguito mostriamo tre modi equivalenti per stimare la differenza tra due gruppi con brms. Per ogni blocco indichiamo: cosa fa il modello, come leggere i coefficienti, quali quantità riportare.\n\n31.3.1 1) Codifica dummy \\(x\\in\\{0,1\\}\\) (modello “standard”)\nIdea. Stimiamo \\(\\alpha\\) (media del gruppo \\(x=0\\)) e \\(\\beta\\) (differenza \\(\\mu_1-\\mu_0\\)). Le prior student_t(3, 0, 10) sono debolmente informative: centrano i parametri a 0 e consentono ampia variabilità (code più pesanti della normale).\n#| message: false\n# install.packages(c(\"brms\",\"posterior\",\"tidyverse\",\"bayestestR\",\"loo\",\"cmdstanr\"))\nlibrary(brms); library(posterior); library(tidyverse); library(bayestestR); library(loo)\n\nfit &lt;- brm(\n  y ~ 1 + x,                 # Intercetta + indicatrice (0/1)\n  data = df,\n  family = gaussian(),\n  prior = c(\n    prior(student_t(3, 0, 10), class = \"Intercept\"),  # prior su α (media gruppo 0)\n    prior(student_t(3, 0, 10), class = \"b\"),          # prior su β (differenza)\n    prior(student_t(3, 0, 10), class = \"sigma\")       # prior su σ (half-t implicita)\n  ),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\nCome leggere i risultati.\n\n\nb_Intercept stima \\(\\mu_0\\).\n\nb_x stima \\(\\Delta=\\mu_1-\\mu_0\\).\n\nsigma è la deviazione standard comune. Calcoliamo anche \\(d=\\Delta/\\sigma\\) e due probabilità a posteriori utili: \\(\\Pr(\\Delta&gt;0)\\) e \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\ndraws &lt;- as_draws_df(fit)\npost &lt;- draws %&gt;%\n  transmute(\n    mu0   = b_Intercept,          # = α\n    mu1   = b_Intercept + b_x,    # = α + β\n    delta = b_x,                  # = β\n    sigma = sigma,\n    d     = delta / sigma         # effetto standardizzato (pooled)\n  )\n\nposterior::summarise_draws(post[, c(\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\n\nSESOI &lt;- 5  # definita a priori in base al contesto applicativo\nc(\n  P_delta_gt0  = mean(post$delta &gt; 0),\n  P_delta_gtS  = mean(abs(post$delta) &gt; SESOI)\n)\nCosa riportare nel testo: media e intervallo credibile per \\(\\mu_0,\\mu_1,\\Delta,d\\); \\(\\Pr(\\Delta&gt;0)\\); \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n31.3.2 2) Codifica centrata \\(x_c=x-\\tfrac12\\)\n\nIdea. L’intercetta diventa la grand mean \\((\\mu_0+\\mu_1)/2\\); il coefficiente su \\(x_c\\) è direttamente \\(\\Delta\\). Le prior sono normali (comode quando interpretiamo \\(\\alpha\\) come media complessiva).\ndf &lt;- df %&gt;% mutate(xc = x - 0.5)  # xc ∈ {-0.5, +0.5}\n\nfit_c &lt;- brm(\n  y ~ 1 + xc,\n  data = df,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 10), class = \"Intercept\"),   # prior su grand mean\n    prior(normal(0, 10), class = \"b\"),           # prior sulla differenza\n    prior(student_t(3, 0, 10), class = \"sigma\")\n  ),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\n\ndraws_c &lt;- as_draws_df(fit_c)\npost_c &lt;- draws_c %&gt;%\n  transmute(\n    grand_mean = b_Intercept,            # = (μ0+μ1)/2\n    delta      = b_xc,                   # = μ1 - μ0\n    mu0        = b_Intercept - 0.5*b_xc, # ricostruzione\n    mu1        = b_Intercept + 0.5*b_xc,\n    sigma      = sigma,\n    d          = delta / sigma\n  )\nposterior::summarise_draws(post_c[, c(\"grand_mean\",\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\nQuando usarla: quando vuoi dare prior separate e intuitive su media complessiva e differenza.\n\n31.3.3 3) Medie di cella (senza intercetta)\nIdea. Stimiamo direttamente \\(\\mu_0\\) e \\(\\mu_1\\). Vantaggio: puoi assegnare prior indipendenti sulle due medie.\ndf &lt;- df %&gt;% mutate(group = factor(x, levels = c(0,1), labels = c(\"G0\",\"G1\")))\n\nfit_cells &lt;- brm(\n  y ~ 0 + group,              # niente intercetta: i coefficienti SONO le medie\n  data = df, family = gaussian(),\n  prior = c(\n    prior(normal(0, 10), class = \"b\", coef = \"groupG0\"),  # prior su μ0\n    prior(normal(0, 10), class = \"b\", coef = \"groupG1\"),  # prior su μ1\n    prior(student_t(3, 0, 10), class = \"sigma\")\n  ),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\n\ndraws_cells &lt;- as_draws_df(fit_cells)\npost_cells &lt;- draws_cells %&gt;%\n  transmute(\n    mu0   = b_groupG0,\n    mu1   = b_groupG1,\n    delta = b_groupG1 - b_groupG0,\n    sigma = sigma,\n    d     = delta / sigma\n  )\nposterior::summarise_draws(post_cells[, c(\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\nQuando usarla: quando vuoi controllare in modo esplicito le prior sulle due medie (e.g., vincoli diversi per ciascun gruppo).\n\n\n\n\n\n\nNota sulle prior indotte\n\n\n\nCon la forma “intercetta + differenza”, prior indipendenti su \\(\\alpha\\) e \\(\\beta\\) inducono correlazione tra \\(\\mu_0\\) e \\(\\mu_1\\) (\\(\\mu_0=\\alpha,\\ \\mu_1=\\alpha+\\beta\\)). Se desideri indipendenza a priori tra \\(\\mu_0\\) e \\(\\mu_1\\), usa la parametrizzazione a medie di cella.\n\n\n\n\n\n\n\n\nNomi dei coefficienti: attenzione alla codifica\n\n\n\n\nSe x è numerica (0/1): il coefficiente si chiama tipicamente b_x.\nSe x è fattore (due livelli): il coefficiente sarà b_x1 o b_x&lt;nomeLivello&gt;.\nCon 0 + group: i coefficienti si chiamano b_groupG0, b_groupG1 (le etichette dipendono dai livelli della variabile). Controlla sempre i nomi esatti in names(as_draws_df(fit)) prima di costruire le trasformazioni.\n\n\n\n\n\n\n\n\n\nDiagnostica minima da riportare\n\n\n\nVerifica Rhat (~1.00), ESS, assenza di divergenze e PPC coerenti. Se necessario aumenta adapt_delta (0.95–0.99) e max_treedepth (es. 15).\n\n\n\nRiassunto operativo. Qualunque parametrizzazione tu scelga, riporta sempre: \\(\\mu_0,\\mu_1,\\Delta,d\\) con intervalli credibili e le probabilità \\(\\Pr(\\Delta&gt;0)\\) e \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n\n31.3.4 Interpretazione operativa (cosa leggere nelle posteriori)\nDi seguito come leggere e riportare i risultati a seconda della codifica usata per il predittore binario.\n1) Codifica dummy \\(D\\in\\{0,1\\}\\)\n\n\nIntercept \\(\\Rightarrow\\) \\(\\mu_0\\) (media del gruppo \\(D=0\\)).\nCoefficiente su D \\(\\Rightarrow\\) \\(\\Delta=\\mu_1-\\mu_0\\) (differenza tra medie).\nDa riportare sempre: \\(\\mu_1=\\mu_0+\\Delta\\), \\(\\sigma\\), \\(d=\\Delta/\\sigma\\), \\(\\Pr(\\Delta&gt;0)\\), \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n2) Codifica centrata \\(D_c=D-\\tfrac12\\in\\{-\\tfrac12,+\\tfrac12\\}\\)\n\n\nIntercept \\(\\Rightarrow\\) grand mean \\(\\displaystyle \\alpha=\\tfrac{\\mu_0+\\mu_1}{2}\\).\nCoefficiente su D_c \\(\\Rightarrow\\) \\(\\Delta=\\mu_1-\\mu_0\\).\nRicostruzioni utili: \\(\\mu_0=\\alpha-\\tfrac12\\Delta\\), \\(\\mu_1=\\alpha+\\tfrac12\\Delta\\).\nDa riportare come sopra: \\(\\Delta\\), \\(d\\), \\(\\Pr(\\Delta&gt;0)\\), \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n3) Parametrizzazione a “medie di cella” (senza intercetta)\n\nI coefficienti sono direttamente \\(\\mu_0\\) e \\(\\mu_1\\).\nLa differenza si ottiene come combinazione lineare a posteriori: \\(\\Delta=\\mu_1-\\mu_0\\).\nDa riportare: \\(\\mu_0,\\mu_1,\\Delta,\\sigma,d,\\Pr(\\Delta&gt;0),\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n\n\n\n\n\n\nPromemoria pratico. Indipendentemente dalla codifica, l’oggetto sostantivo è sempre \\(\\Delta\\) (e, quando serve, \\(d=\\Delta/\\sigma\\)). Per la discussione applicativa affianca sempre:\n\nun intervallo credibile per \\(\\Delta\\);\n\n\\(\\Pr(\\Delta&gt;0\\mid\\text{dati})\\);\n\n\\(\\Pr(|\\Delta|&gt;\\text{SESOI}\\mid\\text{dati})\\) con una SESOI definita prima dell’analisi.\n\n\n\n\nEsempio di lettura sintetica. Se la posteriore di \\(\\Delta\\) ha media 4.8, intervallo credibile 95% \\([2.1,\\ 7.4]\\), \\(\\Pr(\\Delta&gt;0)=0.99\\) e \\(\\Pr(|\\Delta|&gt;5)=0.46\\) (SESOI = 5), allora: la differenza media è plausibilmente positiva, ma la probabilità di superare la soglia di rilevanza scelta è circa 46% (informazione utile per l’interpretazione sostantiva).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#confronto-tra-approcci-frequentista-e-bayesiano",
    "href": "chapters/linear_models/08_two_means.html#confronto-tra-approcci-frequentista-e-bayesiano",
    "title": "31  Confronto tra le medie di due gruppi",
    "section": "\n31.4 Confronto tra approcci: frequentista e bayesiano",
    "text": "31.4 Confronto tra approcci: frequentista e bayesiano\n\n\n\n\n\n\n\nAspetto\nFrequentista\nBayesiano\n\n\n\nRappresentazione\nIntervallo di confidenza\nIntervallo di credibilità\n\n\nUnità di analisi\nCompatibilità dei dati con \\(H_0\\)\n\nDistribuzione a posteriori su \\(\\Delta\\) e probabilità su regioni di interesse (SESOI/ROPE)\n\n\nIpotesi di partenza\nIpotesi nulla puntuale come riferimento\nModello + prior; non richiede un \\(H_0\\) puntuale, ma consente ipotesi su regioni parametriche\n\n\nUso di informazione pregressa\nNon previsto\nIntegrabile tramite prior\n\n\nDomanda tipica\n“Quanto sono rari i dati se \\(\\Delta=0\\)?”\n“Quanto è plausibile che \\(\\Delta\\) superi una soglia definita (SESOI)?”",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#esempio-istruzione-materna-e-qi",
    "href": "chapters/linear_models/08_two_means.html#esempio-istruzione-materna-e-qi",
    "title": "31  Confronto tra le medie di due gruppi",
    "section": "\n31.5 Esempio: istruzione materna e QI",
    "text": "31.5 Esempio: istruzione materna e QI\nUsiamo il dataset kidiq (sviluppo cognitivo): per ogni bambino abbiamo il QI (kid_score) e se la madre ha il diploma (mom_hs: 0 = non diplomata; 1 = diplomata).\nDomanda: i figli di madri diplomate hanno, in media, un QI diverso? Inoltre, fissiamo a titolo esemplificativo una SESOI = 5 punti di QI (soglia di rilevanza pratica da motivare nel contesto).\n\n31.5.1 Esplorazione iniziale dei dati\n1) Import, pulizia minima e etichette chiare.\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\n# Ricodifica esplicita per leggibilità nei grafici e nelle tabelle\nkidiq &lt;- kidiq |&gt;\n  mutate(\n    mom_hs = factor(mom_hs, levels = c(0, 1),\n                    labels = c(\"Non diplomata\", \"Diplomata\"))\n  )\n\n# Controllo veloce: struttura e eventuali missing\nglimpse(kidiq)\n#&gt; Rows: 434\n#&gt; Columns: 5\n#&gt; $ kid_score &lt;dbl&gt; 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78, 1…\n#&gt; $ mom_hs    &lt;fct&gt; Diplomata, Diplomata, Diplomata, Diplomata, Diplomata, Non d…\n#&gt; $ mom_iq    &lt;dbl&gt; 121.1, 89.4, 115.4, 99.4, 92.7, 107.9, 138.9, 125.1, 81.6, 9…\n#&gt; $ mom_work  &lt;dbl&gt; 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, 3, …\n#&gt; $ mom_age   &lt;dbl&gt; 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 24, …\ncolSums(is.na(kidiq[, c(\"kid_score\", \"mom_hs\")]))\n#&gt; kid_score    mom_hs \n#&gt;         0         0\n\n2) Statistiche descrittive per gruppo.\n\nkidiq |&gt;\n  group_by(mom_hs) |&gt;\n  summarise(\n    n        = n(),\n    media_QI = mean(kid_score, na.rm = TRUE),\n    sd_QI    = sd(kid_score, na.rm = TRUE),\n    mediana  = median(kid_score, na.rm = TRUE),\n    IQR      = IQR(kid_score, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n#&gt; # A tibble: 2 × 6\n#&gt;   mom_hs            n media_QI sd_QI mediana   IQR\n#&gt;   &lt;fct&gt;         &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Non diplomata    93     77.5  22.6      80    37\n#&gt; 2 Diplomata       341     89.3  19.0      92    26\n\n\nLettura rapida: riportiamo numerosità, media e deviazione standard (oltre a mediana e IQR per un controllo di robustezza). Nel nostro campione tipicamente i gruppi sono sbilanciati (ad es., ~93 vs ~341): è un’informazione utile per interpretare precisione e incertezza delle stime.\n\n3) Visualizzazione della distribuzione nei due gruppi.\n\nggplot(kidiq, aes(x = mom_hs, y = kid_score)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.12, outlier.shape = NA) +\n  geom_jitter(width = 0.08, alpha = 0.25, size = 1) +\n  labs(\n    x = \"Istruzione materna\",\n    y = \"QI del bambino\"\n  ) \n\n\n\n\n\n\n\n\nCosa mostra il grafico: le medie sembrano diverse, ma le distribuzioni si sovrappongono in modo consistente. È un pattern tipico in psicologia: la differenza media non esaurisce l’informazione: servono stima dell’ampiezza, incertezza e, se possibile, rilevanza pratica (SESOI).\n\nDomanda guida per l’analisi inferenziale\nLa differenza osservata è compatibile con la sola variabilità campionaria oppure suggerisce una tendenza nella popolazione?\nPer rispondere, nel seguito stimiamo la differenza tra le medie con approccio frequentista (t-test) e con approccio bayesiano (modello gaussiano con brms), riportando anche le probabilità a posteriori rispetto alla SESOI.\n\n31.5.1.1 Approccio frequentista\nPer verificare se la differenza media osservata può essere attribuita alla sola variabilità campionaria, applichiamo un t-test per campioni indipendenti (versione con varianze uguali):\n\nt.test(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  var.equal = TRUE\n)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  kid_score by mom_hs\n#&gt; t = -5, df = 432, p-value = 0.0000006\n#&gt; alternative hypothesis: true difference in means between group Non diplomata and group Diplomata is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -16.34  -7.21\n#&gt; sample estimates:\n#&gt; mean in group Non diplomata     mean in group Diplomata \n#&gt;                        77.5                        89.3\n\nInterpretazione.\n\nLe medie campionarie sono circa 77.6 (madri non diplomate) e 89.3 (madri diplomate).\nLa differenza (gruppo 1 − gruppo 0) è ~ +11.8 punti QI.\nL’IC al 95% stampato da R si riferisce a (gruppo 0 − gruppo 1) ed è \\([-16.34,\\ -7.21]\\); quindi, per (gruppo 1 − gruppo 0) l’IC corrispondente è [+7.21, +16.34].\nIl p-value \\(= 6\\times 10^{-7}\\) indica che, se nella popolazione non ci fosse differenza (\\(\\mu_1=\\mu_0\\)), sarebbe molto raro osservare una differenza almeno così grande. (Non è la probabilità che \\(H_0\\) sia vera.)\n\n\nAssunzioni e note pratiche.\n\nIl test qui usa varianze uguali (var.equal=TRUE). In pratica è spesso preferibile la versione di Welch (default di t.test, cioè senza var.equal=TRUE), più robusta a varianze diverse e sbilanciamento tra gruppi.\nL’inferenza frequentista fornisce una decisione rispetto a \\(H_0\\) e un IC; non restituisce la probabilità che l’effetto superi una soglia di interesse applicativo.\n\nNel paragrafo successivo stimiamo la stessa differenza con l’approccio bayesiano, ottenendo una distribuzione a posteriori per \\(\\Delta\\) e quantità direttamente interpretabili come \\(\\Pr(\\Delta&gt;0)\\) e \\(\\Pr(|\\Delta|&gt;\\text{SESOI})\\).\n\n31.5.1.2 Approccio bayesiano\nCon mom_hs codificata come 0 = non diplomata e 1 = diplomata, il modello\n\\[\ny_i \\sim \\mathcal N(\\alpha+\\beta\\,\\text{mom\\_hs}_i,\\ \\sigma)\n\\]\nsi interpreta così:\n\n\n\\(\\alpha\\) = media del gruppo mom_hs = 0;\n\n\\(\\beta = \\Delta\\) = differenza tra medie (gruppo 1 − gruppo 0);\n\n\\(\\sigma\\) = deviazione standard residua (assunta uguale nei due gruppi).\n\n\n# Assicuriamoci che la referenza sia \"Non diplomata\"\nkidiq$mom_hs &lt;- relevel(kidiq$mom_hs, ref = \"Non diplomata\")\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs,\n  data   = kidiq,\n  family = gaussian(),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000, seed = 123\n)\n\n\n# ===== Ponte sicuro tra nomi \"umani\" e nomi dei draw =====\n# Termini dei coefficienti a livello fissato (esclude l'intercetta)\nterm_names &lt;- setdiff(rownames(fixef(fit_1)), \"Intercept\")\nstopifnot(length(term_names) == 1)         # qui ci aspettiamo un solo coefficiente: \"mom_hsDiplomata\"\n\nb_name &lt;- paste0(\"b_\", term_names)         # es. \"b_mom_hsDiplomata\"\n\ndr &lt;- as_draws_df(fit_1)\n\n# Quantità di interesse\npost &lt;- dr %&gt;%\n  transmute(\n    mu0   = b_Intercept,         # media del gruppo di riferimento (Non diplomata)\n    delta = .data[[b_name]],     # differenza vs referenza: (Diplomata - Non diplomata)\n    mu1   = b_Intercept + delta, # media del gruppo \"Diplomata\"\n    sigma = sigma,\n    d     = delta / sigma\n  )\n\nSESOI &lt;- 5\nposterior::summarise_draws(post[, c(\"mu0\",\"mu1\",\"delta\",\"d\",\"sigma\")])\n#&gt; # A tibble: 5 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu0      77.570 77.559 2.030 2.016 74.205 80.885 1.000 3811.388 2972.604\n#&gt; 2 mu1      89.308 89.307 1.063 1.066 87.602 91.079 1.000 3931.890 2780.415\n#&gt; 3 delta    11.737 11.787 2.309 2.309  7.911 15.506 1.000 4154.701 3119.643\n#&gt; 4 d         0.591  0.593 0.118 0.120  0.395  0.783 1.000 4130.593 3034.413\n#&gt; 5 sigma    19.894 19.868 0.702 0.709 18.780 21.073 1.000 3713.284 3095.218\n\nc(\n  P_delta_gt0    = mean(post$delta &gt; 0),          # Pr(Δ &gt; 0 | dati)\n  P_absDelta_gtS = mean(abs(post$delta) &gt; SESOI)  # Pr(|Δ| &gt; 5 | dati)\n)\n#&gt;    P_delta_gt0 P_absDelta_gtS \n#&gt;          1.000          0.999\n\nCome leggere i risultati:\n\nmu0 e mu1 sono le medie di gruppo stimate (con incertezza).\ndelta è la differenza media \\((\\mu_1-\\mu_0)\\); d è la versione standardizzata.\n\nLe due probabilità a posteriori rispondono a domande pratiche:\n\n\n\\(\\Pr(\\Delta&gt;0\\mid\\text{dati})\\): quanto è plausibile che i figli di madri diplomate abbiano un QI medio maggiore?\n\n\\(\\Pr(|\\Delta|&gt;\\text{SESOI}\\mid\\text{dati})\\): quanto è plausibile che la differenza superi 5 punti (soglia di rilevanza scelta)?",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#approfondimenti-bayesiani",
    "href": "chapters/linear_models/08_two_means.html#approfondimenti-bayesiani",
    "title": "31  Confronto tra le medie di due gruppi",
    "section": "\n31.6 Approfondimenti bayesiani",
    "text": "31.6 Approfondimenti bayesiani\nFinora abbiamo stimato la differenza tra i gruppi e le relative probabilità a posteriori. Qui vediamo come controllare l’adeguatezza del modello e, se serve, raffinarlo. Usiamo tre strumenti: (1) verifiche predittive a posteriori (PPC), (2) verifiche a priori, (3) confronto predittivo tra modelli.\n\n31.6.1 1) Posterior predictive checks (PPC)\nL’idea è semplice: il modello dovrebbe essere in grado di rigenerare dati simili a quelli osservati.\n\n# Verifica globale (densità osservata vs replicata dal modello)\npp_check(fit_1)   # default: dens_overlay\n\n\n\n\n\n\n\nCosa guardare.\n\n\nForma: la distribuzione simulata copre quella osservata? Ci sono code o asimmetrie non riprodotte?\n\n31.6.2 2) Verifica predittiva a priori\n\nServe a controllare se le prior producono dati plausibili prima di vedere i dati.\n\npri &lt;- c(\n  prior(normal(90, 20), class = \"Intercept\"),  # scala QI\n  prior(normal(0, 15),  class = \"b\"),          # differenza attesa moderata\n  prior(student_t(3, 0, 20), class = \"sigma\")\n)\n\nfit_prior &lt;- brm(\n  kid_score ~ mom_hs,\n  data = kidiq,\n  family = gaussian(),\n  prior = pri,\n  sample_prior = \"only\",       # ignora i dati: simula dai prior\n  backend = \"cmdstanr\",\n  chains = 2, iter = 1000, seed = 123\n)\n\n\npp_check(fit_prior, ndraws = 100)\n\n\n\n\n\n\n\nInterpretazione: se i dati simulati a priori cadono in range irrealistici (es. molti QI &lt; 30 o &gt; 180), le prior vanno allineate alla conoscenza di dominio.\n\n31.6.3 3) Varianti del modello (quando i PPC suggeriscono limiti)\nCode pesanti / outlier → t di Student:\n\nfit_t &lt;- brm(kid_score ~ mom_hs, family = student(), data = kidiq,\n               backend = \"cmdstanr\", chains = 4, iter = 2000, seed = 123)\n\nVarianze diverse per gruppo → eteroscedastico:\n\nfit_het &lt;- brm(bf(kid_score ~ mom_hs, sigma ~ mom_hs),\n                 family = gaussian(),  data = kidiq,\n                 backend = \"cmdstanr\", chains = 4, iter = 2000, seed = 123)\n\nAsimmetria → skew-normal:\n\nfit_sn &lt;- brm(kid_score ~ mom_hs, family = skew_normal(), data = kidiq,\n              backend = \"cmdstanr\", chains = 4, iter = 2000, seed = 123)\n\nDopo l’eventuale rifit, ripeti i PPC (globali e per gruppo).\n\n31.6.4 4) Confronto predittivo tra modelli (LOO/ELPD)\nScegliamo il modello che predice meglio nuovi dati simili a quelli osservati.\n\nloo_fit1  &lt;- loo(fit_1)\nloo_fit_t &lt;- loo(fit_t)\nloo_fit_het &lt;- loo(fit_het)\nloo_fit_sn  &lt;- loo(fit_sn)\n\nloo_compare(loo_fit1, loo_fit_t, loo_fit_het, loo_fit_sn)\n#&gt;         elpd_diff se_diff\n#&gt; fit_sn   0.0       0.0   \n#&gt; fit_het -6.0       5.9   \n#&gt; fit_1   -7.4       5.3   \n#&gt; fit_t   -8.8       5.5\n\nNel confronto tra modelli, un modello migliore è caratterizzato da un valore di ELPD più elevato. Quando la differenza nell’ELPD è paragonabile al suo errore standard (se_diff), il vantaggio predittivo può considerarsi modesto; in tali circostanze, è preferibile adottare il modello più semplice che superi le posterior predictive checks. È inoltre opportuno verificare i parametri di forma Pareto \\(k\\): qualora numerosi valori superino la soglia di 0.7, si raccomanda di impiegare la procedura di reloo o di ricorrere alla validazione incrociata k-fold.\nNel caso in esame, il confronto mediante LOO indica un lieve vantaggio predittivo del modello basato sulla distribuzione skew-normal rispetto alle alternative gaussiane, sia omoscedastiche che eteroscedastiche, nonché rispetto al modello con distribuzione t di Student. Tuttavia, le differenze nell’ELPD sono dell’ordine di grandezza dell’errore standard, pertanto l’evidenza a favore della skew-normal risulta moderata. Le posterior predictive checks mostrano un migliore allineamento delle code e della struttura di asimmetria nel caso della skew-normal; per questo motivo, tale modello viene adottato come specificazione principale, affiancandolo da un’analisi di sensibilità delle stime di \\(\\Delta\\) rispetto alle diverse assunzioni di likelihood. Il modesto vantaggio del modello eteroscedastico rispetto all’omoscedastico suggerisce la presenza di differenze nella variabilità tra gruppi, sebbene l’impatto predittivo di tale eterogeneità sia contenuto.\nIn sintesi, il criterio dell’ELPD favorisce il modello skew-normal, sebbene con differenze esigue rispetto alle alternative. La scelta del modello deve essere giustificata congiuntamente in base a: (i) compatibilità predittiva mediante LOO, (ii) esito delle posterior predictive checks, e (iii) robustezza delle quantità sostantive di interesse, quali \\(\\Delta\\), \\(\\Pr(\\Delta &gt; 0)\\) e \\(\\Pr(|\\Delta| &gt; \\text{SESOI})\\). Quando le differenze predittive sono esigue, la stabilità di \\(\\Delta\\) tra diverse specificazioni diventa un elemento cruciale per l’interpretazione sostantiva dei risultati.\nQuesto approccio consente di mantenere l’analisi trasparente e riproducibile, collegando le stime ottenute a domande di ricerca concrete—attraverso l’uso di smallest effect sizes of interest (SESOI)—senza introdurre soglie arbitrarie di significatività.\n\n\n\n\n\n\nDiagnostica MCMC (workflow minimo)\n\n\n\nControllare sistematicamente: Rhat ≈ 1.00, ESS adeguati, assenza di divergenze e E-BFMI bassi; ispezionare pairs() per funnel. Se necessario, aumentare adapt_delta (es. 0.95–0.99) e max_treedepth (es. 15).\n\n\n\n\n\n\n\n\nApprofondimento statistico (opzionale)\n\n\n\n\n\nConsideriamo ora le basi statistiche su cui si basa l’approccio frequentista. Nel paradigma frequentista, l’inferenza sulla differenza tra due gruppi si basa sulla distribuzione campionaria della differenza tra le medie. L’idea di fondo è che, se ripetessimo il campionamento molte volte, otterremmo valori diversi per la differenza tra le medie campionarie, e questa variabilità può essere descritta attraverso una distribuzione probabilistica.\nSupponiamo di avere due popolazioni normali e indipendenti:\n\\[\nY_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2) \\quad \\text{e} \\quad Y_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)\n\\]\ne di osservare due campioni indipendenti, rispettivamente di dimensione \\(n_1\\) e \\(n_2\\).\nSe assumiamo inoltre che le varianze siano uguali (\\(\\sigma_1^2 = \\sigma_2^2 = \\sigma^2\\)), possiamo utilizzare una versione semplificata del modello.\nStatistica di interesse. Il nostro obiettivo è stimare la differenza tra le medie delle due popolazioni, ovvero:\n\\[\n\\mu_1 - \\mu_2.\n\\]\nLa stima di questa quantità è data dalla differenza tra le medie campionarie:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2.\n\\]\nProprietà della statistica campionaria.\nValore atteso. Nel caso di due campioni indipendenti:\n\\[\nE(\\bar{Y}_1 - \\bar{Y}_2) = \\mu_1 - \\mu_2.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nSi parte dalla definizione di media campionaria per ciascun gruppo e si applica la linearità dell’operatore valore atteso:\n\\[\nE(\\bar{Y}_1 - \\bar{Y}_2) = E(\\bar{Y}_1) - E(\\bar{Y}_2) = \\mu_1 - \\mu_2.\n\\]\n\n\n\nVarianza. La varianza della differenza tra le medie campionarie è:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nPoiché i due campioni sono indipendenti, la varianza della differenza si ottiene sommando le varianze delle due medie:\n\\[\n\\operatorname{Var}(\\bar{Y}_1) = \\frac{\\sigma_1^2}{n_1}, \\quad \\operatorname{Var}(\\bar{Y}_2) = \\frac{\\sigma_2^2}{n_2}\n\\]\nquindi:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}.\n\\]\n\n\n\nSe assumiamo varianze uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)), possiamo scrivere:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\sigma^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right).\n\\]\nPoiché \\(\\sigma^2\\) è sconosciuta, la si stima tramite la varianza pooled:\n\\[\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2},\n\\]\ndove \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie:\n\\[\ns_j^2 = \\frac{1}{n_j - 1} \\sum_{i=1}^{n_j} (y_{j,i} - \\bar{y}_j)^2, \\quad j = 1,2.\n\\]\nDistribuzione della statistica. Sotto l’ipotesi di normalità e indipendenza, e assumendo varianze uguali, la statistica \\(\\bar{Y}_1 - \\bar{Y}_2\\) segue (almeno approssimativamente) una distribuzione normale:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2 \\sim \\mathcal{N} \\left( \\mu_1 - \\mu_2,\\ \\sigma \\sqrt{ \\frac{1}{n_1} + \\frac{1}{n_2} } \\right).\n\\]\nQuesta proprietà permette di costruire un intervallo di confidenza al 95% per la differenza tra le medie, oppure di effettuare un test t di Student per due campioni indipendenti, basato sulla seguente statistica:\n\\[\nt = \\frac{(\\bar{Y}_1 - \\bar{Y}_2) - (\\mu_1 - \\mu_2)}{s_p \\sqrt{ \\frac{1}{n_1} + \\frac{1}{n_2} }}.\n\\]\nQuesta statistica segue, sotto l’ipotesi nulla \\(\\mu_1 = \\mu_2\\), una distribuzione t di Student con \\(n_1 + n_2 - 2\\) gradi di libertà.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#riflessioni-conclusive",
    "href": "chapters/linear_models/08_two_means.html#riflessioni-conclusive",
    "title": "31  Confronto tra le medie di due gruppi",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo riformulato il classico problema del confronto tra due medie in chiave bayesiana. Abbiamo visto come il modello possa essere espresso sia come differenza diretta tra le medie di due distribuzioni normali (\\(\\Delta = \\mu_1 - \\mu_0\\)), sia come un semplice modello di regressione con variabile indicatrice. Entrambe le formulazioni portano alla stessa conclusione: ciò che ci interessa non è un verdetto dicotomico sull’esistenza o meno di una differenza, ma la distribuzione delle nostre credenze sulla sua ampiezza.\nL’approccio bayesiano ci fornisce esattamente questo: una distribuzione a posteriori per \\(\\Delta\\), da cui possiamo derivare probabilità direttamente interpretabili, come la probabilità che la differenza sia positiva o che superi una soglia di rilevanza pratica. Questo rappresenta un cambiamento radicale rispetto al frequentismo, dove la risposta si riduce a un p-value, senza informazioni sulla magnitudine dell’effetto né sulla sua plausibilità relativa.\nIl confronto tra due gruppi è un esempio paradigmatico perché mostra con chiarezza i punti di forza dell’inferenza bayesiana: trasparenza, flessibilità e possibilità di collegare l’analisi statistica a domande scientifiche sostantive. Ma rappresenta anche un punto di partenza. Nella ricerca psicologica, infatti, non basta sapere che due medie differiscono: dobbiamo anche chiederci quanto questa differenza sia grande e se abbia una reale rilevanza pratica.\nPer questo, nel capitolo successivo introdurremo il tema della grandezza dell’effetto, collegando la differenza tra medie alla variabilità dei dati e discutendo strumenti per valutare non solo la presenza di un effetto, ma anche la sua importanza scientifica.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        tzdb_0.5.0            haven_2.5.5          \n#&gt; [22] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [25] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [31] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [34] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [37] R.utils_2.13.0        pacman_0.5.1          readr_2.1.5          \n#&gt; [40] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [43] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [46] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [49] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [58] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [61] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [64] hms_1.1.3             rstantools_2.5.0      scales_1.4.0         \n#&gt; [67] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [70] tools_4.5.1           data.table_1.17.8     forcats_1.0.0        \n#&gt; [73] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [76] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [79] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [82] V8_7.0.0              gtable_0.3.6          R.methodsS3_1.8.2    \n#&gt; [85] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [88] farver_2.1.2          R.oo_1.27.1           memoise_2.0.1        \n#&gt; [91] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_two_means.html#bibliografia",
    "href": "chapters/linear_models/08_two_means.html#bibliografia",
    "title": "31  Confronto tra le medie di due gruppi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html",
    "href": "chapters/linear_models/09_effect_size.html",
    "title": "32  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto come formulare il problema dell’inferenza su una media e come estenderlo al confronto tra due gruppi. Questi passaggi ci hanno permesso di comprendere che la domanda scientifica non è semplicemente se esista una differenza, ma quanto grande essa sia e con quale grado di incertezza.\nÈ qui che entra in gioco il concetto di grandezza dell’effetto. Nella ricerca psicologica non basta dimostrare che due gruppi differiscono: occorre valutare se la differenza osservata abbia una rilevanza pratica o teorica. Un effetto può essere statisticamente distinto da zero, ma così piccolo da non avere alcuna importanza sostantiva; al contrario, un effetto di ampiezza moderata o grande può essere cruciale anche se stimato con incertezza.\nIn questo capitolo discuteremo come quantificare la grandezza di un effetto sia in termini assoluti (\\(\\Delta\\), la differenza tra medie) sia in termini standardizzati (\\(d = \\Delta/\\sigma\\)), che permettono il confronto tra studi e misure diverse. L’approccio bayesiano ci offre un vantaggio importante: la possibilità di esprimere la nostra incertezza sulla grandezza dell’effetto attraverso una distribuzione a posteriori e di calcolare probabilità direttamente interpretabili, ad esempio la probabilità che l’effetto superi una soglia di rilevanza pratica (ROPE o SESOI).\nLa grandezza dell’effetto rappresenta quindi un ponte tra la statistica e la sostanza psicologica: ci aiuta a passare da un risultato numerico alla valutazione della sua importanza per la teoria, la pratica clinica o l’intervento applicativo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#introduzione",
    "href": "chapters/linear_models/09_effect_size.html#introduzione",
    "title": "32  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "",
    "text": "Panoramica del capitolo\n\nChe cosa misuriamo quando parliamo di “grandezza dell’effetto”.\nCome stimarlo con modelli bayesiani in brms.\nCome comunicarlo con intervalli e predizioni.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere “Bayesian estimation supersedes the t test” (Kruschke, 2013).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, brms, bayestestR, insight)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#perché-stimare-la-grandezza-delleffetto",
    "href": "chapters/linear_models/09_effect_size.html#perché-stimare-la-grandezza-delleffetto",
    "title": "32  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n32.1 Perché stimare la grandezza dell’effetto",
    "text": "32.1 Perché stimare la grandezza dell’effetto\nLa grandezza dell’effetto fornisce un ponte tra analisi statistica e interpretazione sostanziale dei dati. Essa consente di rispondere a domande come:\n\nQuanto è marcata la differenza osservata?\nL’effetto ha un impatto concreto nella vita reale o nelle applicazioni cliniche?\nLa variazione osservata è sufficiente a giustificare interventi, cambiamenti o nuove ipotesi teoriche?\n\nL’American Psychological Association (APA) raccomanda di riportare sempre una misura di grandezza dell’effetto, in quanto essa fornisce un’informazione critica che va oltre la mera dicotomia “effetto presente / effetto assente”.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#standardizzare-le-differenze-il-d-di-cohen",
    "href": "chapters/linear_models/09_effect_size.html#standardizzare-le-differenze-il-d-di-cohen",
    "title": "32  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n32.2 Standardizzare le differenze: il d di Cohen",
    "text": "32.2 Standardizzare le differenze: il d di Cohen\nNel confronto tra due gruppi, una delle misure più comuni di grandezza dell’effetto è il d di Cohen, che esprime la differenza tra due medie in unità di deviazione standard:\n\\[\nd = \\frac{\\mu_1 - \\mu_2}{\\sigma},\n\\]\ndove:\n\n\n\\(\\mu_1\\) e \\(\\mu_2\\) sono le medie dei due gruppi,\n\n\\(\\sigma\\) è una stima comune della deviazione standard.\n\nL’interpretazione di d è indipendente dalle unità di misura originali, il che la rende particolarmente utile per confrontare risultati provenienti da diversi studi o contesti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#il-d-di-cohen-in-unottica-bayesiana",
    "href": "chapters/linear_models/09_effect_size.html#il-d-di-cohen-in-unottica-bayesiana",
    "title": "32  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n32.3 Il d di Cohen in un’ottica bayesiana",
    "text": "32.3 Il d di Cohen in un’ottica bayesiana\nNell’approccio bayesiano non ci limitiamo a stimare un singolo valore di d. L’idea è diversa: costruiamo una distribuzione a posteriori di valori plausibili per la grandezza dell’effetto. Questa distribuzione si ottiene combinando i campioni posteriori della differenza tra gruppi con quelli della deviazione standard residua. In questo modo, invece di una stima unica, otteniamo un quadro completo delle incertezze ancora presenti dopo aver osservato i dati.\n\n32.3.1 Esempio pratico con brms\n\nRiprendiamo il modello già stimato nel capitolo precedente:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  backend = \"cmdstanr\",\n  silent = 0\n)\n\nDai campioni posteriori estraiamo sia la stima della differenza tra i gruppi (b_mom_hs) sia la stima della deviazione standard residua (sigma). Dividendo i due otteniamo i campioni della distribuzione di Cohen’s d:\n\npost &lt;- as_draws_df(fit_1)\nd_samples &lt;- post$b_mom_hs / post$sigma\n\n\n32.3.2 Visualizzare la distribuzione di d\n\nLa distribuzione a posteriori di d si può esplorare graficamente. Ad esempio:\n\nmcmc_areas(as_draws_df(tibble(d = d_samples)), pars = \"d\", prob = 0.89) \n\n\n\n\n\n\n\nIl grafico mostra l’intero intervallo di valori plausibili per la grandezza dell’effetto, mettendo in evidenza la regione che contiene l’89% degli esiti più credibili. È una rappresentazione diretta dell’incertezza che rimane anche dopo aver osservato i dati.\n\n32.3.3 Statistiche riassuntive\nPer sintetizzare numericamente i risultati si può usare la funzione describe_posterior():\n\nbayestestR::describe_posterior(d_samples, ci = 0.89)\n#&gt; Summary of Posterior Distribution\n#&gt; \n#&gt; Parameter | Median |       89% CI |   pd |          ROPE | % in ROPE\n#&gt; --------------------------------------------------------------------\n#&gt; Posterior |   0.60 | [0.41, 0.78] | 100% | [-0.10, 0.10] |        0%\n\nQuesta funzione restituisce la stima centrale (media o mediana), l’intervallo di credibilità, e la probabilità che la grandezza dell’effetto superi o resti al di sotto di valori soglia rilevanti.\n\n32.3.4 Interpretare la grandezza dell’effetto\nNella tradizione frequentista è comune adottare la classificazione proposta da Cohen:\n\n\nValore di d\n\nInterpretazione convenzionale\n\n\n\n≈ 0.2\nEffetto piccolo\n\n\n≈ 0.5\nEffetto medio\n\n\n≥ 0.8\nEffetto grande\n\n\n\nQueste soglie sono utili come orientamento, ma rischiano di essere applicate in modo meccanico. L’approccio bayesiano offre un vantaggio importante: consente di trasformare queste soglie in domande probabilistiche. Possiamo chiederci, ad esempio, qual è la probabilità che d sia almeno pari a 0.5, oppure la probabilità che resti al di sotto di 0.2. Con i campioni posteriori queste domande trovano risposta diretta:\n\nmean(d_samples &gt; 0.5)  # Probabilità che l'effetto sia almeno medio\n#&gt; [1] 0.793\nmean(d_samples &gt; 0.8)  # Probabilità che l'effetto sia grande\n#&gt; [1] 0.042\nmean(d_samples &lt; 0.2)  # Probabilità che l'effetto sia trascurabile\n#&gt; [1] 0.00025\n\nIn questo modo non abbiamo un giudizio binario (grande/piccolo), ma una descrizione più sfumata e realistica.\n\n32.3.5 La soglia di rilevanza pratica\nIn applicazioni concrete non è sufficiente stabilire che l’effetto sia diverso da zero: è necessario valutare se supera una soglia di rilevanza pratica (minimum effect of interest, o ROPE — region of practical equivalence).\nSupponiamo, per esempio, che uno psicologo clinico ritenga irrilevante qualsiasi effetto inferiore a d = 0.3. In questo caso, la domanda da porsi è: qual è la probabilità che l’effetto osservato sia superiore a 0.3? La risposta si ottiene immediatamente dai campioni posteriori:\n\nmean(d_samples &gt; 0.3)\n#&gt; [1] 0.994\n\nQuesto numero esprime in modo diretto la probabilità che la differenza osservata abbia una rilevanza clinica concreta, spostando l’attenzione da soglie arbitrarie a valutazioni fondate sulle esigenze specifiche del contesto.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/09_effect_size.html#riflessioni-conclusive",
    "title": "32  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come la differenza tra due gruppi non debba essere valutata solo in termini di esistenza, ma anche di ampiezza e di rilevanza pratica. L’approccio bayesiano ci permette di quantificare questa ampiezza attraverso la distribuzione a posteriori dell’effetto, fornendo una rappresentazione trasparente dell’incertezza e consentendo di calcolare probabilità direttamente interpretabili: la probabilità che l’effetto sia positivo, che superi una soglia di rilevanza pratica, o che ricada in una regione di equivalenza.\nQuesta prospettiva sposta l’attenzione dal verdetto dicotomico tipico dell’approccio frequentista alla valutazione sfumata e continua della plausibilità dei diversi scenari. In altre parole, non ci limitiamo più a dire se un effetto “c’è o non c’è”, ma cerchiamo di capire quanto sia importante in rapporto alle nostre domande scientifiche e applicative.\nLa grandezza dell’effetto rappresenta dunque un punto di incontro tra la statistica e la psicologia: ci ricorda che i numeri hanno senso solo se inseriti in un contesto teorico e pratico, e che l’obiettivo ultimo dell’analisi non è solo descrivere i dati, ma trarne indicazioni utili per la comprensione dei fenomeni.\nIl passo successivo è conseguente: se l’interesse è valutare effetti di una certa ampiezza, diventa cruciale chiedersi quanti dati servono per stimarli con un’incertezza accettabile. Nel prossimo capitolo affronteremo quindi il tema della pianificazione della dimensione campionaria, mostrando come il quadro bayesiano possa guidare scelte di ricerca più consapevoli ed efficienti.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      ggridges_0.5.7        compiler_4.5.1       \n#&gt; [10] reshape2_1.4.4        systemfonts_1.2.3     vctrs_0.6.5          \n#&gt; [13] stringr_1.5.1         pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        tzdb_0.5.0            haven_2.5.5          \n#&gt; [22] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [25] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [31] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [34] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [37] R.utils_2.13.0        pacman_0.5.1          readr_2.1.5          \n#&gt; [40] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [43] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [46] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [49] pkgbuild_1.4.8        plyr_1.8.9            lattice_0.22-7       \n#&gt; [52] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [55] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [58] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [61] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [64] hms_1.1.3             rstantools_2.5.0      scales_1.4.0         \n#&gt; [67] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [70] tools_4.5.1           data.table_1.17.8     forcats_1.0.0        \n#&gt; [73] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [76] datawizard_1.2.0      colorspace_2.1-1      nlme_3.1-168         \n#&gt; [79] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [82] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [85] R.methodsS3_1.8.2     digest_0.6.37         TH.data_1.1-4        \n#&gt; [88] htmlwidgets_1.6.4     farver_2.1.2          R.oo_1.27.1          \n#&gt; [91] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [94] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_effect_size.html#bibliografia",
    "href": "chapters/linear_models/09_effect_size.html#bibliografia",
    "title": "32  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html",
    "href": "chapters/linear_models/10_sample_size.html",
    "title": "33  Pianificazione della dimensione campionaria",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto come stimare la media di una popolazione, come confrontare due gruppi e come valutare la grandezza di un effetto. Un filo conduttore è emerso chiaramente: ogni stima statistica è accompagnata da un margine di incertezza, che può essere più o meno ampio a seconda della quantità di dati a disposizione.\nQuesto ci porta a una domanda pratica fondamentale: quanti dati servono per affrontare in modo credibile la nostra domanda di ricerca? In psicologia, come in molte altre scienze sociali, raccogliere dati è spesso costoso e impegnativo. Pianificare in anticipo la dimensione campionaria significa quindi trovare un equilibrio tra vincoli pratici e obiettivi scientifici, evitando sia studi troppo piccoli — che producono stime imprecise e poco informative — sia campioni eccessivamente grandi, che sprecano risorse senza reale beneficio.\nNell’approccio frequentista, la pianificazione campionaria è tradizionalmente legata al concetto di potenza statistica: il calcolo della probabilità di rifiutare l’ipotesi nulla quando l’effetto è presente. In un’ottica bayesiana, lo stesso problema può essere affrontato in modo più trasparente, attraverso simulazioni o analisi predittive che ci permettono di esplorare come l’ampiezza dell’effetto atteso e il numero di osservazioni influiscano sulla precisione delle stime e sulla probabilità di trarre conclusioni scientificamente utili.\nIn questo capitolo vedremo come impostare la pianificazione della dimensione campionaria in chiave bayesiana, utilizzando esempi concreti e mostrando come la nozione di “grandezza dell’effetto” si traduca in criteri pratici per decidere il numero di partecipanti da includere in uno studio psicologico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html#introduzione",
    "href": "chapters/linear_models/10_sample_size.html#introduzione",
    "title": "33  Pianificazione della dimensione campionaria",
    "section": "",
    "text": "Panoramica del capitolo\n\nPresentare la definizione frequentista di potenza e il calcolo classico della dimensione campionaria.\nDiscutere i limiti della potenza (soglie arbitrarie, stime imprecise, false certezze).\nIntrodurre l’approccio bayesiano, basato su criteri di precisione e utilità pratica delle stime.\nMostrare l’uso della simulazione generativa per valutare in anticipo l’informatività di uno studio.\nFornire strumenti per pianificare campioni che producano risultati solidi e interpretabili in psicologia.\n\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nConsultare Regression and Other Stories (Gelman et al., 2021).\nPrestare particolare attenzione al capitolo 16, “Design and sample size decisions”, che offrono una guida dettagliata al tema del potere statistico frequentista che spesso genera aspettative irrealistiche sulla rilevabilità degli effetti e conduce alla progettazione di studi con elevata variabilità e scarso valore informativo.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice, brms, cmdstanr)\n\n\n\n\n\n\n\n\n\n\nCollegamento con ROS\n\n\n\n\n\nNel capitolo 16 di Regression and Other Stories (Gelman et al., 2021) viene illustrato l’approccio frequentista alla pianificazione campionaria, basato sul calcolo della potenza. In questo capitolo riprendiamo quel punto di partenza ma allarghiamo la prospettiva:\n\n\ncontinuità: riconosciamo il ruolo della potenza come strumento tradizionale di progettazione degli studi;\n\nestensione: mostriamo come, in ottica bayesiana, la pianificazione si concentri non sul p-value ma sulla precisione delle stime e sulla loro utilità pratica;\n\nstrumenti aggiuntivi: introduciamo la simulazione generativa, che permette di verificare, prima della raccolta dati, se un disegno è in grado di produrre risultati realmente informativi.\n\nIn questo modo gli studenti possono collocare quanto vedranno qui come un passo successivo e complementare rispetto a ROS.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html#lapproccio-frequentista",
    "href": "chapters/linear_models/10_sample_size.html#lapproccio-frequentista",
    "title": "33  Pianificazione della dimensione campionaria",
    "section": "\n33.1 L’approccio frequentista",
    "text": "33.1 L’approccio frequentista\nNel framework frequentista, la potenza è definita come la probabilità, calcolata prima che uno studio venga condotto, che un determinato test statistico produca un p-value inferiore a una soglia prestabilita (tipicamente 0,05), dato un effetto reale ipotizzato.\nIl calcolo della potenza richiede:\n\nuna stima della dimensione dell’effetto atteso,\nuna stima della variabilità nei dati (deviazione standard),\nuna decisione sulla soglia di significatività,\ne infine un calcolo (o simulazione) della probabilità che il p-value sia &lt; 0.05.\n\nSi sconsiglia in genere di condurre studi con potenza bassa, perché hanno una bassa probabilità di produrre risultati “significativi”. Tuttavia, questo ragionamento non considera che il concetto stesso di significatività può essere fuorviante: anche quando un test ha potenza dell’80%, ciò non garantisce che l’effetto stimato sia preciso o utile.\n\n\n\n\n\n\nPerché non basta l’80% di potenza? Uno studio con potenza dell’80% può comunque produrre risultati distorti: gli effetti osservati tendono a essere esagerati (errore di tipo M, magnitude), o addirittura sbagliati nel segno (errore di tipo S, sign). Questo accade perché la potenza misura solo la probabilità di ottenere p &lt; .05, non la precisione né l’utilità pratica delle stime.\n\n\n\n\n33.1.1 La maledizione del vincitore\nUno studio con bassa potenza può produrre risultati statisticamente significativi che sono ingannevoli. In presenza di molto rumore, gli effetti significativi osservati tendono a essere:\n\n\nesagerati (errore di tipo \\(M\\), magnitude),\n\nsbagliati nel segno (errore di tipo \\(S\\), sign).\n\nIn altre parole, anche quando uno studio riesce a “scoprire” un effetto, la stima ottenuta può essere gravemente distorta. Questa è una delle ragioni principali per cui molti risultati pubblicati si rivelano non replicabili (Gelman & Carlin, 2014).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html#un-esempio-concreto",
    "href": "chapters/linear_models/10_sample_size.html#un-esempio-concreto",
    "title": "33  Pianificazione della dimensione campionaria",
    "section": "\n33.2 Un esempio concreto",
    "text": "33.2 Un esempio concreto\nPer rendere il confronto più chiaro, usiamo un esempio con gli stessi dati in entrambi gli approcci:\n\ndifferenza vera tra le medie: \\(\\Delta = 5\\);\ndeviazione standard comune: \\(\\sigma = 10\\);\ndimensione del campione: \\(n = 64\\) per gruppo;\neffetto standardizzato: Cohen’s d = 0.5\n\n\n\n33.2.1 Analisi frequentista: dimensione del campione per potenza dell’80%\nPer stimare la dimensione del campione necessaria a ottenere una potenza dell’80% in un confronto tra due gruppi indipendenti (con varianza uguale), possiamo usare la funzione power.t.test() disponibile in R.\nNel nostro esempio ipotizziamo:\n\nuna differenza attesa tra i gruppi pari a \\(\\Delta = 5\\),\nuna deviazione standard comune pari a \\(\\sigma = 10\\),\nun test bilaterale con livello di significatività \\(\\alpha = 0.05\\).\n\n\n33.2.1.1 Calcolo in R\n\n# Calcolo della dimensione campionaria necessaria per 80% di potenza\npower.t.test(\n  delta = 5,        # differenza attesa tra le medie\n  sd    = 10,       # deviazione standard\n  power = 0.8,      # potenza desiderata\n  sig.level = 0.05, # livello di significatività\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 63.8\n#&gt;           delta = 5\n#&gt;              sd = 10\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.8\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\nIl risultato indica che sono necessari circa 64 partecipanti per gruppo per ottenere l’80% di potenza con questi parametri. Tuttavia, come vedremo nella sezione successiva, questo valore non garantisce necessariamente che la stima dell’effetto sarà sufficientemente precisa o utile dal punto di vista decisionale. L’analisi bayesiana ci offrirà uno strumento più flessibile per valutare l’informatività del disegno proposto.\n\n33.2.2 Analisi bayesiana: informatività a posteriori\nNell’approccio bayesiano, non ci si chiede se l’effetto è “significativo” rispetto a una soglia arbitraria, ma quanto è informativo il risultato per prendere decisioni pratiche. In questo contesto, pianificare uno studio significa domandarsi:\n“Con quanti dati il mio modello bayesiano riuscirà a fornire una stima sufficientemente precisa e utile dell’effetto?”\nPer rispondere, possiamo stabilire dei criteri di informatività che riflettano le esigenze del nostro problema. Due criteri possibili sono:\n\nl’intervallo di credibilità all’89% per Cohen’s d ha larghezza ≤ 0.4 (criterio di precisione);\nla probabilità a posteriori che d &gt; 0.3 è ≥ 90% (criterio di utilità pratica).\n\n\n33.2.2.1 Simulazione generativa di uno studio\nPer verificare se un disegno sperimentale con \\(n = 64\\) per gruppo soddisfa questi criteri, possiamo simulare uno studio 100 volte, ogni volta:\n\ngenerando nuovi dati,\nstimando un modello bayesiano,\nvalutando se il risultato è sufficientemente informativo.\n\nDi seguito definiamo la funzione sim_once() che esegue una singola simulazione.\n\n# Funzione per standardizzare su scala z\nstandardise &lt;- function(x) (x - mean(x)) / sd(x)\n\n# Una singola simulazione bayesiana di uno studio\nsim_once &lt;- function(n = 64, mu0 = 100, delta = 5, sigma = 10) {\n\n  # 1. Generazione dei dati\n  y0 &lt;- rnorm(n, mu0, sigma)         # gruppo controllo\n  y1 &lt;- rnorm(n, mu0 + delta, sigma) # gruppo trattamento\n\n  # 2. Standardizzazione\n  dat &lt;- tibble(score = standardise(c(y0, y1)),\n                group = factor(rep(c(\"ctrl\", \"trt\"), each = n)))\n\n  # 3. Stima del modello bayesiano\n  fit &lt;- brm(score ~ group,\n             data = dat,\n             backend = \"cmdstanr\",\n             chains = 2, iter = 1000, warmup = 500,\n             refresh = 0, silent = 0,\n             prior = c(\n               prior(normal(0, 2), class = \"b\"),\n               prior(exponential(2), class = \"sigma\")\n             ))\n\n  # 4. Estrazione dei campioni posteriori e calcolo di Cohen's d\n  post &lt;- as_draws_df(fit)\n  d_smp &lt;- post$b_grouptrt / post$sigma\n\n  # 5. Output: due indici di informatività\n  tibble(\n    CIw89  = diff(quantile(d_smp, c(.055, .945))),  # larghezza IC 89%\n    p_gt03 = mean(d_smp &gt; 0.3)                      # P(d &gt; 0.3)\n  )\n}\n\nEcco cosa succede passo passo:\n\nSimulazione dei dati\n\n  y0 &lt;- rnorm(n, mu0, sigma)\n  y1 &lt;- rnorm(n, mu0 + delta, sigma)\n\n\nSi generano due gruppi di n = 64 osservazioni:\n\nIl gruppo di controllo ha media mu0 = 100.\nIl gruppo trattamento ha media aumentata di delta = 5.\nEntrambi i gruppi hanno la stessa variabilità (sigma = 10).\n\n\nIn pratica: simula un esperimento in cui il trattamento ha un effetto medio di 5 unità.\n\n\nStandardizzazione dei dati\n\n  score = standardise(c(y0, y1))\n\nLe osservazioni dei due gruppi vengono unite e standardizzate (portate su scala z): media = 0, deviazione standard = 1.\n\nQuesto serve a:\n\nrendere i dati comparabili tra simulazioni,\nsemplificare l’interpretazione dei risultati (si lavora su scala standardizzata).\n\n\n\n\nCreazione del dataset\n\n  dat &lt;- tibble(score = ..., group = ...)\n\n\nSi crea una tabella con le variabili:\n\nscore: i dati standardizzati\ngroup: un’etichetta che indica se il dato appartiene al gruppo controllo (ctrl) o trattamento (trt).\n\n\n\n\nStima del modello bayesiano\n\n  fit &lt;- brm(score ~ group, ...)\n\n\nSi stima un modello bayesiano con brms, dove:\n\nla variabile score è prevista dalla variabile group,\nsi usano priori debolmente informativi su effetto (b) e variabilità (sigma).\n\n\nIl coefficiente b_grouptrt stima la differenza media tra i gruppi (sulla scala standardizzata).\n\n\nEstrazione dei campioni posteriori\n\n  post &lt;- as_draws_df(fit)\n  d_smp &lt;- post$b_grouptrt / post$sigma\n\nSi estraggono i campioni dalla distribuzione a posteriori.\nSi calcola Cohen’s d a posteriori dividendo l’effetto stimato per la deviazione standard stimata: d_smp.\n\n\nOutput: due indicatori di informatività\n\n  tibble(\n    CIw89  = diff(quantile(d_smp, c(.055, .945))),\n    p_gt03 = mean(d_smp &gt; 0.3)\n  )\n\n\nCIw89: larghezza dell’intervallo di credibilità all’89% → misura di precisione.\n\np_gt03: proporzione dei campioni a posteriori in cui d &gt; 0.3 → misura di utilità pratica.\n\nIn sintesi, ogni volta che chiami sim_once():\n\nsimuli un nuovo dataset realistico;\nstimi l’effetto del trattamento con un modello bayesiano;\nmisuri quanto è preciso e informativo il risultato.\n\nQuesta funzione è il mattone fondamentale per la simulazione generativa di uno studio: ti permette di verificare, ad esempio, se con n = 64 per gruppo riesci a stimare d in modo sufficientemente utile.\n\n33.2.2.2 Esecuzione della simulazione\nSimuliamo 100 studi indipendenti con n = 64 per gruppo:\n\nset.seed(123)\nres &lt;- bind_rows(replicate(100, sim_once(), simplify = FALSE))\n\nEsaminiamo i risultati della simulazione:\n\nresum &lt;- summarise(res,\n  mean_CI   = mean(CIw89),\n  sd_CI     = sd(CIw89),\n  prop_good = mean(p_gt03 &gt;= 0.9)\n)\nprint(resum)\n#&gt; # A tibble: 1 × 3\n#&gt;   mean_CI  sd_CI prop_good\n#&gt;     &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1   0.570 0.0204      0.33\n\n\n33.2.2.3 Visualizzazione dei risultati\nIl primo grafico mostra la distribuzione delle larghezze degli intervalli di credibilità all’89%, evidenziando quante simulazioni superano la soglia di 0.4. Il secondo mostra quante simulazioni soddisfano il criterio di utilità.\n\n# Grafico 1: distribuzione della larghezza IC89\nggplot(res, aes(x = CIw89)) +\n  geom_histogram(binwidth = 0.02) +\n  geom_vline(xintercept = 0.4) +\n  labs(\n    x = \"Larghezza IC89\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\n# Grafico 2: classificazione delle simulazioni utili/non utili\nggplot(res, aes(x = p_gt03 &gt;= 0.9)) +\n  geom_bar() +\n  scale_x_discrete(labels = c(\"FALSE\" = \"Non utile\", \"TRUE\" = \"Utile\")) +\n  labs(\n    x = \"Criterio: P(d &gt; 0.3) ≥ 0.9\",\n    y = \"Numero di simulazioni\"\n  ) \n\n\n\n\n\n\n\n\n33.2.2.4 Interpretazione dei risultati\n\n\nmean_CI rappresenta la larghezza media dell’intervallo di credibilità all’89%. Nel nostro caso è circa 0.569, quindi troppo ampio per considerare la stima precisa.\n\nprop_good è la proporzione di simulazioni in cui l’evidenza a favore di un effetto pratico d &gt; 0.3 supera il 90%. Con prop_good = 0.1, solo 1 simulazione su 10 soddisfa questo criterio.\n\nConclusione: con n = 64 per gruppo, lo studio simulato è sottodimensionato: raramente produce una stima precisa e utile. Serve un campione più grande (es. n = 80 o n = 100) per raggiungere criteri più severi di informatività.\n\n33.2.2.5 Confronto con la potenza frequentista\nSecondo l’approccio frequentista, n = 64 per gruppo garantisce circa 80% di potenza per d = 0.5. Ma la simulazione bayesiana mostra che:\n\nl’intervallo di credibilità risulta troppo ampio (≈ 0.57);\nl’evidenza utile (P(d &gt; 0.3) ≥ 0.9) si verifica solo nel 10% dei casi.\n\nQuesto evidenzia i limiti della potenza come unico criterio per pianificare gli studi. Anche uno studio “con potenza adeguata” potrebbe produrre risultati imprecisi o non praticabili, e contribuire agli errori di tipo M (esagerazione della stima) o S (errore nel segno dell’effetto).\nIn sintesi, pianificare uno studio non significa garantire il p &lt; .05, ma garantire che la stima sia abbastanza precisa e utile per informare decisioni.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/10_sample_size.html#riflessioni-conclusive",
    "title": "33  Pianificazione della dimensione campionaria",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come la questione della dimensione campionaria sia inseparabile dal problema dell’inferenza statistica. Ogni stima è accompagnata da incertezza, e l’ampiezza di questa incertezza dipende in larga misura dal numero di osservazioni a disposizione. Studiare quante persone includere in un’indagine non è quindi un passaggio tecnico secondario, ma una scelta sostanziale che determina la credibilità e l’utilità scientifica dei risultati.\nL’approccio bayesiano ci offre strumenti flessibili per affrontare questo problema. Attraverso simulazioni e analisi predittive possiamo esplorare in anticipo gli scenari più plausibili, valutare come diverse dimensioni campionarie incidano sulla precisione delle stime e collegare le nostre decisioni a soglie di rilevanza pratica. Questo rende la pianificazione non più un esercizio astratto, ma un vero e proprio strumento di progettazione della ricerca, in cui obiettivi teorici, risorse pratiche e criteri di utilità scientifica sono considerati insieme.\nIl percorso che abbiamo seguito — dalla stima di una media al confronto tra due gruppi, dalla valutazione della grandezza dell’effetto alla pianificazione campionaria — ci consegna un quadro coerente: fare statistica in psicologia significa gestire l’incertezza in modo esplicito, valutare l’importanza degli effetti osservati e pianificare con consapevolezza la raccolta dei dati.\nNel prossimo capitolo vedremo come l’ANOVA a una via si inserisca in questo stesso quadro, come caso particolare del modello lineare. Questo ci permetterà di consolidare ulteriormente la visione unificata che abbiamo sviluppato e di collegare strumenti apparentemente diversi all’interno di un impianto metodologico comune.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        mice_3.18.0           pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              nloptr_2.2.1         \n#&gt; [22] ragg_1.5.0            purrr_1.1.0           jomo_2.7-6           \n#&gt; [25] xfun_0.53             glmnet_4.1-10         cachem_1.1.0         \n#&gt; [28] jsonlite_2.0.0        pan_1.9               broom_1.0.9          \n#&gt; [31] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [34] RColorBrewer_1.1-3    rpart_4.1.24          boot_1.3-32          \n#&gt; [37] lubridate_1.9.4       estimability_1.5.1    iterators_1.0.14     \n#&gt; [40] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [43] nnet_7.3-20           Matrix_1.7-4          splines_4.5.1        \n#&gt; [46] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [49] yaml_2.3.10           codetools_0.2-20      processx_3.8.6       \n#&gt; [52] curl_7.0.0            pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [55] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [58] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [61] tensorA_0.36.2.1      checkmate_2.3.3       foreach_1.5.2        \n#&gt; [64] stats4_4.5.1          reformulas_0.4.1      distributional_0.5.0 \n#&gt; [67] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [70] scales_1.4.0          minqa_1.2.8           xtable_1.8-4         \n#&gt; [73] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [76] data.table_1.17.8     lme4_1.1-37           mvtnorm_1.3-3        \n#&gt; [79] grid_4.5.1            rbibutils_2.3         QuickJSR_1.8.0       \n#&gt; [82] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [85] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [88] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [91] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [94] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [97] mitml_0.4-5           MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_sample_size.html#bibliografia",
    "href": "chapters/linear_models/10_sample_size.html#bibliografia",
    "title": "33  Pianificazione della dimensione campionaria",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html",
    "href": "chapters/linear_models/11_anova_1via.html",
    "title": "34  ANOVA ad una via",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo affrontato l’inferenza su una media, il confronto tra due gruppi e la valutazione della grandezza dell’effetto. Abbiamo visto come questi problemi possano essere formulati in modo elegante all’interno del modello lineare e affrontati sia con l’approccio frequentista sia con quello bayesiano.\nUn passo ulteriore, molto frequente nella ricerca psicologica, è il confronto tra più di due gruppi o condizioni. Pensiamo, ad esempio, a uno studio in cui vogliamo confrontare il livello medio di ansia in tre diversi contesti sperimentali, o a una ricerca educativa che mette a confronto più metodi di insegnamento. In questi casi, la domanda non è più soltanto se due medie differiscono, ma se esistono differenze sistematiche tra più gruppi.\nLo strumento tradizionalmente utilizzato in ambito frequentista è l’ANOVA a una via (Analysis of Variance), che permette di testare l’ipotesi nulla di uguaglianza tra tutte le medie di popolazione. Tuttavia, come per i casi precedenti, anche qui la prospettiva bayesiana offre un quadro più ricco: non ci limita a un verdetto dicotomico, ma ci restituisce la distribuzione a posteriori dei parametri, consentendo di quantificare la plausibilità di scenari diversi e di valutare l’ampiezza delle differenze.\nIn questo capitolo vedremo come l’ANOVA a una via possa essere interpretata come un caso particolare del modello di regressione lineare con variabile indicatrice, e come possa essere affrontata in chiave bayesiana per ottenere inferenze più trasparenti e direttamente interpretabili. In questo modo, l’ANOVA non appare come uno strumento separato, ma come parte integrante di un impianto metodologico unificato, fondato sul modello lineare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#introduzione",
    "href": "chapters/linear_models/11_anova_1via.html#introduzione",
    "title": "34  ANOVA ad una via",
    "section": "",
    "text": "Panoramica del capitolo\n\nFare inferenza sulla media di un campione.\nTrovare le distribuzioni a posteriori usando brms.\nVerificare il modello usando i pp-check plots.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Geocentric models di Statistical rethinking (McElreath, 2020).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#codifica-del-modello-con-variabili-dummy",
    "href": "chapters/linear_models/11_anova_1via.html#codifica-del-modello-con-variabili-dummy",
    "title": "34  ANOVA ad una via",
    "section": "\n34.1 Codifica del modello con variabili dummy",
    "text": "34.1 Codifica del modello con variabili dummy\nSupponiamo un esperimento con tre gruppi. Per rappresentare questo fattore all’interno di un modello lineare, usiamo due variabili dummy e consideriamo il terzo gruppo come riferimento implicito. Il modello assume la forma:\n\\[\nY_i = \\alpha + \\gamma_1 D_{i1} + \\gamma_2 D_{i2} + \\varepsilon_i\n\\tag{34.1}\\]\ndove:\n\n\n\\(\\alpha\\) è l’intercetta del modello,\n\n\\(\\gamma_1\\) e \\(\\gamma_2\\) sono i coefficienti associati alle variabili dummy,\n\n\\(D_{i1}\\) e \\(D_{i2}\\) indicano l’appartenenza dell’osservazione \\(i\\) ai gruppi 1 e 2, rispettivamente,\n\n\\(\\varepsilon_i\\) è l’errore aleatorio.\n\nLa codifica delle dummy è la seguente:\n\\[\n\\begin{array}{c|cc}\n\\text{Gruppo} & D_{1} & D_{2} \\\\\n\\hline\n1 & 1 & 0 \\\\\n2 & 0 & 1 \\\\\n3 & 0 & 0\n\\end{array}\n\\tag{34.2}\\]\n\n34.1.1 Interpretazione dei parametri\nCon questa codifica, possiamo esprimere le medie di ciascun gruppo come:\n\\[\n\\begin{aligned}\n\\mu_1 &= \\alpha + \\gamma_1 \\\\\n\\mu_2 &= \\alpha + \\gamma_2 \\\\\n\\mu_3 &= \\alpha\n\\end{aligned}\n\\]\nDa cui otteniamo:\n\\[\n\\alpha = \\mu_3, \\quad \\gamma_1 = \\mu_1 - \\mu_3, \\quad \\gamma_2 = \\mu_2 - \\mu_3.\n\\]\nQuindi:\n\n\n\\(\\alpha\\): media del gruppo 3 (riferimento),\n\n\\(\\gamma_1\\): quanto il gruppo 1 si discosta da \\(\\mu_3\\),\n\n\\(\\gamma_2\\): quanto il gruppo 2 si discosta da \\(\\mu_3\\).\n\nIn un’ottica bayesiana, questi coefficienti possono essere pensati come distribuzioni: esprimono quanto crediamo che ciascuna differenza sia plausibile, date le osservazioni. Passiamo ora a una simulazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#simulazione",
    "href": "chapters/linear_models/11_anova_1via.html#simulazione",
    "title": "34  ANOVA ad una via",
    "section": "\n34.2 Simulazione",
    "text": "34.2 Simulazione\nSimuliamo un esperimento con tre condizioni: controllo, psicoterapia1 e psicoterapia2. Ogni gruppo ha una media diversa ma la stessa deviazione standard. Ci interessa modellare la variabilità tra le condizioni e interpretare le differenze in modo probabilistico.\n\nset.seed(123)\n\nn &lt;- 30  # numero di osservazioni per gruppo\n# Medie di ciascun gruppo\nmean_control &lt;- 30\nmean_psico1  &lt;- 25\nmean_psico2  &lt;- 20\n# Deviazione standard comune\nsd_value &lt;- 5\n\n# Generazione dei dati\ncontrollo     &lt;- rnorm(n, mean_control, sd_value)\npsicoterapia1 &lt;- rnorm(n, mean_psico1,  sd_value)\npsicoterapia2 &lt;- rnorm(n, mean_psico2,  sd_value)\n\n# Creazione del data frame\ndf &lt;- data.frame(\n  condizione = rep(c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\"), each = n),\n  punteggio  = c(controllo, psicoterapia1, psicoterapia2)\n)\n\ndf |&gt; head()\n#&gt;   condizione punteggio\n#&gt; 1  controllo      27.2\n#&gt; 2  controllo      28.8\n#&gt; 3  controllo      37.8\n#&gt; 4  controllo      30.4\n#&gt; 5  controllo      30.6\n#&gt; 6  controllo      38.6\n\n\n34.2.1 Esplorazione iniziale\nVisualizziamo le distribuzioni dei punteggi:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +\n  geom_violin(trim = FALSE, color = css_palette$text_primary, linewidth = 0.3) +\n  geom_boxplot(width = 0.22, outlier.shape = NA,\n               color = css_palette$text_primary, fill = scales::alpha(\"white\", 0.55)) +\n  labs(x = \"Condizione sperimentale\", y = \"Punteggio di depressione\") +\n  scale_fill_manuscript(limits = levels(df$condizione), drop = FALSE) +  \n  theme_manuscript() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nCalcoliamo media e deviazione standard per ogni gruppo:\n\ndf |&gt; \n  group_by(condizione) |&gt; \n  summarize(\n    media = mean(punteggio),\n    sd = sd(punteggio)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   condizione    media    sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 controllo      29.8  4.91\n#&gt; 2 psicoterapia1  25.9  4.18\n#&gt; 3 psicoterapia2  20.1  4.35",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#modello-lineare-con-variabili-dummy",
    "href": "chapters/linear_models/11_anova_1via.html#modello-lineare-con-variabili-dummy",
    "title": "34  ANOVA ad una via",
    "section": "\n34.3 Modello lineare con variabili dummy",
    "text": "34.3 Modello lineare con variabili dummy\nConvertiamo condizione in fattore e definiamo controllo come categoria di riferimento:\n\ndf$condizione &lt;- factor(df$condizione)\ndf$condizione &lt;- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#&gt;               psicoterapia1 psicoterapia2\n#&gt; controllo                 0             0\n#&gt; psicoterapia1             1             0\n#&gt; psicoterapia2             0             1\n\nIl modello di regressione con le variabili dummy sarà:\n\\[\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{psicoterapia1}_i + \\beta_2 \\cdot \\text{psicoterapia2}_i + \\varepsilon_i,\n\\]\ndove:\n\n\n\\(\\beta_0\\) è la media del gruppo di controllo;\n\n\\(\\beta_1\\) e \\(\\beta_2\\) sono le differenze tra le rispettive psicoterapie e il gruppo di controllo.\n\n\n34.3.1 Stima del modello\nEseguiamo una prima analisi usando il metodo di massima verosimiglianza:\n\nfm1 &lt;- lm(punteggio ~ condizione, data = df)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)               29.764      0.819   36.33  &lt; 2e-16\n#&gt; condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#&gt; condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nVerifica delle medie e differenze tra i gruppi:\n\nout &lt;- tapply(df$punteggio, df$condizione, mean)\nout[2] - out[1]  # psicoterapia1 - controllo\n#&gt; psicoterapia1 \n#&gt;         -3.87\nout[3] - out[1]  # psicoterapia2 - controllo\n#&gt; psicoterapia2 \n#&gt;         -9.64",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#contrasti-personalizzati",
    "href": "chapters/linear_models/11_anova_1via.html#contrasti-personalizzati",
    "title": "34  ANOVA ad una via",
    "section": "\n34.4 Contrasti personalizzati",
    "text": "34.4 Contrasti personalizzati\nI contrasti ci permettono di andare oltre il test globale e formulare ipotesi teoriche mirate. Ad esempio:\n\nla media del gruppo controllo è diversa dalla media delle due psicoterapie?\nle due psicoterapie differiscono tra loro?\n\nA questo fine, specifichiamo la seguente matrice dei contrasti:\n\nmy_contrasts &lt;- matrix(c(\n  0.6667,  0,     # controllo\n -0.3333,  0.5,   # psicoterapia1\n -0.3333, -0.5    # psicoterapia2\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts) &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\ncontrasts(df$condizione) &lt;- my_contrasts\n\nAdattiamo il modello:\n\nmod_custom &lt;- lm(punteggio ~ condizione, data = df)\n\nEsaminiamo i coefficienti:\n\nsummary(mod_custom)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)                   25.259      0.473   53.40  &lt; 2e-16\n#&gt; condizioneCtrl_vs_PsicoMean    6.758      1.003    6.73  1.7e-09\n#&gt; condizioneP1_vs_P2             5.770      1.159    4.98  3.2e-06\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nInterpretazione dei coefficienti:\n\n\nIntercetta: non rappresenta più una singola media, ma una combinazione lineare dei gruppi.\n\nCtrl_vs_PsicoMean: confronta la media di controllo con la media combinata delle due psicoterapie.\n\nP1_vs_P2: differenza tra le due psicoterapie.\n\nVerifica manuale:\n\n# Controllo - media delle psicoterapie\nout[1] - (out[2] + out[3]) / 2\n#&gt; controllo \n#&gt;      6.76\n\n\n# Psicoterapia1 - Psicoterapia2\nout[2] - out[3]\n#&gt; psicoterapia1 \n#&gt;          5.77",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#estensione-bayesiana-con-brms-e-emmeans",
    "href": "chapters/linear_models/11_anova_1via.html#estensione-bayesiana-con-brms-e-emmeans",
    "title": "34  ANOVA ad una via",
    "section": "\n34.5 Estensione bayesiana con brms e emmeans\n",
    "text": "34.5 Estensione bayesiana con brms e emmeans\n\nUsiamo ora il modello bayesiano:\n\nmod &lt;- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ condizione \n#&gt;    Data: df (Number of observations: 90) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n#&gt; Intercept                      25.26      0.48    24.33    26.15 1.00     4321\n#&gt; condizioneCtrl_vs_PsicoMean     6.78      1.04     4.73     8.85 1.00     4260\n#&gt; condizioneP1_vs_P2              5.76      1.16     3.49     8.08 1.00     4598\n#&gt;                             Tail_ESS\n#&gt; Intercept                       2937\n#&gt; condizioneCtrl_vs_PsicoMean     2964\n#&gt; condizioneP1_vs_P2              2785\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.54      0.34     3.93     5.26 1.00     4287     3279\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nLe medie marginali e i confronti possono essere ottenuti con il pacchetto emmeans:\n\nem &lt;- emmeans(mod, specs = \"condizione\")\nem\n#&gt;  condizione    emmean lower.HPD upper.HPD\n#&gt;  controllo       29.8      28.1      31.4\n#&gt;  psicoterapia1   25.9      24.3      27.5\n#&gt;  psicoterapia2   20.1      18.4      21.7\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nConfronti tra gruppi:\n\npairs(em)  # confronti a coppie\n#&gt;  contrast                      estimate lower.HPD upper.HPD\n#&gt;  controllo - psicoterapia1         3.90      1.70      6.21\n#&gt;  controllo - psicoterapia2         9.65      7.31     12.03\n#&gt;  psicoterapia1 - psicoterapia2     5.76      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nContrasti personalizzati:\n\nmy_list &lt;- list(\n  \"Ctrl_vs_PsicoMean\" = c(\n    \"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5\n  ),\n  \"P1_vs_P2\" = c(\n    \"controllo\" = 0, \"psicoterapia1\" = 1, \"psicoterapia2\" = -1\n  )\n)\n\n\ncontrast(em, method = my_list)\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.77      4.77      8.88\n#&gt;  P1_vs_P2              5.76      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n# Visualizzazione\nplot(em)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#riflessioni-conclusive",
    "href": "chapters/linear_models/11_anova_1via.html#riflessioni-conclusive",
    "title": "34  ANOVA ad una via",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come l’ANOVA a una via non sia un metodo a sé stante, ma un caso particolare del modello lineare. Attraverso l’uso di variabili indicatrici, infatti, il confronto tra più gruppi può essere formulato come un’estensione naturale della regressione, in cui ciascuna media di gruppo è rappresentata da un parametro del modello.\nL’approccio frequentista tradizionale all’ANOVA si concentra sul test dell’ipotesi nulla di uguaglianza tra le medie, producendo un singolo indice sintetico (la statistica \\(F\\)). L’approccio bayesiano, invece, ci permette di andare oltre: possiamo stimare la distribuzione a posteriori delle differenze tra gruppi, valutare la probabilità che certe medie siano più alte o più basse di altre, e soprattutto ragionare sulla rilevanza pratica delle differenze osservate.\nL’insegnamento più importante è che regressione e ANOVA non sono strumenti separati, ma due volti dello stesso impianto metodologico. Il modello lineare costituisce il quadro unificante che ci consente di descrivere, stimare e interpretare relazioni tra variabili, sia quantitative sia categoriali, con la stessa logica di base.\nCon questo capitolo si chiude la sezione dedicata alla regressione. Abbiamo percorso un itinerario che ci ha portato dalla regressione bivariata alla regressione verso la media, dal confronto tra due gruppi all’ANOVA, passando per l’interpretazione bayesiana dei modelli e per la loro implementazione in Stan. Il filo conduttore è stato duplice: da un lato, la consapevolezza che i modelli lineari sono strumenti fenomenologici, utili per descrivere le associazioni ma non per spiegare i meccanismi sottostanti; dall’altro, la convinzione che l’approccio bayesiano renda queste descrizioni più trasparenti, interpretabili e coerenti con il modo in cui la psicologia scientifica dovrebbe affrontare l’incertezza.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] emmeans_1.11.2-8      bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          insight_1.4.2        \n#&gt; [58] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [61] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [64] glue_1.8.0            tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_anova_1via.html#bibliografia",
    "href": "chapters/linear_models/11_anova_1via.html#bibliografia",
    "title": "34  ANOVA ad una via",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/conclusions_sec.html",
    "href": "chapters/linear_models/conclusions_sec.html",
    "title": "Riflessioni conclusive della sezione",
    "section": "",
    "text": "La sezione dedicata alla regressione ci ha permesso di esplorare uno degli strumenti più centrali della statistica applicata in psicologia. Abbiamo visto come la regressione lineare nasca come modello fenomenologico: descrive relazioni tra variabili, ma non pretende di spiegare i meccanismi sottostanti. Proprio per questo, la regressione è onnipresente nella ricerca empirica: offre un linguaggio comune per riassumere i dati, stimare differenze e formulare previsioni.\nAbbiamo iniziato dalla regressione lineare bivariata, per comprendere concetti di base come intercetta, pendenza e variabilità residua, e abbiamo visto come la regressione verso la media rappresenti un fenomeno statistico inevitabile che ci mette in guardia dai rischi di interpretazioni affrettate. Successivamente abbiamo introdotto l’approccio bayesiano alla regressione, che ci consente di esprimere l’incertezza in modo diretto e di integrare conoscenze pregresse, trasformando la regressione da strumento puramente descrittivo a parte di un quadro inferenziale più ampio.\nCon l’introduzione di Stan abbiamo visto come l’approccio bayesiano diventi praticabile anche in modelli più complessi, a patto di saperne interpretare correttamente i risultati e di essere consapevoli dei limiti derivanti da un’eventuale specificazione errata del modello o dall’omissione di variabili rilevanti.\nAbbiamo poi riformulato problemi classici — la stima di una media, il confronto tra due gruppi, la valutazione della grandezza dell’effetto — come casi particolari del modello lineare. Questo ci ha permesso di mettere in evidenza il vero obiettivo della ricerca psicologica: non stabilire soltanto se una differenza “esiste”, ma comprenderne l’ampiezza, la plausibilità e la rilevanza pratica. Da qui il passo verso la pianificazione della dimensione campionaria è stato naturale: l’inferenza statistica non riguarda solo l’analisi dei dati raccolti, ma anche la progettazione consapevole degli studi.\nInfine, abbiamo visto come l’ANOVA a una via si inserisca nello stesso quadro concettuale, come estensione del modello di regressione con variabili indicatrici. Ciò conferma che regressione e ANOVA non sono strumenti distinti, ma espressioni diverse dello stesso impianto metodologico.\nIn sintesi, la sezione ha mostrato come il modello lineare costituisca un quadro unificante per gran parte delle analisi psicologiche, e come l’approccio bayesiano renda questo quadro più trasparente e interpretabile. Ma ci ha anche ricordato che si tratta di modelli fenomenologici, che descrivono associazioni senza entrare nel merito dei processi che le generano. Nel prosieguo del manuale vedremo come sia possibile andare oltre, introducendo modelli più ricchi e meccanicistici, capaci non solo di descrivere, ma anche di simulare e spiegare i processi cognitivi e affettivi che stanno alla base dei dati psicologici.",
    "crumbs": [
      "Regressione",
      "Riflessioni conclusive della sezione"
    ]
  },
  {
    "objectID": "chapters/glm/introduction_sec.html",
    "href": "chapters/glm/introduction_sec.html",
    "title": "Introduzione alla sezione",
    "section": "",
    "text": "Con la sezione sulla regressione abbiamo costruito un quadro unificato che ci permette di affrontare molti dei problemi classici dell’analisi statistica in psicologia: dalla stima di una media al confronto tra gruppi, dalla valutazione della grandezza dell’effetto all’ANOVA. Abbiamo visto come tutti questi casi possano essere interpretati come declinazioni di un unico modello lineare, descritto e stimato sia in chiave frequentista sia in chiave bayesiana.\nTuttavia, la realtà dei dati psicologici è spesso più complessa. Non sempre le relazioni sono lineari, non sempre le variabili sono quantitative e continue, e non sempre possiamo ridurre la nostra domanda di ricerca a un confronto tra medie. Per rispondere a queste sfide, occorre estendere il modello lineare, rendendolo più flessibile e capace di adattarsi a tipi di dati e a domande diverse.\nNella sezione che segue introdurremo dunque il modello lineare generalizzato (GLM) e le sue estensioni. Questo ci permetterà di analizzare variabili di natura diversa (conteggi, proporzioni, variabili dicotomiche), di applicare link non lineari e di esplorare situazioni che vanno oltre i casi elementari. Anche in questo percorso manterremo il doppio sguardo frequentista e bayesiano, per confrontare vantaggi e limiti di ciascun approccio.\nIl filo conduttore rimarrà lo stesso: sviluppare una statistica che non si limiti a produrre verdetti dicotomici, ma che descriva in modo trasparente l’incertezza, valorizzi la grandezza degli effetti e mantenga un saldo legame con le domande sostantive della psicologia.\nUn ulteriore passo importante è affrontare il problema dei valori mancanti. Nella pratica della ricerca psicologica i dati incompleti sono la norma piuttosto che l’eccezione, e i GLM in contesto bayesiano permettono di integrarli naturalmente nel modello, trattandoli non come un ostacolo, ma come un’ulteriore fonte di incertezza da stimare. In questo modo l’analisi diventa più robusta e realistica, evitando semplificazioni arbitrarie o perdite di informazione.",
    "crumbs": [
      "GLM",
      "Introduzione alla sezione"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html",
    "href": "chapters/glm/01_logistic_regr.html",
    "title": "35  Regressione logistica con Stan",
    "section": "",
    "text": "Introduzione\nLa regressione logistica è un’estensione del modello lineare che consente di analizzare esiti dicotomici, cioè variabili che assumono soltanto due valori (ad esempio: successo/insuccesso, presente/assente, risposta corretta/errata). Situazioni di questo tipo sono molto frequenti nella ricerca psicologica: pensiamo alle risposte a item vero/falso, alla presenza o assenza di un sintomo clinico, oppure alla scelta tra due alternative in un compito sperimentale.\nA differenza della regressione lineare, non modelliamo direttamente la probabilità di successo, ma il suo logit, ossia il logaritmo del rapporto tra odds di successo e odds di insuccesso. Questo passaggio ha due vantaggi fondamentali: da un lato mantiene la struttura lineare del modello, dall’altro assicura che le probabilità restino confinate tra 0 e 1, rispettando così la natura del fenomeno da descrivere.\nIn questo capitolo ci concentreremo sulla regressione logistica bivariata, cioè con un solo predittore, continuo o categoriale. L’obiettivo è duplice: da un lato, imparare a stimare i coefficienti del modello in un’ottica bayesiana utilizzando Stan; dall’altro, capire come interpretare questi coefficienti su scale diverse: in termini di probabilità, di odds ratio e di risk ratio. Vedremo in particolare come un coefficiente unico possa assumere significati diversi a seconda della scala di lettura, e come il caso di un predittore dicotomico (dummy) sia in realtà una specializzazione del modello con variabile continua.\nLa regressione logistica rappresenta dunque un primo passo importante nel percorso dei modelli lineari generalizzati (GLM), ampliando le possibilità dell’analisi statistica ben oltre il caso della regressione lineare e preparandoci ad affrontare dati e domande di ricerca più vari e realistici.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#introduzione",
    "href": "chapters/glm/01_logistic_regr.html#introduzione",
    "title": "35  Regressione logistica con Stan",
    "section": "",
    "text": "Panoramica del capitolo\n\nspecificare una regressione logistica con un predittore continuo;\ninterpretare i coefficienti sulla scala dei logit, degli odds e delle probabilità, ricavando in modo chiaro le relazioni algebriche tra \\(RD\\), \\(OR\\) e \\(RR\\);\nstimare il modello con approccio frequentista (glm) e bayesiano (brms/Stan), comprendendo l’effetto dei priori e leggendo le distribuzioni a posteriori;\nprodurre predizioni posteriori su una griglia di valori di \\(x\\) e rappresentare l’incertezza con curve e intervalli credibili;\nvalutare l’adeguatezza del modello attraverso i posterior predictive checks.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo dedicato alla regressione statistica di Applied regression analysis and generalized linear models (Fox, 2015).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, cmdstanr, posterior, brms, bayestestR, insight)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#il-modello-di-regressione-logistica",
    "href": "chapters/glm/01_logistic_regr.html#il-modello-di-regressione-logistica",
    "title": "35  Regressione logistica con Stan",
    "section": "\n35.1 Il modello di regressione logistica",
    "text": "35.1 Il modello di regressione logistica\nSupponiamo di osservare \\(n\\) individui, ciascuno con un esito binario \\(y_i \\in \\{0,1\\}\\) e un predittore continuo \\(x_i\\). La regressione logistica specifica che\n\\[\ny_i \\sim \\text{Bernoulli}(p_i), \\qquad\n\\text{logit}(p_i) = \\alpha + \\beta x_i .\n\\] Qui \\(p_i\\) è la probabilità di successo per l’individuo \\(i\\). L’intercetta \\(\\alpha\\) è il log-odds di successo quando \\(x_i=0\\), mentre il coefficiente \\(\\beta\\) rappresenta il cambiamento nei log-odds per ogni unità di incremento in \\(x\\).\nSulla scala degli odds questo significa che\n\\[\n\\text{odds}(x) = \\frac{p(x)}{1-p(x)} = \\exp(\\alpha + \\beta x).\n\\] Confrontando due valori consecutivi, \\(x=a\\) e \\(x=a+1\\), otteniamo\n\\[\n\\frac{\\text{odds}(a+1)}{\\text{odds}(a)} = e^{\\beta}.\n\\] Quindi l’esponenziale di \\(\\beta\\) è l’odds ratio (OR): il fattore moltiplicativo con cui cambiano gli odds per un incremento unitario in \\(x\\). Ad esempio, se \\(\\beta=1.0\\), allora \\(OR \\approx 2.7\\): ogni unità in più di \\(x\\) rende gli odds di successo circa 2.7 volte maggiori.\n\n\n\n\n\n\nPerché \\(e^{\\beta}\\) è l’odds ratio\n\n\n\n\n\nNel modello logistico \\(\\log\\!\\big(\\tfrac{p(x)}{1-p(x)}\\big)=\\alpha+\\beta x\\), l’odds a livello \\(x\\) è \\(\\tfrac{p(x)}{1-p(x)}=\\exp(\\alpha+\\beta x)\\). Consideriamo due valori qualsiasi del predittore, \\(x=a\\) e \\(x=b\\). L’odds ratio che confronta \\(b\\) con \\(a\\) è definito come\n\\[\nOR(b\\,\\text{vs}\\,a)\n=\\frac{\\tfrac{p(b)}{1-p(b)}}{\\tfrac{p(a)}{1-p(a)}}\n=\\frac{\\exp(\\alpha+\\beta b)}{\\exp(\\alpha+\\beta a)}\n=\\exp\\!\\big(\\beta(b-a)\\big).\n\\]\nSe la variazione è unitaria (\\(b=a+1\\)), segue immediatamente che\n\\[\nOR(a+1\\,\\text{vs}\\,a)=\\exp(\\beta).\n\\]\nQuesta identità mostra due fatti chiave. Primo, l’odds ratio dipende solo dalla differenza \\(b-a\\) e non dal livello di partenza \\(a\\): in un modello logistico bivariato l’OR per un incremento fissato è costante lungo l’asse di \\(x\\). Secondo, la scala di misura di \\(x\\) determina l’interpretazione di \\(\\beta\\): se \\(x\\) è una dummy \\(\\{0,1\\}\\), \\(\\beta\\) è il log-odds ratio tra i due gruppi e \\(\\exp(\\beta)\\) è l’OR gruppi; se \\(x\\) aumenta di 10 unità, allora \\(\\exp(10\\beta)\\) è l’OR per un incremento di dieci unità; se \\(x\\) è standardizzato (ad es. z-score), \\(\\exp(\\beta)\\) è l’OR per un incremento di una deviazione standard.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#risk-difference-odds-ratio-e-risk-ratio",
    "href": "chapters/glm/01_logistic_regr.html#risk-difference-odds-ratio-e-risk-ratio",
    "title": "35  Regressione logistica con Stan",
    "section": "\n35.2 Risk difference, odds ratio e risk ratio",
    "text": "35.2 Risk difference, odds ratio e risk ratio\nConsideriamo due valori qualsiasi del predittore, \\(x=a\\) e \\(x=b\\). Indichiamo con\n\\[\np_a = \\text{logit}^{-1}(\\alpha + \\beta a), \\qquad\np_b = \\text{logit}^{-1}(\\alpha + \\beta b)\n\\] le probabilità corrispondenti. Possiamo descrivere la differenza fra i due livelli in tre modi:\n\nRisk difference (RD):\\[\nRD = p_b - p_a .\n\\] È la differenza assoluta fra le due probabilità.\nOdds ratio (OR):\\[\nOR = \\frac{p_b/(1-p_b)}{p_a/(1-p_a)} = \\exp\\!\\bigl(\\beta(b-a)\\bigr).\n\\] Mostra come gli odds cambiano passando da \\(a\\) a \\(b\\).\nRisk ratio (RR):\\[\nRR = \\frac{p_b}{p_a}.\n\\] È il rapporto diretto fra probabilità, usato spesso in ambito epidemiologico.\n\nLe tre misure sono modi diversi, ma coerenti, di esprimere l’effetto del predittore.\n\n35.2.1 Scala delle probabilità e la regola del “dividere per 4”\nLa funzione logistica che lega \\(x\\) a \\(p(x)\\) è\n\\[\np(x) = \\frac{e^{\\alpha + \\beta x}}{1 + e^{\\alpha + \\beta x}}.\n\\] Se consideriamo la variazione di probabilità per un incremento unitario in \\(x\\),\n\\[\n\\Delta p = p(x+1) - p(x),\n\\] vediamo che l’effetto non è costante ma dipende dal livello di \\(x\\). Ai margini della curva, quando \\(p\\) è vicino a 0 o 1, la variazione è minima; nella zona centrale, quando \\(p \\approx 0.5\\), la curva è più ripida e l’effetto massimo.\nLa derivata della funzione logistica è\n\\[\n\\frac{dp}{dx} = \\beta \\, p(x)\\,[1 - p(x)].\n\\] Il termine \\(p(x)(1-p(x))\\) è massimo quando \\(p=0.5\\), e in quel punto vale \\(0.25\\). Quindi la massima variazione di probabilità per unità di \\(x\\) è\n\\[\n\\max \\frac{dp}{dx} = \\frac{\\beta}{4}.\n\\] Questa è la cosiddetta regola del dividere per 4: un metodo semplice per stimare, in prima approssimazione, l’effetto massimo di \\(\\beta\\) sulla scala delle probabilità. Ad esempio, se \\(\\beta=1.0\\), il massimo incremento di probabilità per unità di \\(x\\) è circa 0.25, cioè 25 punti percentuali, quando \\(p=0.5\\). Questa regola non è esatta in generale, ma fornisce un’intuizione immediata dell’ordine di grandezza dell’effetto di \\(\\beta\\) sulla probabilità.\n\n35.2.2 Sintesi\nIl coefficiente \\(\\beta\\) della regressione logistica ha interpretazioni coerenti su scale diverse:\n\nsulla scala logit è la variazione lineare dei log-odds;\n\nsulla scala odds il suo esponenziale è l’odds ratio, il moltiplicatore degli odds;\n\nsulla scala probabilità descrive variazioni non costanti, con massimo effetto pari a circa \\(\\beta/4\\) quando \\(p=0.5\\).\n\nQueste interpretazioni non sono alternative ma complementari: lo stesso coefficiente viene letto in tre linguaggi diversi, offrendo prospettive complementari sul legame tra \\(x\\) e la probabilità di successo.\n\n35.2.3 Visualizzazione delle tre scale\nPer fissare meglio le idee, possiamo rappresentare graficamente l’effetto del coefficiente \\(\\beta\\) sulle tre scale: logit, odds e probabilità. Useremo valori simulati, così da confrontare direttamente i tre casi.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n35.2.3.1 Come leggere i tre grafici\n\n\nScala logit: la relazione con \\(x\\) è lineare. Ogni unità in più di \\(x\\) aumenta i log-odds di \\(\\beta\\).\n\nScala odds: la crescita è esponenziale. Qui \\(\\exp(\\beta)\\) indica di quanto si moltiplicano gli odds per ogni unità aggiuntiva di \\(x\\).\n\nScala probabilità: la curva è sigmoide e rimane sempre tra 0 e 1. L’effetto di \\(\\beta\\) non è costante: è massimo quando \\(p \\approx 0.5\\), e minimo ai margini (quando la curva è piatta).\n\n35.2.4 Interpretazione didattica\nLa regressione logistica descrive una relazione non lineare fra il predittore \\(x\\) e la probabilità di successo \\(p(x)\\). La curva che ne risulta è una sigmoide: per valori molto bassi di \\(x\\) la probabilità si avvicina a 0, per valori molto alti tende a 1, e nella zona centrale varia rapidamente.\nIl segno del coefficiente \\(\\beta\\) determina la direzione dell’effetto. Se \\(\\beta &gt; 0\\), all’aumentare di \\(x\\) crescono log-odds, odds e probabilità: la curva ha pendenza positiva. Se \\(\\beta &lt; 0\\), accade il contrario e la curva decresce.\nLo stesso effetto può essere letto su scale diverse, che offrono prospettive complementari:\n\nsulla scala delle probabilità, si osserva la variazione assoluta di \\(p(x)\\);\n\nsulla scala degli odds, l’effetto è un moltiplicatore costante \\(OR = e^{\\beta}\\) per ogni incremento unitario di \\(x\\);\n\nsulla scala logit, l’effetto si traduce in un incremento lineare costante di \\(\\beta\\) nei log-odds.\n\nUn ulteriore strumento utile è la risk difference (RD), cioè la differenza di probabilità fra due livelli di \\(x\\), e il risk ratio (RR), cioè il loro rapporto. Queste misure, pur non derivando direttamente dal coefficiente come l’odds ratio, offrono un linguaggio più immediato in molti contesti applicativi (per esempio in epidemiologia o psicologia clinica).\nLa forza della regressione logistica sta proprio in questa unificazione: un unico modello produce tre chiavi di lettura — logit, odds e probabilità — che, se usate insieme, permettono di descrivere in modo chiaro e coerente l’impatto di una variabile indipendente su un esito binario.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#esempio-numerico",
    "href": "chapters/glm/01_logistic_regr.html#esempio-numerico",
    "title": "35  Regressione logistica con Stan",
    "section": "\n35.3 Esempio numerico",
    "text": "35.3 Esempio numerico\nSimuliamo dati con un predittore discreto \\(X\\) e una variabile dicotomica \\(Y\\), in cui la probabilità di successo cresce con \\(X\\). Applichiamo quindi la regressione logistica e tracciamo la curva stimata, confrontandola con le proporzioni empiriche osservate.\n\n# Fissiamo il seme per riproducibilità\nset.seed(42)\n\n# Numero di osservazioni\nn &lt;- 1000\n\n# Predittore X: estraiamo numeri interi fra 0 e 9 con uguale probabilità\nX &lt;- sample(0:9, n, replace = TRUE)\n\n# Definiamo una funzione logistica che restituisce plogis(alpha + beta * x),\n# cioè la trasformazione inversa del logit\nlogistic &lt;- function(x, beta0, beta1) plogis(beta0 + beta1 * x)\n\n# Parametri veri del modello usato per simulare i dati\nbeta0 &lt;- -2   # intercetta\nbeta1 &lt;- 1    # coefficiente\n\n# Calcoliamo la probabilità di successo associata a ciascun valore di X\np &lt;- logistic(X, beta0, beta1)\n\n# Generiamo i dati binari (0/1) da una distribuzione binomiale di Bernoulli\nY &lt;- rbinom(n, size = 1, prob = p)\n\n# Creiamo un data frame con i dati simulati\ndf &lt;- tibble::tibble(X = X, Y = Y)\nhead(df)\n#&gt; # A tibble: 6 × 2\n#&gt;       X     Y\n#&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1     0     0\n#&gt; 2     4     1\n#&gt; 3     0     0\n#&gt; 4     8     1\n#&gt; 5     9     1\n#&gt; 6     3     0\n\nStima del modello di regressione logistica con funzione glm():\n\n# family = binomial(link = \"logit\") specifica che usiamo una regressione logistica\nlogit_model &lt;- glm(Y ~ X, data = df, family = binomial(link = \"logit\"))\n\n\n# Creiamo una griglia di valori di X su cui calcolare le probabilità predette\nx_vals &lt;- seq(min(df$X), max(df$X), length.out = 100)\n\n# Data frame per le predizioni\npred_df &lt;- data.frame(X = x_vals)\n\n# Calcoliamo le probabilità predette dal modello (scala di risposta, cioè probabilità)\npred_df$pred &lt;- predict(logit_model, newdata = pred_df, type = \"response\")\n\nGrafico finale:\n\nggplot(df, aes(x = X, y = Y)) +\n  # Per ogni valore di X mostriamo la proporzione empirica di successi (punti blu)\n  stat_summary(fun = mean, geom = \"point\", color = \"blue\") +\n  # Sovrapponiamo la curva logistica stimata dal modello (linea rossa)\n  geom_line(data = pred_df, aes(x = X, y = pred), color = \"red\") +\n  # Etichette degli assi\n  labs(x = \"X\", y = \"Probabilità stimata\")\n\n\n\n\n\n\n\nIn questo esempio i punti blu rappresentano la proporzione empirica di successi per ciascun valore di \\(X\\), mentre la linea rossa mostra la curva logistica stimata dal modello. La forma sigmoide emerge naturalmente e garantisce che le probabilità rimangano sempre comprese tra 0 e 1.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#stima-bayesiana-con-stan",
    "href": "chapters/glm/01_logistic_regr.html#stima-bayesiana-con-stan",
    "title": "35  Regressione logistica con Stan",
    "section": "\n35.4 Stima bayesiana con Stan",
    "text": "35.4 Stima bayesiana con Stan\nFinora abbiamo stimato i coefficienti \\(\\alpha\\) e \\(\\beta\\) con glm(), ottenendo valori puntuali secondo il metodo della massima verosimiglianza. Con Stan possiamo costruire lo stesso modello in chiave bayesiana, specificando priori debolmente informativi. Questo ci consente di ottenere l’intera distribuzione a posteriori dei parametri, invece di un singolo punto stima, e di quantificare direttamente l’incertezza.\nUn dettaglio importante è che i risultati di Stan possono differire leggermente da quelli di glm(). La ragione è proprio la presenza dei priori: anche se scelti molto larghi (qui normal(0, 2.5)), essi esercitano un piccolo “effetto di contrazione” verso lo zero, soprattutto con campioni finiti. In assenza di priori (o con dati molto abbondanti), le due stime coincidono. Questa differenza è didatticamente preziosa, perché mostra come l’approccio frequentista si possa vedere come un caso limite del bayesiano.\n\n35.4.1 Il modello in Stan\nIl modello di regressione logistica per un predittore continuo si scrive così:\n\nstan_code &lt;- '\ndata {\n  int&lt;lower=0&gt; N;           // numero di osservazioni\n  array[N] int&lt;lower=0, upper=1&gt; y;  // esiti (0/1)\n  vector[N] x;              // predittore\n}\nparameters {\n  real alpha;               // intercetta\n  real beta;                // coefficiente di regressione\n}\nmodel {\n  // prior deboli\n  alpha ~ normal(0, 2.5);\n  beta ~ normal(0, 2.5);\n  \n  // verosimiglianza\n  y ~ bernoulli_logit(alpha + beta * x);\n}\ngenerated quantities {\n  real OR = exp(beta);      // odds ratio\n}\n'\n\nQuesto modello assume gli stessi dati simulati nell’esempio precedente. Prepariamo i dati in R:\n\nstan_data &lt;- list(\n  N = nrow(df),\n  y = df$Y,\n  x = df$X\n)\n\nCompiliamo e stimiamo:\n\nmod &lt;- cmdstan_model(write_stan_file(stan_code))\n\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 2000\n)\n\n\n35.4.2 Risultati\nEsaminiamo ora i coefficienti stimati dal modello bayesiano:\n\nfit$summary(variables = c(\"alpha\",\"beta\",\"OR\"))\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    -1.721 -1.716 0.171 0.170 -2.012 -1.447 1.003 2673.568 2761.536\n#&gt; 2 beta      0.901  0.899 0.062 0.062  0.802  1.006 1.004 2687.550 2860.012\n#&gt; 3 OR        2.467  2.457 0.154 0.153  2.231  2.735 1.003 2687.550 2860.012\n\nIn uscita otteniamo per ciascun parametro la media posteriore, la deviazione standard e un intervallo credibile. Ad esempio, il coefficiente \\(\\beta\\) ha un intervallo interamente positivo, coerente con la costruzione dei dati, e l’odds ratio risulta ben al di sopra di 1: segno che all’aumentare di \\(X\\) cresce la probabilità di successo.\n\n35.4.3 Interpretazione sulle tre scale\nLe distribuzioni posteriori di \\(\\alpha\\) e \\(\\beta\\) possono essere tradotte nelle tre scale discusse in precedenza.\nScala dei logit. L’intercetta \\(\\alpha\\) rappresenta i log-odds quando \\(x=0\\). Supponiamo, ad esempio, che la posteriore dia \\(\\alpha \\approx -2\\) con CrI 95% [-2.2, -1.8]. Significa che al livello di riferimento la probabilità è bassa. Il coefficiente \\(\\beta\\), centrato intorno a 1 con CrI 95% [0.9, 1.1], indica che ogni unità in più di \\(x\\) aumenta i log-odds di circa un punto.\nScala degli odds. Esponenziando \\(\\beta\\) otteniamo l’odds ratio. Con \\(\\beta \\approx 1\\), la distribuzione posteriore di \\(OR\\) è centrata su 2.7, con CrI ad esempio [2.5, 3.0]. Questo significa che, con altissima probabilità, un incremento unitario di \\(x\\) moltiplica gli odds di successo di circa 2.5–3 volte.\nScala delle probabilità. Applicando la trasformazione logistica, otteniamo \\(p(x) = \\text{logit}^{-1}(\\alpha + \\beta x)\\). Per ogni draw posteriore possiamo calcolare una curva sigmoide: ne risulta un ventaglio di curve plausibili che descrivono l’incertezza. Intorno a \\(p=0.5\\), la pendenza è massima e vale circa \\(\\beta/4\\). Con \\(\\beta \\approx 1\\), ciò corrisponde a un incremento massimo di probabilità di circa 25 punti percentuali per unità di \\(x\\).\n\n35.4.4 Quantità derivate: RD, OR, RR\nPossiamo anche confrontare due valori specifici del predittore, ad esempio \\(x=0\\) e \\(x=1\\), e derivare da ciascun draw posteriore tre misure di interesse:\n\n# Estrazione dei campioni posteriori\npost &lt;- as_draws_df(fit)\n\n# Confronto tra x=0 e x=1\nx_a &lt;- 0\nx_b &lt;- 1\n\npost &lt;- post %&gt;%\n  mutate(\n    p_a = plogis(alpha + beta * x_a),\n    p_b = plogis(alpha + beta * x_b),\n    RD  = p_b - p_a,            \n    OR  = exp(beta * (x_b - x_a)),\n    RR  = p_b / p_a\n  )\n\nposterior_summary &lt;- tibble(\n  quantity = c(\"p_a (x=0)\", \"p_b (x=1)\", \"RD (p_b - p_a)\", \"OR\", \"RR\"),\n  mean     = c(mean(post$p_a), mean(post$p_b),\n               mean(post$RD), mean(post$OR), mean(post$RR)),\n  q2.5     = c(quantile(post$p_a, .025), quantile(post$p_b, .025),\n               quantile(post$RD, .025), quantile(post$OR, .025), quantile(post$RR, .025)),\n  q97.5    = c(quantile(post$p_a, .975), quantile(post$p_b, .975),\n               quantile(post$RD, .975), quantile(post$OR, .975), quantile(post$RR, .975))\n)\n\nposterior_summary\n#&gt; # A tibble: 5 × 4\n#&gt;   quantity        mean  q2.5 q97.5\n#&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 p_a (x=0)      0.153 0.112 0.198\n#&gt; 2 p_b (x=1)      0.307 0.255 0.359\n#&gt; 3 RD (p_b - p_a) 0.153 0.137 0.170\n#&gt; 4 OR             2.47  2.20  2.80 \n#&gt; 5 RR             2.02  1.79  2.32\n\nQui \\(p_a\\) e \\(p_b\\) sono le probabilità predette per i due valori di \\(x\\), la risk difference è la loro differenza assoluta, l’odds ratio corrisponde a \\(e^\\beta\\), e il risk ratio è il rapporto fra probabilità. Tutte queste quantità hanno ora distribuzioni posteriori con i rispettivi intervalli credibili.\n\n35.4.5 Visualizzazione dell’incertezza\nPer rendere più chiara la variabilità delle predizioni, possiamo tracciare alcune curve campionate dalla posteriore, insieme alla curva media:\n\nx_grid &lt;- seq(0, 9, length.out = 100)\n\npred_curves &lt;- post %&gt;%\n  slice_sample(n = 200) %&gt;%\n  mutate(.draw = row_number()) %&gt;%\n  expand_grid(x = x_grid) %&gt;%\n  mutate(p = plogis(alpha + beta * x))\n\npred_mean &lt;- post %&gt;%\n  expand_grid(x = x_grid) %&gt;%\n  group_by(x) %&gt;%\n  summarise(p = mean(plogis(alpha + beta * x)), .groups = \"drop\")\n\nggplot() +\n  geom_line(data = pred_curves, aes(x = x, y = p, group = .draw),\n            alpha = 0.1, color = \"grey\") +\n  geom_line(data = pred_mean, aes(x = x, y = p),\n            color = \"black\", size = 1) +\n  labs(\n    x = \"X\", y = \"Probabilità stimata\"\n  )\n\n\n\n\n\n\n\nIl grafico mostra come i dati sostengano un’intera famiglia di curve logistiche compatibili: la linea nera è la media posteriore, mentre le linee grigie rendono visibile l’incertezza.\n\n35.4.6 Sintesi\nRispetto a glm(), l’approccio bayesiano con Stan fornisce un quadro più ricco e trasparente. Non abbiamo solo un punto stima e un errore standard, ma distribuzioni posteriori per tutti i parametri e le quantità derivate. Ciò ci permette di dire, ad esempio, che con il 95% di probabilità posteriore l’odds ratio si colloca tra 2.5 e 3.0, o che l’incremento massimo di probabilità per unità di \\(x\\) è di circa 25 punti percentuali.\nIn sintesi, la regressione logistica bayesiana non solo replica quanto già visto con l’approccio frequentista, ma lo arricchisce con una rappresentazione completa dell’incertezza e con inferenze direttamente interpretabili in termini probabilistici.\n\n\n\nRiassunto delle stime posteriori sulle tre scale: logit (α, β), odds (OR), probabilità (p ai due livelli scelti, RD e RR), con intervalli credibili al 95%.\n\n\n\n\n\n\nScala\nQuantità\nMedia [CrI 95%]\n\n\n\nLogit\nα (log-odds a x=0)\n-1.721 [-2.068, -1.399]\n\n\nLogit\nβ (incremento di log-odds per +1 in X)\n0.901 [0.787, 1.031]\n\n\nOdds\nOR = exp(β) per +1 in X\n2.467 [2.196, 2.804]\n\n\nProbabilità\np(x=0)\n0.153 [0.112, 0.198]\n\n\nProbabilità\np(x=1)\n0.307 [0.255, 0.359]\n\n\nProbabilità\nRD = p(x=1) - p(x=0)\n0.153 [0.137, 0.170]\n\n\nProbabilità\nRR = p(x=1) / p(x=0)\n2.020 [1.787, 2.320]\n\n\nProbabilità\nPendenza massima ≈ β/4 (a p≈0.5)\n0.225 [0.197, 0.258]",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#collegamento-con-il-caso-a-due-gruppi",
    "href": "chapters/glm/01_logistic_regr.html#collegamento-con-il-caso-a-due-gruppi",
    "title": "35  Regressione logistica con Stan",
    "section": "\n35.5 Collegamento con il caso a due gruppi",
    "text": "35.5 Collegamento con il caso a due gruppi\nSe il predittore \\(x\\) è una variabile dummy, che assume valore 0 in un gruppo e 1 nell’altro, il modello con predittore continuo si riduce esattamente al caso del confronto tra due proporzioni discusso nel capitolo successivo. In quel contesto avevamo:\n\\[\np_{\\text{ref}} = \\text{logit}^{-1}(\\alpha), \\qquad\np_{\\text{work}} = \\text{logit}^{-1}(\\alpha + \\gamma),\n\\] da cui derivano naturalmente\n\\[\nRD = p_{\\text{work}} - p_{\\text{ref}}, \\qquad\nOR = \\exp(\\gamma), \\qquad\nRR = \\frac{p_{\\text{work}}}{p_{\\text{ref}}}.\n\\] Il confronto fra due gruppi, dunque, non è un modello separato ma un’applicazione particolare della regressione logistica generale. Questo ponte concettuale è importante perché mostra come il caso elementare delle due proporzioni si inserisca nello stesso quadro teorico della regressione logistica con predittori continui. Questo collegamento prepara il terreno per il prossimo capitolo, dove il confronto fra due proporzioni sarà analizzato in dettaglio.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#riflessioni-conclusive",
    "href": "chapters/glm/01_logistic_regr.html#riflessioni-conclusive",
    "title": "35  Regressione logistica con Stan",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo introdotto la regressione logistica come estensione naturale del modello lineare ai casi in cui l’esito è dicotomico. Abbiamo visto come il passaggio dal parametro probabilistico al logit consenta di mantenere la struttura lineare del modello, pur rispettando i vincoli logici delle probabilità comprese tra 0 e 1.\nLa stima bayesiana dei coefficienti, implementata in Stan, ci ha permesso di ottenere una rappresentazione completa dell’incertezza sulle relazioni tra predittori ed esiti. Abbiamo imparato a interpretare i coefficienti su scale diverse — probabilità, odds ratio, risk ratio — cogliendo così la flessibilità del modello e la sua capacità di adattarsi a molteplici domande di ricerca.\nLa regressione logistica è particolarmente rilevante in psicologia, dove esiti binari o dicotomici sono frequenti: dalle risposte corrette/errate in compiti cognitivi, alla presenza o assenza di sintomi clinici, fino alle scelte tra due alternative in contesti decisionali. Comprendere questo modello significa quindi dotarsi di uno strumento fondamentale, capace di connettere le nostre ipotesi teoriche con la natura concreta dei dati raccolti.\nMa la regressione logistica rappresenta anche un punto di partenza. Essa appartiene alla più ampia famiglia dei modelli lineari generalizzati (GLM), che consentono di modellare variabili di natura diversa attraverso la combinazione di una distribuzione della famiglia esponenziale e di una funzione di collegamento (link). Nei prossimi capitoli esploreremo altri casi di GLM, consolidando così l’idea che regressione lineare, regressione logistica e ANOVA non siano strumenti separati, ma variazioni di un unico quadro metodologico, flessibile e coerente.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] knitr_1.50            glue_1.8.0            insight_1.4.2        \n#&gt;  [4] bayestestR_0.17.0     cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [7] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt; [10] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [13] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [16] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [19] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [22] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [25] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [28] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          emmeans_1.11.2-8     \n#&gt; [61] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [64] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [67] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [70] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [73] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [76] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [79] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_logistic_regr.html#bibliografia",
    "href": "chapters/glm/01_logistic_regr.html#bibliografia",
    "title": "35  Regressione logistica con Stan",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFox, J. (2015). Applied regression analysis and generalized linear models. Sage publications.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html",
    "href": "chapters/glm/02_one_proportion.html",
    "title": "36  Inferenza sulle proporzioni",
    "section": "",
    "text": "Introduzione\nDopo aver affrontato il problema dell’inferenza sulle medie, ci spostiamo ora a un altro scenario molto comune nella ricerca psicologica: l’analisi delle proporzioni. Capita spesso di voler confrontare la frequenza relativa di un certo evento tra due gruppi indipendenti. Per esempio, possiamo chiederci se la proporzione di soggetti che rispondono correttamente a un item sia più alta in un gruppo sperimentale rispetto a un gruppo di controllo, oppure se la proporzione di persone che presentano un sintomo clinico differisca tra due popolazioni.\nCome nel caso delle medie, anche qui il confronto diretto tra le proporzioni osservate può essere fuorviante, perché le differenze nei dati sono sempre accompagnate da variabilità casuale. Per interpretarle correttamente è necessario formulare un modello statistico che tenga conto dell’incertezza.\nL’approccio tradizionale è quello frequentista, che utilizza un test di ipotesi con l’ipotesi nulla di uguaglianza tra le proporzioni. Questo metodo, tuttavia, si limita a stabilire se i dati sono compatibili o meno con l’assenza di differenze, senza dirci nulla sull’ampiezza e sull’importanza sostantiva delle differenze stesse.\nL’approccio bayesiano rovescia la prospettiva. Non si tratta solo di stabilire se due proporzioni siano uguali o diverse, ma di stimare quanto siano differenti e con quale grado di incertezza. Questo significa ottenere una distribuzione a posteriori per la differenza tra proporzioni, da cui derivare probabilità direttamente interpretabili, come la probabilità che una proporzione sia maggiore dell’altra o che la differenza superi una soglia di rilevanza pratica. In questo modo, l’analisi diventa più informativa e più utile per supportare decisioni scientifiche.\nIn questo capitolo introdurremo dunque l’inferenza bayesiana sulle proporzioni, utilizzando il pacchetto brms in R. Per rendere il percorso graduale, partiremo dal caso più semplice dell’inferenza su una singola proporzione, per poi estendere i concetti al confronto tra due gruppi. Questo ci permetterà di apprezzare sia i limiti dell’approccio frequentista sia i vantaggi di quello bayesiano, che ci restituisce una descrizione completa della nostra incertezza.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html#introduzione",
    "href": "chapters/glm/02_one_proportion.html#introduzione",
    "title": "36  Inferenza sulle proporzioni",
    "section": "",
    "text": "Panoramica del capitolo\n\nFondamenti dell’inferenza su una proporzione (modello Beta-Binomiale).\nConfronto tra l’approccio frequentista (test e intervalli di confidenza) con quello bayesiano.\nConcetto di ROPE per valutare la significatività pratica, e non solo statistica, di un effetto.\nEstensione al confronto tra due proporzioni.\nLinee guida per la reportistica e la pianificazione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Learning about a Binomial Probability del testo di Albert & Hu (2019).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, tidyr, broom, tidybayes, scales)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html#inferenza-su-una-proporzione",
    "href": "chapters/glm/02_one_proportion.html#inferenza-su-una-proporzione",
    "title": "36  Inferenza sulle proporzioni",
    "section": "\n36.1 Inferenza su una proporzione",
    "text": "36.1 Inferenza su una proporzione\nCome esempio per l’inferenza su una proporzione, utilizzeremo i dati dello studio di Brückner & Bearman (2005), discussi anche da Wagenmakers et al. (2010). Nell’articolo After the promise: the STD consequences of adolescent virginity pledges, Brückner & Bearman (2005) analizzano una serie di interviste condotte nell’ambito del National Longitudinal Study of Adolescent Health (Add Health). Lo studio si concentra sul comportamento sessuale di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto un “virginity pledge”, ovvero una promessa pubblica o scritta di rimanere vergini fino al matrimonio. Studi scientifici indicano che il comportamento sessuale di questi adolescenti non sia statisticamente diverso da quello di chi non ha fatto tale promessa, con l’unica eccezione che i “pledgers” hanno una minore probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nI dati rilevanti per la nostra analisi sono i seguenti:\n\nsu 777 adolescenti che hanno fatto il “virginity pledge”, 424 (54.6%) hanno dichiarato di aver usato il preservativo durante il primo rapporto sessuale;\nsu 9072 adolescenti che non hanno fatto la promessa, 5416 (59.7%) hanno dichiarato di aver usato il preservativo.\n\n\n36.1.1 Obiettivo dell’analisi\nNella prima analisi, ci concentreremo sul campione di adolescenti che hanno fatto il “virginity pledge”. Ci chiediamo se sia credibile pensare che questi adolescenti tendano ad avere un rapporto protetto, nel loro primo rapporto sessuale, in una proporzione minore di quella che ci si potrebbe aspettare in caso di casualità (ovvero, una proporzione di 0.5).\n\n36.1.2 Analisi frequentista\nIniziamo con un test frequentista usando la funzione prop.test() per confrontare la proporzione osservata con il valore di riferimento 0.5.\n\nprop_test_freq_vol &lt;- prop.test(\n  x = 424,\n  n = 777,\n  p = 0.5\n)\n\ntidy(prop_test_freq_vol)\n#&gt; # A tibble: 1 × 8\n#&gt;   estimate statistic p.value parameter conf.low conf.high\n#&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1    0.546      6.31  0.0120         1    0.510     0.581\n#&gt;   method                                               alternative\n#&gt;   &lt;chr&gt;                                                &lt;chr&gt;      \n#&gt; 1 1-sample proportions test with continuity correction two.sided\n\nL’intervallo di confidenza frequentista non include il valore di riferimento 0.5, quindi, in base a questa analisi, possiamo concludere che la proporzione osservata (0.546) sia maggiore del valore atteso in caso di casualità (0.5).\n\n36.1.3 Approccio bayesiano\nSe utilizziamo dei prior non informativi, ci aspettiamo di giungere alla stessa conclusione anche con un approccio bayesiano. Tuttavia, l’approccio bayesiano ci permette di ottenere una distribuzione completa della probabilità a posteriori del parametro di interesse, offrendo una visione più ricca e flessibile rispetto all’approccio frequentista.\nIniziamo creando un data frame che sarà utilizzato con la funzione brm().\n\npledge_binomial_df &lt;- tibble(\n  n_yes = 424,\n  n_total = 777\n)\n\n# tiny data\npledge_binomial_df\n#&gt; # A tibble: 1 × 2\n#&gt;   n_yes n_total\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   424     777\n\n\n36.1.3.1 Modello bayesiano\nUtilizziamo un modello di regressione con una funzione link binomiale. Questo significa che stimeremo la proporzione \\(p\\) con un modello di regressione beta-binomiale bayesiano utilizzando brms. Useremo un prior non informativo \\(\\mathcal{Beta}(1, 1)\\). Questo è un modello solo con intercetta, senza altre covariate, poiché siamo interessati solo alla proporzione sottostante, senza condizionarla su altre variabili.\nIl modello può essere rappresentato come segue:\n\\[\n\\begin{aligned}\ny_{\\text{condom\\_use}} &\\sim \\mathcal{Binomial}(n, \\pi) \\\\\n\\pi &= \\beta_0 \\\\\n\\beta_0 &\\sim \\mathcal{Beta}(1, 1)\n\\end{aligned}\n\\]\nEseguiamo l’analisi bayesiana.\n\nmodel_pledge_binomial &lt;- brm(\n  n_yes | trials(n_total) ~ 1,\n  data = pledge_binomial_df,\n  family = binomial(link = \"identity\"),\n  prior = c(prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1)),\n  chains = 4, warmup = 1000, iter = 4000, seed = 123,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n\nPoiché questo è un modello di regressione, si comporta come qualsiasi altro modello brms. Il coefficiente per l’intercetta rappresenta la proporzione stimata di adolescenti tra i 18 e i 24 anni che hanno usato il preservativo durante il primo rapporto sessuale nel campione.\n\nsummary(model_pledge_binomial)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ 1 \n#&gt;    Data: pledge_binomial_df (Number of observations: 1) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 12000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.55      0.02     0.51     0.58 1.00     3835     5744\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSi noti come l’intervallo di credibilità al 95% riproduce l’intervallo frequentista calcolato in precedenza.\n\n36.1.4 Confronto tra i due approcci\nConfrontiamo ora i risultati ottenuti dai due approcci. L’analisi frequentista ha mostrato che la proporzione osservata (0.546) è significativamente maggiore del valore di riferimento 0.5. L’approccio bayesiano conferma questa conclusione, fornendo una distribuzione completa della probabilità a posteriori per la proporzione π. Uno dei vantaggi dell’approccio bayesiano è la possibilità di incorporare informazioni a priori, se disponibili, migliorando così la robustezza delle inferenze. Inoltre, l’intervallo di credibilità bayesiano fornisce una descrizione più completa della distribuzione dei parametri, consentendo una migliore interpretazione dei risultati.\n\n36.1.5 Modello Beta-Binomiale e soluzione analitica\nIn questo contesto, il problema può essere modellato utilizzando una distribuzione beta-binomiale, per la quale esiste una soluzione analitica per la distribuzione a posteriori. Il modello beta-binomiale è particolarmente adatto quando si lavora con dati binomiali (ad esempio, successi e fallimenti) e si desidera incorporare una distribuzione a priori coniugata per la proporzione \\(p\\).\n\n36.1.5.1 Contestualizzazione del modello\nPer il gruppo “pledgers”, abbiamo \\(y_1\\) successi su \\(n_1\\) prove. Se assumiamo una distribuzione a priori Beta(\\(\\alpha\\), \\(\\beta\\)), la distribuzione a posteriori per la proporzione \\(p_1\\) sarà anch’essa una distribuzione Beta, data da:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(\\alpha + y_1, \\beta + n_1 - y_1).\n\\]\nNel nostro caso specifico, scegliamo una prior non informativa \\(\\mathcal{Beta}(1, 1)\\), che equivale a una distribuzione uniforme sull’intervallo [0, 1]. Questa scelta riflette l’assenza di informazioni pregresse sulla proporzione \\(p_1\\). Pertanto, la distribuzione a posteriori per il gruppo “pledgers” diventa:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(1 + 424, 1 + 777 - 424) = \\mathcal{Beta}(425, 354).\n\\]\n\n36.1.5.2 Calcolo dell’intervallo di credibilità\nUtilizziamo R per calcolare l’intervallo di credibilità al 95% basato sulla distribuzione a posteriori derivata analiticamente.\n\n# Parametri della distribuzione Beta\na_post &lt;- 425  # Parametro alpha\nb_post &lt;- 354  # Parametro beta\n\n# Calcolo dell'intervallo centrale al 95%\ncredibility_interval &lt;- qbeta(c(0.025, 0.975), shape1 = a_post, shape2 = b_post)\nprint(credibility_interval)\n#&gt; [1] 0.511 0.580\n\nIl risultato ottenuto dall’analisi bayesiana analitica replica quello ottenuto tramite il modello brm() implementato in precedenza. Questo confronto tra approcci dimostra la coerenza tra le tecniche frequentista, bayesiana numerica e bayesiana analitica.\n\n36.1.6 Discussione e confronto tra approcci\nL’utilizzo della distribuzione beta-binomiale e della soluzione analitica offre diversi vantaggi:\n\n\nSemplicità: La soluzione analitica è spesso più semplice da implementare rispetto ai metodi numerici, come quelli utilizzati in brms.\n\nVelocità: I calcoli sono generalmente più veloci poiché non richiedono iterazioni o campionamenti.\n\nInterpretazione: L’uso di distribuzioni coniugate facilita l’interpretazione dei risultati, fornendo direttamente la distribuzione a posteriori senza bisogno di complessi algoritmi di inferenza.\n\nTuttavia, l’approccio bayesiano numerico tramite brms presenta anche vantaggi significativi:\n\n\nFlessibilità: Può gestire modelli più complessi e includere covariate multiple.\n\nPriori informativi: Permette di incorporare facilmente informazioni a priori, se disponibili.\n\nEstensioni: Facilita l’estensione del modello a casi più complessi, come il confronto tra proporzioni di due gruppi.\n\n\n36.1.6.1 Analisi della distribuzione a posteriori\nEssendo un’analisi bayesiana, possiamo lavorare con l’intera distribuzione a posteriori e calcolare direttamente l’estimando, come la differenza tra la proporzione campionaria e la proporzione di riferimento (0.5).\n\npledge_draws &lt;- model_pledge_binomial |&gt; \n  spread_draws(b_Intercept) |&gt; \n  mutate(diff = b_Intercept - 0.5)\n\nVisualizziamo la distribuzione a posteriori della proporzione.\n\np1 &lt;- ggplot(pledge_draws, aes(x = b_Intercept, y = \"Age 18–24\")) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0.5) +\n  scale_x_continuous(labels = label_percent()) +\n  coord_cartesian(ylim = c(1.5, 1.5)) +\n  labs(x = \"Proportion used a condom at first sex\", y = NULL)\np1\n\n\n\n\n\n\n\nIl valore di riferimento (0.5) non è incluso nella distribuzione a posteriori, il che significa che la differenza tra la proporzione campionaria e la proporzione di riferimento non include lo zero, con un livello di credibilità del 95%. Possiamo quindi concludere, con un livello soggettivo di credibilità del 95%, che l’uso del preservativo durante il primo rapporto sessuale sia maggiore del caso, per gli adolescenti che hanno fatto il “virginity pledge”.\n\n36.1.7 La regione di equivalenza pratica\nL’analisi precedente confronta la proporzione osservata con un singolo valore di riferimento (0.5). Un approccio alternativo è considerare un intervallo di valori attorno a 0.5 che possano essere considerati “praticamente equivalenti” al valore di riferimento. Questo intervallo è chiamato Regione di Equivalenza Pratica (ROPE).\nSecondo Kruschke & Liddell (2018), la ROPE può essere definita come un intervallo attorno al valore nullo (baseline) che corrisponde a un decimo della deviazione standard della distribuzione a posteriori del parametro di interesse. Nel nostro caso, il parametro di interesse è la proporzione \\(p\\), e il valore nullo è 0.5. Per calcolare la ROPE, estraiamo i campioni a posteriori dal modello.\n\nposterior_samples &lt;- as_draws_df(model_pledge_binomial)\n\nCalcoliamo la deviazione standard a posteriori di \\(p\\).\n\nposterior_std_dev &lt;- sd(posterior_samples$b_Intercept)\nposterior_std_dev\n#&gt; [1] 0.018\n\nDefiniamo la ROPE come un intervallo attorno al valore di riferimento 0.5.\n\nbaseline &lt;- 0.5  # Valore nullo (baseline)\nrope_low &lt;- baseline - 0.1 * posterior_std_dev\nrope_high &lt;- baseline + 0.1 * posterior_std_dev\n\nCalcoliamo ora la probabilità che la proporzione \\(p\\) si trovi all’interno della ROPE.\n\nrope_probability &lt;-\n  mean(\n    posterior_samples$b_Intercept &gt;= rope_low &\n      posterior_samples$b_Intercept &lt;= rope_high\n  )\nrope_probability\n#&gt; [1] 0.003\n\nVisualizziamo la distribuzione a posteriori di \\(p\\) insieme alla ROPE.\n\nggplot(posterior_samples, aes(x = b_Intercept)) +\n  geom_density(fill = \"gray\", alpha = 0.5) +\n  annotate(\n    geom = \"rect\", \n    xmin = rope_low, \n    xmax = rope_high, \n    ymin = 0, ymax = Inf, \n    fill = \"lightgray\", alpha = 0.2\n  ) +\n  geom_vline(xintercept = baseline, color = \"lightgray\") +\n  scale_x_continuous(labels = scales::percent) +\n  labs(x = \"Proportion used a condom at first sex\", y = \"Density\")\n\n\n\n\n\n\n\nIn conclusione, dato che solo lo 0.325% (meno dell’uno per cento) della distribuzione a posteriori di \\(p\\) si trova nella ROPE, possiamo concludere che ci sono evidenze credibili che la distribuzione a posteriori del parametro \\(p\\) (la proporzione di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto il “virginity pledge” e hanno usato il preservativo durante il primo rapporto sessuale) sia diversa dal valore di riferimento 0.5. Nel caso specifico, questa proporzione è più alta, indicando che la tendenza ad avere un rapporto protetto è maggiore rispetto al caso di casualità, per questa popolazione.\n\n36.1.7.1 Discussione\nL’utilizzo della ROPE offre una prospettiva aggiuntiva nell’interpretazione delle inferenze bayesiane. Invece di semplicemente determinare se un parametro è statisticamente significativo rispetto a un valore di riferimento, la ROPE permette di valutare se le differenze osservate siano praticamente rilevanti in termini di impatto reale.\n\n\nSoglia di rilevanza: L’impostazione di una ROPE consente di stabilire una soglia di rilevanza pratica. Se la maggior parte della distribuzione a posteriori cade al di fuori della ROPE, possiamo concludere che la differenza è non solo statistica ma anche pratica.\n\nInterpretazione clinica: Nelle applicazioni pratiche, come in ambito medico o sociale, la ROPE aiuta a distinguere tra risultati statisticamente significativi ma clinicamente insignificanti e quelli che hanno un impatto rilevante.\n\nNel contesto dello studio sui “pledgers”, l’uso della ROPE fornisce una valutazione più completa della tendenza degli adolescenti a utilizzare il preservativo durante il primo rapporto sessuale, dimostrando che questa tendenza è non solo statisticamente diversa dal caso di casualità, ma anche significativa dal punto di vista pratico.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "href": "chapters/glm/02_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "title": "36  Inferenza sulle proporzioni",
    "section": "\n36.2 Inferenza sulla differenza tra due proporzioni",
    "text": "36.2 Inferenza sulla differenza tra due proporzioni\nEstendiamo ora l’analisi precedente per confrontare le proporzioni di due gruppi, un compito per il quale non esiste una soluzione analitica semplice. Nello studio in esame, ci poniamo la domanda: Fino a che punto l’analisi statistica supporta l’ipotesi che i “pledgers” abbiano una minore probabilità rispetto ai “non-pledgers” di usare il preservativo durante il primo rapporto sessuale?\nPer testare questa ipotesi utilizzando brms, estendiamo il modello bayesiano includendo due gruppi: i pledgers (che hanno fatto il voto di astinenza) e i non-pledgers (che non lo hanno fatto). L’obiettivo è stimare la differenza tra le due proporzioni e valutare se questa sia credibilmente diversa da zero.\nCostruiamo un tibble con i dati relativi ai due gruppi:\n\npledge_data &lt;- tibble(\n  group = c(\"pledgers\", \"nonpledgers\"),\n  n_yes = c(424, 5416),   # Numero di partecipanti che hanno usato il preservativo\n  n_total = c(777, 9072)  # Totale dei partecipanti per ciascun gruppo\n)\nprint(pledge_data)\n#&gt; # A tibble: 2 × 3\n#&gt;   group       n_yes n_total\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 pledgers      424     777\n#&gt; 2 nonpledgers  5416    9072\n\n\n36.2.1 Modello bayesiano per il confronto tra proporzioni\nIn questo modello, adottiamo un approccio bayesiano per analizzare la differenza nell’utilizzo del preservativo tra due gruppi distinti: i “pledgers” (chi ha sottoscritto l’impegno) e i “non-pledgers” (chi non lo ha sottoscritto). La struttura del modello si basa sulla distribuzione binomiale, appropriata per dati che rappresentano conteggi di successi su un numero fisso di prove.\nSpecifica del modello. Il modello assume che il numero di utilizzi del preservativo in ciascun gruppo segua una distribuzione binomiale:\n\\[\ny_i \\sim \\text{Binomial}(n_i, \\theta_i)\n\\] dove:\n\n\n\\(y_i\\) è il numero di utilizzi del preservativo nel gruppo \\(i\\),\n\n\\(n_i\\) è il numero totale di individui nel gruppo \\(i\\),\n\n\\(\\theta_i\\) è la probabilità di utilizzo del preservativo nel gruppo \\(i\\).\n\nModellazione delle probabilità. La relazione tra i gruppi viene modellata attraverso una specificazione lineare sulla probabilità stessa (utilizzando un link identità):\n\\[\n\\theta_i = \\beta_0 + \\beta_1 \\cdot x_i,\n\\] dove:\n\n\n\\(x_i\\) è una variabile indicatrice che vale 0 per i non-pledgers e 1 per i pledgers,\n\n\\(\\beta_0\\) rappresenta la probabilità di utilizzo del preservativo nel gruppo di riferimento (non-pledgers),\n\n\\(\\beta_1\\) rappresenta la differenza assoluta nella probabilità di utilizzo tra pledgers e non-pledgers.\n\nScelta dei prior. La specificazione dei prior riflette le nostre conoscenze a priori sui parametri:\n\nPer \\(\\beta_0\\) (probabilità base nei non-pledgers): utilizziamo un prior Beta(1,1), equivalente a una distribuzione uniforme tra 0 e 1, che rappresenta un’assenza di informazioni specifiche sulla probabilità attesa\nPer \\(\\beta_1\\) (differenza tra gruppi): utilizziamo un prior normale con media 0 e deviazione standard 1, che assegna probabilità decrescenti a differenze maggiori in valore assoluto, pur mantenendo la possibilità di effetti in entrambe le direzioni\n\nImplementazione pratica. L’implementazione del modello in brms utilizza la seguente sintassi:\n\nmodel_pledge_diff &lt;- brm(\n  formula = n_yes | trials(n_total) ~ group,  # Specifica della risposta binomiale\n  data = pledge_data,                         # Dataset contenente i dati\n  family = binomial(link = \"identity\"),       # Link identità per interpretazione diretta\n  prior = c(\n    prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1),  # Prior per la probabilità base\n    prior(normal(0, 1), class = \"b\")                         # Prior per l'effetto del gruppo\n  ),\n  chains = 4,                 # Quattro catene Markoviane\n  warmup = 1000,              # 1000 iterazioni di burn-in per catena\n  iter = 4000,                # 4000 iterazioni totali per catena\n  seed = 123,                 # Seed per riproducibilità\n  refresh = 0,                # Nessun output intermedio\n  backend = \"cmdstanr\"        # Motore di inferenza efficiente\n)\n\n\n36.2.2 Risultati\nEsaminiamo il sommario del modello per valutare la stima della differenza tra le proporzioni:\n\nsummary(model_pledge_diff)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ group \n#&gt;    Data: pledge_data (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 12000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept         0.60      0.01     0.59     0.61 1.00    13571     9174\n#&gt; grouppledgers    -0.05      0.02    -0.09    -0.01 1.00     3602     4230\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPer interpretare meglio i risultati, estraiamo i campioni a posteriori per la differenza tra le due proporzioni:\n\npledge_diff_draws &lt;- model_pledge_diff |&gt; \n  spread_draws(b_Intercept, b_grouppledgers) |&gt; \n  mutate(\n    nonpledgers_prop = b_Intercept,  # Stima della proporzione nei non-pledgers\n    pledgers_prop = b_Intercept + b_grouppledgers,  # Stima della proporzione nei pledgers\n    diff = nonpledgers_prop - pledgers_prop  # Differenza tra le due proporzioni\n  )\n\nVisualizziamo la distribuzione a posteriori della differenza:\n\np3 &lt;- ggplot(pledge_diff_draws, aes(x = diff)) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  scale_x_continuous(labels = label_percent()) +\n  labs(x = \"Differenza nella proporzione di utilizzo del preservativo\", \n       y = \"Densità a posteriori\") \nprint(p3)\n\n\n\n\n\n\n\nCalcoliamo la probabilità che la differenza tra le proporzioni sia maggiore di zero:\n\ndiff_probability &lt;- mean(pledge_diff_draws$diff &gt; 0)\nprint(diff_probability)\n#&gt; [1] 0.998\n\n\n36.2.2.1 Interpretazione\nLa probabilità calcolata è 0.997; ciò significa che c’è una probabilità del 99.7% che la proporzione di non-pledgers che usano il preservativo sia maggiore rispetto a quella dei pledgers. Questo supporta con elevata credibilità l’ipotesi che i pledgers abbiano meno probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nPossiamo quindi concludere che la differenza tra le due proporzioni è credibilmente diversa da zero, con un’elevata probabilità a favore dell’ipotesi che i pledgers abbiano una minore propensione all’uso del preservativo rispetto ai non-pledgers. Questi risultati riproducono quelli riportati dalla letteratura precedente, come discusso da Brückner & Bearman (2005).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html#riflessioni-conclusive",
    "href": "chapters/glm/02_one_proportion.html#riflessioni-conclusive",
    "title": "36  Inferenza sulle proporzioni",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come il problema del confronto tra proporzioni possa essere affrontato sia con l’approccio frequentista tradizionale, basato sui test di ipotesi, sia con l’approccio bayesiano. La differenza non è soltanto tecnica: il frequentismo ci dice se i dati sono compatibili o meno con l’ipotesi nulla di uguaglianza, mentre il bayesianesimo ci fornisce una distribuzione a posteriori per la differenza tra proporzioni, che quantifica direttamente la nostra incertezza e ci permette di calcolare probabilità interpretabili, come la probabilità che una proporzione superi l’altra o che la differenza abbia un’ampiezza rilevante.\nAbbiamo anche sottolineato l’importanza di iniziare dall’inferenza su una singola proporzione: questo passaggio preliminare ci ha permesso di familiarizzare con la logica bayesiana in un contesto semplice, prima di affrontare il caso più generale del confronto tra gruppi. L’uso di brms ha reso l’implementazione accessibile, mostrando come strumenti moderni consentano di stimare modelli complessi mantenendo intatta la logica concettuale dell’aggiornamento bayesiano.\nDal punto di vista psicologico, il messaggio è chiaro: non basta sapere se due proporzioni sono “significativamente diverse”. Dobbiamo chiederci quanto differiscono, quanto siamo incerti su questa differenza, e se l’effetto osservato abbia un senso pratico e teorico. Solo così l’analisi statistica può davvero informare le nostre decisioni scientifiche.\nNel prosieguo vedremo come lo stesso principio si applichi a una gamma più ampia di modelli all’interno della famiglia dei GLM: che si tratti di proporzioni, conteggi o esiti multinomiali, l’approccio bayesiano ci offre sempre una rappresentazione trasparente dell’incertezza e un linguaggio unificato per affrontare dati di natura diversa.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] scales_1.4.0          broom_1.0.9           bayestestR_0.17.0    \n#&gt;  [4] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [7] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [10] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [13] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [16] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [19] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [22] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [25] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [28] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        plyr_1.8.9           \n#&gt; [46] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [49] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [52] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [55] stats4_4.5.1          insight_1.4.2         distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [64] tools_4.5.1           data.table_1.17.8     mvtnorm_1.3-3        \n#&gt; [67] grid_4.5.1            QuickJSR_1.8.0        colorspace_2.1-1     \n#&gt; [70] nlme_3.1-168          cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          Brobdingnag_1.2-9     V8_7.0.0             \n#&gt; [76] gtable_0.3.6          digest_0.6.37         TH.data_1.1-4        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          memoise_2.0.1        \n#&gt; [82] htmltools_0.5.8.1     lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_one_proportion.html#bibliografia",
    "href": "chapters/glm/02_one_proportion.html#bibliografia",
    "title": "36  Inferenza sulle proporzioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBrückner, H., & Bearman, P. (2005). After the promise: The STD consequences of adolescent virginity pledges. Journal of Adolescent Health, 36(4), 271–278.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). Bayesian data analysis for newcomers. Psychonomic Bulletin & Review, 25(1), 155–177.\n\n\nWagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., & Grasman, R. (2010). Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method. Cognitive Psychology, 60(3), 158–189.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html",
    "href": "chapters/glm/03_two_proportions.html",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "",
    "text": "Introduzione\nUno dei problemi più frequenti nella ricerca psicologica e clinica è stabilire se due gruppi abbiano la stessa probabilità di ottenere un certo esito binario. Pensiamo, ad esempio, a due trattamenti terapeutici e alla probabilità di guarigione, oppure a due metodi di insegnamento e alla probabilità di superare un esame. In tutti questi casi ogni individuo può trovarsi in una delle due categorie: successo o insuccesso, sì o no, guarito o non guarito.\nPer affrontare dati di questo tipo ricorriamo alla regressione logistica, che collega la probabilità di successo a una variabile predittiva. Quando i gruppi sono due e indipendenti, il modello si riduce a una forma particolarmente semplice: un unico predittore binario che indica l’appartenenza al gruppo. In questo caso, l’intercetta rappresenta la probabilità (sul logit) di successo nel gruppo di riferimento, mentre il coefficiente del predittore descrive la differenza in log-odds tra i due gruppi.\nL’approccio bayesiano aggiunge un ulteriore livello di interpretabilità. Possiamo esprimere in modo esplicito le nostre ipotesi iniziali tramite distribuzioni a priori e ottenere come risultato non un singolo valore stimato, ma una distribuzione a posteriori che riflette tutta l’incertezza sui parametri. Da questa distribuzione possiamo calcolare probabilità direttamente interpretabili: la probabilità che un trattamento sia più efficace dell’altro, la probabilità che la differenza superi una certa soglia di rilevanza pratica, o la probabilità che le due proporzioni siano sostanzialmente equivalenti.\nIn questo capitolo vedremo come formulare il confronto tra due proporzioni come un caso di regressione logistica, come stimarlo in chiave bayesiana con brms, e come interpretarne i risultati non solo in termini di odds ratio, ma anche di probabilità e differenze di proporzioni. Questo ci permetterà di collegare il tema del confronto tra proporzioni al quadro più generale dei modelli lineari generalizzati (GLM), di cui la regressione logistica rappresenta un caso centrale.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#introduzione",
    "href": "chapters/glm/03_two_proportions.html#introduzione",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "",
    "text": "Panoramica del capitolo\n\nComprendere il confronto tra due proporzioni come caso base della regressione logistica.\n\nTradurre i coefficienti logit in probabilità, differenza di rischio, odds ratio e risk ratio.\n\nStimare i parametri con approccio bayesiano tramite brms.\n\nInterpretare le distribuzioni posteriori e l’incertezza delle stime.\n\nEseguire controlli predittivi e visualizzare i risultati.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere l’articolo “Children’s arithmetic skills do not transfer between applied and academic mathematics” (Banerjee et al., 2025).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, cmdstanr, posterior, brms, bayestestR, insight)\n\nconflicts_prefer(dplyr::count)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#perché-usare-la-regressione-logistica-per-confrontare-due-proporzioni",
    "href": "chapters/glm/03_two_proportions.html#perché-usare-la-regressione-logistica-per-confrontare-due-proporzioni",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n37.1 Perché usare la regressione logistica per confrontare due proporzioni",
    "text": "37.1 Perché usare la regressione logistica per confrontare due proporzioni\nConfrontare due proporzioni significa chiedersi se la probabilità di successo osservata in un gruppo differisce da quella osservata nell’altro. Se nel gruppo 0 registriamo \\(x_0\\) successi su \\(n_0\\) prove e nel gruppo 1 osserviamo \\(x_1\\) successi su \\(n_1\\) prove, le proporzioni vere possono essere indicate con \\(\\theta_0\\) e \\(\\theta_1\\). La differenza tra le due proporzioni, \\(\\Delta = \\theta_1 - \\theta_0\\), fornisce una misura diretta del divario. Un altro indice spesso utilizzato è l’odds ratio, che confronta il rapporto tra successi e insuccessi in ciascun gruppo.\nLa regressione logistica permette di formalizzare questa idea. Se indichiamo con \\(D_i\\) una variabile che assume valore zero per gli individui del gruppo di riferimento e valore uno per gli individui del gruppo di confronto, possiamo scrivere il modello come\n\\[\ny_i \\sim \\text{Bernoulli}(p_i), \\qquad \\text{logit}(p_i) = \\alpha + \\gamma D_i .\n\\]\nIn questo contesto, l’intercetta \\(\\alpha\\) rappresenta i log-odds del gruppo di riferimento, mentre il coefficiente \\(\\gamma\\) esprime la differenza di log-odds fra i due gruppi, cioè il logaritmo dell’odds ratio. L’esponenziale di \\(\\gamma\\) fornisce infatti l’odds ratio vero e proprio.\nQuesto schema mostra che confrontare due proporzioni equivale a stimare una regressione logistica con un unico predittore dummy, con il vantaggio di ottenere risultati coerenti con modelli più complessi e di poter passare facilmente da una scala all’altra, dalle probabilità agli odds, fino alle differenze o ai rapporti di rischio. In un quadro bayesiano, questo confronto si arricchisce ulteriormente perché le stime vengono fornite sotto forma di distribuzioni a posteriori, permettendo di esprimere direttamente l’incertezza su ciascuna quantità di interesse.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#un-esempio-concreto",
    "href": "chapters/glm/03_two_proportions.html#un-esempio-concreto",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n37.2 Un esempio concreto",
    "text": "37.2 Un esempio concreto\nUn’applicazione particolarmente chiara di queste idee si trova nello studio di Banerjee et al. (2025), che ha confrontato le abilità matematiche di due gruppi di bambini in India: da un lato quelli che lavoravano nei mercati di Kolkata e Delhi, dall’altro quelli che frequentavano la scuola senza lavorare. Lo scopo era verificare se le competenze sviluppate nel lavoro quotidiano, come dare il resto o sommare i prezzi, si trasferissero al contesto scolastico e se, viceversa, l’addestramento scolastico potesse essere utile nei problemi pratici del mercato. I risultati hanno mostrato che i bambini lavoratori erano molto abili nei problemi concreti, ma meno preparati in quelli astratti, mentre gli scolarizzati presentavano lo schema opposto.\nConsideriamo i dati relativi ai problemi astratti. Tra i bambini lavoratori si sono registrati 670 successi su 1488 prove, pari a una proporzione di circa 0.45. Tra i bambini scolarizzati i successi sono stati 320 su 542, cioè circa 0.59. La situazione è ancora più marcata nei problemi di mercato: i bambini lavoratori hanno ottenuto 134 successi su 373 prove, pari a 0.36, mentre i bambini scolarizzati hanno risolto solo 3 problemi su 271, cioè appena lo 0.01.\n\n# Successi e denominatori\nx_work   &lt;- 670 ; n_work   &lt;- 1488\nx_non    &lt;- 320 ; n_non    &lt;-  542\n\n# Tabella aggregata per il modello binomiale\ndat_a &lt;- tibble(\n  count = c(x_non,   x_work),   # ordine: riferimento (non-working), poi working\n  tot   = c(n_non,   n_work),\n  group = factor(c(\"non-working\", \"working\"),\n                 levels = c(\"non-working\", \"working\"))\n)\n\ndat_a\n#&gt; # A tibble: 2 × 3\n#&gt;   count   tot group      \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;      \n#&gt; 1   320   542 non-working\n#&gt; 2   670  1488 working",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#un-rapido-controllo",
    "href": "chapters/glm/03_two_proportions.html#un-rapido-controllo",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n37.3 Un rapido controllo",
    "text": "37.3 Un rapido controllo\nPrima di impostare il modello bayesiano, può essere utile calcolare in chiave frequentista la differenza osservata fra le due proporzioni, insieme a un intervallo di confidenza. Questo non fa parte del nostro approccio principale, ma consente di verificare che i dati siano coerenti con quelli riportati in letteratura e ci offre un punto di riferimento preliminare.\n\np_non  &lt;- x_non  / n_non\np_work &lt;- x_work / n_work\nrd_obs &lt;- p_non - p_work\n\nalpha  &lt;- 0.05\nse_ci  &lt;- sqrt(p_non*(1-p_non)/n_non + p_work*(1-p_work)/n_work)\nz_crit &lt;- qnorm(1 - alpha/2)\nci_rd  &lt;- c(rd_obs - z_crit*se_ci, rd_obs + z_crit*se_ci)\n\nsprintf(\"Differenza osservata (non-working - working): %.3f (95%% CI: [%.2f, %.2f])\",\n        rd_obs, ci_rd[1], ci_rd[2])\n#&gt; [1] \"Differenza osservata (non-working - working): 0.140 (95% CI: [0.09, 0.19])\"\n\nQuesto rapido controllo conferma che i bambini scolarizzati hanno una proporzione di risposte corrette maggiore rispetto ai bambini lavoratori nei problemi astratti, come già segnalato dagli autori dello studio.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#modello-bayesiano-con-regressione-logistica",
    "href": "chapters/glm/03_two_proportions.html#modello-bayesiano-con-regressione-logistica",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n37.4 Modello bayesiano con regressione logistica",
    "text": "37.4 Modello bayesiano con regressione logistica\nPassiamo ora al modello bayesiano. Usiamo il pacchetto brms con backend cmdstanr, in continuità con i capitoli precedenti. Per impostare il modello binomiale con esito aggregato, specifichiamo dei prior debolmente informativi sulla scala logit:\n\npriors &lt;- c(\n  prior(normal(0, 2.5), class = \"Intercept\"),\n  prior(normal(0, 2.5), class = \"b\")\n)\n\nLa stima viene quindi effettuata sul numero di successi in ciascun gruppo, tenendo conto del numero totale di prove, con la variabile categoriale group che distingue fra bambini scolarizzati e bambini lavoratori. Nel gruppo di riferimento, definito come “non-working”, l’intercetta del modello rappresenta i log-odds di successo, mentre il coefficiente associato al predittore misura lo scarto di log-odds del gruppo “working”.\nDopo aver impostato il modello, procediamo alla stima con brms. I dati vengono trattati in forma aggregata, specificando il numero di successi e di prove per ciascun gruppo. Usiamo la famiglia binomiale, fissiamo i prior debolmente informativi sulla scala logit, e chiediamo al campionatore MCMC di esplorare lo spazio dei parametri.\n\nfit_a &lt;- brm(\n  count | trials(tot) ~ group,\n  data         = dat_a,\n  family       = binomial(),\n  prior        = priors,\n  backend      = \"cmdstanr\",\n  seed         = 1234,\n  iter         = 4000, chains = 4, cores = 4,\n  sample_prior = \"yes\",\n  refresh = 0 \n)\n\nUn primo sguardo ai risultati con summary(fit_a) ci mostra i coefficienti stimati sulla scala logit. Tuttavia, per comprendere appieno il significato psicologico e applicativo di questi numeri, è utile trasformarli nelle quantità di maggiore interesse: le probabilità di successo nei due gruppi, la loro differenza, e i rapporti che le mettono a confronto.\n\nsummary(fit_a)\n#&gt;  Family: binomial \n#&gt;   Links: mu = logit \n#&gt; Formula: count | trials(tot) ~ group \n#&gt;    Data: dat_a (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept        0.37      0.09     0.20     0.54 1.00     3230     3722\n#&gt; groupworking    -0.57      0.10    -0.77    -0.37 1.00     3929     3843\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nA partire dall’intercetta otteniamo la probabilità dei bambini scolarizzati (gruppo di riferimento), mentre aggiungendo il coefficiente della variabile dummy otteniamo la probabilità del gruppo dei bambini lavoratori. La differenza fra le due probabilità definisce la risk difference. Il coefficiente della dummy, espresso come esponenziale, corrisponde invece all’odds ratio. Infine, il rapporto fra le probabilità fornisce il risk ratio.\n\npost &lt;- as_draws_df(fit_a) %&gt;%\n  mutate(\n    p_ref   = plogis(b_Intercept),\n    p_work  = plogis(b_Intercept + b_groupworking),\n    RD      = p_work - p_ref,\n    OR      = exp(b_groupworking),\n    RR      = p_work / p_ref\n  )\n\nRiepilogando i valori medi e gli intervalli credibili, possiamo osservare direttamente le stime per ciascuna quantità.\n\npost_summary &lt;- tibble(\n  quantity = c(\"p_ref (non-working)\", \"p_work (working)\", \"RD (work - ref)\", \"OR\", \"RR\"),\n  mean  = c(mean(post$p_ref), mean(post$p_work), mean(post$RD), mean(post$OR), mean(post$RR)),\n  q2.5  = c(quantile(post$p_ref, .025), quantile(post$p_work, .025), quantile(post$RD, .025),\n            quantile(post$OR, .025), quantile(post$RR, .025)),\n  q97.5 = c(quantile(post$p_ref, .975), quantile(post$p_work, .975), quantile(post$RD, .975),\n            quantile(post$OR, .975), quantile(post$RR, .975))\n)\n\npost_summary\n#&gt; # A tibble: 5 × 4\n#&gt;   quantity              mean   q2.5   q97.5\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 p_ref (non-working)  0.591  0.550  0.632 \n#&gt; 2 p_work (working)     0.450  0.425  0.476 \n#&gt; 3 RD (work - ref)     -0.141 -0.188 -0.0918\n#&gt; 4 OR                   0.569  0.465  0.692 \n#&gt; 5 RR                   0.763  0.698  0.834\n\nPer avere un’impressione immediata della direzione degli effetti, possiamo calcolare le probabilità posteriori che le quantità di interesse siano minori o maggiori di valori soglia. In particolare, ci chiediamo con quale probabilità la proporzione dei bambini lavoratori superi quella degli scolarizzati, oppure la differenza di rischio sia negativa, o ancora l’odds ratio e il risk ratio siano inferiori a uno.\n\ntibble(\n  `Pr(p_work &gt; p_ref)` = mean(post$p_work &gt; post$p_ref),\n  `Pr(RD &lt; 0)`         = mean(post$RD &lt; 0),\n  `Pr(OR &lt; 1)`         = mean(post$OR &lt; 1),\n  `Pr(RR &lt; 1)`         = mean(post$RR &lt; 1)\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   `Pr(p_work &gt; p_ref)` `Pr(RD &lt; 0)` `Pr(OR &lt; 1)` `Pr(RR &lt; 1)`\n#&gt;                  &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1                    0            1            1            1\n\nGli intervalli credibili confermano e quantificano l’incertezza. La probabilità stimata di successo per i bambini scolarizzati ha un intervallo al 95% che si colloca attorno a valori medio-alti, mentre quella dei bambini lavoratori si concentra su valori più bassi. L’intervallo credibile della differenza di rischio è per lo più negativo, suggerendo una minore probabilità di successo nel gruppo dei lavoratori. Lo stesso vale per l’odds ratio, con valori che tendono a collocarsi stabilmente al di sotto dell’unità.\n\nhdi_p_ref   &lt;- bayestestR::hdi(post$p_ref, ci = 0.95)\nhdi_p_work  &lt;- bayestestR::hdi(post$p_work, ci = 0.95)\nhdi_RD_89   &lt;- bayestestR::hdi(post$RD, ci = 0.89)\nhdi_OR_95   &lt;- bayestestR::hdi(post$OR, ci = 0.95)\n\nlist(\n  `95% HDI p_ref`  = hdi_p_ref,\n  `95% HDI p_work` = hdi_p_work,\n  `89% HDI RD`     = hdi_RD_89,\n  `95% HDI OR`     = hdi_OR_95\n)\n#&gt; $`95% HDI p_ref`\n#&gt; 95% HDI: [0.55, 0.63]\n#&gt; \n#&gt; $`95% HDI p_work`\n#&gt; 95% HDI: [0.43, 0.48]\n#&gt; \n#&gt; $`89% HDI RD`\n#&gt; 89% HDI: [-0.18, -0.10]\n#&gt; \n#&gt; $`95% HDI OR`\n#&gt; 95% HDI: [0.46, 0.69]\n\nInterpretare questi risultati significa tradurre le diverse scale. Le proporzioni forniscono una misura intuitiva: nei dati considerati, la probabilità di successo dei bambini scolarizzati si aggira intorno al 59 per cento, mentre quella dei bambini lavoratori è più vicina al 45 per cento. La differenza di rischio, cioè lo scarto fra le due proporzioni, risulta negativa e conferma un divario a sfavore dei lavoratori. L’odds ratio esprime lo stesso fenomeno su un’altra scala: un valore inferiore a uno indica che gli odds di successo dei lavoratori sono più bassi di quelli degli scolarizzati. Il risk ratio, infine, mostra che la probabilità di successo dei lavoratori corrisponde solo a una frazione di quella degli scolarizzati.\nTutte queste trasformazioni raccontano la stessa storia con linguaggi diversi, e lo fanno in modo coerente con quanto osservato nei dati grezzi. Il vantaggio del modello bayesiano è che non ci limita a un’unica stima puntuale, ma ci offre distribuzioni posteriori complete che quantificano l’incertezza e permettono di rispondere a domande probabilistiche dirette, come “quanto è probabile che la differenza di proporzioni sia negativa?” oppure “quanto è probabile che l’odds ratio sia minore di uno?”.\nQuesto capitolo si collega direttamente alla discussione precedente sull’odds ratio. In quel caso avevamo stimato l’indice in modo diretto, come parametro principale di un modello. Qui, invece, vediamo come lo stesso odds ratio emerga naturalmente come trasformazione del coefficiente logit in una regressione con variabile dummy. Le due prospettive non sono in contrasto, ma si integrano: la regressione logistica fornisce un quadro generale dal quale si derivano OR, RR e RD, mentre l’analisi bayesiana dell’odds ratio ci ha mostrato come sia possibile focalizzarsi in modo mirato su un singolo parametro di interesse.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#un-secondo-esempio-i-problemi-di-mercato",
    "href": "chapters/glm/03_two_proportions.html#un-secondo-esempio-i-problemi-di-mercato",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n37.5 Un secondo esempio: i problemi di mercato",
    "text": "37.5 Un secondo esempio: i problemi di mercato\nRiprendiamo ora i dati relativi ai problemi di mercato. Qui le differenze tra i due gruppi diventano ancora più evidenti. I bambini lavoratori hanno risolto correttamente 134 problemi su 373, con una proporzione di circa 0.36. I bambini scolarizzati, invece, hanno risposto correttamente solo 3 volte su 271, con una proporzione che sfiora lo zero, appena 0.01. Questo scenario rappresenta una situazione di forte divario, opposta a quella vista nei problemi astratti.\n\n# Dati per i problemi di mercato\nx_work_m &lt;- 134 ; n_work_m &lt;- 373\nx_non_m  &lt;-   3 ; n_non_m  &lt;- 271\n\ndat_m &lt;- tibble(\n  count = c(x_non_m, x_work_m),\n  tot   = c(n_non_m, n_work_m),\n  group = factor(c(\"non-working\", \"working\"),\n                 levels = c(\"non-working\", \"working\"))\n)\n\ndat_m\n#&gt; # A tibble: 2 × 3\n#&gt;   count   tot group      \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;      \n#&gt; 1     3   271 non-working\n#&gt; 2   134   373 working\n\nImpostiamo lo stesso modello bayesiano, mantenendo la struttura logistica con dummy di gruppo.\n\nfit_m &lt;- brm(\n  count | trials(tot) ~ group,\n  data         = dat_m,\n  family       = binomial(),\n  prior        = priors,\n  backend      = \"cmdstanr\",\n  seed         = 1234,\n  iter         = 4000, chains = 4, cores = 4,\n  sample_prior = \"yes\",\n  refresh = 0 \n)\n\nDopo la stima, estraiamo nuovamente le quantità di interesse: le probabilità nei due gruppi, la loro differenza, l’odds ratio e il risk ratio.\n\npost_m &lt;- as_draws_df(fit_m) %&gt;%\n  mutate(\n    p_ref   = plogis(b_Intercept),\n    p_work  = plogis(b_Intercept + b_groupworking),\n    RD      = p_work - p_ref,\n    OR      = exp(b_groupworking),\n    RR      = p_work / p_ref\n  )\n\npost_summary_m &lt;- tibble(\n  quantity = c(\"p_ref (non-working)\", \"p_work (working)\", \"RD (work - ref)\", \"OR\", \"RR\"),\n  mean  = c(mean(post_m$p_ref), mean(post_m$p_work), mean(post_m$RD), mean(post_m$OR), mean(post_m$RR)),\n  q2.5  = c(quantile(post_m$p_ref, .025), quantile(post_m$p_work, .025), quantile(post_m$RD, .025),\n            quantile(post_m$OR, .025), quantile(post_m$RR, .025)),\n  q97.5 = c(quantile(post_m$p_ref, .975), quantile(post_m$p_work, .975), quantile(post_m$RD, .975),\n            quantile(post_m$OR, .975), quantile(post_m$RR, .975))\n)\n\npost_summary_m\n#&gt; # A tibble: 5 × 4\n#&gt;   quantity               mean     q2.5    q97.5\n#&gt;   &lt;chr&gt;                 &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 p_ref (non-working)  0.0141  0.00393   0.0312\n#&gt; 2 p_work (working)     0.358   0.310     0.408 \n#&gt; 3 RD (work - ref)      0.344   0.295     0.396 \n#&gt; 4 OR                  51.8    17.0     143.    \n#&gt; 5 RR                  33.4    11.3      91.3\n\nLe stime posteriori raccontano una storia molto chiara. La probabilità di successo per i bambini scolarizzati è praticamente nulla, con un intervallo credibile che resta vicino allo zero. Per i bambini lavoratori, invece, la probabilità si colloca intorno al 36 per cento. La differenza di rischio è quindi nettamente positiva e l’odds ratio assume valori molto superiori a uno, indicando un vantaggio marcato dei lavoratori.\nPer rendere ancora più evidente la forza dell’effetto, possiamo calcolare la probabilità a posteriori che la proporzione dei lavoratori sia superiore a quella degli scolarizzati, oppure che la differenza di rischio e l’odds ratio siano strettamente positivi.\n\ntibble(\n  `Pr(p_work &gt; p_ref)` = mean(post_m$p_work &gt; post_m$p_ref),\n  `Pr(RD &gt; 0)`         = mean(post_m$RD &gt; 0),\n  `Pr(OR &gt; 1)`         = mean(post_m$OR &gt; 1),\n  `Pr(RR &gt; 1)`         = mean(post_m$RR &gt; 1)\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   `Pr(p_work &gt; p_ref)` `Pr(RD &gt; 0)` `Pr(OR &gt; 1)` `Pr(RR &gt; 1)`\n#&gt;                  &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1                    1            1            1            1\n\nIn questo caso le probabilità posteriori sono praticamente pari a uno, cioè la certezza che i bambini lavoratori abbiano prestazioni migliori nei problemi di mercato.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#confronto-fra-i-due-scenari",
    "href": "chapters/glm/03_two_proportions.html#confronto-fra-i-due-scenari",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n37.6 Confronto fra i due scenari",
    "text": "37.6 Confronto fra i due scenari\nMettendo insieme i due esempi — problemi astratti e problemi di mercato — si ottiene un quadro coerente con le ipotesi teoriche dello studio. Nei problemi astratti, tipici dell’ambiente scolastico, i bambini scolarizzati mostrano una probabilità di successo più elevata rispetto ai lavoratori. Nei problemi di mercato, invece, il risultato si ribalta: i bambini che hanno esperienza diretta nelle attività quotidiane del lavoro sono nettamente più preparati, mentre gli scolarizzati faticano.\nLa regressione logistica in chiave bayesiana ci permette di quantificare entrambi gli scenari con la stessa cornice concettuale. Le differenze non vengono solo osservate nei dati grezzi, ma diventano stime probabilistiche con intervalli credibili che riflettono l’incertezza. È particolarmente utile osservare come le diverse scale (proporzioni, differenza di rischio, odds ratio, risk ratio) restituiscano sempre la stessa conclusione, ciascuna con il proprio linguaggio: più intuitivo nel caso delle proporzioni, più compatto e comparabile in quello dell’odds ratio.\nQuesta analisi illustra bene il vantaggio di un modello unificato. Con un’unica struttura logistica possiamo descrivere scenari molto diversi, da un divario moderato a uno estremo, e tradurre i risultati su scale diverse a seconda delle esigenze interpretative.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#visualizzazione-dei-risultati",
    "href": "chapters/glm/03_two_proportions.html#visualizzazione-dei-risultati",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n37.7 Visualizzazione dei risultati",
    "text": "37.7 Visualizzazione dei risultati\nPer rendere più intuitiva l’interpretazione, possiamo rappresentare graficamente le distribuzioni posteriori.\n\n37.7.1 Differenza di rischio (RD)\nNel primo grafico vediamo le distribuzioni posteriori della risk difference nei due scenari. Nel caso dei problemi astratti, la distribuzione si concentra su valori negativi, indicando un vantaggio per i bambini scolarizzati. Nei problemi di mercato, al contrario, la distribuzione si colloca interamente su valori positivi, con un vantaggio netto per i bambini lavoratori.\n\npost_RD &lt;- bind_rows(\n  post %&gt;% select(RD) %&gt;% mutate(scenario = \"Problemi astratti\"),\n  post_m %&gt;% select(RD) %&gt;% mutate(scenario = \"Problemi di mercato\")\n)\n\nggplot(post_RD, aes(x = RD, fill = scenario)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  facet_wrap(~scenario, ncol = 1, scales = \"free_y\") +\n  labs(\n    x = \"RD = p_work - p_non\",\n    y = \"Densità\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n37.7.2 Odds ratio (OR)\nUn secondo grafico mostra le distribuzioni posteriori dell’odds ratio. Nei problemi astratti, la distribuzione è concentrata al di sotto di 1, evidenziando odds più bassi per i bambini lavoratori. Nei problemi di mercato, l’odds ratio risulta al contrario molto più grande di 1, segnalando un vantaggio consistente per i lavoratori.\n\npost_OR &lt;- bind_rows(\n  post %&gt;% select(OR) %&gt;% mutate(scenario = \"Problemi astratti\"),\n  post_m %&gt;% select(OR) %&gt;% mutate(scenario = \"Problemi di mercato\")\n)\n\nggplot(post_OR, aes(x = OR, fill = scenario)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(xintercept = 1, linetype = \"dashed\") +\n  facet_wrap(~scenario, ncol = 1, scales = \"free_y\") +\n  scale_x_continuous(trans = \"log\", breaks = c(0.1, 0.5, 1, 2, 5, 10, 50)) +\n  labs(\n    x = \"Odds ratio (scala log)\",\n    y = \"Densità\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nQueste figure completano l’analisi, mostrando visivamente come lo stesso modello possa descrivere due situazioni opposte. La regressione logistica, in chiave bayesiana, fornisce un linguaggio comune per esprimere risultati che nei dati appaiono così divergenti: vantaggio per i bambini scolarizzati nei compiti astratti, e vantaggio per i bambini lavoratori nei compiti concreti di mercato.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#proporzioni-posteriori-di-successo-per-gruppo",
    "href": "chapters/glm/03_two_proportions.html#proporzioni-posteriori-di-successo-per-gruppo",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n37.8 Proporzioni posteriori di successo per gruppo",
    "text": "37.8 Proporzioni posteriori di successo per gruppo\nPer completare il quadro conviene mostrare direttamente le probabilità di successo stimate per ciascun gruppo, nei due scenari. L’idea è di partire dai draw posteriori già calcolati e di riassumerli con mediana e intervalli credibili. Il grafico risultante rende evidente, a colpo d’occhio, sia la distanza fra i gruppi sia l’ampiezza dell’incertezza.\n\n# Raccogliamo i draw di p per ciascuno scenario e gruppo\npost_props &lt;- bind_rows(\n  post %&gt;%\n    transmute(\n      scenario = \"Problemi astratti\",\n      `non-working` = p_ref,\n      `working`     = p_work\n    ),\n  post_m %&gt;%\n    transmute(\n      scenario = \"Problemi di mercato\",\n      `non-working` = p_ref,\n      `working`     = p_work\n    )\n) |&gt;\n  pivot_longer(cols = c(`non-working`, `working`),\n               names_to = \"gruppo\", values_to = \"p\")\n\n# Riassunto con mediana e intervalli credibili\nsumm_props &lt;- post_props |&gt;\n  group_by(scenario, gruppo) |&gt;\n  median_qi(p, .width = c(.95, .89)) |&gt;\n  ungroup()\n\n# Grafico punto + intervallo credibile\nggplot(summ_props, aes(x = gruppo, y = p, ymin = .lower, ymax = .upper)) +\n  geom_pointrange(position = position_dodge(width = 0.4)) +\n  facet_wrap(~ scenario, ncol = 1) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    x = NULL,\n    y = \"Probabilità di successo\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nIl pannello sui problemi astratti mostra una probabilità di successo più alta per i bambini scolarizzati rispetto ai lavoratori, con intervalli credibili che riflettono l’incertezza ma mantengono un chiaro distacco fra i gruppi. Il pannello sui problemi di mercato, al contrario, evidenzia un’inversione marcata: i lavoratori presentano una probabilità sensibilmente maggiore, mentre gli scolarizzati rimangono vicini allo zero. La lettura combinata di questi due pannelli rafforza l’interpretazione proposta nei paragrafi precedenti e rende visiva la coerenza fra scale diverse, perché le conclusioni tratte da RD, OR e RR trovano una corrispondenza immediata nelle probabilità stimate.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#il-modello-scritto-in-stan",
    "href": "chapters/glm/03_two_proportions.html#il-modello-scritto-in-stan",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n37.9 Il modello scritto in Stan",
    "text": "37.9 Il modello scritto in Stan\nPer completezza, possiamo mostrare come la stessa analisi sia realizzabile direttamente in Stan, senza passare da brms. Questo esempio ha uno scopo puramente didattico: nel capitolo “Regressione logistica con Stan” troveremo la discussione più dettagliata della sintassi e delle scelte di modellizzazione. Qui ci interessa soprattutto vedere come la struttura logistica con variabile dummy possa essere implementata in modo molto semplice.\nIl modello prevede due gruppi. Per ciascun gruppo conosciamo il numero di successi e il numero totale di prove. Introduciamo inoltre un predittore dummy che vale 0 per il gruppo di riferimento (non-working) e 1 per il gruppo di confronto (working). Il modello utilizza una parametrizzazione logit con due coefficienti: l’intercetta \\(\\alpha\\), che descrive i log-odds del gruppo di riferimento, e il coefficiente \\(\\gamma\\), che rappresenta la differenza di log-odds fra i gruppi. A partire da questi due parametri possiamo ricavare tutte le quantità di interesse già discusse, cioè le probabilità di successo nei due gruppi, la differenza di rischio, l’odds ratio e il risk ratio.\n\nstan_code &lt;- '\ndata {\n  int&lt;lower=1&gt; G;                // numero di gruppi (=2)\n  array[G] int&lt;lower=0&gt; y;       // successi osservati per ciascun gruppo\n  array[G] int&lt;lower=0&gt; n;       // prove totali per ciascun gruppo\n  array[G] int&lt;lower=0,upper=1&gt; D; // dummy: 0 = non-working, 1 = working\n}\nparameters {\n  real alpha;                     // intercetta (log-odds gruppo di riferimento)\n  real gamma;                     // coefficiente della dummy (log-odds ratio)\n}\nmodel {\n  // prior deboli sulla scala logit\n  alpha ~ normal(0, 2.5);\n  gamma ~ normal(0, 2.5);\n\n  // verosimiglianza binomiale per ciascun gruppo\n  for (g in 1:G) {\n    real eta = alpha + gamma * D[g];\n    y[g] ~ binomial(n[g], inv_logit(eta));\n  }\n}\ngenerated quantities {\n  real p_ref    = inv_logit(alpha);             // probabilità nel gruppo di riferimento\n  real p_work   = inv_logit(alpha + gamma);     // probabilità nel gruppo working\n  real RD       = p_work - p_ref;               // differenza di probabilità\n  real OR       = exp(gamma);                   // odds ratio\n  real RR       = p_work / p_ref;               // risk ratio\n}\n'\n\nI dati da fornire a Stan sono molto semplici: i conteggi di successi e prove nei due gruppi, più la variabile dummy che distingue i gruppi.\n\ndat_stan &lt;- list(\n  G = 2,\n  y = c(x_non, x_work),\n  n = c(n_non, n_work),\n  D = c(0L, 1L)\n)\n\nCompiliamo quindi il modello e avviamo il campionamento MCMC.\n\nmod  &lt;- cmdstan_model(write_stan_file(stan_code))\nfitS &lt;- mod$sample(data = dat_stan, seed = 1234,\n                   chains = 4, parallel_chains = 4)\n\nInfine, estraiamo le quantità derivate di maggiore interesse, esattamente le stesse già calcolate nel caso di brms.\n\nfitS$summary(variables = c(\"p_ref\",\"p_work\",\"RD\",\"OR\",\"RR\"))\n#&gt; # A tibble: 5 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 p_ref     0.590  0.591 0.022 0.022  0.553  0.625 1.005  929.925  853.063\n#&gt; 2 p_work    0.451  0.451 0.013 0.013  0.429  0.472 1.000 3200.938 2588.523\n#&gt; 3 RD       -0.140 -0.140 0.025 0.025 -0.180 -0.098 1.006  877.412  873.285\n#&gt; 4 OR        0.572  0.568 0.059 0.058  0.482  0.676 1.005  874.895  869.354\n#&gt; 5 RR        0.765  0.763 0.036 0.035  0.709  0.826 1.006  929.621 1006.127\n\nI risultati ottenuti coincidono con quelli ricavati tramite brms. Questo conferma che la parametrizzazione logit con dummy è del tutto equivalente all’impostazione con predittore categoriale, e che da essa possiamo derivare in modo trasparente tutte le grandezze interpretative: probabilità nei gruppi, differenza di rischio, odds ratio e risk ratio. In questo modo il modello Stan, pur scritto in forma minimale, ci permette di vedere con chiarezza la logica interna dell’analisi e rafforza la comprensione concettuale della regressione logistica come strumento per il confronto fra proporzioni.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#posterior-predictive-check",
    "href": "chapters/glm/03_two_proportions.html#posterior-predictive-check",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "\n37.10 Posterior predictive check",
    "text": "37.10 Posterior predictive check\nUn vantaggio di Stan è che possiamo generare, nello stesso modello, dei dati replicati secondo la distribuzione predittiva posteriore. Questo ci consente di confrontare i dati osservati con quelli che il modello si aspetta, valutando così la bontà dell’adattamento.\nBasta aggiungere, nella sezione generated quantities, delle variabili che rappresentino i successi simulati a posteriori per ciascun gruppo. Queste repliche, combinate con le quantità già calcolate (\\(p_{ref}\\), \\(p_{work}\\), \\(RD\\), \\(OR\\), \\(RR\\)), ci permettono di eseguire controlli predittivi direttamente in R dopo l’esecuzione del modello.\n\nstan_code_ppc &lt;- '\ndata {\n  int&lt;lower=1&gt; G;                  // numero gruppi (=2)\n  array[G] int&lt;lower=0&gt; y;         // successi osservati\n  array[G] int&lt;lower=0&gt; n;         // prove totali\n  array[G] int&lt;lower=0,upper=1&gt; D; // dummy: 0 = non-working, 1 = working\n}\nparameters {\n  real alpha;                       // intercetta (log-odds gruppo di riferimento)\n  real gamma;                       // coefficiente dummy (log-odds ratio)\n}\nmodel {\n  // prior deboli\n  alpha ~ normal(0, 2.5);\n  gamma ~ normal(0, 2.5);\n\n  for (g in 1:G) {\n    real eta = alpha + gamma * D[g];\n    y[g] ~ binomial(n[g], inv_logit(eta));\n  }\n}\ngenerated quantities {\n  real p_ref    = inv_logit(alpha);\n  real p_work   = inv_logit(alpha + gamma);\n  real RD       = p_work - p_ref;\n  real OR       = exp(gamma);\n  real RR       = p_work / p_ref;\n\n  // dati replicati per i due gruppi\n  array[G] int y_rep;\n  for (g in 1:G) {\n    real eta = alpha + gamma * D[g];\n    y_rep[g] = binomial_rng(n[g], inv_logit(eta));\n  }\n}\n'\n\nPrepariamo i dati nello stesso modo di prima:\n\ndat_stan &lt;- list(\n  G = 2,\n  y = c(x_non, x_work),\n  n = c(n_non, n_work),\n  D = c(0L, 1L)\n)\n\nCompiliamo e lanciamo il modello:\n\nmod_ppc &lt;- cmdstan_model(write_stan_file(stan_code_ppc))\nfit_ppc &lt;- mod_ppc$sample(data = dat_stan, seed = 1234,\n                          chains = 4, parallel_chains = 4)\n\nOra possiamo esaminare le repliche generate a posteriori. Ad esempio, visualizziamo le distribuzioni predittive delle proporzioni replicate e confrontiamole con quelle osservate.\n\n# Estraiamo le repliche\ny_rep &lt;- fit_ppc$draws(\"y_rep\") |&gt; as_draws_matrix()\ny_rep_df &lt;- as_tibble(y_rep) |&gt; \n  mutate(draw = row_number()) |&gt; \n  pivot_longer(-draw, names_to = \"var\", values_to = \"count_rep\") |&gt; \n  mutate(group = ifelse(var == \"y_rep[1]\", \"non-working\", \"working\"),\n         tot   = ifelse(group == \"non-working\", n_non, n_work),\n         observed = ifelse(group == \"non-working\", x_non, x_work),\n         prop_rep = count_rep / tot,\n         prop_obs = observed / tot)\n\nggplot(y_rep_df, aes(x = prop_rep)) +\n  geom_density(alpha = 0.5, fill = \"#56B4E9\") +\n  geom_vline(aes(xintercept = prop_obs), linetype = \"dashed\") +\n  facet_wrap(~ group, scales = \"free\") +\n  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    title = \"Posterior predictive check (Stan)\",\n    subtitle = \"Linea tratteggiata = proporzione osservata;\\ncurva = distribuzione delle proporzioni replicate\",\n    x = \"Proporzione di successi (repliche posteriori)\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nIl grafico mostra che le proporzioni osservate nei due gruppi ricadono all’interno delle distribuzioni predittive generate dal modello. Questo è un segnale positivo: il modello è capace di riprodurre i dati reali con buona coerenza. Naturalmente, controlli più sofisticati possono includere altre statistiche riassuntive o l’uso di funzioni dedicate, ma questo esempio illustra bene il principio fondamentale: Stan non si limita a stimare parametri, ma permette anche di simulare nuovi dati per verificare in modo diretto l’adeguatezza del modello.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#riflessioni-conclusive",
    "href": "chapters/glm/03_two_proportions.html#riflessioni-conclusive",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come il problema del confronto tra due proporzioni possa essere formulato come un caso particolare di regressione logistica, con un unico predittore binario che distingue i due gruppi. Questo ci ha permesso di interpretare l’intercetta come la probabilità di successo nel gruppo di riferimento e il coefficiente come la differenza in log-odds tra i gruppi.\nL’approccio bayesiano ci ha dato un vantaggio decisivo: invece di ridurre l’analisi a un verdetto basato su un p-value, abbiamo ottenuto una distribuzione a posteriori dei parametri. Questa distribuzione ci consente di calcolare probabilità direttamente interpretabili, come la probabilità che un trattamento sia più efficace dell’altro o la probabilità che la differenza superi una soglia di rilevanza pratica. In questo modo, l’analisi diventa più ricca e più utile per guidare decisioni empiriche e cliniche.\nDal punto di vista concettuale, abbiamo imparato che il confronto tra due proporzioni non è un problema isolato, ma si inserisce pienamente nel quadro dei modelli lineari generalizzati. La regressione logistica, infatti, non è soltanto uno strumento per analizzare variabili dicotomiche, ma anche un linguaggio unificante che ci permette di trattare proporzioni, probabilità e differenze tra gruppi con coerenza e rigore.\nNei capitoli successivi vedremo come questa stessa logica possa estendersi ad altri tipi di dati, come i conteggi, consolidando ulteriormente l’idea che i GLM costituiscano un quadro flessibile e generale per affrontare molte delle domande tipiche della ricerca psicologica.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_two_proportions.html#bibliografia",
    "href": "chapters/glm/03_two_proportions.html#bibliografia",
    "title": "37  Confronto tra due proporzioni con la regressione logistica",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBanerjee, A. V., Bhattacharjee, S., Chattopadhyay, R., Duflo, E., Ganimian, A. J., Rajah, K., & Spelke, E. S. (2025). Children’s arithmetic skills do not transfer between applied and academic mathematics. Nature, 1–9.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Confronto tra due proporzioni con la regressione logistica</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html",
    "href": "chapters/glm/04_poisson_model.html",
    "title": "38  Modello di Poisson",
    "section": "",
    "text": "Introduzione\nNelle sezioni precedenti abbiamo visto come i modelli lineari generalizzati possano estendere la logica della regressione a esiti non continui, come variabili dicotomiche o proporzioni. Un altro tipo di dati molto comune nella ricerca psicologica e sociale è costituito dai conteggi: quante volte si verifica un certo evento in un intervallo di tempo o in un contesto definito. Pensiamo, ad esempio, al numero di errori commessi in un compito cognitivo, al numero di episodi di un comportamento clinicamente rilevante, o al numero di interazioni osservate in un gruppo.\nPer modellare questi dati ricorriamo alla regressione di Poisson, che assume che la variabile di risposta \\(Y\\) segua una distribuzione di Poisson e che il logaritmo del suo valore atteso possa essere espresso come una combinazione lineare di parametri sconosciuti. In questo modo, possiamo descrivere il tasso medio di occorrenza di un evento e studiare come esso vari al variare dei predittori.\nIn questo capitolo utilizzeremo CmdStan per stimare un modello di Poisson in chiave bayesiana. Dopo aver esaminato la media a posteriori e l’incertezza associata al tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ciascun anno, ci chiederemo se vi siano evidenze di una tendenza crescente nel tempo. Questo esempio, oltre a illustrare il funzionamento del modello di Poisson, mostra anche come i GLM possano essere applicati a dati di grande rilevanza sociale.\nPer chi volesse approfondire il contesto sostantivo, segnaliamo l’articolo Racial Disparities in Police Use of Deadly Force Against Unarmed Individuals Persist After Appropriately Benchmarking Shooting Data on Violent Crime Rates [Ross et al. (2021)], che offre uno sfondo importante al fenomeno analizzato. La lettura non è obbligatoria per seguire il capitolo, ma aiuta a comprendere meglio il valore applicativo di questo tipo di analisi.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html#introduzione",
    "href": "chapters/glm/04_poisson_model.html#introduzione",
    "title": "38  Modello di Poisson",
    "section": "",
    "text": "Panoramica del capitolo\n\nIntroduzione alla regressione di Poisson per dati di conteggio.\nStudio dell’andamento temporale delle sparatorie fatali della polizia USA (2015-2024).\nImplementazione del modello in Stan.\nPosterior predictive check e analisi degli Incidence Rate Ratios (IRR).\nTraduzione dei coefficienti in termini di conteggi attesi e trend percentuale annuo.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere Racial Disparities in Police Use of Deadly Force Against Unarmed Individuals Persist After Appropriately Benchmarking Shooting Data on Violent Crime Rates per ottenere una panoramica approfondita su questo fenomeno e sul relativo ambito di ricerca.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, HDInterval, lubridate, brms, bayesplot, tidybayes, posterior, tidyr)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html#regressione-di-poisson",
    "href": "chapters/glm/04_poisson_model.html#regressione-di-poisson",
    "title": "38  Modello di Poisson",
    "section": "\n38.1 Regressione di Poisson",
    "text": "38.1 Regressione di Poisson\nLa regressione di Poisson è un caso di GLM per variabili di risposta di conteggio (0, 1, 2, …). Denoteremo con \\(\\lambda_i\\) il valore atteso (e, sotto il modello di Poisson, anche la varianza) del conteggio \\(Y_i\\) alla \\(i\\)-esima osservazione.\n\n38.1.1 Distribuzione di base\nUna variabile casuale di Poisson ha funzione di massa\n\\[\n\\Pr(Y=y)=\\frac{\\lambda^{\\,y}e^{-\\lambda}}{y!},\\qquad y\\in\\{0,1,2,\\dots\\},\n\\] dove \\(\\lambda&gt;0\\) è sia media sia varianza: \\(\\mathbb{E}[Y]=\\lambda,\\ \\mathrm{Var}(Y)=\\lambda\\).\nNel contesto del modello di regressione,\n\\[\nY_i \\mid \\mathbf{x}_i \\sim \\text{Poisson}(\\lambda_i),\n\\qquad \\lambda_i&gt;0 .\n\\]\n\n38.1.2 Forma GLM e funzione di legame\nPer garantire \\(\\lambda_i&gt;0\\) si usa il link logaritmico (naturale):\n\\[\n\\log \\lambda_i = \\eta_i\n\\quad\\text{con}\\quad\n\\eta_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n\\] Equivalente a:\n\\[\n\\lambda_i = \\exp(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}).\n\\]\n\nNota terminologica: il link è \\(\\log(\\cdot)\\); l’esponenziale è la sua inversa. Non è corretto chiamare “link esponenziale”.\n\n\n38.1.3 Conteggi e predittori\nNel modello di regressione di Poisson assumiamo che ciascun conteggio \\(Y_i\\) segua una distribuzione di Poisson con media \\(\\lambda_i\\). Il legame tra la media \\(\\lambda_i\\) e le variabili esplicative è dato dalla funzione logaritmica:\n\\[\n\\log \\lambda_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n\\] In questo modo il numero medio di eventi attesi \\(\\lambda_i\\) viene sempre stimato come un valore positivo:\n\\[\n\\lambda_i = \\exp(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}).\n\\] Questa formulazione è adatta quando tutti i conteggi si riferiscono a intervalli di osservazione uguali (per esempio, il numero di episodi aggressivi in un anno per ciascuno studente). In tal caso non serve introdurre ulteriori correzioni: il modello lavora direttamente sui conteggi osservati.\n\n38.1.4 Interpretazione dei coefficienti\nNel modello di regressione di Poisson ogni osservazione \\(Y_i\\) segue\n\\[\nY_i \\sim \\text{Poisson}(\\lambda_i),\n\\qquad \\log \\lambda_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n\\] Qui \\(\\lambda_i\\) è il numero medio di eventi attesi per l’osservazione \\(i\\).\nPer il j-esimo predittore \\(x_{ij}\\), il rapporto tra i valori attesi quando \\(x_{ij}\\) aumenta di 1 unità è\n\\[\n\\frac{\\lambda_i(x_{ij}+1)}{\\lambda_i(x_{ij})} = \\exp(\\beta_j).\n\\] Questo significa che \\(\\exp(\\beta_j)\\) è il fattore moltiplicativo atteso sul numero medio di eventi per un incremento unitario di \\(x_{ij}\\).\n\nSe \\(\\beta_j = 0\\), non c’è effetto (\\(\\exp(\\beta_j)=1\\)).\nSe \\(\\beta_j &gt; 0\\), i conteggi attesi crescono moltiplicati per \\(\\exp(\\beta_j)\\).\nSe \\(\\beta_j &lt; 0\\), i conteggi attesi diminuiscono, divisi per \\(\\exp(|\\beta_j|)\\).\n\nPer variabili binarie, \\(\\exp(\\beta_j)\\) confronta direttamente i due gruppi (1 contro 0).\nEsempio. Se studiamo il numero di episodi aggressivi in un anno per ciascuno studente, il modello può essere scritto come\n\\[\n\\log \\lambda_i = \\beta_0 + \\beta_1 \\,\\text{Stress}_i + \\beta_2 \\,\\text{Supporto}_i + \\beta_3 \\,\\text{Depressione}_i.\n\\] Qui \\(\\exp(\\beta_1)\\) indica di quanto si moltiplica il numero medio di episodi aggressivi attesi quando lo stress aumenta di 1 unità, a parità delle altre variabili.\n\n38.1.5 Assunzioni di base\nPer usare la regressione di Poisson facciamo alcune ipotesi semplici:\n\n\nRisposta a conteggio: la variabile dipendente è un numero intero non negativo (0, 1, 2, …).\n\nIndipendenza: le osservazioni sono considerate indipendenti tra loro.\n\nMedia = varianza: nella distribuzione di Poisson la media e la varianza coincidono. Se nei dati la varianza è molto più grande della media, il modello di Poisson può non essere adatto.\n\nRelazione log-lineare: il logaritmo del numero medio di eventi è una combinazione lineare dei predittori.\n\n38.1.6 Come il modello rappresenta lambda\nNella regressione di Poisson non stimiamo direttamente il valore medio \\(\\lambda_i\\), ma il suo logaritmo:\n\\[\n\\eta_i = \\log \\lambda_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}.\n\\]\n\n\nCaso senza predittori: il modello stima solo l’intercetta \\(\\alpha\\). In questo caso\n\\[\n\\lambda = \\exp(\\alpha).\n\\]\n\n\nCaso con predittori: dati i valori delle variabili esplicative \\(\\mathbf{x}_i\\), il numero medio di eventi per l’osservazione \\(i\\) è\n\\[\n\\lambda_i = \\exp\\big(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}\\big).\n\\] In altre parole, il modello lavora sempre sulla scala logaritmica (più semplice da trattare matematicamente), e poi si passa alla scala naturale dei conteggi applicando l’esponenziale.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html#la-domanda-di-ricerca",
    "href": "chapters/glm/04_poisson_model.html#la-domanda-di-ricerca",
    "title": "38  Modello di Poisson",
    "section": "\n38.2 La domanda di ricerca",
    "text": "38.2 La domanda di ricerca\nGrazie all’archivio pubblico del Washington Post disponiamo di tutti i casi di sparatorie fatali accadute negli Stati Uniti dal 2015 in poi. L’interesse è stimare quante se vi siano evidenze di una tendenza all’aumento di tale tasso nel corso del tempo.\nImportiamo e prepariamo i dati:\n\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nraw &lt;- read.csv(url, stringsAsFactors = FALSE)\nraw$date &lt;- as.Date(raw$date)\nraw$year &lt;- lubridate::year(raw$date)\n\n# Escludiamo il 2025 perché l’anno è ancora in corso e i dati sarebbero incompleti\nshootings &lt;- subset(raw, year &lt; 2025)\n\ndf &lt;- shootings %&gt;%\n  dplyr::count(year, name = \"events\")\ndf\n#&gt;    year events\n#&gt; 1  2015    995\n#&gt; 2  2016    959\n#&gt; 3  2017    984\n#&gt; 4  2018    992\n#&gt; 5  2019    993\n#&gt; 6  2020   1021\n#&gt; 7  2021   1050\n#&gt; 8  2022   1097\n#&gt; 9  2023   1164\n#&gt; 10 2024   1175\n\nPer facilitare l’interpretazione, centriamo la colonna year. In questo modo, l’intercetta si riferità all’anno 2019.\n\ndf &lt;- df |&gt; \n  mutate(year = year - 2019)\ndf\n#&gt;    year events\n#&gt; 1    -4    995\n#&gt; 2    -3    959\n#&gt; 3    -2    984\n#&gt; 4    -1    992\n#&gt; 5     0    993\n#&gt; 6     1   1021\n#&gt; 7     2   1050\n#&gt; 8     3   1097\n#&gt; 9     4   1164\n#&gt; 10    5   1175\n\nA questo punto abbiamo una tabella df con due colonne: year (centrato), che va dal -4 (2015) a 5 (2024), ed events, che contiene il numero di sparatorie fatali registrate in ciascun anno.\n\n38.2.1 Modello Stan\nDefiniamo il seguente modello\n\nstan_code &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  array[N] int&lt;lower=0&gt; y;   // conteggi\n  vector[N] year;            // -4, -3, ..., 5 (non standardizzato)\n}\n\nparameters {\n  real alpha;                // log media per anno 0\n  real beta;                 // effetto per 1 anno (log-IRR per anno)\n}\n\nmodel {\n  // Priors coerenti con: lambda ~ 600 circa, 400–900 plausibile\n  alpha ~ normal(6.4, 0.25);   // oppure 0.30 se preferisci più ampia\n  beta  ~ normal(0, 0.05);     // oppure 0.10 se vuoi più permissiva\n\n  // Poisson con link log\n  y ~ poisson_log(alpha + beta * year);\n}\n\ngenerated quantities {\n  vector[N] eta = alpha + beta * year;\n  vector[N] lambda = exp(eta);\n  array[N] int&lt;lower=0&gt; y_rep;\n  for (n in 1:N) y_rep[n] = poisson_log_rng(eta[n]);\n}\n'\n\nSpecificare la distribuzione a priori:\n\n\nIntercetta: \\(\\alpha=\\log\\lambda\\). Poiché riteniamo plausibile, prima dei dati, una media annua \\(\\lambda\\) centrata attorno a 600, con intervallo ~400–900, imponiamo \\(\\alpha \\sim \\mathcal N(6.40,\\ 0.25)\\) (oppure \\(0.30\\) per un intervallo un po’ più ampio).\n\nPendenza: \\(\\beta\\) è il log-IRR per anno. Attese variazioni annue piccole ⇒ \\(\\beta \\sim \\mathcal N(0,\\ 0.05)\\) (più prudente) oppure \\(\\mathcal N(0,\\ 0.10)\\) (più ampia).\n\nDati:\n\ndat &lt;- data.frame(\n  year   = -4:5,\n  events = c(995, 959, 984, 992, 993, 1021, 1050, 1097, 1164, 1175)\n)\n\nstan_data &lt;- list(\n  N = nrow(dat),\n  y = dat$events,\n  year = dat$year\n)\nglimpse(stan_data)\n#&gt; List of 3\n#&gt;  $ N   : int 10\n#&gt;  $ y   : num [1:10] 995 959 984 992 993 ...\n#&gt;  $ year: int [1:10] -4 -3 -2 -1 0 1 2 3 4 5\n\nCompiliamo il modello e avviamo il campionamento MCMC.\n\nmod  &lt;- cmdstan_model(write_stan_file(stan_code))\n\n\nfit &lt;- mod$sample(\n  data = stan_data, seed = 1234,\n  chains = 4, parallel_chains = 4\n)\n\nEstraiamo le quantità derivate di maggiore interesse:\n\nfit$summary(variables = c(\"alpha\", \"beta\", \"lambda\"))\n#&gt; # A tibble: 12 × 10\n#&gt;    variable       mean   median     sd    mad       q5      q95  rhat ess_bulk\n#&gt;    &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 alpha         6.936    6.936  0.010  0.010    6.919    6.953 1.002 2204.738\n#&gt;  2 beta          0.022    0.022  0.003  0.003    0.017    0.028 1.001 3921.050\n#&gt;  3 lambda[1]   941.474  941.801 17.650 17.035  912.472  971.438 1.001 2679.962\n#&gt;  4 lambda[2]   962.558  962.748 15.339 15.008  937.673  988.402 1.001 2529.218\n#&gt;  5 lambda[3]   984.125  984.098 13.197 12.980  962.847 1006.315 1.001 2360.153\n#&gt;  6 lambda[4]  1006.188 1006.306 11.435 11.412  987.696 1025.400 1.002 2225.370\n#&gt;  7 lambda[5]  1028.757 1028.715 10.386 10.218 1011.757 1045.887 1.002 2204.743\n#&gt;  8 lambda[6]  1051.845 1051.811 10.420 10.291 1034.962 1069.068 1.001 2432.282\n#&gt;  9 lambda[7]  1075.464 1075.166 11.672 11.765 1056.337 1094.511 1.001 2907.241\n#&gt; 10 lambda[8]  1099.626 1099.600 13.949 14.347 1076.660 1122.705 1.001 3450.415\n#&gt; 11 lambda[9]  1124.344 1124.076 16.959 17.358 1096.501 1152.436 1.002 3873.761\n#&gt; 12 lambda[10] 1149.631 1149.272 20.487 20.926 1116.283 1183.948 1.002 4105.120\n#&gt;    ess_tail\n#&gt;       &lt;dbl&gt;\n#&gt;  1 2351.782\n#&gt;  2 3015.859\n#&gt;  3 2639.793\n#&gt;  4 2550.928\n#&gt;  5 2548.232\n#&gt;  6 2343.254\n#&gt;  7 2351.782\n#&gt;  8 2512.354\n#&gt;  9 2834.135\n#&gt; 10 2973.167\n#&gt; 11 2997.796\n#&gt; 12 3053.556\n\n\n38.2.2 Interpretazione\nIl parametro alpha rappresenta il logaritmo del numero medio atteso di eventi nell’anno di riferimento \\(x=0\\). Nel nostro modello l’anno 0 è semplicemente il punto centrale della sequenza di anni osservata (−4,…,5).\nIl valore stimato è \\(\\alpha \\approx 6.94\\), con un intervallo di credibilità al 95% compreso tra 6.92 e 6.95. Trasformando sulla scala naturale, otteniamo:\n\\[\n\\exp(\\alpha) \\approx 1\\,030\n\\] cioè circa 1030 eventi attesi nell’anno di riferimento.\nIl parametro beta misura la variazione logaritmica attesa per ogni anno aggiuntivo. La stima \\(\\beta \\approx 0.022\\) (ICr 95%: 0.017–0.028) indica una crescita positiva.\nPer interpretare questo effetto sulla scala dei conteggi:\n\\[\n\\exp(\\beta) \\approx 1.022 ,\n\\] ossia ogni anno in più corrisponde a un aumento atteso di circa +2.2% degli eventi rispetto all’anno precedente.\nSe traduciamo questa percentuale in termini assoluti, partendo dal valore base \\(\\exp(\\alpha)\\approx 1.030\\), otteniamo:\n\\[\n\\exp(\\alpha)\\times(\\exp(\\beta)-1) \\;\\approx\\; 23\n\\] quindi in media circa 23 eventi in più per ogni anno successivo.\n\n# Anni da predire (quelli del dataset)\nyears &lt;- -4:5\n\n# Estrai i draw posteriori di alpha e beta da cmdstanr\n# (se vuoi in formato data frame \"largo\")\ndraws &lt;- as_draws_df(fit$draws(variables = c(\"alpha\", \"beta\")))\n\n# Costruisci predizioni posteriori di lambda per ogni anno\npred &lt;- lapply(years, function(y) {\n  tibble(\n    year   = y,\n    lambda = exp(draws$alpha + draws$beta * y)\n  )\n}) |&gt;\n  bind_rows()\n\n# Riassumi: media e intervallo di credibilità 95%\npred_sum &lt;- pred |&gt;\n  group_by(year) |&gt;\n  summarise(\n    lambda_mean = mean(lambda),\n    lambda_q05  = quantile(lambda, 0.05),\n    lambda_q95  = quantile(lambda, 0.95),\n    .groups = \"drop\"\n  )\n\n# (opzionale) unisci i dati osservati\ndat &lt;- tibble(\n  year   = -4:5,\n  events = c(995, 959, 984, 992, 993, 1021, 1050, 1097, 1164, 1175)\n)\n\n# Grafico: banda 90% (5%-95%), linea media e punti osservati\nggplot(pred_sum, aes(x = year)) +\n  geom_ribbon(aes(ymin = lambda_q05, ymax = lambda_q95), alpha = 0.2) +\n  geom_line(aes(y = lambda_mean), linewidth = 1) +\n  geom_point(data = dat, aes(y = events), size = 2) +\n  labs(\n    x = \"Anno (codifica -4 … 5)\",\n    y = \"Numero atteso di eventi\"\n  ) \n\n\n\n\n\n\n\nIl modello di regressione di Poisson mostra che il numero medio di eventi segue una crescita regolare nel tempo. L’intercetta indica che nell’anno di riferimento (\\(x=0\\)) ci si attendono circa 1030 eventi, mentre la pendenza suggerisce un incremento annuo di circa +2%, pari a una ventina di eventi in più ogni anno.\nLa banda di credibilità attorno alla curva stimata conferma che l’incertezza sulle previsioni è contenuta e che l’andamento crescente è chiaramente supportato dai dati. In termini sostantivi, il modello descrive bene una tendenza di crescita graduale ma costante negli anni osservati.\n\n38.2.3 Posterior predictive check\n\n# Dati osservati\ndat &lt;- tibble::tibble(\n  year   = -4:5,\n  events = c(995, 959, 984, 992, 993, 1021, 1050, 1097, 1164, 1175)\n)\n\n# Estrai i draw di y_rep in matrice (draws x N)\nyrep_mat &lt;- fit$draws(variables = \"y_rep\") |&gt;\n  as_draws_matrix()\n# Seleziona solo le colonne y_rep[...] mantenendo l'ordine\ncols &lt;- grep(\"^y_rep\\\\[\", colnames(yrep_mat))\nyrep_mat &lt;- yrep_mat[, cols, drop = FALSE]\n\n# Calcola quantili per colonna (per ogni anno)\nqs &lt;- colQuantiles(yrep_mat, probs = c(0.05, 0.50, 0.95))\npred_sum &lt;- tibble::tibble(\n  year = dat$year,\n  q05  = qs[, 1],\n  q50  = qs[, 2],\n  q95  = qs[, 3]\n)\n\n# Grafico PPC: banda 90% + mediana + punti osservati\nggplot(pred_sum, aes(x = year)) +\n  geom_ribbon(aes(ymin = q05, ymax = q95), alpha = 0.2) +\n  geom_line(aes(y = q50), linewidth = 1) +\n  geom_point(data = dat, aes(y = events), size = 2) +\n  labs(\n    x = \"Anno (codifica -4 … 5)\",\n    y = \"Conteggio\"\n  ) \n\n\n\n\n\n\n\n\nLa banda ombreggiata rappresenta il 90% della distribuzione predittiva del conteggio per ciascun anno (5%–95%).\nLa linea è la mediana predittiva; i punti sono i conteggi osservati.\nSe i punti stanno per lo più dentro le bande, il modello riproduce bene i livelli di conteggio anno per anno.\nSe molti punti cadono fuori (o tutti da un lato), il modello potrebbe essere troppo rigido o mancare di struttura (p.es. overdispersione, forma non lineare nel tempo, effetti non inclusi).\n\n\n# Media/varianza osservate\nmean_obs &lt;- mean(dat$events)\nvar_obs  &lt;- var(dat$events)\n\n# Media/varianza delle repliche (per draw)\nmean_rep &lt;- rowMeans(yrep_mat)\nvar_rep  &lt;- apply(yrep_mat, 1, var)\n\n# p-value predittivi (proporzione di repliche &gt;= osservato)\np_mean &lt;- mean(mean_rep &gt;= mean_obs)\np_var  &lt;- mean(var_rep  &gt;= var_obs)\n\ntibble::tibble(\n  stat      = c(\"media\", \"varianza\"),\n  osservato = c(mean_obs, var_obs),\n  media_rep = c(mean(mean_rep), mean(var_rep)),\n  p_pred    = c(p_mean, p_var)\n)\n#&gt; # A tibble: 2 × 4\n#&gt;   stat     osservato media_rep p_pred\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 media        1043      1042.  0.468\n#&gt; 2 varianza     5940.     6093.  0.486\n\n\np1 &lt;- ggplot(data.frame(mean_rep), aes(x = mean_rep)) +\n  geom_histogram(bins = 30) +\n  geom_vline(xintercept = mean_obs, linetype = 2) +\n  labs(title = \"PPC media\", x = \"Media (repliche)\", y = \"Frequenza\")\n\np2 &lt;- ggplot(data.frame(var_rep), aes(x = var_rep)) +\n  geom_histogram(bins = 30) +\n  geom_vline(xintercept = var_obs, linetype = 2) +\n  labs(title = \"PPC varianza\", x = \"Varianza (repliche)\", y = \"Frequenza\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIl controllo predittivo mostra che i conteggi osservati ricadono interamente entro le bande di credibilità del modello. Inoltre, la media e la varianza osservate sono molto vicine a quelle prodotte dalle repliche simulate (p-value predittivi ~0.5), il che indica che il modello non sottostima né sovrastima la variabilità dei dati. Nel complesso, questi risultati suggeriscono che la regressione di Poisson con legame log e trend lineare nel tempo fornisce una rappresentazione adeguata dei dati osservati.\n\n38.2.3.1 Incidence Rate Ratio (IRR)\n\nirr &lt;- draws |&gt;\n  transmute(\n    IRR = exp(beta)\n  ) |&gt;\n  summarise(\n    mean = mean(IRR),\n    q05  = quantile(IRR, 0.05),\n    q95  = quantile(IRR, 0.95)\n  )\nirr\n#&gt; # A tibble: 1 × 3\n#&gt;    mean   q05   q95\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  1.02  1.02  1.03\n\nIl valore medio stimato dell’IRR è 1.022, con un intervallo di credibilità al 90% compreso tra 1.017 e 1.028. Questo significa che, a ogni anno in più, il numero medio di eventi attesi aumenta di circa il 2.2%, con un margine di incertezza che va da circa +1.7% a +2.8%.\nPoiché l’intero intervallo si colloca sopra 1, il modello suggerisce con elevata credibilità che la tendenza temporale sia effettivamente crescente: non stiamo osservando fluttuazioni casuali, ma un aumento sistematico anno dopo anno.\nIl valore medio dell’IRR è 1.022: questo equivale a un incremento di circa +2.2% per anno.\n\nIn termini assoluti, partendo da una media di circa 1030 eventi, un aumento del 2.2% corrisponde a circa +23 eventi all’anno.\nL’intervallo di credibilità (1.017–1.028) implica che l’aumento medio sia compreso tra circa +18 e +29 eventi per anno.\n\nIn altre parole, il modello suggerisce che il fenomeno osservato cresce in modo regolare e consistente: ogni anno si verificano in media da una ventina a una trentina di eventi in più rispetto all’anno precedente.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/glm/04_poisson_model.html#riflessioni-conclusive",
    "title": "38  Modello di Poisson",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come il modello di Poisson possa essere usato per descrivere dati che rappresentano conteggi, come il numero di comportamenti osservati in un certo periodo di tempo o la frequenza con cui si manifesta un sintomo. L’idea centrale è semplice: invece di trattare i dati come proporzioni o medie, li consideriamo come eventi che “accadono” con una certa intensità, rappresentata dal parametro \\(\\lambda\\). Questo ci permette di modellare direttamente le frequenze osservate, rispettando la natura discreta e positiva dei dati.\nDal punto di vista psicologico, ciò significa avere uno strumento adatto per studiare fenomeni che non si esprimono in valori continui ma in conteggi (ad esempio, il numero di episodi ansiosi in una settimana, o il numero di errori commessi in un compito). L’approccio bayesiano aggiunge un ulteriore vantaggio: possiamo combinare le informazioni provenienti dai dati con ciò che sappiamo (o ipotizziamo) a priori sul fenomeno, ottenendo una stima che riflette sia l’evidenza empirica sia la nostra conoscenza di base.\nNei prossimi capitoli vedremo come estendere ulteriormente questa logica ad altri tipi di dati e modelli, consolidando l’idea che i GLM rappresentino un quadro flessibile e potente per affrontare molte delle domande classiche della ricerca psicologica.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] lubridate_1.9.4       HDInterval_0.2.4      cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [64] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [67] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [70] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [73] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [76] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [79] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_poisson_model.html#bibliografia",
    "href": "chapters/glm/04_poisson_model.html#bibliografia",
    "title": "38  Modello di Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRoss, C. T., Winterhalder, B., & McElreath, R. (2021). Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates. Social Psychological and Personality Science, 12(3), 323–332.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html",
    "href": "chapters/glm/05_logistic_process.html",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "",
    "text": "Introduzione\nLa regressione logistica è lo strumento di riferimento per analizzare esiti binari \\(y\\in\\{0,1\\}\\) in funzione di predittori osservabili \\(\\mathbf{x}\\). Fin qui l’abbiamo usata come GLM statico, assumendo osservazioni indipendenti, effetti invarianti nel tempo e un unico meccanismo generativo. Queste ipotesi sono utili per molti problemi, ma diventano limitanti quando vogliamo descrivere processi psicologici dinamici, in cui la risposta osservata è l’esito momentaneo di stati interni che si evolvono nel tempo.\nEsempi classici: in un compito ripetuto, la risposta al trial \\(t\\) può dipendere dall’esito al trial \\(t-1\\) (rinforzo, frustrazione, fatica), così come da stati latenti che variano lentamente (motivazione, attenzione). Il GLM logit standard non “vede” questa history dependence: tratta ogni risposta come se nascesse da zero. Per catturare la dimensione temporale, introduciamo una variabile latente continua \\(u_{i,t}\\) — la propensione interna a rispondere “1” del soggetto \\(i\\) al tempo \\(t\\) — e le permettiamo di portare memoria del passato:\n\\[\n\\Pr(y_{i,t}=1\\mid u_{i,t})=\\operatorname{logit}^{-1}(u_{i,t}), \\qquad\nu_{i,t}= \\alpha_i + \\mathbf{x}_{i,t}^\\top\\boldsymbol\\beta + \\phi\\,u_{i,t-1} + \\eta_{i,t}.\n\\]\nQui \\(\\alpha_i\\) cattura la propensione media soggetto-specifica, \\(\\boldsymbol\\beta\\) gli effetti dei predittori, \\(\\phi\\) la persistenza dinamica (quanta parte dello stato passato sopravvive), e \\(\\eta_{i,t}\\) il rumore di processo. Se \\(\\phi=0\\), torniamo al GLM statico; se \\(\\phi\\neq 0\\), modelliamo esplicitamente la dipendenza seriale.\nIn questo capitolo mostreremo come passare dal GLM logit a un modello processuale autoregressivo (AR) su scala logit, implementato in Stan. Partiremo da un’interpretazione latente del logit, introdurremo l’AR(1) e la sua estensione AR(\\(K\\)) per memorie più lunghe, simuleremo dati per verificare il recupero dei parametri e confronteremo le stime con un GLMM logit (via brms). Vedremo che distinguere tra effetto dei predittori (\\(\\boldsymbol\\beta\\)) e dinamica interna (\\(\\phi\\)) è essenziale per evitare stime distorte e per ancorare l’analisi statistica a ipotesi psicologiche sui meccanismi che generano il comportamento.\nL’obiettivo di questo capitolo è mostrare come, con Stan, sia possibile esplicitare il meccanismo generativo delle risposte, superando i limiti della regressione logistica classica e introducendo la nozione di processi dinamici autoregressivi che meglio riflettono la natura temporale dei fenomeni psicologici.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#introduzione",
    "href": "chapters/glm/05_logistic_process.html#introduzione",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "",
    "text": "Esempio.\n\n\n\n\n\nImmaginiamo uno studente che affronta un test a scelta multipla. Con un modello logistico classico possiamo prevedere se risponderà correttamente in base alla difficoltà della domanda. Ma se lo stesso studente sta svolgendo una lunga serie di prove, la sua risposta alla domanda 10 dipende anche da come è andata la domanda 9: un errore può ridurre la fiducia, un successo può aumentarla. In più, col passare del tempo, possono intervenire affaticamento o distrazione. Il modello statico logit non cattura nulla di tutto ciò. Per includere questi aspetti servono modelli che riconoscano che ogni osservazione porta memoria del passato.\n\n\n\n\nPanoramica del capitolo\n\nIntroduzione ai modelli dinamici in psicologia, superando i limiti dei GLM statici.\nLa regressione logistica classica reinterpretata attraverso variabili latenti e soglie.\nEstensione al modello AR(1) per catturare la dipendenza temporale e la “memoria” del passato.\nImplementazione pratica in Stan, con simulazione dati e confronto con modelli statici (GLMM).\nEvidenza che i modelli processuali dinamici forniscono stime più fedeli ai meccanismi generativi.\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, cmdstanr, posterior, brms, bayestestR, insight, conflicted)\n\nconflicts_prefer(posterior::mad)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#dal-modello-statico-al-modello-processuale",
    "href": "chapters/glm/05_logistic_process.html#dal-modello-statico-al-modello-processuale",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "\n39.1 Dal modello statico al modello processuale",
    "text": "39.1 Dal modello statico al modello processuale\n\n39.1.1 La regressione logistica classica\nNel modello di regressione logistica (GLM logit) la probabilità di osservare una risposta positiva è:\n\\[\n\\Pr(y_i=1 \\mid \\mathbf{x}_i) = \\operatorname{logit}^{-1}\\!\\left(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol\\beta\\right).\n\\]\nQui:\n\n\n\\(\\alpha\\) è l’intercetta, che rappresenta la tendenza di base a rispondere 1;\n\n\\(\\boldsymbol\\beta\\) descrive come i predittori osservati influenzano questa probabilità.\n\nUn modo intuitivo per interpretare la formula è introdurre una variabile latente continua \\(u_i\\), che possiamo pensare come la propensione interna dell’individuo a rispondere “1”:\n\\[\nu_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol\\beta + \\varepsilon_i,\n\\qquad \\varepsilon_i \\sim \\text{Logistic}(0,1).\n\\]\nLa regola di decisione è semplice:\n\nse \\(u_i &gt; 0\\) allora osserviamo \\(y_i=1\\),\nse \\(u_i \\leq 0\\) allora osserviamo \\(y_i=0\\).\n\nIn altre parole, immaginiamo che l’individuo abbia una soglia fissa: quando la propensione supera questa soglia, la risposta osservata diventa positiva.\nPossiamo pensare a \\(u_i\\) come a un “serbatoio di propensione”: se il livello supera la soglia, si osserva una risposta positiva. Nei modelli statici il serbatoio si svuota e si riempie indipendentemente a ogni trial; nei modelli dinamici, invece, il livello attuale dipende anche da quanto era pieno al trial precedente.\nNella regressione logistica classica, questa soglia è sempre costante nel tempo e uguale per tutti i trial. Ma nei processi psicologici reali ciò non è sempre realistico: la soglia decisionale (o l’intensità della propensione) può cambiare da un momento all’altro, ad esempio per effetto di apprendimento, fatica o variazioni di motivazione.\nEd è proprio da qui che nasce la necessità di estendere il modello logit statico a un modello dinamico, in cui la variabile latente \\(u\\) (e talvolta anche la soglia) possa variare nel tempo e riflettere la natura evolutiva dei processi psicologici.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#oltre-il-glm-dinamica-temporale",
    "href": "chapters/glm/05_logistic_process.html#oltre-il-glm-dinamica-temporale",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "\n39.2 Oltre il GLM: dinamica temporale",
    "text": "39.2 Oltre il GLM: dinamica temporale\nNella regressione logistica classica abbiamo visto che ogni risposta osservata \\(y_i\\) può essere pensata come il risultato di una propensione latente \\(u_i\\), confrontata con una soglia fissa. Questa impostazione funziona bene se consideriamo le osservazioni come indipendenti e isolate.\nMa in psicologia le cose vanno spesso diversamente:\n\nnegli esperimenti con prove ripetute, le decisioni prese oggi sono influenzate da quelle appena fatte;\nnelle misurazioni longitudinali (EMA), lo stato emotivo o motivazionale di un momento dipende in parte da quello precedente;\nnei compiti di apprendimento, l’esperienza accumulata modifica gradualmente la propensione a scegliere un’opzione rispetto a un’altra.\n\nIn tutti questi casi, è naturale immaginare che la variabile latente \\(u_{i,t}\\) non nasca da zero a ogni prova, ma porti memoria del passato.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#il-modello-ar1",
    "href": "chapters/glm/05_logistic_process.html#il-modello-ar1",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "\n39.3 Il modello AR(1)",
    "text": "39.3 Il modello AR(1)\nPer rendere esplicita la dipendenza dal passato, usiamo un modello autoregressivo di ordine 1 (AR(1); Chatfield & Xing (2019)):\n\\[\n\\begin{aligned}\nu_{i,t} &= \\alpha_i\n          + \\mathbf{x}_{i,t}^\\top \\boldsymbol\\beta\n          + \\phi \\, u_{i,t-1}\n          + \\eta_{i,t},\n& \\eta_{i,t} \\sim \\mathcal{N}(0,\\sigma_u), \\\\[6pt]\ny_{i,t} \\mid u_{i,t} &\\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_{i,t})\\right).\n\\end{aligned}\n\\]\nPossiamo immaginare \\(u_{i,t}\\) come il livello di un “serbatoio di propensione”: se questo valore supera la soglia implicita dello 0 sulla scala logit, la risposta osservata è positiva \\((y_{i,t}=1)\\). La novità rispetto al modello statico è che il livello attuale \\(u_{i,t}\\) dipende anche da quello precedente \\(u_{i,t-1}\\), attraverso il termine \\(\\phi u_{i,t-1}\\).\nSignificati dei parametri del modello AR(1):\n\n\\(\\alpha_i\\) (intercetta soggetto-specifica): propensione media di un individuo (es. uno studente molto ansioso potrebbe avere più probabilità di rispondere “no”).\n\\(\\beta\\) (effetto dei predittori): effetto di variabili osservabili (es. domande più facili aumentano la probabilità di risposta corretta).\n\n\\(\\phi\\) (persistenza dinamica): quanta parte dello stato passato sopravvive:\n\nse \\(\\phi=0\\), nessuna memoria: ogni risposta è “indipendente”,\nse \\(\\phi&gt;0\\), inerzia: un successo ieri aumenta la probabilità di successo oggi,\nse \\(\\phi&lt;0\\), alternanza: un successo ieri rende più probabile un errore oggi (pattern a zig-zag).\n\n\n\\(\\sigma_u\\) (variabilità del processo): irregolarità: se grande, le traiettorie diventano rumorose (es. risposte altalenanti per distrazioni).\n\nUn piccolo schema concettuale aiuta a visualizzare:\nu(t-1)  ──▶  u(t)  ──▶  y(t)\n   │\n   └─────────── φ ───────────┘\nPer esempio:\n\n\n\\(\\alpha_i\\): uno studente particolarmente ansioso potrebbe avere un’alta probabilità di rispondere “no” a prescindere dalla domanda;\n\n\\(\\beta\\): se la domanda è facile (\\(x=1\\)), aumenta la probabilità di risposta corretta;\n\n\\(\\phi\\): se lo studente ha risposto correttamente ieri, oggi sarà più probabile che risponda ancora correttamente;\n\n\\(\\sigma_u\\): cattura la variabilità inspiegata, come distrazioni improvvise.\n\n\n39.3.1 Che cos’è \\(u_{i,t}\\)?\n\n\n\\(u_{i,t}\\) non è osservato: è uno stato latente.\nPossiamo pensarlo come il “livello di propensione” di un individuo in un certo istante \\(t\\).\nL’osservazione \\(y_{i,t}\\) (corretto/errato, sì/no, 1/0) nasce da questo stato: se \\(u_{i,t}\\) è alto, la probabilità di risposta positiva è alta; se è basso, è bassa.\nNei modelli Bayesiani o di stato latente, i valori di \\(u_{i,t}\\) non si calcolano direttamente dai dati ma vengono stimati/inferiti dal modello. In pratica, otteniamo una distribuzione a posteriori su ciascun \\(u_{i,t}\\), non un singolo valore deterministico.\n\n39.3.2 E il ruolo di \\(\\phi\\)?\nIl coefficiente \\(\\phi\\) funziona come un “peso di memoria”:\n\nSe \\(\\phi = 0\\), il passato non conta: \\(u\\_{i,t}\\) dipende solo dai predittori e dal rumore.\nSe \\(\\phi &gt; 0\\), c’è inerzia: lo stato precedente influenza positivamente quello attuale.\nSe \\(\\phi &lt; 0\\), c’è compensazione o alternanza: uno stato alto ieri spinge verso uno basso oggi.\n\nFormalmente, \\(\\phi\\) è un coefficiente di regressione come \\(\\alpha\\) e \\(\\beta\\), ma agisce sulla variabile latente del tempo precedente, quindi introduce dipendenza temporale.\n\n39.3.3 Come “si trovano” i valori di \\(u_{i,t-1}\\)?\n\nAll’inizio (al tempo \\(t=1\\)), bisogna specificare una condizione iniziale per \\(u_{i,0}\\), ad esempio assumendo \\(u_{i,0} \\sim \\mathcal{N}(0,\\sigma_0)\\).\nPer i tempi successivi, ogni \\(u_{i,t}\\) viene costruito ricorsivamente dal precedente: il modello stesso definisce la sequenza degli stati latenti.\nIn fase di stima (ad esempio con Stan), si usano i dati osservati \\(y_{i,t}\\) per inferire a posteriori quali valori plausibili di \\(u_{i,t}\\) rendono il modello coerente con le risposte osservate.\n\nRiassumendo:\n\n\n\\(u_{i,t}\\): stato latente, stimato dal modello, non osservato.\n\n\\(\\phi\\): coefficiente che regola quanto lo stato passato influenza quello presente.\n\n\\(\\alpha_i\\), \\(\\beta\\): intercetta e predittori osservati, come in una regressione logistica.\n\n\\(\\sigma_u\\): variabilità residua del processo latente.\n\n39.3.4 Perché è importante?\nCon il modello AR(1) facciamo un passo oltre la regressione logistica classica. La probabilità di risposta non è più determinata solo dai fattori esterni osservati, ma anche dagli stati interni accumulati nel tempo. In altre parole, il comportamento osservato non nasce “da zero” a ogni prova: porta con sé una traccia del passato.\nEsempi concreti aiutano a capirlo:\n\n\nCompito di apprendimento: se un partecipante ha appena ricevuto un rinforzo positivo, la sua propensione a ripetere la stessa scelta sarà più alta al trial successivo.\n\nDiario EMA: un umore negativo oggi aumenta la probabilità di trovarsi in uno stato simile anche domani, a meno che un evento esterno intervenga a interrompere la continuità.\n\nLa lezione fondamentale è questa: le scelte non sono indipendenti, ma intrecciate con la storia recente dell’individuo. Ed è proprio questa “memoria del passato” che rende i modelli dinamici strumenti più realistici e potenti per descrivere processi psicologici rispetto ai modelli statici.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nPer fare un esempio semplice, consideriamo un modello continuo con un solo predittore continuo. La dipendenza temporale la collochiamo nei residui, con una struttura AR(1). In questo modo evitiamo il problema di introdurre variabili latenti non osservabili come \\(u\\).\nPer il soggetto \\(i\\) al tempo \\(t\\):\n\\[\n\\begin{aligned}\ny_{i,t} &= \\alpha_i + \\beta\\,x_{i,t} + e_{i,t},\\\\\ne_{i,t} &= \\phi\\, e_{i,t-1} + \\eta_{i,t}, \\qquad \\eta_{i,t}\\sim\\mathcal N(0,\\sigma_\\eta^2).\n\\end{aligned}\n\\]\ndove:\n\n\n\\(y_{i,t}\\) è la risposta osservata (continua),\n\n\\(x_{i,t}\\) è il predittore osservato (continuo),\n\n\\(e_{i,t}\\) è l’errore con memoria AR(1),\n\n\\(\\phi\\) è l’autocorrelazione a lag 1 dei residui,\n\n\\(\\sigma_\\eta\\) controlla l’ampiezza del rumore “nuovo” che entra a ogni passo.\n\nIn altre parole, il valore osservato \\(y_{i,t}\\) è composto da:\n\nuna parte sistematicamente spiegata dal predittore \\(x_{i,t}\\), ponderata da \\(\\beta\\),\nuna parte casuale, \\(e_{i,t}\\), che però non è indipendente: conserva memoria del residuo precedente (\\(\\phi e_{i,t-1}\\)). Se ieri il modello ha sovrastimato, è probabile che anche oggi rimanga un residuo positivo; lo stesso vale per una sottostima.\n\n\nNota su \\(e_{i,0}\\). Per generare una serie “stazionaria”, inizializziamo il primo residuo dalla distribuzione stazionaria:\n\\[\ne_{i,0} \\sim \\mathcal N\\!\\left(0,\\; \\frac{\\sigma_\\eta^2}{1-\\phi^2}\\right).\n\\]\n\n\n# ---- Funzione di simulazione ----\nsimulate_reg_ar1 &lt;- function(alpha, beta = 0.8, phi = 0.7, sigma_eta = 1.0,\n                             T_ = 60, x_sd = 1, seed = 123) {\n  set.seed(seed)\n  n_subj &lt;- length(alpha)\n  rec &lt;- vector(\"list\", n_subj)\n\n  # Varianza stazionaria dei residui AR(1)\n  sigma_e2 &lt;- sigma_eta^2 / (1 - phi^2)\n\n  for (i in seq_len(n_subj)) {\n    e_prev &lt;- rnorm(1, mean = 0, sd = sqrt(sigma_e2))  # e_{i,0}\n    rows &lt;- vector(\"list\", T_)\n    for (t in seq_len(T_)) {\n      x_t &lt;- rnorm(1, 0, x_sd)             # predittore osservato\n      eta &lt;- rnorm(1, 0, sigma_eta)        # innovazione\n      e_t &lt;- phi * e_prev + eta            # residuo AR(1)\n      y_t &lt;- alpha[i] + beta * x_t + e_t   # risposta continua\n      rows[[t]] &lt;- data.frame(\n        subject = i, time = t,\n        x = x_t, e = e_t, y = y_t\n      )\n      e_prev &lt;- e_t\n    }\n    rec[[i]] &lt;- dplyr::bind_rows(rows)\n  }\n  dplyr::bind_rows(rec)\n}\n\n# ---- Parametri e simulazione ----\nalpha &lt;- c(-1, 0, 1)   # intercette soggetto-specifiche\nbeta  &lt;- 0.8           # effetto del predittore x\nphi   &lt;- 0.7           # autocorrelazione a lag 1 dei residui\nsigma_eta &lt;- 1.0       # deviazione standard innovazione\nT_    &lt;- 60            # lunghezza serie temporale\n\ndf &lt;- simulate_reg_ar1(alpha, beta, phi, sigma_eta, T_)\n\n# ---- Grafico didattico ----\ndf &lt;- df %&gt;%\n  group_by(subject) %&gt;%\n  mutate(x_scaled = (x - mean(x)) / sd(x) * sd(y) + mean(y)) %&gt;%\n  ungroup()\n\nggplot(df, aes(time)) +\n  geom_line(aes(y = y), linewidth = 0.9) +\n  geom_line(aes(y = x_scaled), linetype = \"dashed\") +\n  geom_hline(aes(yintercept = ave_y),\n             data = df %&gt;% group_by(subject) %&gt;% summarise(ave_y = mean(y)),\n             linewidth = 0.3, color = \"grey40\") +\n  facet_wrap(~ subject, ncol = 1,\n             labeller = as_labeller(function(s) {\n               i &lt;- as.integer(s)\n               paste0(\"Soggetto \", s, \" (alpha = \", alpha[i], \")\")\n             })) +\n  labs(title = \"Regressione con residui AR(1): y(t) e x(t) riscalato\",\n       subtitle = paste0(\"phi = \", phi, \", sigma_eta = \", sigma_eta, \", beta = \", beta),\n       y = \"y(t)  (x in tratteggio, riscalato)\", x = \"Tempo\")\n\n\n\n\n\n\n\n\n\nStruttura del modello\n\nLa parte regressiva è \\(\\alpha_i + \\beta x_{i,t}\\).\nLa memoria sta nei residui: \\(e_{i,t} = \\phi e_{i,t-1} + \\eta_{i,t}\\).\nCosì il predittore \\(x_{i,t}\\) è esogeno e \\(\\phi\\) ha un significato chiaro: è l’autocorrelazione tra residui consecutivi.\n\n\n\nGrafico a pannelli\n\nLinea piena = \\(y_{i,t}\\).\nTratteggio = \\(x_{i,t}\\), riscalato per confrontarlo visivamente con \\(y\\).\nSi vede che \\(y\\) segue \\(x\\), ma non cambia bruscamente: la presenza di \\(\\phi=0.7\\) rende la traiettoria più “liscia” grazie alla memoria nei residui.\n\n\n\n\n# ---- Verifica dell'AR(1) sui residui (soggetto 1) ----\ndf1 &lt;- df %&gt;% filter(subject == 1)\nols_fit &lt;- lm(y ~ x, data = df1)\nresid_ols &lt;- resid(ols_fit)\n\npar(mfrow = c(1, 2))\nplot(df1$time, resid_ols, type = \"l\", main = \"Residui OLS (soggetto 1)\",\n     xlab = \"Tempo\", ylab = \"Residuo\")\nacf(resid_ols, main = \"ACF residui OLS (soggetto 1)\")\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n\nACF dei residui OLS\n\nNel modello di regressione lineare semplice \\(y \\sim x\\) si assume che i residui siano indipendenti. Nel nostro esempio, però, i residui hanno memoria AR(1): se ieri erano positivi, oggi tendono a esserlo di nuovo.\nL’ACF (autocorrelation function) dei residui ci permette di vedere questo effetto:\n\nmisura quanto i residui in tempi diversi sono correlati,\nil valore a lag 1 (tra residui consecutivi) è chiaramente positivo e vicino a \\(\\phi\\).\n\nQuindi:\n\nil modello lineare classico che assume residui indipendenti non descrive bene i dati,\noccorre un modello che includa la memoria, come l’AR(1) sui residui o un modello equivalente in stato-spazio.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#dallar1-allark",
    "href": "chapters/glm/05_logistic_process.html#dallar1-allark",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "\n39.4 Dall’AR(1) all’AR(K)",
    "text": "39.4 Dall’AR(1) all’AR(K)\nIl modello AR(1) ci ha mostrato che lo stato latente \\(u_{i,t}\\) non nasce mai da zero, ma porta con sé una traccia del passato immediato. Tuttavia, in molti processi psicologici questa “memoria a un passo” può essere troppo corta.\nPensiamo a situazioni in cui:\n\nl’effetto di un’esperienza non si esaurisce al trial successivo ma dura più a lungo,\nl’umore di oggi non dipende solo da quello di ieri, ma anche da quello di due o tre giorni fa,\nl’apprendimento si accumula su una coda di feedback estesa.\n\nIn questi casi conviene estendere il modello ad un processo autoregressivo di ordine \\(K\\) (AR(K)):\n\\[\nu_{i,t} = \\alpha_i\n        + \\mathbf{x}_{i,t}^\\top \\boldsymbol\\beta\n        + \\phi_1 u_{i,t-1}\n        + \\phi_2 u_{i,t-2}\n        + \\dots\n        + \\phi_K u_{i,t-K}\n        + \\eta_{i,t},\n\\] \\[\n\\eta_{i,t} \\sim \\mathcal{N}(0,\\sigma_u).\n\\]\n\n39.4.1 Interpretazione psicologica\n\n\n\\(K=1\\) (AR(1)) → memoria cortissima: il presente dipende solo dallo stato immediatamente precedente (es. l’effetto diretto di un feedback appena ricevuto).\n\n\\(K=2\\) (AR(2)) → memoria breve: lo stato attuale risente degli ultimi due passi (es. l’umore influenzato dagli ultimi due giorni consecutivi).\n\n\\(K \\geq 3\\) → memoria più lunga: utile per processi cumulativi o ciclici (es. oscillazioni tra fasi di alta e bassa motivazione).\n\nIn altre parole, aumentando \\(K\\) allarghiamo la “finestra temporale” che il modello utilizza per spiegare il presente.\n\n39.4.2 Perché è utile?\nL’estensione ad AR(K) consente di modellare una gamma più ricca di dinamiche:\n\n\ninerzia semplice (AR(1)),\n\neffetti ritardati, che emergono dopo due o più step,\n\noscillazioni regolari o pattern ciclici (catturabili già con un AR(2) o AR(3)).\n\nCosì il modello diventa più flessibile e aderente alla complessità dei processi psicologici reali, nei quali la memoria del passato non ha sempre la stessa profondità, ma può essere breve, prolungata o ciclica.\n\n\n\n\n\n\nQuando usare modelli AR in psicologia?\n\nNei compiti decisionali con prove ripetute, quando sospettiamo che non solo l’ultima esperienza ma anche quelle precedenti influenzino la scelta.\nNegli studi EMA, quando l’umore o la motivazione di oggi risentono di più giorni consecutivi.\nIn generale, in tutti i casi in cui la sequenza temporale porta informazioni importanti che sarebbe un errore trattare come semplice rumore.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#simulazione-dati",
    "href": "chapters/glm/05_logistic_process.html#simulazione-dati",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "\n39.5 Simulazione dati",
    "text": "39.5 Simulazione dati\nPrima di stimare il modello su dati reali, conviene costruire un dataset simulato (AR(1) logit a livello latente). In questo modo possiamo verificare se il modello riesce a recuperare parametri noti e comprendere meglio il suo funzionamento.\nImmaginiamo \\(I=100\\) soggetti, ciascuno con \\(T=30\\) prove, e un predittore binario \\(x_{i,t}\\) (ad esempio: tipo di stimolo, 0 = neutro, 1 = emozionale). Lo stato latente \\(u_{i,t}\\) evolve come un AR(1) sulla scala logit.\n\nset.seed(123)\n\nI   &lt;- 100   # numero di soggetti\nTt  &lt;- 30    # numero di trial per soggetto\nN   &lt;- I*Tt  # osservazioni totali\n\n# Parametri \"veri\" usati per generare i dati\nalpha_mu    &lt;- 0.0   # intercetta media\nalpha_sigma &lt;- 0.7   # variabilità tra-soggetti\nbeta_true   &lt;- 0.6   # effetto del predittore\nphi_true    &lt;- 0.5   # persistenza dinamica\nsigma_u     &lt;- 0.6   # rumore di processo\n\n# Intercette soggetto-specifiche\nalpha_i &lt;- rnorm(I, alpha_mu, alpha_sigma)\n\n# Predittore binario (0/1) random\nx &lt;- rbinom(N, 1, 0.5)\n\n# Costruzione dataset\ndf &lt;- tibble::tibble(\n  id = rep(1:I, each = Tt),\n  t  = rep(1:Tt, times = I),\n  x  = x\n)\n\n# Stato latente e risposta\nu &lt;- numeric(N)\ny &lt;- integer(N)\n\nfor (i in 1:I) {\n  a  &lt;- alpha_i[i]\n  ui &lt;- numeric(Tt)\n  for (tt in 1:Tt) {\n    idx &lt;- (i-1)*Tt + tt\n    mean_ut &lt;- a + beta_true*df$x[idx] + ifelse(tt == 1, 0, phi_true*ui[tt-1])\n    ui[tt]  &lt;- rnorm(1, mean_ut, sigma_u)        # stato latente\n    p       &lt;- 1/(1 + exp(-ui[tt]))              # probabilità risposta\n    y[idx]  &lt;- rbinom(1, 1, p)                   # risposta binaria\n  }\n  u[((i-1)*Tt+1):(i*Tt)] &lt;- ui\n}\n\ndf$u_lat &lt;- u\ndf$y     &lt;- y\n\nIl modello ha bisogno di sapere quale osservazione viene prima nello stesso soggetto. Se non stiamo attenti, potremmo collegare l’ultimo trial del soggetto \\(i\\) con il primo del soggetto \\(i+1\\), il che è sbagliato. Per evitare errori, creiamo un indice prev che punta al trial precedente solo dello stesso soggetto. Se non esiste (primo trial), mettiamo 0.\n\ndf &lt;- df[order(df$id, df$t), ]\nprev &lt;- integer(nrow(df))\nfor (i in unique(df$id)) {\n  idx  &lt;- which(df$id == i)\n  prev[idx] &lt;- c(0, head(idx, -1))  # 0 = nessun precedente\n}\nstopifnot(all(df$t[prev[df$t&gt;1]] == df$t[df$t&gt;1]-1))\n\nEsempio: se il soggetto 5 ha 30 trial, per il trial 12 prev punterà al trial 11, mentre per il trial 1 avrà valore 0.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#tabella-ponte-dallalgebra-a-stan",
    "href": "chapters/glm/05_logistic_process.html#tabella-ponte-dallalgebra-a-stan",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "\n39.6 Tabella-ponte: dall’algebra a Stan",
    "text": "39.6 Tabella-ponte: dall’algebra a Stan\nPer tradurre il modello matematico in Stan, costruiamo una “mappa” dei concetti.\n\n\n\n\n\n\n\n\nConcetto\nSimbolo\nStan\nNota\n\n\n\nNumero osservazioni\n\\(N\\)\nint&lt;lower=1&gt; N;\n\n\n\nNumero soggetti\n\\(I\\)\nint&lt;lower=1&gt; I;\n\n\n\nSoggetto per trial\n—\narray[N] int&lt;lower=1,upper=I&gt; id;\n\n\n\nTrial precedente (stesso soggetto)\n—\narray[N] int&lt;lower=0,upper=N&gt; prev;\n0 se non esiste\n\n\nPredittori\n\\(\\mathbf{x}_{i,t}\\)\narray[N] int x;\nEstendibile a matrice\n\n\nRisposta\n\\(y_{i,t}\\)\narray[N] int y;\nBernoulli\n\n\nStato latente\n\\(u_{i,t}\\)\nvector[N] u;\n\n\n\nIntercetta soggetto\n\\(\\alpha_i\\)\n\nvector[I] alpha; (non centrato)\n\n\n\nPersistenza\n\\(\\phi\\)\nreal&lt;lower=-0.99,upper=0.99&gt; phi;\nvincolo stazionarietà\n\n\nRumore di processo\n\\(\\sigma_u\\)\nreal&lt;lower=0&gt; sigma_u;\ndeviazione standard",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#modello-stan",
    "href": "chapters/glm/05_logistic_process.html#modello-stan",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "\n39.7 Modello Stan",
    "text": "39.7 Modello Stan\nOra traduciamo il modello AR(1) logit in Stan. L’idea è di rappresentare esplicitamente tre parti del processo:\n\nIntercette soggetto-specifiche (\\(\\alpha_i\\)), stimate in forma non centrata per migliorare la mescolanza della catena.\n\nEvoluzione dello stato latente \\(u_{i,t}\\):\n\nal primo trial di ciascun soggetto, \\(u_{i,1}\\) dipende solo dall’intercetta, dai predittori e dal rumore;\nnei trial successivi, \\(u_{i,t}\\) dipende anche dal valore precedente \\(u_{i,t-1}\\), con peso \\(\\phi\\).\n\n\nLikelihood: la risposta osservata \\(y_{i,t}\\) segue una Bernoulli logit con parametro \\(u_{i,t}\\).\n\nInoltre, nel blocco generated quantities calcoliamo:\n\n\ny_rep = repliche simulate, utili per i posterior predictive check;\n\nlog_lik = contributi della verosimiglianza, necessari per il calcolo di LOO/WAIC.\n\nFormalmente, il modello implementato è:\n\\[\n\\begin{aligned}\nu_{i,1} &\\sim \\mathcal{N}(\\alpha_i + \\mathbf{x}_{i,1}^\\top \\beta, \\sigma_u), \\\\\nu_{i,t} &\\sim \\mathcal{N}(\\alpha_i + \\mathbf{x}_{i,t}^\\top \\beta + \\phi u_{i,t-1}, \\sigma_u) \\quad (t&gt;1), \\\\\ny_{i,t} \\mid u_{i,t} &\\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_{i,t})\\right).\n\\end{aligned}\n\\]\n\nstan_code &lt;- '\ndata{\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; I;\n  array[N] int&lt;lower=1,upper=I&gt; id;\n  array[N] int&lt;lower=0,upper=1&gt; x;    // estendibile a vettore\n  array[N] int&lt;lower=0,upper=1&gt; y;\n  array[N] int&lt;lower=0,upper=N&gt; prev; // 0 se non esiste trial precedente dello stesso soggetto\n}\nparameters{\n  vector[I] alpha_raw;\n  real      alpha_mu;\n  real&lt;lower=0&gt; alpha_sigma;\n\n  real beta;\n  real&lt;lower=-0.99, upper=0.99&gt; phi;\n  real&lt;lower=0&gt; sigma_u;\n\n  vector[N] eps; // innovazioni standard N(0,1)\n}\ntransformed parameters{\n  vector[I] alpha = alpha_mu + alpha_sigma * alpha_raw;\n  vector[N] u;\n  for (n in 1:N){\n    real mean_u = alpha[id[n]] + beta * x[n];\n    if (prev[n] == 0) {\n      // opzionale: condizione stazionaria per il primo trial\n      real sd1 = sigma_u / sqrt(1 - square(phi));\n      u[n] = mean_u + sd1 * eps[n];\n    } else {\n      u[n] = mean_u + phi * u[prev[n]] + sigma_u * eps[n];\n    }\n  }\n}\nmodel{\n  // Priori più informative (vedi §2)\n  alpha_raw   ~ normal(0, 1);\n  alpha_mu    ~ normal(0, 0.5);\n  alpha_sigma ~ normal(0, 0.5);   // &lt;lower=0&gt; già impone metà-normale\n  beta        ~ normal(0, 0.5);\n  phi         ~ normal(0, 0.4);   // bounds già imposti\n  sigma_u     ~ normal(0, 0.5);   // metà-normale su sd\n\n  eps ~ normal(0,1);              // innovazioni standard\n  y ~ bernoulli_logit(u);\n}\ngenerated quantities{\n  array[N] int y_rep;\n  vector[N] log_lik;\n  for (n in 1:N){\n    y_rep[n] = bernoulli_logit_rng(u[n]);\n    log_lik[n] = bernoulli_logit_lpmf(y[n] | u[n]);\n  }\n}\n'\nstan_file &lt;- write_stan_file(stan_code)\n\nFocalizziamoci sul blocco di codice che costruisce la variabile latente dinamica \\(u_n\\) su cui poi si basa la likelihood logistica dei dati osservati \\(y_n\\).\nStruttura della likelihood. Il modello assume che la risposta osservata \\(y_n \\in \\{0,1\\}\\) derivi da una regressione logistica:\n\\[\ny_n \\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_n)\\right),\n\\]\ndove \\(u_n\\) è il predittore lineare dinamico che evolve nel tempo con memoria AR(1). In pratica, invece di avere un predittore statico \\(u_n = \\alpha_i + \\beta x_n\\), qui aggiungiamo una dipendenza dal passato: lo stato latente corrente dipende anche da quello precedente.\nCostruzione di \\(u_n\\) nel codice:\nfor (n in 1:N){\n  real mean_u = alpha[id[n]] + beta * x[n];\n  if (prev[n] == 0) {\n    // primo trial del soggetto\n    real sd1 = sigma_u / sqrt(1 - square(phi));\n    u[n] = mean_u + sd1 * eps[n];\n  } else {\n    // trial successivi\n    u[n] = mean_u + phi * u[prev[n]] + sigma_u * eps[n];\n  }\n}\n\n\nLinea 1. Calcoliamo il contributo sistematico del soggetto e del predittore:\n\\[\n\\texttt{mean\\_u} = \\alpha_{id[n]} + \\beta x_n.\n\\]\nQui \\(\\alpha_{id[n]}\\) è l’intercetta specifica del soggetto, mentre \\(\\beta x_n\\) è l’effetto del predittore osservato.\n\n\nCaso prev[n]==0. È il primo trial di quel soggetto. Non abbiamo uno stato precedente a cui agganciarci, quindi inizializziamo \\(u_n\\) assumendo la condizione stazionaria del processo AR(1):\n\\[\nu_n \\sim \\mathcal N\\!\\left(\\texttt{mean\\_u}, \\; \\frac{\\sigma_u^2}{1-\\phi^2}\\right).\n\\]\nQuesto è implementato come mean_u + sd1 * eps[n], dove eps[n] ~ Normal(0,1) e sd1 = sigma_u / sqrt{1 - phi^2}.\n\n\nCaso prev[n]!=0. È un trial successivo. In questo caso \\(u_n\\) dipende dal valore precedente \\(u_{prev[n]}\\):\n\\[\nu_n = \\texttt{mean\\_u} + \\phi \\, u_{prev[n]} + \\sigma_u \\, \\varepsilon_n,\n\\quad \\varepsilon_n \\sim \\mathcal N(0,1).\n\\]\nQui \\(\\phi\\) è il coefficiente AR(1) che controlla quanto del passato sopravvive nel presente.\n\n\nIntuizione:\n\n\n\\(\\alpha_i\\): propensione media del soggetto.\n\n\\(\\beta x_n\\): effetto del predittore osservato al trial \\(n\\).\n\n\\(\\phi u_{prev[n]}\\): memoria: se ieri \\(u\\) era alto, oggi tenderà a restare alto (se \\(\\phi&gt;0\\)).\n\n\\(\\sigma_u \\varepsilon_n\\): rumore nuovo che introduce variabilità tra un trial e l’altro.\n\nIl risultato finale è che la probabilità di risposta positiva è:\n\\[\n\\Pr(y_n=1) = \\operatorname{logit}^{-1}(u_n),\n\\]\ne l’intera likelihood del modello è:\n\\[\np(y \\mid \\alpha, \\beta, \\phi, \\sigma_u) = \\prod_{n=1}^N \\text{Bernoulli}\\!\\left(y_n \\,\\middle|\\, \\operatorname{logit}^{-1}(u_n)\\right),\n\\]\ndove ciascun \\(u_n\\) è costruito ricorsivamente come sopra.\nGenerazione dei dati di input:\n\nstan_dat &lt;- list(\n  N   = nrow(df),\n  I   = length(unique(df$id)),\n  id  = as.integer(df$id),\n  x   = as.array(as.integer(df$x)),\n  y   = as.array(as.integer(df$y)),\n  prev = as.array(prev)\n)\n\nCompilazione del modello:\n\nmod &lt;- cmdstanr::cmdstan_model(stan_file)\n\nCampionamento:\n\nfit &lt;- mod$sample(\n  data = stan_dat,\n  seed = 2024,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 1500,\n  adapt_delta = 0.99,\n  max_treedepth = 15\n)\n\nRiassunto dei parametri chiave:\n\nfit$summary(c(\"alpha_mu\",\"alpha_sigma\",\"beta\",\"phi\",\"sigma_u\"))\n#&gt; # A tibble: 5 × 10\n#&gt;   variable     mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha_mu    0.104  0.098 0.099 0.094 -0.047 0.275 1.004 1146.168 1890.425\n#&gt; 2 alpha_sigma 0.691  0.684 0.116 0.114  0.517 0.895 1.002  936.525 2046.042\n#&gt; 3 beta        0.609  0.607 0.094 0.095  0.456 0.770 1.000 2591.209 4164.984\n#&gt; 4 phi         0.492  0.495 0.069 0.068  0.374 0.601 1.001 1218.997 2733.870\n#&gt; 5 sigma_u     0.695  0.691 0.187 0.176  0.393 1.004 1.005  381.850  561.846\n\nLettura dei risultati.\nConfrontiamo i valori stimati con quelli usati nella simulazione:\n\n\\(\\alpha_\\mu\\) (vero = 0.0) → stimato ≈ 0.10. L’intercetta media è molto vicina al valore vero, con intervallo che comprende lo 0. La stima è quindi ben calibrata.\n\\(\\alpha_\\sigma\\) (vero = 0.7) → stimato ≈ 0.69. La variabilità tra soggetti è recuperata quasi perfettamente. Questo mostra che il modello distingue bene la propensione media dei soggetti dalle loro differenze individuali.\n\\(\\beta\\) (vero = 0.6) → stimato ≈ 0.61. L’effetto del predittore viene stimato con grande precisione, centrato sul valore vero.\n\\(\\phi\\) (vero = 0.5) → stimato ≈ 0.49. Anche il parametro di persistenza dinamica è correttamente recuperato: la memoria del passato è catturata in linea con i dati generati.\n\\(\\sigma_u\\) (vero = 0.6) → stimato ≈ 0.69. Il rumore di processo è leggermente sovrastimato, ma rimane molto vicino al valore usato nella simulazione.\n\nIn sintesi, il modello MCMC recupera in modo accurato tutti i parametri simulati. Le diagnostiche (Rhat ≈ 1, ESS elevati, nessuna divergenza) confermano che la catena ha esplorato bene lo spazio dei parametri.\n\n39.7.1 Diagnostica e Posterior Predictive Check\nUn passo fondamentale è confrontare i dati osservati con quelli simulati dal modello (y_rep). Se il modello è adeguato, le distribuzioni delle repliche devono sovrapporsi a quella dei dati reali.\n\nyrep_draws &lt;- fit$draws(\"y_rep\")\n\n# Converte in data.frame e poi in matrice\nyrep_df  &lt;- as_draws_df(yrep_draws)\nyrep_mat &lt;- as.matrix(yrep_df[, grepl(\"^y_rep\", names(yrep_df))])\n\n# proporzione osservata\nprop_obs &lt;- mean(stan_dat$y)\n\n# proporzioni replicate (una per draw)\nprop_rep &lt;- rowMeans(yrep_mat)\n\nppc_dens_overlay(y = stan_dat$y, yrep = yrep_mat[1:100, ])\n\n\n\n\n\n\n\nIl posterior predictive check mostra che la distribuzione dei dati simulati dal modello (y_rep) si sovrappone bene a quella dei dati osservati (y).\n\nLa densità osservata (linea nera) cade quasi sempre all’interno del ventaglio di densità replicate (linee colorate).\nQuesto significa che il modello riesce a generare dati che “assomigliano” a quelli reali, un segnale che la struttura autoregressiva AR(1) e i parametri stimati catturano i meccanismi principali del processo.\nSe vedessimo sistematiche discrepanze (ad esempio code troppo corte o una distribuzione spostata), sarebbe un campanello d’allarme che il modello è mal specificato o che mancano variabili importanti.\n\nIn sintesi: un buon PPC non prova che il modello sia vero, ma aumenta la fiducia che sia plausibile e che descriva i dati in modo coerente con le ipotesi teoriche.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#confronto-con-glmm-logit-via-brm",
    "href": "chapters/glm/05_logistic_process.html#confronto-con-glmm-logit-via-brm",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "\n39.8 Confronto con GLMM logit (via brm)",
    "text": "39.8 Confronto con GLMM logit (via brm)\nPer confronto abbiamo stimato lo stesso dataset con un GLM logit semplice in brm:\n\ndat &lt;- tibble(\n  y = as.numeric(stan_dat$y),\n  x = as.numeric(stan_dat$x),\n  id = as.numeric(stan_dat$id)\n)\n\n\n# ATTENZIONE: brms ignora la dipendenza seriale e l'eterogeneità nei trials!\nfit_glmer &lt;- brm(\n  y ~ x + (x | id),\n  data = dat,\n  family = bernoulli(link = \"logit\"),\n  prior = c(prior(normal(0, 1), class = \"b\")),\n  chains = 2, iter = 2000, seed = 123,\n  backend = \"cmdstanr\"\n)\n\n\nsummary(fit_glmer)\n#&gt;  Family: bernoulli \n#&gt;   Links: mu = logit \n#&gt; Formula: y ~ x + (x | id) \n#&gt;    Data: dat (Number of observations: 3000) \n#&gt;   Draws: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 2000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~id (Number of levels: 100) \n#&gt;                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sd(Intercept)        1.20      0.11     1.00     1.44 1.00      608     1062\n#&gt; sd(x)                0.13      0.10     0.00     0.37 1.00      552      821\n#&gt; cor(Intercept,x)    -0.09      0.55    -0.95     0.92 1.00     2199     1438\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.42      0.13     0.17     0.68 1.01      347      630\n#&gt; x             0.50      0.09     0.32     0.69 1.00     2547     1579\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n39.8.1 Interpretazione dei risultati brm\n\nIl modello multilevel logit con slope/intercetta casuali, \\(y \\sim x + (x \\mid id)\\), stima:\n\n\nIntercept = 0.42 (SE ≈ 0.13): log-odds media di risposta 1 quando \\(x=0\\), considerando la variabilità tra soggetti.\n\n\\(x = 0.50\\) (SE ≈ 0.09; 95% CI [0.32, 0.69]): effetto medio del predittore sulla log-odds, con pooling parziale tra soggetti.\n\nEterogeneità tra soggetti:\n\n\nsd(Intercept) ≈ 1.20: forte variabilità individuale nella propensione di base.\n\nsd(x) ≈ 0.13: variabilità più contenuta nell’effetto di \\(x\\).\n\ncor(Intercept, x) ≈ −0.09 con IC molto ampio: nessuna evidenza di relazione sistematica tra tendenza di base e sensibilità al predittore.\n\nIl modello, quindi, distingue l’effetto medio di \\(x\\) dalla notevole eterogeneità individuale, ma non rappresenta esplicitamente la dipendenza seriale tra prove.\n\n39.8.2 Confronto con Stan (modello processuale AR(1))\nIl modello AR(1) in Stan, stimato sugli stessi dati simulati, recupera accuratamente i valori veri:\n\n\n\\(\\beta \\approx 0.61\\) (vero = 0.60),\n\n\\(\\phi \\approx 0.49\\) (vero = 0.50),\n\n\\(\\alpha_\\sigma \\approx 0.69\\) (vero = 0.70),\n\n\\(\\sigma_u \\approx 0.69\\) (vero = 0.60).\n\nLa differenza principale riguarda l’effetto di \\(x\\):\n\nNel GLMM multilevel, \\(\\hat\\beta \\approx 0.50\\),\nNel modello processuale AR(1), \\(\\hat\\beta \\approx 0.61\\), perfettamente in linea con il valore vero.\n\nQuesto accade perché il modello brm controlla l’eterogeneità individuale ma non rappresenta la dinamica temporale: la memoria del passato (\\(\\phi\\)) resta non modellata e una parte della dipendenza seriale viene assorbita nelle stime delle varianze casuali o nell’effetto medio del predittore.\nIl modello in Stan, invece, separa esplicitamente il contributo del predittore (\\(\\beta\\)) dalla persistenza dinamica (\\(\\phi\\)) e dal rumore di processo (\\(\\sigma_u\\)), producendo stime più fedeli al meccanismo generativo.\n\n39.8.3 Messaggio chiave\n\nIl GLMM con slope/intercette casuali cattura bene l’eterogeneità tra soggetti, ma non la dipendenza temporale.\nIl modello AR(1) in Stan, introducendo la dinamica degli stati latenti, fornisce un effetto di \\(x\\) più vicino al valore vero e una rappresentazione più realistica del processo psicologico sottostante.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#riflessioni-conclusive",
    "href": "chapters/glm/05_logistic_process.html#riflessioni-conclusive",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo superato i limiti del GLM logit statico introducendo una struttura dinamica sugli stati latenti. L’idea chiave è semplice e potente: la probabilità di risposta non dipende solo da \\(\\mathbf{x}\\), ma anche da ciò che è appena accaduto, tramite lo stato \\(u_{i,t}\\) che accumula informazioni nel tempo. Con l’AR(1) (ed estensioni AR(\\(K\\))) abbiamo reso esplicita la memoria del processo; con Stan abbiamo separato in modo netto propensione media (\\(\\alpha_i\\)), effetto dei predittori (\\(\\boldsymbol\\beta\\)), persistenza (\\(\\phi\\)) e rumore di processo (\\(\\sigma_u\\)), ottenendo stime fedeli al meccanismo generativo.\nIl confronto con un GLMM logit ha chiarito il punto: i modelli multilevel gestiscono bene l’eterogeneità tra soggetti, ma se la dipendenza temporale non è rappresentata, parte della dinamica viene assorbita in varianze casuali o negli effetti medi, distorcendo l’interpretazione. I posterior predictive checks hanno confermato che il modello processuale riproduce le caratteristiche salienti dei dati, aumentando la fiducia nella sua adeguatezza.\nIl messaggio metodologico è duplice:\n\n\nStatisticamente, i GLM restano un quadro unificante, ma vanno estesi quando la struttura dei dati lo richiede: nei compiti ripetuti, nelle misure EMA, nei processi di apprendimento o affaticamento, la storia conta.\n\nPsicologicamente, passare a un modello processuale significa spostarsi dalla descrizione all’ipotesi sui meccanismi: ciò che stimiamo non è solo “se un predittore influisce”, ma come l’influenza si accumula, persiste o si alterna nel tempo.\n\nNei capitoli successivi useremo questa logica per ampliare la modellazione di processi cognitivi e decisionali: la dinamica latente diventerà il filo conduttore che collega il dato osservato al processo che lo ha generato.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.4.2         bayestestR_0.17.0     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        reshape2_1.4.4       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        utf8_1.2.6           \n#&gt; [19] rmarkdown_2.29        ps_1.9.1              ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           xfun_0.53             cachem_1.1.0         \n#&gt; [25] jsonlite_2.0.0        broom_1.0.9           parallel_4.5.1       \n#&gt; [28] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [31] lubridate_1.9.4       estimability_1.5.1    knitr_1.50           \n#&gt; [34] zoo_1.8-14            pacman_0.5.1          Matrix_1.7-4         \n#&gt; [37] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     \n#&gt; [40] abind_1.4-8           yaml_2.3.10           codetools_0.2-20     \n#&gt; [43] curl_7.0.0            processx_3.8.6        pkgbuild_1.4.8       \n#&gt; [46] plyr_1.8.9            lattice_0.22-7        withr_3.0.2          \n#&gt; [49] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [52] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [55] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [58] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [61] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [64] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [67] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [70] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [73] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_logistic_process.html#bibliografia",
    "href": "chapters/glm/05_logistic_process.html#bibliografia",
    "title": "39  Dal GLM a un modello processuale per dati binari",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChatfield, C., & Xing, H. (2019). The analysis of time series: an introduction with R. Chapman; hall/CRC.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_missing_values.html",
    "href": "chapters/glm/06_missing_values.html",
    "title": "40  Dati mancanti in psicologia",
    "section": "",
    "text": "Introduzione\nIn molte ricerche psicologiche, i dati mancanti non sono semplicemente “buchi” da riempire, ma possono essere la conseguenza diretta del fenomeno che vogliamo studiare (Little, 2024). Questo significa che l’assenza di una risposta è essa stessa un dato psicologico. Ad esempio:\nIn questi casi, la probabilità che un dato sia osservato dipende dal valore vero non osservato. Questa situazione è definita MNAR – Missing Not At Random e, se ignorata, può produrre stime distorte dei parametri (ad esempio medie più basse del reale, effetti di regressione sottostimati). In pratica: si può concludere che un trattamento funziona quando in realtà non è così, o viceversa.\nIn questo capitolo:",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_missing_values.html#introduzione",
    "href": "chapters/glm/06_missing_values.html#introduzione",
    "title": "40  Dati mancanti in psicologia",
    "section": "",
    "text": "nei questionari su temi sensibili (come ansia sociale, uso di sostanze, esperienze traumatiche) le persone con punteggi più elevati possono saltare più facilmente alcune domande per evitare disagio emotivo;\nnegli studi EMA (Ecological Momentary Assessment), i partecipanti possono rispondere meno quando sono di cattivo umore, sotto stress o in situazioni socialmente impegnative.\n\n\n\n\nrivedremo le principali tipologie di dati mancanti (MCAR, MAR, MNAR);\nvedremo come riconoscere un caso MNAR nella ricerca psicologica;\nimpareremo a costruire e stimare un modello Bayesiano in Stan per gestire dati MNAR.\n\n\n\n\n\n\n\nMCAR, MAR, MNAR: i tre meccanismi chiave\n\n\n\nQuando analizzi dati mancanti, è fondamentale capire perché mancano. Le principali categorie sono:\n\n\nMCAR (Missing Completely At Random): la probabilità che un dato manchi è indipendente sia dalle variabili osservate sia dal valore mancante.\n\n\nEsempio: in un questionario online, alcune risposte mancano a causa di un problema tecnico che interrompe la connessione.\n\n\n\nMAR (Missing At Random): la probabilità di mancanza dipende solo da variabili osservate (non dal valore mancante), una volta controllato per queste.\n\n\nEsempio: in un test di ansia, i partecipanti più anziani saltano alcune domande, ma conosciamo l’età di tutti.\n\n\n\nMNAR (Missing Not At Random): la probabilità di mancanza dipende dal valore vero mancante, anche dopo aver considerato le variabili osservate.\n\n\nEsempio: in un questionario su sintomi depressivi, chi è più depresso tende a non rispondere a domande su pensieri negativi.\n\n\n\nNota operativa: Ignorare un meccanismo MNAR può portare a stime distorte e a conclusioni errate, specialmente in studi clinici o longitudinali.\n\n\nPanoramica del capitolo\n\nDistinguere tra MCAR, MAR e MNAR e comprendere le implicazioni in psicologia.\nRiconoscere situazioni in cui i dati mancanti non sono casuali (MNAR).\nFormulare un modello Bayesiano per gestire dati MNAR.\nImplementare il modello in Stan e interpretarne i risultati.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nConoscenza di base della probabilità e dell’inferenza Bayesiana.\nFamiliarità con R e pacchetti brms e cmdstanr.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Additional packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, loo, cmdstanr, stringr, tidyr)\nconflicts_prefer(dslabs::heights)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_missing_values.html#simulazione-di-dati-con-meccanismo-mnar",
    "href": "chapters/glm/06_missing_values.html#simulazione-di-dati-con-meccanismo-mnar",
    "title": "40  Dati mancanti in psicologia",
    "section": "\n40.1 Simulazione di dati con meccanismo MNAR",
    "text": "40.1 Simulazione di dati con meccanismo MNAR\nSupponiamo di voler misurare il punteggio di ansia sociale (\\(y\\)) in un campione di partecipanti. Nella popolazione, ipotizziamo che \\(y\\) segua una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\nPer semplificare i calcoli, standardizziamo la variabile:\n\\[\ny_z = \\frac{y - 50}{10} \\quad \\Rightarrow \\quad y_z \\sim \\mathcal{N}(0, 1)\n\\]\nOra modelliamo una situazione comune nella ricerca psicologica: le persone con ansia sociale più elevata tendono a evitare a rispondere al questionario, lasciando più risposte mancanti.\nIl comportamento di evitamento è formalizzato attraverso un modello di selezione (selection model) di tipo logistico, che specifica la probabilità condizionata di osservazione del dato nel modo seguente:\n\\[\n\\Pr(R_i = 1 \\mid y_i) = \\text{logit}^{-1}(\\alpha + \\beta\\, y_i) .\n\\tag{40.1}\\]\nDefinizione formale delle componenti del modello:\n\n\nVariabile di risposta latente:\\(R_i \\in \\{0,1\\}\\) è una variabile binaria latente che modella il processo di osservazione, dove:\n\n\n\\(R_i = 1\\) indica che l’osservazione \\(y_i\\) è osservabile (il partecipante ha fornito una risposta valida);\n\n\n\\(R_i = 0\\) denota un dato mancante (mancata risposta del partecipante).\n\n\n\nParametro \\(\\beta\\) e meccanismo di missingness:\nLa relazione tra \\(y_i\\) e \\(\\Pr(R_i = 1 \\mid y_i)\\) è governata dal parametro \\(\\beta\\):\n\nSe \\(\\beta &lt; 0\\): sussiste un meccanismo di missingness non ignorabile (MNAR) con dipendenza negativa monotona. Valori più elevati di \\(y_i\\) riducono la probabilità di osservazione, indicando un pattern di evitamento selettivo (es. partecipanti con sintomi di ansia sociale più severi tendono ad evitare di rispondere).\n\nSe \\(\\beta &gt; 0\\): il missingness è ancora MNAR, ma con dipendenza positiva monotona. Valori elevati di \\(y_i\\) aumentano la probabilità di osservazione (es. partecipanti con maggiore ansia sociale hanno maggiore propensione a rispondere).\n\nSe \\(\\beta = 0\\): la probabilità di osservazione è indipendente da \\(y_i\\), soddisfacendo l’ipotesi di Missing Completely at Random (MCAR).\n\n\n\nNota: l’esempio qui discusso riflette un tipico caso MNAR, in cui la probabilità di osservare il dato dipende direttamente dal valore vero della variabile di interesse.\nGeneriamo un dataset sintetico di \\(N\\) = 1000 unità statistiche, dove il meccanismo di missingness segue un modello di selezione logistico con parametri:\n\nintercetta (\\(\\alpha\\)) = 0,\neffetto della variabile risposta (\\(\\beta\\)) = -2.0.\n\n\nset.seed(1234)   \n\nN          &lt;- 1000\nalpha_true &lt;- 0\nbeta_true  &lt;- -2.0\n\ny_true &lt;- rnorm(N, 0, 1)\np_obs  &lt;- plogis(alpha_true + beta_true * y_true)\nR      &lt;- rbinom(N, 1, p_obs)\ny_obs  &lt;- ifelse(R == 1, y_true, NA_real_)\n\ntbl &lt;- tibble(y_true, R, y_obs, p_obs)\nmean(R)\n#&gt; [1] 0.501\nmean(is.na(y_obs))\n#&gt; [1] 0.499\n\n\n40.1.1 Analisi del bias indotto da MNAR\n\nsumm &lt;- tibble(\n  grandezza = c(\"Media\", \"Varianza\"),\n  vero      = c(mean(tbl$y_true), var(tbl$y_true)),\n  osservato = c(mean(tbl$y_obs, na.rm = TRUE), var(tbl$y_obs, na.rm = TRUE))\n)\nprint(summ)\n#&gt; # A tibble: 2 × 3\n#&gt;   grandezza    vero osservato\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Media     -0.0266    -0.594\n#&gt; 2 Varianza   0.995      0.663\n\nI dati evidenziando una sottostima sistematica dovuta al meccanismo MNAR.\n\n40.1.2 Visualizzazione degli effetti di selezione\nVisualizziamo ora la probabilità di osservazione in funzione del valore vero e confrontiamo la distribuzione dei valori veri con quella dei valori osservati, escludendo i valori mancanti.\n\n# 1) Probabilità di osservazione in funzione del valore vero\np1 &lt;- ggplot(tbl, aes(x = y_true, y = p_obs)) +\n  geom_point(alpha = 0.20) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(\n    title = \"MNAR: Pr(R=1 | y)\",\n    x = \"y (vero, scala z)\", y = \"Pr(R=1 | y)\"\n  ) \n\n# 2) Distribuzione dei valori veri, con linea su media=0\np2 &lt;- ggplot(tbl, aes(x = y_true)) +\n  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.35) +\n  geom_density() +\n  geom_vline(xintercept = mean(tbl$y_true), linetype = 2) +\n  labs(\n    title = \"Distribuzione dei valori veri\",\n    x = \"y (vero, scala z)\", y = \"Densità\"\n  ) \n\n# 3) Distribuzione dei valori osservati (cond. a R=1), con linea su media osservata\np3 &lt;- ggplot(filter(tbl, R == 1), aes(x = y_obs)) +\n  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.35) +\n  geom_density() +\n  geom_vline(xintercept = mean(tbl$y_obs, na.rm = TRUE), linetype = 2) +\n  labs(\n    title = \"Distribuzione dei valori osservati (R=1)\",\n    x = \"y osservato\", y = \"Densità\"\n  ) \n\np1; p2; p3\n\n\n\nMNAR: probabilità di osservazione e distribuzioni ‘vero’ vs ‘osservato’.\n\n\n\n\n\nMNAR: probabilità di osservazione e distribuzioni ‘vero’ vs ‘osservato’.\n\n\n\n\n\nMNAR: probabilità di osservazione e distribuzioni ‘vero’ vs ‘osservato’.\n\n\n\nMessaggio chiave. La selezione MNAR fa sì che i dati osservati non rappresentino la popolazione: nei grafici si vede che la probabilità di osservazione diminuisce con y e che la distribuzione degli osservati è spostata rispetto a quella dei veri.\nConseguenza: le analisi che ignorano il meccanismo (vedi Modello 1) tendono a stimare una media distorta e/o una varianza alterata.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_missing_values.html#modello-1-outcome-only-ignora-il-meccanismo",
    "href": "chapters/glm/06_missing_values.html#modello-1-outcome-only-ignora-il-meccanismo",
    "title": "40  Dati mancanti in psicologia",
    "section": "\n40.2 Modello 1 — Outcome-only (ignora il meccanismo)",
    "text": "40.2 Modello 1 — Outcome-only (ignora il meccanismo)\nIn questo modello assumiamo che la variabile osservata \\(y\\) (su scala z) segua:\n\\[\ny \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\ncon aspettative \\(\\mu \\approx 0\\) e \\(\\sigma \\approx 1\\).\nI valori mancanti vengono trattati come parametri latenti e stimati direttamente1, senza modellare la variabile \\(R\\) che indica la risposta. In pratica, stiamo assumendo implicitamente che i dati mancanti siano MCAR (completamente a caso) o MAR (a caso dato il modello).\n\n40.2.1 Intuizione operativa\n\nIl modello stima i valori mancanti “come se” fossero assenti in modo casuale, basandosi solo sulla distribuzione di \\(y\\).\nSe i dati sono in realtà MNAR, le stime di parametri chiave come \\(\\mu\\) possono risultare sistematicamente distorte.\nQuesto approccio è utile come baseline per confrontare l’effetto di modelli più realistici che tengono conto del meccanismo di mancanza.\n\n40.2.2 Codice Stan (outcome-only)\n\n# Modello Stan: Outcome-only (ignora R)\n# Tratta i mancanti come latenti e assume MCAR/MAR\n\nstan_ignore &lt;- '\ndata {\n  int&lt;lower=0&gt; N_obs;             // Numero di osservazioni\n  int&lt;lower=0&gt; N_mis;             // Numero di valori mancanti\n  array[N_obs] real y_obs;        // Valori osservati\n}\nparameters {\n  real mu;                        // Media della distribuzione\n  real&lt;lower=0&gt; sigma;            // Deviazione standard\n  array[N_mis] real y_mis;        // Valori mancanti (stimati)\n}\nmodel {\n  // Priors\n  mu    ~ normal(0, 1);\n  sigma ~ normal(1, 0.5);\n  \n  // Likelihood per dati osservati\n  y_obs ~ normal(mu, sigma);\n  \n  // Likelihood per dati mancanti (uguale agli osservati)\n  y_mis ~ normal(mu, sigma);\n}\ngenerated quantities {\n  real y_mean = mu;               // Stima della media\n  real y_sd   = sigma;             // Stima della deviazione standard\n}\n'\nwriteLines(stan_ignore, \"ignore_mnar.stan\")\n\n\n# Prepara i dati per Stan\ny_obs_vec &lt;- tbl$y_obs[!is.na(tbl$y_obs)]\nN_obs     &lt;- length(y_obs_vec)                 # numero osservazioni\nN_mis     &lt;- sum(is.na(tbl$y_obs))              # numero mancanti\n\ndata_ignore &lt;- list(\n  N_obs = N_obs,\n  N_mis = N_mis,\n  y_obs = y_obs_vec\n)\n\nStima:\n\nmod_ignore &lt;- cmdstan_model(\"ignore_mnar.stan\")\n\n\n# Stima Bayesiana\nfit_ignore &lt;- mod_ignore$sample(\n  data = data_ignore, seed = 11,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 2000,\n  adapt_delta = 0.99, max_treedepth = 14\n)\n\nRiassunto dei parametri stimati:\n\nsumm_ignore &lt;- fit_ignore$summary(variables = c(\"mu\", \"sigma\"))\n\n\n40.2.3 Modello 2 — Selection Model (per dati MNAR esplicito)\nIl Selection Model è un approccio per modellare dati Mancanti Non In Modo Casuale (MNAR), in cui la probabilità che un dato sia osservato (missingness) dipende dal valore (mancante o osservato) della variabile stessa \\(y\\).\nQuesto legame è modellato esplicitamente attraverso un parametro, indicato come \\(\\beta\\), all’interno di un modello di regressione logistica che regola la probabilità di osservazione \\(R\\).\n\n40.2.3.1 Interpretazione del parametro beta\nIl coefficiente \\(\\beta\\) quantifica la direzione e l’intensità della dipendenza tra \\(y\\) e la probabilità di essere osservato:\n\n\n\\(\\beta &gt; 0\\) (Positivo): Valori più alti di \\(y\\) hanno una maggiore probabilità di essere osservati.\n\n\\(\\beta &lt; 0\\) (Negativo): Valori più alti di \\(y\\) hanno una minore probabilità di essere osservati. Questo è uno scenario comune, noto come avoidance (es. in un questionario sul reddito, gli individui con entrate molto alte potrebbero essere più reticenti a rispondere).\n\n\\(\\beta = 0\\): La probabilità di osservazione non dipende da \\(y\\). In questo caso, il meccanismo di missingness ricade nelle categorie MCAR o MAR (condizionatamente ad altre covariate nel modello).\n\nEsempio: Se \\(y\\) rappresenta il punteggio di depressione, un \\(\\beta\\) negativo indica che all’aumentare della sintomatologia depressiva (valore di \\(y\\) più alto), la probabilità di rispondere al questionario diminuisce. Questo è un tipico caso di MNAR.\n\n40.2.3.2 L’idea fondamentale del modello\nL’approccio del Selection Model combina due componenti in un unico modello statistico:\n\n\nModello dei dati: Un modello che descrive la distribuzione della variabile di interesse \\(y\\) (es. un modello lineare: \\(y_i \\sim N(\\mu_i, \\sigma^2)\\)).\n\nModello della selezione (missingness): Un modello (es. regressione logistica) che descrive la probabilità che \\(y\\) sia osservato in funzione del suo stesso valore: \\(\\text{logit}(P(R_i = 1)) = \\alpha + \\beta y_i\\).\n\nLa soluzione elegante e potente di questo framework è di trattare i valori mancanti \\(y_{\\text{mis}}\\) non come semplici “assenti”, ma come parametri latenti da stimare simultaneamente al modello. In questo modo, per ogni unità statistica, il modello di selezione “vede” e utilizza il valore di \\(y\\) (osservato o stimato) per determinare la probabilità di osservazione.\n\n40.2.3.3 Nota sull’interpretazione e sulla scala\nNel modello di selezione logistico, \\(\\beta\\) si interpreta sulla scala logit: un incremento di una unità in \\(y\\) è associato a una variazione di \\(\\beta\\) unità nel log-odds di osservazione.\nPer facilitare l’interpretazione e rendere la scelta di una distribuzione a priori per \\(\\beta\\) più sensata e generalizzabile, è fortemente consigliato centrare e scalare la variabile \\(y\\). In questo modo, \\(\\beta\\) rappresenterà l’effetto di uno scostamento di un deviazione standard dalla media, rendendo il parametro più confrontabile tra diversi studi e diverse variabili.\n\n40.2.4 Modello 2A — Incorporare una prior informativa sul parametro beta\nIl Modello 2A estende il Selection Model base introducendo una distribuzione a priori informativa sul parametro chiave \\(\\beta\\). Ricordiamo che \\(\\beta\\) quantifica il legame tra il valore della variabile \\(y\\) e la probabilità che questo venga osservato.\nMentre nel selection model potevamo usare una prior vaga (es. \\(\\beta \\sim N(0, 100)\\)), in questo scenario vogliamo incorporare nella nostra analisi una conoscenza pregressa credibile sul probabile meccanismo di missingness.\nGiustificazione per l’uso di una prior informativa\nNel nostro esempio simulato, il meccanismo è costruito per essere MNAR con un \\(\\beta\\) negativo. Anche in contesti reali, spesso possiamo formulare ipotesi teoriche robuste su questo meccanismo:\n\n\nIn psicologia: Soggetti con sintomatologia molto elevata (valori alti di \\(y\\) in scale di depressione o ansia) potrebbero avere una minore probabilità di completare un questionario.\n\nIn economia: Individui con redditi molto alti o molto bassi potrebbero essere più reticenti a rivelare le proprie finanze.\n\nQueste ipotesi si traducono in un’aspettativa sulla direzione (segno di \\(\\beta\\)) e su un intervallo plausibile di valori per la sua grandezza.\nVantaggi di questo approccio:\n\n\nMaggior Stabilità e Identificabilità: La stima del parametro \\(\\beta\\) in un selection model può essere spesso instabile, specialmente con campioni piccoli o quando il pattern di dati mancanti è limitato. Una prior informativa agisce da “regolarizzatore”, ancorando la stima a un valore plausibile e prevenendo conclusioni estreme o erratiche guidate dal rumore nei dati.\n\nIncorporazione Trasparente della Conoscenza: Questo approccio ci permette di integrare in modo esplicito e quantificabile evidenza precedente (di letteratura o teorica) all’interno del nostro modello, spostandoci da un’analisi puramente guidata dai dati a una analisi guidata da dati e teoria.\n\nIn sintesi, il Modello 2A rappresenta una strategia analitica più sofisticata e potente. Non ci limitiamo a chiedere ai dati “C’è un effetto MNAR?” usando un’ipotesi neutra (prior vaga). Piuttosto, chiediamo: “Alla luce della nostra convinzione che il meccanismo sia MNAR con un effetto negativo di una certa entità, cosa ci dicono i dati?”. Questo rende l’analisi più robusta e teoricamente fondata.\nCodice Stan:\n\nstan_selection_inf &lt;- '\ndata {\n  int&lt;lower=0&gt; N_obs;\n  int&lt;lower=0&gt; N_mis;\n  int&lt;lower=0&gt; N_total;\n  array[N_obs] real y_obs;\n  array[N_total] int&lt;lower=0,upper=1&gt; R;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n  array[N_mis] real y_mis;\n  real alpha;\n  real beta;\n}\ntransformed parameters {\n  array[N_total] real y_all;\n  for (n in 1:N_obs)   y_all[n] = y_obs[n];\n  for (n in 1:N_mis)   y_all[N_obs + n] = y_mis[n];\n}\nmodel {\n  // Priors ancoranti su outcome (scala nota) + informativa su beta\n  mu    ~ normal(0, 0.3);\n  sigma ~ normal(1, 0.2) T[0,];\n  alpha ~ normal(0, 1);\n  beta  ~ normal(-1.5, 0.5);\n\n  // Outcome\n  y_obs ~ normal(mu, sigma);\n  y_mis ~ normal(mu, sigma);\n\n  // Selection\n  for (n in 1:N_total)\n    R[n] ~ bernoulli_logit(alpha + beta * y_all[n]);\n}\ngenerated quantities {\n  real y_mean = mu;\n  real y_sd   = sigma;\n}\n'\nwriteLines(stan_selection_inf, \"selection_mnar_informative.stan\")\n\nDati:\n\nN_obs   &lt;- sum(!is.na(tbl$y_obs))\nN_mis   &lt;- sum(is.na(tbl$y_obs))\nN_total &lt;- nrow(tbl)\n\ndata_sel &lt;- list(\n  N_obs   = N_obs,\n  N_mis   = N_mis,\n  N_total = N_total,\n  y_obs   = y_obs_vec,\n  R       = as.integer(tbl$R)\n)\n\nCompilazione del modello:\n\nmod_sel_inf &lt;- cmdstan_model(\"selection_mnar_informative.stan\")\n\nCampionamento:\n\n# Stima Bayesiana\nfit_sel_inf &lt;- mod_sel_inf$sample(\n  data = data_sel, seed = 33,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 2000,\n  adapt_delta = 0.99, max_treedepth = 14\n)\n\nRiassunto dei parametri principali:\n\nsumm_sel_inf &lt;- fit_sel_inf$summary(variables = c(\"mu\",\"sigma\",\"alpha\",\"beta\"))\n\n\n40.2.5 Modello 2B — Uno studio di robustezza: Prior ampia su beta con outcome ancorato\nIl Modello 2B è progettato come uno studio di robustezza e sensibilità per testare la forza del segnale MNAR presente nei dati. Combina strategicamente due scelte opposte riguardo le prior:\n\n\nUna prior fortemente informativa sui parametri della distribuzione di \\(y\\) (\\(\\mu\\) e \\(\\sigma\\)).\n\nUna prior ampia e neutrale sul parametro del meccanismo MNAR (\\(\\beta\\)).\n\n1. Ancoraggio della scala dell’outcome: Assumiamo a priori che la variabile \\(y\\) sia già standardizzata, imponendo dei forti vincoli bayesiani: * Media (\\(\\mu\\)): \\(\\sim \\mathcal{N}(0, 0.2)\\) * Interpretazione: Siamo molto certi che la vera media della popolazione sia vicina a 0. * Deviazione Standard (\\(\\sigma\\)): \\(\\sim \\mathcal{N}(1, 0.1)\\) (troncata ai positivi) * Interpretazione: Siamo molto certi che la vera deviazione standard sia vicina a 1.\n2. Prior neutrale sul meccanismo MNAR: Sul parametro cruciale \\(\\beta\\) usiamo invece una prior deliberatamente ampia e neutrale: * Effetto MNAR (\\(\\beta\\)): \\(\\sim \\mathcal{N}(0, 2)\\) * Interpretazione: Pur ipotizzando che l’effetto più plausibile sia nullo (priore centrata su 0), ammettiamo un’ampia gamma di valori sia positivi che negativi come possibili. Il dato ha massima libertà di rivelarci la direzione e l’intensità del vero meccanismo.\n\n40.2.5.1 La logica strategica del modello 2B\nQuesta combinazione apparentemente contraddittoria ha uno scopo preciso: isolare e testare il segnale del meccanismo MNAR.\n\nPerché ancorare \\(\\mu\\) e \\(\\sigma\\)? L’incertezza sulla posizione e sulla scala della distribuzione sottostante \\(y\\) è intrinsecamente legata alla stima di \\(\\beta\\). “Bloccando” strategicamente \\(\\mu\\) e \\(\\sigma\\) a valori plausibili, riduciamo il rumore nel modello. Questo impedisce che l’incertezza su questi parametri “contagini” e oscuri la stima di \\(\\beta\\), permettendoci di vedere più chiaramente l’effetto che i dati hanno su di esso.\nPerché usare una prior ampia su \\(\\beta\\)? È un atto di umiltà epistemologica. Stiamo dicendo: “So già come è fatta la distribuzione di y (perché l’ho standardizzata), ma non voglio pregiudicare la direzione o l’esistenza del meccanismo mancante. Voglio che siano i dati, il più liberamente possibile, a dimostrarmi se c’è un effetto MNAR e quanto è forte.”\n\nIn sintesi, il Modello 2B risponde a una domanda cruciale:\n\n“Se rimuoviamo il supporto di un’ipotesi teorica forte (la prior informativa del Modello 2A) e controlliamo per altre fonti di incertezza, il segnale MNAR nei dati è ancora sufficientemente robusto da emergere da solo?”\n\n\nstan_sel_wide &lt;- '\ndata {\n  int&lt;lower=0&gt; N_obs;\n  int&lt;lower=0&gt; N_mis;\n  int&lt;lower=0&gt; N_total;\n  array[N_obs] real y_obs;\n  array[N_total] int&lt;lower=0,upper=1&gt; R;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n  array[N_mis] real y_mis;\n  real alpha;\n  real beta;\n}\nmodel {\n  // Priors: outcome fortemente ancorato (scala z), beta ampia\n  mu    ~ normal(0, 0.2);\n  sigma ~ normal(1, 0.1) T[0,];\n  alpha ~ normal(0, 2);\n  beta  ~ normal(0, 2);\n\n  // Outcome\n  y_obs ~ normal(mu, sigma);\n  y_mis ~ normal(mu, sigma);\n\n  // Selection con indicizzazione corretta\n  {\n    int i_obs = 1;\n    int i_mis = 1;\n    for (n in 1:N_total) {\n      real y_n = (R[n] == 1) ? y_obs[i_obs] : y_mis[i_mis];\n      R[n] ~ bernoulli_logit(alpha + beta * y_n);\n      if (R[n] == 1) i_obs += 1; else i_mis += 1;\n    }\n  }\n}\ngenerated quantities {\n  real y_mean = mu;\n  real y_sd   = sigma;\n}\n'\nwriteLines(stan_sel_wide, \"selection_mnar_wide.stan\")\n\n\nmod_sel_wide &lt;- cmdstan_model(\"selection_mnar_wide.stan\")\n\n\nfit_sel_wide &lt;- mod_sel_wide$sample(\n  data = data_sel, seed = 33,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 2500, iter_sampling = 3000,\n  adapt_delta = 0.999, max_treedepth = 20\n)\n\n\nsumm_sel_wide &lt;- fit_sel_wide$summary(variables = c(\"mu\",\"sigma\",\"alpha\",\"beta\"))",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_missing_values.html#scelte-dei-prior-e-loro-razionale",
    "href": "chapters/glm/06_missing_values.html#scelte-dei-prior-e-loro-razionale",
    "title": "40  Dati mancanti in psicologia",
    "section": "\n40.3 Scelte dei prior e loro razionale",
    "text": "40.3 Scelte dei prior e loro razionale\nLe differenze tra i tre modelli non riguardano solo la parte di likelihood, ma soprattutto le scelte di prior, che riflettono ipotesi diverse sulla natura del meccanismo di mancanza e sulla scala dell’outcome. Qui riassumiamo il razionale di ciascun modello.\n\n\n\n\n\n\n\n\n\nModello\nPrior su \\(\\mu\\) e \\(\\sigma\\)\n\nPrior su \\(\\beta\\)\n\nRazionale\nAttese sulle stime\n\n\n\nOutcome-only\nLarghe (nessun ancoraggio)\nNessuna (\\(\\beta\\) assente)\nTest di riferimento: stimiamo \\(\\mu\\) e \\(\\sigma\\) ignorando il meccanismo di mancanza\nPossibile bias se i dati sono MNAR\n\n\n2A — Prior informativa su \\(\\beta\\)\nLarghe (nessun ancoraggio)\nInformativa centrata su valore negativo plausibile\nIncorporiamo conoscenza teorica/empirica sul segno e l’ordine di grandezza di \\(\\beta\\)\n\nStima di \\(\\beta\\) più stabile e intervalli credibili più stretti\n\n\n\n2B — Prior ampia su \\(\\beta\\) e outcome ancorato\nFortemente ancorate (\\(\\mu\\)≈0, \\(\\sigma\\)≈1)\nAmpia, \\(\\mathcal{N}(0, 2)\\)\n\nL’ancoraggio rende interpretabile \\(\\beta\\) in unità di deviazione standard; prior ampia per lasciare ai dati il compito di “dire la verità”\nStima di \\(\\beta\\) simile a 2A se i dati sono informativi, ma con intervalli più ampi\n\n\n\n\n\n40.3.1 Perché ancorare mu e sigma nel modello 2B?\nNon è un trucco per “facilitare” la stima, ma una scelta metodologica per fissare una scala interpretabile. Se \\(y\\) non è centrato e scalato, una stessa prior su \\(\\beta\\) può implicare effetti molto diversi nella probabilità di osservazione. Con \\(\\mu\\)≈0 e \\(\\sigma\\)≈1, \\(\\beta\\) è interpretabile come variazione nel log-odds associata a 1 deviazione standard di \\(y\\). Questo permette anche di confrontare \\(\\beta\\) tra studi diversi.\n\n40.3.2 Confronto visivo tra le prior di beta\nRicordiamo che \\(\\beta\\) controlla la pendenza della relazione logit tra il valore dell’outcome \\(y\\) e la probabilità di osservarlo (\\(R=1\\)):\n\n\n\\(\\beta\\) &lt; 0 → i valori più alti di \\(y\\) hanno minore probabilità di essere osservati;\n\n\\(\\beta\\) &gt; 0 → i valori più bassi di \\(y\\) hanno minore probabilità di essere osservati;\n\n\\(\\beta\\) ≈ 0 → la probabilità di osservazione non dipende da \\(y\\) (MAR condizionato).\n\nNello scenario simulato sappiamo che il meccanismo MNAR “vero” ha \\(\\beta\\) negativo: più alto è \\(y\\), più è probabile che manchi.\nLe due versioni del selection model adottano ipotesi molto diverse su \\(\\beta\\):\n\ndf_beta &lt;- bind_rows(\n  data.frame(beta = rnorm(5000, mean = -0.5, sd = 0.3), model = \"2A — Informativa\"),\n  data.frame(beta = rnorm(5000, mean = 0, sd = 2), model = \"2B — Ampia\")\n)\n\nggplot(df_beta, aes(x = beta, fill = model)) +\n  geom_density(alpha = 0.5) +\n  labs(x = expression(beta), y = \"Densità\")\n\n\n\n\n\n\n\n\nLa prior informativa del modello 2A concentra la probabilità su valori negativi plausibili, fornendo una “spinta” teorica verso l’effetto atteso.\nLa prior ampia del modello 2B, invece, consente valori molto più estremi, sia positivi che negativi, lasciando al dato quasi tutta la responsabilità di informare \\(\\beta\\).\n\nMessaggio didattico: confrontare i risultati di 2A e 2B ci permette di capire quanto le nostre assunzioni a priori influenzano la stima e se, in presenza di un segnale forte nei dati, il modello riesce a recuperare comunque il meccanismo MNAR.\n\n40.3.3 Confronto delle stime e interpretazione\nConfrontiamo i parametri chiave (media e deviazione standard) dei tre modelli con i valori veri della simulazione.\nCosa ci aspettiamo di vedere:\n\n\nOutcome-only: bias negativo su \\(\\mu\\) e sottostima di \\(\\sigma\\), perché i valori alti di \\(y\\) sono sottorappresentati.\n\n2A: recupero di \\(\\mu\\) e \\(\\sigma\\) vicino ai valori veri, con \\(\\beta\\) stimato negativo e intervalli più stretti grazie alla prior informativa.\n\n2B: recupero simile a 2A, ma con intervalli più ampi su \\(\\beta\\) e, in parte, su \\(\\mu\\), perché il modello non riceve “spinta” a priori.\n\n\nsumm_ignore\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       -0.594 -0.594 0.036 0.037 -0.654 -0.534 1.000 6441.291 6124.541\n#&gt; 2 sigma     0.817  0.816 0.026 0.025  0.776  0.860 1.000 3383.988 4952.439\n\n\nsumm_sel_inf\n#&gt; # A tibble: 4 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       -0.585 -0.585 0.036 0.036 -0.644 -0.525 1.001 6056.094 6409.331\n#&gt; 2 sigma     0.819  0.818 0.026 0.025  0.777  0.864 1.001 4187.940 5424.535\n#&gt; 3 alpha    -0.019 -0.019 0.092 0.094 -0.168  0.129 1.001 6587.785 5973.368\n#&gt; 4 beta     -0.038 -0.039 0.110 0.109 -0.219  0.141 1.001 4943.585 5281.031\n\n\nsumm_sel_wide\n#&gt; # A tibble: 4 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu        0.047  0.050 0.092 0.091 -0.106  0.190 1.007  706.333 1072.859\n#&gt; 2 sigma     1.038  1.038 0.058 0.058  0.941  1.132 1.008  776.091 1299.449\n#&gt; 3 alpha     0.142  0.125 0.211 0.210 -0.174  0.512 1.005  780.470 1495.664\n#&gt; 4 beta     -2.097 -2.094 0.362 0.351 -2.685 -1.513 1.005  833.017 1098.853\n\nNel grafico seguente visualizziamo gli intervalli (90%) per \\(\\mu\\) e \\(\\sigma\\), con le linee tratteggiate ai valori veri per il Modello 1 e il Modello 2B.\n\nsumm_mu_sigma &lt;- function(fit, model_label) {\n  posterior::summarise_draws(\n    posterior::as_draws_df(fit$draws(variables = c(\"mu\", \"sigma\"))),\n    mean = ~mean(.x),\n    q5   = ~posterior::quantile2(.x, 0.05),\n    q95  = ~posterior::quantile2(.x, 0.95)\n  ) |&gt;\n    dplyr::transmute(model = model_label, variable, mean, q5, q95)\n}\n\ns_ignore &lt;- summ_mu_sigma(fit_ignore,   \"Outcome-only\")\ns_wide   &lt;- summ_mu_sigma(fit_sel_wide, \"Selection (beta ampia, outcome ancorato)\")\n\nplot_tbl &lt;- bind_rows(s_ignore, s_wide) |&gt;\n  mutate(model = factor(model,\n    levels = c(\"Outcome-only\",\n               \"Selection (beta ampia, outcome ancorato)\")))\n\nplot_param &lt;- function(tbl, param_name, label_y) {\n  df &lt;- filter(tbl, variable == param_name)\n  truth_val   &lt;- if (param_name == \"mu\") 0 else 1\n  param_label &lt;- if (param_name == \"mu\") \"Media (mu, z)\" else \"Dev. Std (sigma, z)\"\n\n  ggplot(df, aes(x = model, y = mean)) +\n    geom_pointrange(aes(ymin = q5, ymax = q95)) +\n    geom_hline(yintercept = truth_val, linetype = 2) +\n    labs(title = paste(\"Stime di\", param_label), x = NULL, y = label_y) +\n    coord_flip()\n}\n\ng_mu    &lt;- plot_param(plot_tbl, \"mu\",    \"Media posteriore (90% CI)\")\ng_sigma &lt;- plot_param(plot_tbl, \"sigma\", \"Deviazione standard posteriore (90% CI)\")\n\n\ng_mu\n\n\n\n\n\n\n\n\ng_sigma\n\n\n\n\n\n\n\n\n40.3.4 Lettura dei risultati\n\nOutcome-only. Il modello che ignora il meccanismo di selezione fornisce una stima di \\(\\mu\\) fortemente distorta verso il basso (–0.65 contro il valore vero vicino a 0). Questo accade perché i dati osservati provengono in prevalenza da valori bassi della variabile, e l’assenza di correzione porta a una sottostima sistematica. Anche \\(\\sigma\\) è sottostimata (0.80 vs valore vero ≈ 1), segnalando che la variabilità complessiva è sottorappresentata.\nSelection MNAR con prior informativa su \\(\\beta\\). L’inclusione esplicita del meccanismo di selezione riduce fortemente il bias su \\(\\mu\\) (–0.11) e riporta \\(\\sigma\\) vicino al valore vero (0.99). Come atteso, \\(\\beta\\) viene stimato negativo (–1.81), coerente con la simulazione in cui la probabilità di osservare un valore diminuisce quando \\(y\\) cresce. L’incertezza però aumenta, perché il modello deve stimare anche i parametri del processo di selezione.\nSelection MNAR con prior ampia su \\(\\beta\\) e outcome ancorato. Anche con prior meno informativa su \\(\\beta\\) la stima di \\(\\mu\\) resta vicina a 0 (–0.038) e \\(\\sigma\\) è in linea con il valore vero (1.015). \\(\\beta\\) è di nuovo negativo (–2.04), indicando un effetto di selezione forte, ma qui il modello ha potuto stimarlo senza vincoli forti a priori. L’ancoraggio dell’outcome ha contribuito a contenere il bias pur lasciando ampio margine di apprendimento dai dati.\n\nIn sintesi: ignorare il meccanismo MNAR produce bias sostanziale su media e varianza. Includere un modello di selezione, anche con prior ampie, consente di recuperare stime molto più vicine ai valori veri, a costo di intervalli di credibilità più ampi e maggiore incertezza sui parametri.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_missing_values.html#identificabilità-scaling-e-scelte-di-prior",
    "href": "chapters/glm/06_missing_values.html#identificabilità-scaling-e-scelte-di-prior",
    "title": "40  Dati mancanti in psicologia",
    "section": "\n40.4 Identificabilità, scaling e scelte di prior",
    "text": "40.4 Identificabilità, scaling e scelte di prior\nI modelli MNAR, in particolare i selection models, non sono “gratuiti” in termini di informazione: stimare il meccanismo di mancanza richiede struttura e segnali nei dati.\n\n\nIdentificabilità: con campioni piccoli o con un meccanismo di mancanza debole, \\(\\beta\\) può essere stimato con grande incertezza.\n\nScaling: centrare e scalare \\(y\\) facilita l’assegnazione di prior interpretabili a \\(\\beta\\) (ad esempio normal(0,1)), rendendo la scala dei parametri coerente con l’interpretazione.\n\nScelte di prior: priors debolmente informative su \\(\\mu\\) e \\(\\sigma\\), coerenti con la scala dei dati; su \\(\\alpha\\) e \\(\\beta\\), priors compatibili con la plausibilità teorica del fenomeno.\n\nVariabili ausiliarie: se disponibili, includere misure correlate o precedenti che riducano la dipendenza tra \\(y\\) e il meccanismo di mancanza. Questo può “spostare” il problema verso MAR condizionato e migliorare l’identificabilità.\n\n\n\n\n\n\n\nSuggerimento pratico: confronta più specificazioni (prior diverse, con/senza variabili ausiliarie) e documenta l’impatto sulle stime di interesse. La trasparenza sulle assunzioni è parte integrante dell’inferenza.\n\n\n\n\n40.4.1 Interpretazione dei risultati alla luce della teoria MNAR\nNella simulazione, il vero valore dell’outcome standardizzato è \\(\\mu\\) = 0 (media) e \\(\\sigma\\) = 1 (deviazione standard), e il meccanismo di mancanza è MNAR con \\(\\beta\\) &lt; 0: i valori alti di \\(y\\) hanno minore probabilità di essere osservati.\n\n40.4.2 Comportamento dei modelli\n\n\n\n\n\n\n\n\nModello\nStima \\(\\mu\\)\n\nStima \\(\\sigma\\)\n\nRelazione con il vero valore\n\n\n\nOutcome-only\nDistorto verso il basso\nDistorto verso l’alto\nIgnorando il meccanismo MNAR, \\(\\mu\\) sottostima la media reale (perché i valori alti mancano più spesso), e \\(\\sigma\\) è sovrastimata (perché la variabilità residua è gonfiata)\n\n\n2A — Prior informativa\nVicino al valore vero\nVicino al valore vero\nLa prior su \\(\\beta\\) aiuta a correggere il bias e a recuperare le stime corrette di \\(\\mu\\) e \\(\\sigma\\)\n\n\n\n2B — Prior ampia + outcome ancorato\n\nVicino al valore vero (ma con CI più ampia)\n\nVicino al valore vero (ma con CI più ampia)\nL’ancoraggio di \\(\\mu\\) e \\(\\sigma\\) rende interpretabile \\(\\beta\\); senza prior informativa, l’incertezza è maggiore ma il segnale dei dati basta a recuperare il meccanismo\n\n\n\n40.4.3 Perché ha senso teoricamente?\n\n\nModello Outcome-only: il meccanismo MNAR non è modellato → stimatore biased. In teoria MNAR, ignorare la dipendenza di \\(R\\) da \\(y\\) porta a stime distorte di parametri descrittivi dell’outcome.\n\nModello 2A: la prior informativa su \\(\\beta\\) fornisce una “stampella” teorica → correzione del bias anche con pochi dati o segnale debole.\n\nModello 2B: la prior ampia su \\(\\beta\\), combinata con \\(\\mu\\) e \\(\\sigma\\) ancorati, permette ai dati di “parlare da soli”. Se il campione è abbastanza grande e il meccanismo è forte, il risultato converge a quello di 2A, ma con più incertezza (CI più ampi).\n\n40.4.4 Messaggio didattico\n\n\nIgnorare il meccanismo MNAR tende a produrre bias (qui: \\(\\mu\\) fortemente sottostimata).\nUn selection model che include \\(\\Pr(R=1\\mid y)\\) può ridurre o annullare il bias su \\(\\mu\\) e recuperare la stima di \\(\\sigma\\), identificando al contempo un \\(\\beta&lt;0\\) coerente con il meccanismo simulato.\nCon una prior ampia su \\(\\beta\\) (\\(\\mathcal{N}(0,2)\\)) e un segnale forte nei dati, il parametro viene comunque spinto nella direzione corretta (negativa), ma con maggiore incertezza rispetto a una prior leggermente più informativa (es. \\(\\mathcal{N}(-1.5,1)\\)).\n\nBuone pratiche: monitorare \\(\\hat{R}\\) ed ESS, aumentare le iterazioni se l’identificabilità è debole, e valutare prior motivate teoricamente; includere variabili ausiliarie quando possibile.\n\nIn sintesi, nel modello con prior ampia su \\(\\beta\\) il recupero di \\(\\mu \\approx 0\\) e \\(\\sigma \\approx 1\\) è sostanziale, e l’effetto del meccanismo di mancanza (\\(\\beta \\approx -1.88\\), IC \\(90\\%\\) [-2.65, -0.60]) è coerente con lo scenario MNAR simulato (\\(\\beta*{\\text{true}}=-2\\)). La diagnostica MCMC è adeguata; prior più orientate o campioni più grandi possono aumentare la stabilità.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_missing_values.html#linee-guida-sintetiche",
    "href": "chapters/glm/06_missing_values.html#linee-guida-sintetiche",
    "title": "40  Dati mancanti in psicologia",
    "section": "\n40.5 Linee guida sintetiche",
    "text": "40.5 Linee guida sintetiche\n\n\nDiagnosi iniziale: esplora pattern di mancanza e relazioni temporali/contestuali (“chi non risponde e quando?”).\n\nModello outcome-only: usa un outcome-only come baseline (MAR plausibile?) e aggiungi MNAR se giustificato.\n\nVariabili ausiliarie: sfruttale per ridurre l’informatività del meccanismo.\n\nScala e prior: centra/scala dove utile; usa priors debolmente informative ma plausibili.\n\nAnalisi di sensibilità: verifica la stabilità delle conclusioni al variare di prior e struttura del meccanismo.\n\nDocumentazione: esplicita assunzioni e giustifica il modello con la teoria psicologica o il contesto.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_missing_values.html#riflessioni-conclusive",
    "href": "chapters/glm/06_missing_values.html#riflessioni-conclusive",
    "title": "40  Dati mancanti in psicologia",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\n\nIn presenza di dati MNAR, ignorare il meccanismo può portare a inferenze fuorvianti.\nL’approccio Bayesiano con Stan consente di modellare esplicitamente la mancanza (selection model), riducendo il bias a costo di ipotesi più forti e maggiore incertezza.\nIn psicologia, dove il non rispondere può far parte del processo stesso (evitamento, umore), è metodologicamente opportuno modellare il meccanismo, integrare analisi di sensibilità e riportare in modo trasparente le assunzioni.\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] stringr_1.5.1         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        mgcv_1.9-3           \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [46] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [49] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [58] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [64] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [73] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [76] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [79] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [82] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_missing_values.html#bibliografia",
    "href": "chapters/glm/06_missing_values.html#bibliografia",
    "title": "40  Dati mancanti in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLittle, R. J. (2024). Missing data analysis. Annual Review of Clinical Psychology, 20.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_missing_values.html#footnotes",
    "href": "chapters/glm/06_missing_values.html#footnotes",
    "title": "40  Dati mancanti in psicologia",
    "section": "",
    "text": "Cosa significa “i valori mancanti sono parametri latenti?” Indichiamo con \\(y_i\\) il valore “vero” per l’unità \\(i\\). Per alcune unità \\(y_i\\) non è osservato (manca). Nel modello bayesiano includiamo comunque un oggetto \\(y_i\\) per ogni unità, anche quando è mancante: lo trattiamo come una quantità sconosciuta da inferire insieme a \\(\\mu\\) e \\(\\sigma\\). Tecnicamente: aggiungiamo un nodo \\(y_i^{\\text{mis}}\\) con la stessa distribuzione dell’outcome, ad es. \\(y_i^{\\text{mis}} \\sim \\mathcal{N}(\\mu,\\sigma).\\) Durante il campionamento, il modello genera valori plausibili per ciascun \\(y_i^{\\text{mis}}\\) coerenti con \\(\\mu\\) e \\(\\sigma\\). Importante: questi \\(y_i^{\\text{mis}}\\) non “informano” \\(\\mu\\) e \\(\\sigma\\) oltre ai dati osservati: sono imputazioni coerenti col modello (servono, per esempio, a produrre dataset completi), ma non correggono eventuali distorsioni dovute al meccanismo di mancanza. In breve: l’imputazione discende solo dalla distribuzione scelta per \\(y.\\)↩︎",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Dati mancanti in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/glm/conclusions_sec.html",
    "href": "chapters/glm/conclusions_sec.html",
    "title": "Riflessioni conclusive sulla sezione",
    "section": "",
    "text": "In questa sezione abbiamo visto come il quadro bayesiano si applichi a una varietà di modelli statistici fondamentali per la psicologia e le scienze sociali. Dai modelli per variabili dicotomiche (regressione logistica, confronto di proporzioni) ai modelli per dati di conteggio (Poisson), fino alle prime estensioni dinamiche, abbiamo potuto osservare un filo conduttore comune: la possibilità di descrivere non solo l’effetto medio, ma anche l’incertezza e la plausibilità delle ipotesi in termini probabilistici.\nI modelli presentati hanno messo in luce tre aspetti centrali:\n\nGeneralità del quadro bayesiano. Che si tratti di proporzioni, medie o conteggi, l’inferenza segue sempre lo stesso schema: specificazione di un modello generativo, scelta di priori, campionamento a posteriori, valutazione tramite predizione.\nConnessione tra descrizione e previsione. Non ci limitiamo a stimare parametri, ma valutiamo quanto i modelli siano in grado di riprodurre i dati osservati e di prevedere dati futuri. Questa attenzione alla dimensione predittiva è cruciale per trasformare l’analisi statistica in un vero strumento di spiegazione scientifica.\nFlessibilità e progressività. A partire da modelli semplici possiamo introdurre via via maggiore complessità: effetti di gruppo, interazioni, dinamiche temporali. Ogni estensione non è un’aggiunta arbitraria, ma risponde a precise domande di ricerca e si inserisce nel medesimo linguaggio formale.\n\nAbbiamo inoltre visto come i GLM possano essere estesi per trattare i valori mancanti in modo integrato. Anziché ignorarli o ricorrere a correzioni post hoc, il modello stesso può esplicitare i meccanismi che li generano, producendo stime più affidabili e aderenti alla realtà della raccolta dati. Questo approccio, reso possibile dal framework bayesiano, rappresenta un passo cruciale verso analisi più trasparenti e cumulative in psicologia.\nIl messaggio chiave è che l’approccio bayesiano consente di trattare in modo unitario problemi che, in una prospettiva frequentista, richiedono strumenti distinti e spesso scollegati. Ciò favorisce una maggiore coerenza concettuale, facilita il confronto tra modelli e, soprattutto, offre interpretazioni direttamente utilizzabili nella pratica psicologica e clinica.\nIn sintesi, questa sezione mostra come l’inferenza bayesiana non sia un esercizio puramente teorico, ma un quadro operativo versatile, capace di adattarsi a diversi tipi di dati e di fornire risposte quantitative, trasparenti e contestualizzate alle domande di ricerca. È a partire da questa base che possiamo affrontare modelli più esplicativi e meccanicistici, che tenteranno di catturare non solo che cosa osserviamo, ma anche come e perché quei dati emergono.",
    "crumbs": [
      "GLM",
      "Riflessioni conclusive sulla sezione"
    ]
  },
  {
    "objectID": "chapters/entropy/introduction_sec.html",
    "href": "chapters/entropy/introduction_sec.html",
    "title": "Introduzione alla sezione",
    "section": "",
    "text": "Nelle sezioni precedenti abbiamo imparato a descrivere e stimare modelli, soprattutto in chiave bayesiana. Con Entropia facciamo un passo laterale: introduciamo gli strumenti della teoria dell’informazione per dare un contenuto quantitativo all’idea di incertezza e per collegarla, in modo operativo, alla valutazione dei modelli.\nPartiremo dall’entropia di Shannon come misura media della “sorpresa” di una distribuzione: massima quando gli esiti sono equiprobabili, minima quando uno solo è (quasi) certo. Questo introduce il bit come unità naturale dell’informazione e connette l’entropia a problemi concreti di rappresentazione e compressione (es. codifica di Huffman).\nPoi passeremo alla divergenza di Kullback–Leibler (KL), che non misura più l’incertezza di una distribuzione, ma la distanza informativa tra due distribuzioni: “quanta informazione in più paghiamo utilizzando il modello \\(Q\\) quando la realtà segue \\(P\\)?” Questa idea — l’entropia relativa — è il ponte concettuale tra informazione e scelta del modello.\nInfine useremo KL per motivare gli strumenti pratici della valutazione predittiva in ambito bayesiano: log-score, ELPD, LOO-CV e WAIC. Qui il focus si sposta dall’“adattamento ai dati” alla capacità di generalizzare a dati nuovi, ovvero alla qualità delle previsioni posteriori: massimizzare l’ELPD equivale (in media) ad avvicinare il nostro modello alla distribuzione che genera i dati.\nIl filo conduttore resta quello del manuale: trattare l’incertezza in modo esplicito e valutare i modelli con criteri coerenti con le nostre domande sostantive, evitando verdetti dicotomici e privilegiando grandezza degli effetti e capacità predittiva.",
    "crumbs": [
      "Entropia",
      "Introduzione alla sezione"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html",
    "href": "chapters/entropy/01_entropy.html",
    "title": "41  Entropia e informazione di Shannon",
    "section": "",
    "text": "Introduzione\nImmagina di dover prevedere la risposta di uno studente a una domanda di un test a scelta multipla. Se non sai nulla dello studente, potresti pensare che ogni risposta sia ugualmente probabile: c’è quindi la massima incertezza. Se invece sai che quello studente è molto preparato e risponde quasi sempre correttamente, allora l’incertezza è bassa. Questa quantificazione dell’incertezza è esattamente ciò che chiamiamo entropia.\nIn termini qualitativi, l’entropia misura la quantità di “sorpresa” che ci aspettiamo:\nUn esempio psicologico: nel lancio di una moneta equilibrata (\\(p\\)=0.5), non possiamo sapere se uscirà testa o croce → entropia massima; nel comportamento di un paziente che mostra sempre la stessa risposta a un questionario → entropia minima.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#introduzione",
    "href": "chapters/entropy/01_entropy.html#introduzione",
    "title": "41  Entropia e informazione di Shannon",
    "section": "",
    "text": "è massima quando tutti gli esiti sono equiprobabili (situazione di totale incertezza),\n\nè minima quando uno degli esiti è praticamente certo.\n\n\nPanoramica del capitolo\n\nIntrodurre il concetto di informazione e la sua unità di misura (bit).\nDefinire l’entropia come media della sorpresa di Shannon.\nInterpretare l’entropia in termini di incertezza e numero di alternative equiprobabili.\n\nStimare l’entropia da distribuzioni teoriche e da campioni osservati.\n\nCollegare l’entropia alla codifica di Huffman e al limite teorico di compressione.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nPer i concetti di base sulla teoria dell’informazione, si rimanda ai primi due capitoli di Information Theory: A Tutorial Introduction (Stone, 2022).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(tidygraph)\n\n# Funzione per calcolare la lunghezza media del codice di Huffman\nhuffman_encoding &lt;- function(probabilities) {\n  # Crea la \"coda con priorità\" iniziale come lista di liste\n  heap &lt;- lapply(names(probabilities), function(sym) list(probabilities[[sym]], list(sym, \"\")))\n\n  # Funzione per ordinare la heap per probabilità (peso)\n  sort_heap &lt;- function(heap) {\n    heap[order(sapply(heap, function(x) x[[1]]))]\n  }\n\n  # Costruzione dell'albero di Huffman\n  while (length(heap) &gt; 1) {\n    heap &lt;- sort_heap(heap)\n    lo &lt;- heap[[1]]\n    hi &lt;- heap[[2]]\n    heap &lt;- heap[-c(1, 2)]\n\n    # Aggiunge i prefissi \"0\" e \"1\" ai codici\n    for (i in seq_along(lo)[-1]) {\n      lo[[i]][[2]] &lt;- paste0(\"0\", lo[[i]][[2]])\n    }\n    for (i in seq_along(hi)[-1]) {\n      hi[[i]][[2]] &lt;- paste0(\"1\", hi[[i]][[2]])\n    }\n\n    merged &lt;- c(list(lo[[1]] + hi[[1]]), lo[-1], hi[-1])\n    heap &lt;- append(heap, list(merged))\n  }\n\n  # Estrai la lista finale dei simboli e codici\n  final &lt;- heap[[1]][-1]\n  names(final) &lt;- sapply(final, function(x) x[[1]])\n\n  # Crea dizionario con codici\n  huffman_dict &lt;- lapply(final, function(x) x[[2]])\n\n  # Calcolo della lunghezza media del codice\n  avg_length &lt;- sum(mapply(function(sym, code) {\n    probabilities[[sym]] * nchar(code)\n  }, names(huffman_dict), huffman_dict))\n\n  return(list(avg_length = avg_length, codes = huffman_dict))\n}",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "href": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "title": "41  Entropia e informazione di Shannon",
    "section": "\n41.1 Che cos’è l’informazione?",
    "text": "41.1 Che cos’è l’informazione?\nUn bit è l’unità elementare di informazione: rappresenta la scelta tra due possibilità ugualmente probabili. Ogni volta che raddoppiamo il numero di alternative, serve un bit in più per identificarle. Il logaritmo in base 2 (\\(\\log_2\\)) indica esattamente quanti bit sono necessari per distinguere un certo numero di alternative.\n\n41.1.1 Dalle scelte ai bit: un esempio visivo\nPer capire come l’informazione possa essere misurata in bit, consideriamo il seguente esempio. Immaginiamo di trovarci a un incrocio e di dover scegliere una strada tra due possibilità. Ogni volta che ci troviamo di fronte a un incrocio, dobbiamo prendere una decisione: andare a destra o a sinistra. Ogni decisione può essere codificata con un bit: ad esempio, 0 per andare a sinistra e 1 per andare a destra.\nConsideriamo il percorso con più incroci rappresentato nell’immagine seguente. Ogni percorso completo può essere codificato da una sequenza di bit, dove ogni bit corrisponde a una decisione (binaria) presa a un incrocio. Ad esempio, per raggiungere il punto D011, la sequenza di bit corretta è 011.\n\n\n\n\n\n\n\n\n\n41.1.1.1 Quanti bit sono necessari per identificare una destinazione specifica?\nOgni decisione aggiunge un bit alla sequenza che descrive il percorso. Se ci sono \\(m\\) destinazioni possibili, servono\n\\[\nn = \\log_2 m\n\\] bit per identificarne una in modo univoco. Nel nostro esempio, abbiamo otto destinazioni finali. Pertanto, sono necessari 3 bit (3 decisioni binarie) per identificarne una in modo univoco.\n\n41.1.1.2 Cosa rappresenta un bit in questo contesto?\nUn bit rappresenta un’unità elementare di informazione. In questo caso, ogni bit risponde alla domanda: “Devo andare a destra o a sinistra?”.\n\n41.1.1.3 Perché utilizziamo i logaritmi?\nIl logaritmo in base 2 ci permette di calcolare l’esponente a cui elevare 2 per ottenere un dato numero. In altre parole, ci indica quanti bit sono necessari per rappresentare un certo numero di destinazioni. Per l’esempio considerato, per arrivare a \\(D011\\) partendo da \\(A\\), sono necessarie 3 domande la cui risposta è binaria (destra/sinistra).\nPer riassumere:\n\nper raggiungere il punto D011 partendo da A, abbiamo bisogno di prendere tre decisioni binarie (sinistra o destra) in corrispondenza di tre incroci;\nogni decisione binaria può essere rappresentata da un bit (0 o 1). Quindi, per l’intero percorso, abbiamo bisogno di una sequenza di tre bit: 011;\nper rispondere alla domanda “Come si va da A a D011?”, abbiamo dunque bisogno di 3 bit di informazione.\n\nIn sintesi, esiste una relazione diretta tra il numero di bit di informazione e il numero di possibili destinazioni in un percorso decisionale binario. Ogni bit ci permette di scegliere tra due alternative, raddoppiando così il numero di possibili percorsi.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "href": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "title": "41  Entropia e informazione di Shannon",
    "section": "\n41.2 La sorpresa e l’informazione di Shannon",
    "text": "41.2 La sorpresa e l’informazione di Shannon\nIntroduciamo ora un elemento cruciale: la probabilità dell’evento. Quando due eventi hanno probabilità diverse, anche la quantità di informazione che trasmettono è diversa. Un evento molto probabile suscita poca sorpresa e, di conseguenza, veicola poca informazione. Al contrario, un evento raro produce una sorpresa maggiore e trasmette più informazione.\nShannon tradusse questa intuizione in una formula matematica, definendo l’informazione (o “sorpresa”) associata a un evento \\(x\\) come\n\\[\nh(x) = \\log_2 \\frac{1}{p(x)} = -\\log_2 p(x) \\ \\text{bit}.\n\\tag{41.1}\\] Questa espressione mostra chiaramente come l’informazione associata a un evento dipenda in modo inverso dalla sua probabilità: più l’evento è raro, maggiore sarà il valore di \\(h(x)\\).1\nPer rendere l’idea, immaginiamo tre eventi con probabilità rispettivamente pari a 0.5, 0.25 e 0.10. Applicando la formula di Shannon, otteniamo che la sorpresa corrisponde rispettivamente a 1.00 bit, 2.00 bit e 3.32 bit. Si vede così che, man mano che la probabilità diminuisce, la quantità di informazione – misurata in bit – cresce. In altre parole, un’osservazione inattesa “pesa” di più, perché modifica in misura maggiore le nostre conoscenze sul sistema in esame.\n\n41.2.1 Entropia come media dell’informazione di Shannon\nFinora abbiamo considerato la sorpresa associata a un singolo evento. In molti casi, però, non ci interessa un esito isolato, ma vogliamo descrivere l’incertezza complessiva di un sistema che può produrre esiti diversi. Per farlo, occorre calcolare la sorpresa media tenendo conto di tutti i possibili risultati e delle rispettive probabilità. È proprio questo il significato dell’entropia.\nDal punto di vista matematico, l’entropia è la sorpresa media attesa, calcolata come media pesata dell’informazione di Shannon di tutti i possibili esiti di una variabile casuale \\(X\\):\n\\[\nH(X) \\approx \\frac{1}{n} \\sum_{i=1}^{n} h(x_i).\n\\tag{41.2}\\]\nIn questa espressione, \\(h(x_i)\\) rappresenta la quantità di informazione trasmessa da un singolo esito \\(x_i\\), secondo la definizione di Shannon vista in precedenza. L’entropia non si riferisce dunque a un evento specifico, ma alla sorpresa media che ci aspettiamo di provare osservando ripetutamente la variabile.\nSe la distribuzione delle probabilità è perfettamente equilibrata – ad esempio in una distribuzione uniforme, dove tutti i risultati sono ugualmente probabili – l’entropia è massima, poiché ogni osservazione fornisce una quantità simile e relativamente alta di informazione. Se invece la distribuzione è sbilanciata – per esempio nel caso di una moneta truccata che dà quasi sempre “testa” – l’entropia è più bassa, perché la prevedibilità aumenta e la quantità media di informazione fornita da ciascuna osservazione diminuisce.\nIl grafico seguente illustra come la sorpresa di Shannon varia in funzione della probabilità di un evento: eventi rari producono un valore elevato di sorpresa, mentre eventi comuni producono un valore basso.\n\np_vals &lt;- seq(0.001, 1, by = 0.001)\nsurprise &lt;- -log2(p_vals)\n\nggplot(data.frame(p = p_vals, h = surprise), aes(x = p, y = h)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"Probabilità dell'evento p(x)\",\n    y = \"Sorpresa h(x) [bit]\"\n  ) \n\n\n\n\n\n\n\n\n41.2.2 Interpretazione dell’entropia\nDiamo ora un significato concreto al valore numerico dell’entropia. Poiché essa rappresenta la media della sorpresa attesa osservando la realizzazione di una variabile casuale, tenendo conto di tutti i possibili esiti e delle loro probabilità, può essere interpretata come il numero medio di bit necessari per descrivere un’osservazione della variabile \\(X\\).\nQuando l’entropia è espressa in bit, possiamo tradurla in un numero equivalente di alternative equiprobabili utilizzando la relazione\n\\[\nm = 2^{H(X)} .\n\\tag{41.3}\\] Questo significa che un’entropia di \\(H(X)\\) bit corrisponde alla stessa incertezza che avremmo se dovessimo distinguere tra \\(m\\) esiti tutti ugualmente probabili. In questo senso, l’entropia misura la quantità di informazione contenuta in una variabile, esprimendola in termini del numero di scelte equiprobabili che la variabile potrebbe assumere.\n\n\n\n\n\n\nEsercizio — Interpretazione dell’entropia.\n\n\n\n\n\n1. Caso di riferimento: moneta equa.\nSe una variabile casuale può assumere due valori ugualmente probabili, come una moneta equa con \\(p(\\text{testa}) = p(\\text{croce}) = 0.5\\), la sua entropia è:\n\\[\nH(X) = 0.5 \\log_2\\frac{1}{0.5} + 0.5 \\log_2\\frac{1}{0.5}\n      = 0.5 \\times 1 + 0.5 \\times 1\n      = 1 \\ \\text{bit}.\n\\] Questo è il valore massimo di entropia per una variabile con due soli esiti: 1 bit è l’informazione necessaria per distinguere tra due alternative equiprobabili.\n2. Moneta sbilanciata: singolo lancio.\nQuando la moneta è sbilanciata, l’informazione media diminuisce. Supponiamo \\(p(\\text{testa}) = 0.9\\) e \\(p(\\text{croce}) = 0.1\\).\nLa sorpresa associata a ciascun esito è:\n\\[\nh(\\text{testa}) = \\log_2\\frac{1}{0.9} \\approx 0.15 \\ \\text{bit},\n\\]\n\\[\nh(\\text{croce}) = \\log_2\\frac{1}{0.1} \\approx 3.32 \\ \\text{bit}.\n\\]\nPesando queste sorprese con le rispettive probabilità otteniamo l’entropia media:\n\\[\nH(X) = 0.9 \\times 0.15 + 0.1 \\times 3.32 \\approx 0.469 \\ \\text{bit}.\n\\] Questa entropia è inferiore a 1 bit, nonostante l’esito raro (“croce”) sia molto più sorprendente di quello di una moneta equa. In generale, nessuna moneta sbilanciata può avere un’entropia media superiore a quella di una moneta equa.\n3. Più lanci: interpretazione pratica.\nSe lanciamo questa moneta 1000 volte, l’informazione totale prodotta sarà:\n\\[\n1000 \\times 0.469 \\approx 469 \\ \\text{bit}.\n\\] Quindi, rispetto alla moneta equa (1000 bit), otteniamo meno della metà dell’informazione.\n4. Numero equivalente di alternative equiprobabili.\nL’entropia può essere anche interpretata come il numero equivalente di alternative tutte equiprobabili:\n\\[\nm = 2^{H(X)} = 2^{0.469} \\approx 1.38.\n\\] Questo non significa che esista un dado fisico con 1.38 facce: è solo un modo per dire che la quantità di incertezza media di questa moneta è la stessa di una variabile che può assumere circa 1.38 valori tutti con la stessa probabilità.\n\n# Funzione per calcolare l'entropia di una moneta\nentropy_coin &lt;- function(p) {\n  ifelse(p == 0 | p == 1, 0,\n         -p * log2(p) - (1 - p) * log2(1 - p))\n}\n\n# Sequenza di probabilità\np_values &lt;- seq(0, 1, by = 0.01)\nH_values &lt;- entropy_coin(p_values)\n\n# Dati per i punti di esempio\npoints_df &lt;- data.frame(\n  p = c(0.5, 0.9),\n  H = entropy_coin(c(0.5, 0.9)),\n  label = c(\"Moneta equa\\nH=1 bit\", \"Moneta sbilanciata\\nH=0.469 bit\")\n)\n\n# Grafico\nggplot(data.frame(p = p_values, H = H_values), aes(x = p, y = H)) +\n  geom_line(size = 1) +\n  geom_point(data = points_df, aes(x = p, y = H), color = \"brown\", size = 3) +\n  geom_text(data = points_df, aes(label = label), vjust = -1, hjust = 0.5) +\n  labs(\n    x = expression(paste(\"Probabilità di testa, \", p)),\n    y = \"Entropia H(X) [bit]\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n41.2.3 Caratteristiche dell’entropia\nL’entropia raggiunge il suo valore massimo quando tutti gli esiti possibili hanno la stessa probabilità di verificarsi. In questa condizione, l’incertezza è totale: non esiste alcun indizio che permetta di prevedere il risultato meglio del puro caso, e il grado di imprevedibilità è al massimo.\nAll’opposto, l’entropia è minima quando l’esito è completamente certo, cioè quando un evento ha probabilità pari a 1 e tutti gli altri hanno probabilità pari a 0. In tali circostanze non vi è alcuna incertezza, nessuna sorpresa e quindi nessuna informazione aggiuntiva ottenibile dall’osservazione.\nUn’ulteriore caratteristica fondamentale è l’additività per eventi indipendenti: quando due o più eventi sono indipendenti, l’entropia complessiva della loro combinazione è pari alla somma delle entropie dei singoli eventi. Questa proprietà deriva direttamente dall’additività dei logaritmi nella formula di Shannon e riflette il fatto che, nel caso di eventi indipendenti, l’incertezza complessiva si ottiene sommando le incertezze prodotte da ciascun evento considerato separatamente.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#stimare-lentropia",
    "href": "chapters/entropy/01_entropy.html#stimare-lentropia",
    "title": "41  Entropia e informazione di Shannon",
    "section": "\n41.3 Stimare l’entropia",
    "text": "41.3 Stimare l’entropia\nNelle sezioni precedenti abbiamo visto che l’entropia esprime la sorpresa media attesa quando osserviamo una variabile casuale, ed è strettamente legata all’informazione di Shannon dei singoli eventi. Passiamo ora dal concetto alla sua applicazione pratica, illustrando come calcolare l’entropia sia a partire da una distribuzione di probabilità teorica, sia da un insieme di dati osservati.\n\n41.3.1 L’entropia di una distribuzione di probabilità\nImmaginiamo una variabile casuale discreta \\(X\\), che può assumere un insieme di valori distinti \\(x_1, x_2, \\dots, x_n\\), ciascuno con probabilità \\(p(x) = \\Pr\\{X = x\\}\\). Quando osserviamo un particolare valore di \\(X\\), riceviamo una certa quantità di informazione, che possiamo interpretare come il grado di sorpresa associato a quell’esito. Un evento molto improbabile produce un’alta sorpresa, mentre un evento quasi certo trasmette poca o nessuna informazione.\nPer tradurre questa intuizione in termini matematici, definiamo la sorpresa di un esito \\(x\\) come\n\\[\nh(x) = -\\log_2 p(x).\n\\] Questa funzione ha le proprietà desiderate: è tanto più grande quanto minore è la probabilità di \\(x\\), e vale zero se l’evento è certo (\\(p(x) = 1\\)).\nPoiché siamo interessati non a un singolo esito ma all’incertezza complessiva della distribuzione, calcoliamo la media della sorpresa rispetto alle probabilità dei diversi esiti. Otteniamo così la definizione di entropia di Shannon:\n\\[\nH(X) = -\\sum_{x \\in X} p(x) \\log_2 p(x).\n\\tag{41.4}\\] Ogni termine \\(-p(x)\\log_2 p(x)\\) rappresenta il contributo informativo medio di un esito, ponderato in base alla sua probabilità.\nAlcune proprietà fondamentali:\n\nL’entropia è massima quando la distribuzione è uniforme, cioè quando tutti gli esiti sono equiprobabili: in questo caso, l’incertezza è al suo livello più alto.\n\nL’entropia si riduce man mano che la distribuzione diventa più sbilanciata: se alcuni esiti hanno probabilità molto elevate, il grado di sorpresa complessiva diminuisce.\n\nSe un esito è certo, l’entropia si annulla: non c’è incertezza e nessuna nuova informazione viene trasmessa dall’osservazione.\n\nIn breve, l’entropia \\(H(X)\\) misura l’incertezza media di una variabile casuale e può essere interpretata come il numero medio di bit necessari per descrivere un’osservazione di \\(X\\).\n\n\n\n\n\n\nRipasso matematico\n\n\n\n\nLa somma indica che calcoliamo il contributo di ciascun esito possibile.\n\nIl logaritmo (in base 2) ci dice quanta “informazione” porta ogni esito.\n\nIl segno meno serve perché i logaritmi di numeri tra 0 e 1 sono negativi.\n\n\n\n\n\n\n\n\n\n\nEsercizio — Entropia di un dado con otto facce.\n\n\n\n\n\nSupponiamo di avere un dado con otto facce. Ci sono \\(m = 8\\) esiti possibili:\n\\[\nA_x = \\{1,2,3,4,5,6,7,8\\}.\n\\]\nPoiché il dado è equo, tutti gli otto esiti hanno la stessa probabilità di \\(p(x) = 1/8\\), definendo così una distribuzione di probabilità uniforme:\n\\[\np(X) = \\left\\{\\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}\\right\\}.\n\\]\nL’entropia di questa distribuzione può essere calcolata come:\n\\[\nH(X) = - \\sum_{i=1}^{8} \\frac{1}{8} \\log_2 \\frac{1}{8} = \\log_2 8 = 3 \\text{ bit}.\n\\] Poiché l’informazione associata a ciascun esito è esattamente 3 bit, anche l’entropia media è di 3 bit, che rappresenta l’incertezza complessiva della variabile \\(X\\).\nDato che \\(X\\) ha un’entropia di \\(H(X) = 3\\) bit, possiamo dire che \\(X\\) può rappresentare fino a:\n\\[\nm = 2^{H(X)} = 2^3 = 8\n\\] esiti equiprobabili.\n\n\n\n\n\n\n\n\n\nEsercizio — Entropia di un variabile casuale discreta.\n\n\n\n\n\nSia \\(X\\) una variabile casuale discreta che può assumere i valori \\(a, b, c,\\) e \\(d\\) con una distribuzione di probabilità di massa \\(p(a) = \\frac{1}{2}\\), \\(p(b) = \\frac{1}{4}\\), \\(p(c) = \\frac{1}{8}\\), e \\(p(d) = \\frac{1}{8}\\), rispettivamente. L’entropia di \\(X\\), che misura l’incertezza associata alla distribuzione di probabilità, è calcolata come:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{4} \\log_2 \\frac{1}{4} + \\frac{1}{8} \\log_2 \\frac{1}{8} + \\frac{1}{8} \\log_2 \\frac{1}{8}\\right).\n\\] Calcolando i singoli termini, otteniamo:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\cdot (-1) + \\frac{1}{4} \\cdot (-2) + \\frac{1}{8} \\cdot (-3) + \\frac{1}{8} \\cdot (-3)\\right) = \\frac{7}{4} \\text{ bits}.\n\\] È importante notare che l’entropia \\(H(X)\\) dipende esclusivamente dalla distribuzione di probabilità dei valori di \\(X\\) e non dai valori stessi.\n\n\n\n\n41.3.2 L’entropia in un campione di osservazioni\nFinora abbiamo considerato il caso in cui la distribuzione di probabilità sia nota a priori. Nella pratica della ricerca psicologica, tuttavia, disponiamo spesso soltanto di un campione di osservazioni. In questo caso possiamo stimare l’entropia calcolando le frequenze relative di ciascun valore osservato e utilizzandole come stima empirica delle probabilità.\nIl risultato misura quanto la distribuzione dei valori nel campione sia incerta o imprevedibile. Un campione in cui le frequenze siano simili per tutti i valori possibili mostrerà un’entropia stimata elevata; al contrario, se nel campione un valore domina nettamente sugli altri, l’entropia stimata sarà bassa, indicando una distribuzione più prevedibile.\n\n\n\n\n\n\nEsercizio — Entropia di un campione di osservazioni.\n\n\n\n\n\nPer comprendere meglio questo concetto, possiamo calcolare l’entropia associata a insiemi di osservazioni. Consideriamo i due vettori seguenti:\n\\[\n\\begin{align}\nx &= \\{1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2\\}, \\notag\\\\\ny &= \\{3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4\\}. \\notag\n\\end{align}\n\\]\nTroviamo l’entropia associata a ciascuno di essi.\n\n# Vettori x e y\nx &lt;- c(1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2)\ny &lt;- c(3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4)\n\n# Conta le frequenze\nx_counts &lt;- table(x)\ny_counts &lt;- table(y)\n\n# Calcola le probabilità relative\nx_probabilities &lt;- as.numeric(x_counts) / length(x)\ny_probabilities &lt;- as.numeric(y_counts) / length(y)\n\n# Funzione per calcolare l'entropia (log in base 2)\ncalculate_entropy &lt;- function(probabilities) {\n  -sum(probabilities * log2(probabilities))\n}\n\n# Calcolo dell'entropia\nx_entropy &lt;- calculate_entropy(x_probabilities)\ny_entropy &lt;- calculate_entropy(y_probabilities)\n\n# Stampa i risultati\ncat(sprintf(\"Entropia di x: %.4f bit\\n\", x_entropy))\n#&gt; Entropia di x: 1.8776 bit\ncat(sprintf(\"Entropia di y: %.4f bit\\n\", y_entropy))\n#&gt; Entropia di y: 1.8776 bit\n\nEntrambi i vettori hanno la stessa entropia di 1.8776 bit.\n\n\n\n\n41.3.2.1 Interpretazione finale\nL’entropia \\(H(X)\\) misura dunque l’incertezza media associata a una distribuzione di probabilità. Possiamo leggerla anche come il numero medio di bit necessari per descrivere un’osservazione di \\(X\\).\nIn altre parole, l’entropia ci dice quanta informazione, in media, otteniamo osservando il risultato di una variabile casuale: più alta è l’entropia, maggiore è l’imprevedibilità del fenomeno.\n\n41.3.3 L’entropia di una variabile casuale continua\nAnche per le variabili casuali continue possiamo definire l’entropia, estendendo il caso discreto: la somma sui possibili esiti viene semplicemente sostituita da un integrale. Questa generalizzazione è necessaria perché una variabile continua può assumere un numero infinito di valori. In questo caso, la probabilità che \\(X\\) assuma un valore esatto è sempre zero: ciò che conta non è la probabilità puntuale, ma la densità di probabilità nei diversi punti del dominio.\nPer una variabile casuale continua \\(X\\), con funzione di densità di probabilità \\(p(x)\\), l’entropia, detta in questo caso entropia differenziale, è definita come\n\\[\nH(X) = -\\int p(x) \\log_2 p(x) \\, dx ,\n\\tag{41.5}\\] dove \\(p(x)\\) rappresenta la densità di probabilità di \\(X\\) e l’integrale è calcolato su tutto il dominio della variabile.\nCome nel caso discreto, l’entropia differenziale fornisce una misura dell’incertezza media associata alla distribuzione di probabilità. Se la densità è molto concentrata attorno a pochi valori (ad esempio un picco stretto), l’entropia è bassa: sappiamo già “dove aspettarci” la variabile, quindi l’incertezza è ridotta. Al contrario, una densità più “sparsa” e distribuita uniformemente implica un’entropia più alta, segnalando maggiore imprevedibilità.\nIl segno negativo nella formula deriva dal fatto che, per probabilità comprese tra 0 e 1, il logaritmo è negativo: in questo modo l’entropia assume valori positivi e può essere interpretata, in analogia al caso discreto, come il numero medio di bit necessari per codificare un’osservazione della variabile continua \\(X\\).\n\n\n\n\n\n\nEsercizio — Un confronto numerico: normali più “strette” e più “larghe”.\n\n\n\n\n\nPer la distribuzione normale \\(X \\sim \\mathcal N(\\mu,\\sigma^2)\\) l’entropia differenziale ha una forma chiusa:\n\\[\nH(X)=\\tfrac12 \\log_2\\!\\big(2\\pi e\\,\\sigma^2\\big)\\ \\text{bit}.\n\\] La dipendenza è tutta nella scala \\(\\sigma\\): raddoppiare \\(\\sigma\\) aggiunge esattamente 1 bit di entropia, perché la massa di probabilità si “spalma” su un intervallo più ampio. Numericamente, con \\(\\sigma=0{,}5\\), \\(H(X)\\approx 1{,}047\\) bit; con \\(\\sigma=1\\), \\(H(X)\\approx 2{,}047\\) bit; con \\(\\sigma=2\\), \\(H(X)\\approx 3{,}047\\) bit. L’aumento regolare di un bit per ogni raddoppio di \\(\\sigma\\) rende molto trasparente l’idea che una densità più concentrata (piccola \\(\\sigma\\)) produce minore incertezza, mentre una densità più diffusa (grande \\(\\sigma\\)) produce maggiore incertezza.\nEcco un frammento R che replica il calcolo e mostra le tre densità normalizzate sulla stessa scala, così che la relazione tra forma della densità e entropia sia visibile a colpo d’occhio.\n\n# Entropia differenziale (in bit) per N(mu, sigma^2)\nh_norm_bits &lt;- function(sigma) 0.5 * log2(2 * pi * exp(1) * sigma^2)\n\nsigmas &lt;- c(0.5, 1, 2)\nentropie &lt;- sapply(sigmas, h_norm_bits)\nround(entropie, 3)\n#&gt; [1] 1.05 2.05 3.05\n# atteso: 1.047, 2.047, 3.047\n\n# Visualizzazione delle densità\ndf &lt;- data.frame(\n  x = rep(seq(-6, 6, length.out = 1000), times = length(sigmas)),\n  sigma = factor(rep(sigmas, each = 1000))\n)\ndf$dens &lt;- mapply(function(x, s) dnorm(x, mean = 0, sd = s), df$x, as.numeric(as.character(df$sigma)))\n\nggplot(df, aes(x = x, y = dens, group = sigma)) +\n  geom_line(aes(linetype = sigma), linewidth = 1) +\n  labs(\n    subtitle = paste0(\"H(σ=0.5)≈\", round(entropie[1],3), \" bit; \",\n                      \"H(σ=1)≈\",   round(entropie[2],3), \" bit; \",\n                      \"H(σ=2)≈\",   round(entropie[3],3), \" bit\"),\n    x = \"x\", y = \"densità\"\n  ) \n\n\n\n\n\n\n\nNell’analisi di dati psicologici, la stessa variabile misurata con una scala più “compressa” (varianza più piccola, punteggi concentrati) porta a una minore entropia differenziale rispetto alla stessa variabile osservata con maggiore dispersione. Questo legame diretto tra dispersione e entropia chiarisce perché, in presenza di eterogeneità individuale o situazionale, la “quantità di incertezza” da descrivere aumenti con la variabilità del fenomeno.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-codifica-di-huffman",
    "href": "chapters/entropy/01_entropy.html#la-codifica-di-huffman",
    "title": "41  Entropia e informazione di Shannon",
    "section": "\n41.4 La codifica di Huffman",
    "text": "41.4 La codifica di Huffman\nAbbiamo visto che l’entropia \\(H(X)\\) di una variabile casuale \\(X\\) misura la sorpresa media di un esito. Un risultato fondamentale è che l’entropia rappresenta anche il limite teorico inferiore alla lunghezza media, in bit, di un codice binario che descrive gli esiti di \\(X\\). In altre parole: è impossibile creare un sistema di codifica (una “scorciatoia” per rappresentare l’informazione) che, in media, usi meno bit di \\(H(X)\\) per simbolo, senza perdere informazioni.\nL’algoritmo di Huffman, sviluppato da David A. Huffman nel 1952, fornisce un metodo pratico per costruire un codice che si avvicina moltissimo a questo limite teorico.\n\n41.4.1 L’idea di base\nL’idea centrale è semplice e intuitiva, e riflette una strategia di ottimizzazione che anche la nostra mente potrebbe usare: assegna “etichette” mentali corte agli eventi comuni e etichette più lunghe agli eventi rari.\nPensate a come abbreviate le parole che usate più spesso in un messaggio di testo (“tvb”, “xké”, “nn”) mentre scrivete per intero quelle più rare. State applicando un principio simile a quello di Huffman per risparmiare tempo (bit cognitivi)!\n\n41.4.2 Come funziona l’algoritmo, passo dopo passo\nL’obiettivo è costruire un albero binario le cui foglie sono i simboli da codificare. La procedura è la seguente:\n\n\nLista di partenza: Si parte da un elenco di tutti i simboli con le loro probabilità (o frequenze). Ogni simbolo è un piccolo “nodo”.\n\nUnire i più rari: Si identificano i due nodi con la probabilità più bassa e si uniscono per creare un nuovo nodo. A questo nuovo nodo si associa una probabilità pari alla somma delle probabilità dei due nodi figli.\n\nRipetere: Si ripete il passo 2, unendo sempre i due nodi con la probabilità più bassa (considerando anche i nuovi nodi creati), finché non rimane un unico nodo finale, chiamato radice. Questo è l’albero completo.\n\nAssegnare i codici: Si percorre l’albero dalla radice fino a ciascun simbolo (foglia). Ad ogni ramo sinistro si assegna il valore 0 e ad ogni ramo destro il valore 1. La sequenza di 0 e 1 incontrata nel percorso dalla radice alla foglia è il codice di Huffman per quel simbolo.\n\nLa caratteristica geniale di questo codice è che è un codice prefisso: nessun codice è l’inizio (il “prefisso”) di un altro. Questo elimina ogni ambiguità durante la decodifica, permettendo di leggere il messaggio senza bisogno di simboli separatori.\n\n41.4.3 Esempio concreto: codificare un messaggio\nImmaginiamo di dover codificare un messaggio composto da 43 caratteri, usando solo quattro lettere con queste frequenze:\n\n\nSimbolo\nFrequenza\nProbabilità\n\n\n\nA\n20\n~0.47\n\n\nB\n10\n~0.23\n\n\nC\n8\n~0.19\n\n\nD\n5\n~0.12\n\n\n\nCostruiamo l’albero:\n\n\nPasso 1: Uniamo i due simboli meno frequenti, D (5) e C (8), in un nuovo nodo che chiamiamo temporaneamente N1 con frequenza 13.\n\nPasso 2: Ora i nodi disponibili sono A(20), B(10) e N1(13). I due meno frequenti sono B (10) e N1 (13). Li uniamo in un nuovo nodo N2 con frequenza 23.\n\nPasso 3: Restano solo A(20) e N2(23). Li uniamo per formare la radice con frequenza 43.\n\nL’albero risultante è:\n         (Radice:43)\n         /         \\\n       0/           \\1\n      (A:20)      (N2:23)\n                 /       \\\n               0/         \\1\n            (B:10)      (N1:13)\n                       /       \\\n                     0/         \\1\n                   (D:5)       (C:8)\nAssegniamo i codici (percorrendo il percorso dalla Radice alla foglia):\n\nA: il percorso è solo 0 → Codice: 0\n\nB: il percorso è Radice → N2 (1) → B (0) → Codice: 10\n\nD: il percorso è Radice → N2 (1) → N1 (1) → D (0) → Codice: 110\n\nC: il percorso è Radice → N2 (1) → N1 (1) → C (1) → Codice: 111\n\n\nEcco la nostra tabella di codifica finale:\n\n\nSimbolo\nCodice\nLunghezza\n\n\n\nA\n0\n1 bit\n\n\nB\n10\n2 bit\n\n\nD\n110\n3 bit\n\n\nC\n111\n3 bit\n\n\n\nNotate come il simbolo più frequente (A) ha ottenuto il codice più corto (1 bit), mentre quelli più rari (C e D) hanno codici più lunghi (3 bit).\n\n41.4.4 Collegamento con l’entropia: quanto ci siamo avvicinati al limite?\nTorniamo alla teoria. Usando le probabilità dell’esempio, possiamo calcolare:\n\n\nLunghezza media del codice (\\(L\\)): quanti bit usiamo in media per simbolo?\n\n\\[\n\\begin{align}\nL &= (p(A)\\cdot 1) + (p(B)\\cdot 2) + (p(C)\\cdot 3) + (p(D)\\cdot 3) \\notag\\\\\n&= (0.47\\cdot 1) + (0.23\\cdot 2) + (0.19\\cdot 3) + (0.12\\cdot 3) \\notag \\\\\n   &\\approx 1.9 \\ \\text{bit}\n\\end{align}\n\\]\n\n\nEntropia (\\(H(X)\\)): il limite teorico minimo di bit per simbolo.\n\n\\[\n\\begin{align}\nH(X) &= -\\big[\\,0.47\\log_2(0.47) + 0.23\\log_2(0.23) \\notag\\\\\n&\\qquad + 0.19\\log_2(0.19) + 0.12\\log_2(0.12)\\,\\big] \\notag\\\\\n& \\quad\\approx 1.85 \\ \\text{bit}\n\\end{align}\n\\]\nRisultato: La nostra codifica di Huffman (1.9 bit/simbolo) è estremamente vicina al limite teorico dell’entropia (1.85 bit/simbolo). La piccola differenza è dovuta al fatto che i codici devono avere una lunghezza intera (non possiamo avere un codice di 1.85 bit!), mentre l’entropia è un valore medio che può essere decimale.\n\n41.4.4.1 In sintesi\n\n\n\n\n\n\n\nConcetto\nSignificato Teorico\nAnalogia Psicologica (Approssimativa)\n\n\n\nEntropia H(X)\nLimite teorico assoluto di compressione. Misura l’incertezza/intrinseca.\nIl “carico cognitivo” minimo necessario per rappresentare uno stimolo.\n\n\nCodifica di Huffman\nMetodo pratico per costruire un codice ottimale che si avvicina al limite H(X).\nUna strategia cognitiva efficiente per categorizzare informazioni (es. etichette mentali corte per concetti comuni).\n\n\nLunghezza media L\nIl risultato pratico ottenuto con Huffman.\nIl reale “costo” cognitivo della strategia adottata.\n\n\nDifferenza (L - H(X))\nQuanto il metodo pratico si discosta dal limite teorico ideale.\nQuanto la nostra strategia cognitiva è efficiente rispetto all’ideale.\n\n\n\nIn sintesi, l’algoritmo di Huffman rappresenta un ponte tra la teoria e la pratica. Esso dimostra in modo tangibile come il principio astratto dell’entropia—il limite teorico di compressione—possa essere realizzato in una strategia concreta. Questo processo di ottimizzazione offre una potente analogia per ipotizzare come la nostra mente potrebbe elaborare le informazioni in modo efficiente, privilegiando gli stimoli più frequenti per risparmiare risorse cognitive.\n\n\n\n\n\n\nEsercizio — Entropia e codifica di Huffman.\n\n\n\n\n\nSupponiamo di avere una variabile casuale \\(X\\) che può assumere quattro valori: \\(A\\), \\(B\\), \\(C\\), e \\(D\\), con le seguenti probabilità:\n\n\\(p(A) = 0.4\\)\n\\(p(B) = 0.3\\)\n\\(p(C) = 0.2\\)\n\\(p(D) = 0.1\\)\n\nPer rappresentare questi esiti con un codice binario efficiente possiamo usare la codifica di Huffman, che assegna codici più brevi ai simboli più probabili, e codici più lunghi a quelli meno probabili.\nSupponiamo che Huffman produca la seguente codifica:\n\nA = 0 (1 bit)\nB = 10 (2 bit)\nC = 110 (3 bit)\nD = 111 (3 bit)\n\nLa lunghezza media del codice si ottiene moltiplicando la probabilità di ciascun simbolo per la lunghezza del suo codice binario, e poi sommando:\n\\[\n\\begin{align}\n\\text{Lunghezza media} &= (0.4 \\times 1) + (0.3 \\times 2) + (0.2 \\times 3) + (0.1 \\times 3) \\\\\n&= 0.4 + 0.6 + 0.6 + 0.3 = 1.9 \\text{ bit}.\n\\end{align}\n\\]\nQuesto significa che, in media, servono 1.9 bit per rappresentare un’osservazione della variabile \\(X\\) usando la codifica di Huffman.\nConfermiamo il risultato con il seguente codice R:\n\n# Definizione delle probabilità\nprobabilities &lt;- list(A = 0.4, B = 0.3, C = 0.2, D = 0.1)\n\n\n# Funzione per la codifica di Huffman\nhuffman_encoding &lt;- function(probabilities) {\n  nodes &lt;- lapply(names(probabilities), function(sym) {\n    list(symbol = sym, prob = probabilities[[sym]], left = NULL, right = NULL)\n  })\n\n  while (length(nodes) &gt; 1) {\n    nodes &lt;- nodes[order(sapply(nodes, function(n) n$prob))]\n    left &lt;- nodes[[1]]\n    right &lt;- nodes[[2]]\n    merged &lt;- list(symbol = NULL, prob = left$prob + right$prob, left = left, right = right)\n    nodes &lt;- c(nodes[-c(1, 2)], list(merged))\n  }\n\n  assign_codes &lt;- function(node, prefix = \"\", code_map = list()) {\n    if (!is.null(node$symbol)) {\n      code_map[[node$symbol]] &lt;- prefix\n    } else {\n      code_map &lt;- assign_codes(node$left, paste0(prefix, \"0\"), code_map)\n      code_map &lt;- assign_codes(node$right, paste0(prefix, \"1\"), code_map)\n    }\n    return(code_map)\n  }\n\n  code_map &lt;- assign_codes(nodes[[1]])\n\n  avg_length &lt;- sum(sapply(names(probabilities), function(sym) {\n    probabilities[[sym]] * nchar(code_map[[sym]])\n  }))\n\n  return(list(avg_length = avg_length, huffman_dict = code_map))\n}\n\n\n# Applicazione e stampa dei risultati\nresult &lt;- huffman_encoding(probabilities)\n\ncat(sprintf(\"Lunghezza media del codice di Huffman: %.2f bit/simbolo\\n\", result$avg_length))\n#&gt; Lunghezza media del codice di Huffman: 1.90 bit/simbolo\ncat(\"Codici di Huffman:\\n\")\n#&gt; Codici di Huffman:\nfor (sym in names(result$huffman_dict)) {\n  cat(sprintf(\"%s: %s\\n\", sym, result$huffman_dict[[sym]]))\n}\n#&gt; A: 0\n#&gt; B: 10\n#&gt; D: 110\n#&gt; C: 111\n\nOra calcoliamo l’entropia teorica della variabile \\(X\\), cioè la lunghezza media minima che qualsiasi codifica binaria può raggiungere:\n\\[\n\\begin{align}\nH(X) &= - \\sum p(x) \\log_2 p(x) \\\\\n     &= -[0.4 \\log_2 0.4 + 0.3 \\log_2 0.3 + 0.2 \\log_2 0.2 + 0.1 \\log_2 0.1] \\\\\n     &= 1.8465 \\text{ bit}.\n\\end{align}\n\\] Il valore dell’entropia è leggermente inferiore alla lunghezza media di Huffman (1.9 bit). Questo è normale: Huffman fornisce codici con lunghezza intera in bit, mentre l’entropia può assumere valori decimali. La codifica di Huffman è quindi quasi ottimale.\nIn sintesi:\n\n\nl’entropia \\(H(X)\\) rappresenta la lunghezza media teorica minima (in bit) per codificare una variabile casuale;\nla codifica di Huffman costruisce un codice binario che si avvicina molto a questo limite, usando più bit per i simboli rari e meno bit per quelli frequenti;\nin questo modo, l’entropia ci offre un criterio per valutare quanto efficiente è una codifica: più la lunghezza media si avvicina all’entropia, più è efficiente.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "href": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "title": "41  Entropia e informazione di Shannon",
    "section": "\n41.5 Applicazioni psicologiche",
    "text": "41.5 Applicazioni psicologiche\nIl concetto di entropia, inteso come misura della sorpresa media associata a un evento, trova applicazioni dirette anche nello studio di fenomeni psicologici. In particolare, la sorpresa — formalizzabile in termini di informazione di Shannon — è stata associata a cambiamenti emotivi, processi di apprendimento e modulazione della motivazione.\nUn esempio classico è fornito da Spector (1956), che studiò l’effetto della probabilità a priori sulla soddisfazione dei soggetti in seguito a una promozione lavorativa. I risultati mostrarono che esiti inizialmente percepiti come poco probabili — e quindi più sorprendenti quando si verificano — producevano un impatto emotivo maggiore rispetto a esiti attesi. In altre parole, la sorpresa amplificava la risposta affettiva, confermando l’idea che l’entropia non sia solo una misura astratta, ma un indicatore della potenziale intensità della reazione emotiva.\nRicerche più recenti, in contesti sia sperimentali che ecologici, hanno confermato questo legame. Ad esempio, studi nell’ambito delle neuroscienze cognitive hanno mostrato che eventi ad alta sorpresa modulano l’attività di aree cerebrali legate all’elaborazione emotiva, come l’amigdala e la corteccia prefrontale ventromediale, influenzando sia l’umore immediato sia l’apprendimento successivo. Allo stesso modo, nell’analisi dei dati di Ecological Momentary Assessment (EMA), la probabilità soggettiva di un evento può essere messa in relazione alla variazione momentanea dell’umore, mostrando che episodi rari o inattesi tendono a generare oscillazioni emotive più marcate.\nQuesti risultati illustrano bene come il concetto di entropia possa essere utilizzato in psicologia non solo come strumento di misura della distribuzione di probabilità degli eventi, ma anche come variabile esplicativa in modelli che indagano il legame tra aspettative, sorpresa e stati emotivi. Questo stesso legame sarà centrale quando, nelle prossime sezioni, introdurremo la divergenza di Kullback–Leibler e la utilizzeremo per confrontare modelli in un’ottica bayesiana.\n\n\n\n\n\n\nEsercizio – probabilità, sorpresa e umore.\n\n\n\n\n\nIn questo esempio, simuliamo 200 osservazioni in cui ogni partecipante sperimenta un evento con probabilità variabile. La sorpresa di ciascun evento viene calcolata con la formula di Shannon, e l’effetto sull’umore viene simulato assumendo che eventi più sorprendenti producano, in media, variazioni di umore più ampie (positive o negative).\n\nset.seed(123)\n\n# Numero di osservazioni\nn &lt;- 200\n\n# Probabilità percepita dell'evento (da molto probabile a molto improbabile)\np_event &lt;- runif(n, min = 0.05, max = 0.95)\n\n# Sorpresa di Shannon (in bit)\nsurprise &lt;- -log2(p_event)\n\n# Variazione di umore simulata:\n# partiamo da un effetto medio proporzionale alla sorpresa, con rumore casuale\ndelta_mood &lt;- 0.5 * surprise + rnorm(n, mean = 0, sd = 0.5)\n\n# Mettiamo tutto in un data frame\ndf &lt;- data.frame(\n  p_event = p_event,\n  surprise = surprise,\n  delta_mood = delta_mood\n)\n\n# Visualizzazione\nggplot(df, aes(x = surprise, y = delta_mood)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n  labs(\n    x = \"Sorpresa (bit)\",\n    y = \"Δ Umore\"\n  ) \n\n\n\n\n\n\n\nInterpretazione. Il grafico mostra che, in questa simulazione, eventi più sorprendenti (bit più alti) tendono a produrre variazioni di umore maggiori. Questo illustra visivamente l’idea, già documentata empiricamente, che la sorpresa può amplificare la risposta emotiva.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "href": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "title": "41  Entropia e informazione di Shannon",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esplorato come l’entropia ci permetta di misurare quantitativamente l’incertezza e l’informazione in sistemi complessi. Attraverso esempi concreti - dal lancio di una moneta alla codifica di messaggi - abbiamo visto come questo concetto matematico possa essere applicato in modo pratico e intuitivo.\n\n41.5.1 Cosa abbiamo imparato\n\n\nL’entropia misura l’incertezza: Più una situazione è imprevedibile (come una moneta equilibrata), maggiore è la sua entropia. Situazioni prevedibili (come un comportamento stereotipato) hanno invece entropia bassa.\n\nL’informazione è sorpresa: Eventi rari e inaspettati ci forniscono più informazione rispetto a eventi comuni. La formula di Shannon cattura precisamente questa intuizione quotidiana.\n\nEsiste un limite alla compressione: L’entropia rappresenta il numero minimo di bit necessari per descrivere un’informazione senza perdite. L’algoritmo di Huffman ci mostra come avvicinarci a questo limite nella pratica.\n\n\n41.5.1.1 Perché è rilevante per la psicologia?\nQuesti concetti non sono solo astratti, ma trovano applicazioni concrete nella ricerca psicologica:\n\n\nModellizzazione cognitiva: I processi mentali possono essere visti come sistemi che elaborano informazione. L’entropia ci aiuta a quantificare quanto “lavoro” cognitivo sia necessario per processare stimoli diversi.\n\nEmozioni e sorpresa: Come abbiamo visto nell’esempio finale, eventi sorprendenti (alta entropia) tendono a produrre risposte emotive più intense. Questo collegamento tra probabilità e emozione è un campo di ricerca attivo.\n\nValutazione dei modelli: Nei prossimi capitoli vedremo come l’entropia sia la base per strumenti che ci permettono di confrontare modelli psicologici e valutarne la capacità predittiva.\n\n41.5.1.2 Uno sguardo al futuro\nL’entropia non è solo un concetto isolato, ma il fondamento per strumenti più avanzati che incontreremo:\n\nla divergenza di Kullback-Leibler (nel prossimo capitolo) misura quanto un modello si discosta dalla realtà, usando proprio i concetti di entropia che abbiamo appreso;\nl’ELPD (Expected Log Predictive Density) ci aiuterà a confrontare modelli bayesiani valutando la loro capacità predittiva.\n\nComprendere l’entropia significa quindi possedere una chiave interpretativa potente: ci permette di passare dall’osservazione qualitativa (“questo comportamento è più variabile”) alla misurazione quantitativa (“l’entropia di questo comportamento è X bit”).\n\n\n\n\n\n\nMappa concettuale: dall’entropia alla valutazione dei modelli\n\n\n\n\n\nEntropia \\(H(X)\\)\n→ Misura l’incertezza intrinseca di una variabile casuale.\n→ Interpretabile come la sorpresa media o la lunghezza media minima (in bit) necessaria per codificare gli esiti di \\(X\\).\nDivergenza di Kullback–Leibler \\(D_{KL}(P \\parallel Q)\\)\n→ Confronta due distribuzioni di probabilità \\(P\\) (la “vera” distribuzione) e \\(Q\\) (il modello).\n→ Misura quanto il modello \\(Q\\) si discosta da \\(P\\) in termini di inefficienza nel codificare i dati.\nExpected Log Predictive Density (ELPD)\n→ Valuta la capacità predittiva di un modello su dati nuovi.\n→ Collegata alla minimizzazione della KL tra la distribuzione dei dati e la distribuzione predittiva del modello.\n→ Più alto è l’ELPD, migliore è la capacità del modello di rappresentare e prevedere i dati.\nCollegamento logico:\nEntropia → ci dice quanta incertezza c’è nei dati.\nKL → ci dice quanto un modello spreca informazione rispetto a quella incertezza.\nELPD → ci dice quanto bene il modello prevede, riducendo quello spreco.\n\n\n\n\n\nFigura 41.1: Diagramma visivo che collega Entropia → Divergenza KL → ELPD.\n\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidygraph_1.3.1       ggraph_2.2.2          igraph_2.1.4         \n#&gt;  [4] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        mgcv_1.9-3           \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       arrayhelpers_1.1-0    fastmap_1.2.0        \n#&gt; [16] backports_1.5.0       labeling_0.4.3        rmarkdown_2.29       \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        tweenr_2.0.3         \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      viridis_0.6.5         abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 polyclip_1.10-7      \n#&gt; [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [58] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [64] graphlayouts_1.2.2    mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] ggforce_0.5.0         cli_3.6.5             textshaping_1.0.3    \n#&gt; [73] svUnit_1.0.8          viridisLite_0.4.2     Brobdingnag_1.2-9    \n#&gt; [76] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [79] ggrepel_0.9.6         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [82] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [85] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#bibliografia",
    "href": "chapters/entropy/01_entropy.html#bibliografia",
    "title": "41  Entropia e informazione di Shannon",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSpector, A. J. (1956). Expectations, fulfillment, and morale. The Journal of Abnormal and Social Psychology, 52(1), 51–56.\n\n\nStone, J. V. (2022). Information theory: a tutorial introduction, 2nd edition.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#footnotes",
    "href": "chapters/entropy/01_entropy.html#footnotes",
    "title": "41  Entropia e informazione di Shannon",
    "section": "",
    "text": "Ricorda che per le proprietà dei logaritmi: \\(\\log(1/x) = -\\log(x)\\), perché \\(\\log(1/x) = \\log(1) - \\log(x) = 0 - \\log(x)\\).↩︎",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html",
    "href": "chapters/entropy/02_kl.html",
    "title": "42  La divergenza di Kullback-Leibler",
    "section": "",
    "text": "Introduzione\nNel capitolo precedente abbiamo introdotto l’entropia come misura dell’incertezza di una distribuzione di probabilità. Ora facciamo un passo avanti: invece di misurare l’incertezza di una sola distribuzione, vogliamo misurare quanto una distribuzione differisce da un’altra. Uno strumento cruciale per rispondere a questa domanda è la divergenza di Kullback-Leibler (Kullback & Leibler, 1951), spesso abbreviata come divergenza KL (\\(D_{\\text{KL}}\\)). Essa misura quanto si perde in precisione o efficienza se si utilizza un modello errato per descrivere la realtà.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#introduzione",
    "href": "chapters/entropy/02_kl.html#introduzione",
    "title": "42  La divergenza di Kullback-Leibler",
    "section": "",
    "text": "Panoramica del capitolo\n\nCos’è la divergenza KL e da dove nasce.\nCome si collega al concetto di entropia.\nPerché è utile nella scelta tra modelli statistici.\nCome calcolarla e interpretarla, anche con esempi in R.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nPer comprendere appieno questo capitolo, dovresti aver già appreso i concetti di entropia e informazione di Shannon (Capitolo 41).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Funzione per il calcolo dei termini della divergenza KL\nkl_terms &lt;- function(p, q) {\n  stopifnot(length(p) == length(q))\n  non_zero &lt;- p &gt; 0 & q &gt; 0\n  p &lt;- p[non_zero]\n  q &lt;- q[non_zero]\n  term &lt;- p * log2(p / q)\n  data.frame(x = seq_along(p), p = p, q = q, term = term)\n}\n\n# Funzione compatta per il valore totale\nkl_divergence &lt;- function(p, q) {\n  sum(kl_terms(p, q)$term)\n}\n\n# Entropia vera (in bit)\nentropy &lt;- function(p) {\n  p &lt;- p[p &gt; 0]\n  -sum(p * log2(p))\n}\n\n# Entropia incrociata (in bit)\ncross_entropy &lt;- function(p, q) {\n  non_zero &lt;- p &gt; 0 & q &gt; 0\n  p &lt;- p[non_zero]\n  q &lt;- q[non_zero]\n  -sum(p * log2(q))\n}",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#la-generalizzabilità-dei-modelli-e-il-metodo-scientifico",
    "href": "chapters/entropy/02_kl.html#la-generalizzabilità-dei-modelli-e-il-metodo-scientifico",
    "title": "42  La divergenza di Kullback-Leibler",
    "section": "\n42.1 La generalizzabilità dei modelli e il metodo scientifico",
    "text": "42.1 La generalizzabilità dei modelli e il metodo scientifico\nUno degli obiettivi fondamentali della scienza è la generalizzabilità: un buon modello non deve spiegare solo i dati che abbiamo già, ma anche prevedere correttamente nuovi dati che potremmo raccogliere in futuro. Un modello troppo semplice rischia di sotto-adattarsi ai dati (underfitting), perdendo informazioni importanti; uno troppo complesso rischia di sovra-adattarsi (overfitting), confondendo il rumore casuale con segnali reali. Il problema della generalizzabilità è quindi centrale nel metodo scientifico: vogliamo modelli abbastanza flessibili da catturare i pattern reali, ma non così flessibili da adattarsi anche a variazioni casuali.\nNell’approccio bayesiano, come osserva McElreath (2020), la scelta di un modello implica trovare un equilibrio tra due esigenze:\n\n\naccuratezza predittiva – il modello deve produrre previsioni affidabili sui dati futuri;\n\ncontrollo della complessità – il modello non deve introdurre più complessità di quanta ne richieda il fenomeno studiato.\n\nQuesto principio è vicino a quello noto come rasoio di Occam: tra due modelli che spiegano altrettanto bene i dati, preferiamo quello più semplice. La differenza è che, in ambito bayesiano, questa preferenza non è solo una regola intuitiva, ma può essere formalizzata in termini quantitativi, misurando quanta “informazione in più” dobbiamo spendere quando il nostro modello si discosta dalla realtà. Questa misura è data dalla divergenza di Kullback–Leibler, che vedremo nel seguito.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#lentropia-relativa",
    "href": "chapters/entropy/02_kl.html#lentropia-relativa",
    "title": "42  La divergenza di Kullback-Leibler",
    "section": "\n42.2 L’entropia relativa",
    "text": "42.2 L’entropia relativa\nNel Capitolo 41 abbiamo visto che l’entropia \\(H(P)\\) misura la lunghezza media del codice più efficiente per descrivere una distribuzione di probabilità \\(P\\). Ora estendiamo il ragionamento al confronto tra due distribuzioni:\n\n\n\\(P\\) = distribuzione vera dei dati, cioè quella che genera realmente gli eventi;\n\n\\(Q\\) = distribuzione approssimata, cioè quella fornita dal modello.\n\nLa divergenza di Kullback–Leibler, \\(D_{\\text{KL}}(P \\parallel Q)\\), risponde alla seguente domanda:\n\nin media, quanta informazione in più dobbiamo spendere se usiamo \\(Q\\) invece di \\(P\\) per descrivere i dati?\n\nDal punto di vista della codifica, questa quantità rappresenta l’aumento medio della lunghezza del codice quando si usa un modello impreciso.\n\n42.2.1 Definizione formale\nPer una variabile casuale discreta \\(X\\):\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x p(x) \\log_2 \\frac{p(x)}{q(x)}\n\\tag{42.1}\\]\nche può essere riscritta come:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x p(x) \\left[ \\log_2 p(x) - \\log_2 q(x) \\right].\n\\tag{42.2}\\]\nQuesta forma mette in evidenza un’interpretazione intuitiva:\n\n\n\\(\\log_2 p(x)\\) è l’informazione (in bit) associata all’esito \\(x\\) secondo la distribuzione vera \\(P\\);\n\n\\(\\log_2 q(x)\\) è l’informazione associata allo stesso esito secondo il modello \\(Q\\);\nla differenza \\(\\log_2 p(x) - \\log_2 q(x)\\) indica, per quell’esito, quanto il modello \\(Q\\) sottostima o sovrastima la sorpresa rispetto a \\(P\\);\nmoltiplicando per \\(p(x)\\) e sommando su tutti gli esiti otteniamo una media ponderata (pesata in base a quanto l’esito è probabile nella realtà).\n\nIn sintesi, \\(D_{\\text{KL}}(P \\parallel Q)\\) è la perdita media di efficienza quando descriviamo la variabile \\(X\\) con la distribuzione approssimata \\(Q\\) invece che con la distribuzione vera \\(P\\).\nSe \\(P = Q\\) la divergenza è 0, perché non vi è alcuna perdita. Quanto più \\(Q\\) si discosta da \\(P\\), tanto più grande sarà la divergenza, segnalando un “costo informativo” maggiore.\n\n\n\n\n\n\nEsempio: Divergenza KL (1)\n\n\n\n\n\nSupponiamo che la variabile casuale \\(X\\) possa assumere tre valori: A, B e C.\nLa distribuzione vera (\\(P\\)) è:\n\n\nx\n\\(p(x)\\)\n\n\n\nA\n0.5\n\n\nB\n0.3\n\n\nC\n0.2\n\n\n\nIl modello approssimante (\\(Q\\)) è:\n\n\nx\n\\(q(x)\\)\n\n\n\nA\n0.4\n\n\nB\n0.4\n\n\nC\n0.2\n\n\n\nCalcoliamo la divergenza KL:\n\\[\n\\begin{aligned}\nD_{\\text{KL}}(P \\parallel Q) &= 0.5 \\log_2\\!\\left(\\frac{0.5}{0.4}\\right)\n+ 0.3 \\log_2\\!\\left(\\frac{0.3}{0.4}\\right)\n+ 0.2 \\log_2\\!\\left(\\frac{0.2}{0.2}\\right) \\\\[4pt]\n&= 0.5 \\log_2(1.25) + 0.3 \\log_2(0.75) + 0.2 \\log_2(1) \\\\[4pt]\n&\\approx 0.160 - 0.125 + 0 \\\\[4pt]\n&= 0.035 \\ \\text{bit}.\n\\end{aligned}\n\\]\nInterpretazione\n\nPer A, il modello \\(Q\\) sottostima la probabilità vera (0.4 invece di 0.5). Questo comporta un costo informativo positivo: il codice dovrà essere leggermente più lungo rispetto all’uso di \\(P\\).\nPer B, il modello \\(Q\\) sovrastima la probabilità vera (0.4 invece di 0.3). Qui il costo informativo è negativo, ma va pesato dal fatto che nella divergenza KL la somma è pesata secondo \\(P\\), e dunque conta di più la stima errata sugli eventi più probabili.\nPer C, il modello è perfetto (\\(p(x) = q(x)\\)) e il contributo alla divergenza è nullo.\n\nIl risultato complessivo, 0.035 bit per evento, è molto piccolo: significa che, in media, usando \\(Q\\) al posto di \\(P\\) spenderemmo appena 0.035 bit di informazione in più per descrivere ogni osservazione. Le due distribuzioni sono quindi molto simili, ma la divergenza KL rileva comunque la differenza residua.\n\n\n\n\n\n\n\n\n\nEsempio: Divergenza KL (2)\n\n\n\n\n\nSupponiamo che la variabile casuale \\(X\\) possa assumere tre valori: x = 1, 2, 3.\n\n\nDistribuzione vera (\\(P\\)): \\([0.1, \\ 0.6, \\ 0.3]\\)\n\n\nDistribuzione approssimata (\\(Q\\)): \\([0.2, \\ 0.5, \\ 0.3]\\)\n\n\nCalcoliamo la divergenza KL secondo la formula ?eq-kl-def:\n\n# Definizione delle distribuzioni\nP &lt;- c(0.1, 0.6, 0.3)  # distribuzione vera\nQ &lt;- c(0.2, 0.5, 0.3)  # distribuzione approssimata\n\n\n# Calcolo dei contributi per ciascun esito\ndf_kl_terms &lt;- kl_terms(P, Q)\nprint(df_kl_terms)\n#&gt;   x   p   q   term\n#&gt; 1 1 0.1 0.2 -0.100\n#&gt; 2 2 0.6 0.5  0.158\n#&gt; 3 3 0.3 0.3  0.000\n\n\n# Visualizzazione dei contributi\nggplot(df_kl_terms, aes(x = factor(x), y = term)) +\n  geom_col(fill = \"steelblue\") +\n  geom_hline(yintercept = 0, color = \"black\", linewidth = 0.3) +\n  labs(\n    x = \"Valori possibili di X\",\n    y = \"Contributo alla Divergenza KL\",\n    title = \"Contributo di ciascun esito alla Divergenza KL\"\n  )\n\n\n\n\n\n\n\nInfine, sommiamo i contributi per ottenere la divergenza totale:\n\nKL_total &lt;- sum(df_kl_terms$term)\ncat(sprintf(\"Divergenza KL da P a Q: %.4f bit\\n\", KL_total))\n#&gt; Divergenza KL da P a Q: 0.0578 bit\n\nInterpretazione\n\n\nEsito 1 (\\(p=0.1\\), \\(q=0.2\\)) – Il modello \\(Q\\) sovrastima un evento raro. Il contributo alla divergenza è negativo, ma l’impatto è ridotto perché l’evento è poco probabile nella realtà (\\(p\\) piccolo).\n\nEsito 2 (\\(p=0.6\\), \\(q=0.5\\)) – Il modello sottostima l’evento più frequente. Poiché \\(p\\) è alto, questa sottostima ha un peso maggiore nella media ponderata, generando il contributo positivo più grande.\n\nEsito 3 (\\(p=0.3\\), \\(q=0.3\\)) – Qui il modello è perfetto: \\(p(x) = q(x)\\), quindi il contributo alla divergenza è zero.\n\nIl valore complessivo di \\(D_{\\text{KL}}\\) è la somma di questi contributi: rappresenta la perdita media di efficienza (in bit per evento) quando si usa \\(Q\\) al posto di \\(P\\).\nIn questo caso, il risultato indica che usare \\(Q\\) comporta una leggera inefficienza: la codifica o le previsioni richiedono, in media, un po’ più informazione di quanto sarebbe necessario usando la distribuzione vera.\n\n\n\n\n42.2.2 Legame con l’entropia e l’entropia incrociata\nLa divergenza di Kullback–Leibler può essere riscritta come differenza tra entropia incrociata e entropia vera:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P),\n\\tag{42.3}\\]\ndove:\n\n\n\\(H(P)\\) è l’entropia della distribuzione vera \\(P\\) (incertezza media/lunghezza media del codice ottimale quando conosciamo la distribuzione corretta);\n\n\\(H(P, Q)\\) è l’entropia incrociata, cioè l’incertezza media se codifichiamo dati generati da \\(P\\) utilizzando un codice ottimizzato per \\(Q\\):\n\n\\[\nH(P, Q) = -\\sum_x p(x)\\log_2 q(x).\n\\tag{42.4}\\]\nIntuizione. Con questa forma, \\(D_{\\text{KL}}\\) è la sorpresa extra media (o costo informativo in bit per evento) che paghiamo quando usiamo il modello approssimato \\(Q\\) al posto della distribuzione vera \\(P\\). Poiché \\(H(P)\\) non dipende dal modello, minimizzare \\(D_{\\text{KL}}\\) equivale a minimizzare \\(H(P,Q)\\).\n\n\n\n\n\n\nPerché serve per ELPD e LOO\n\n\n\nCriteri predittivi come ELPD e LOO stimano, in media, la stessa quantità di cui vogliamo minimizzare il valore: l’entropia incrociata \\(H(P,Q)\\). Per questo, massimizzare ELPD (o ridurre la perdita di log-verosimiglianza predittiva) è un modo pratico per avvicinare \\(Q\\) a \\(P\\), ossia per ridurre indirettamente \\(D_{\\text{KL}}(P\\parallel Q)\\).\n\n\n\n\n\n\n\n\nEsempio: Entropia incrociata (1)\n\n\n\n\n\nUtilizziamo le funzioni definite sopra (entropy(), cross_entropy(), kl_divergence()) sullo stesso esempio discusso in precedenza:\n\n# Esempio: distribuzione vera P e modello Q\nP &lt;- c(0.1, 0.6, 0.3)\nQ &lt;- c(0.2, 0.5, 0.3)\n\nH_P   &lt;- entropy(P)           # H(P)\nH_PQ  &lt;- cross_entropy(P, Q)  # H(P,Q)\nDKL   &lt;- kl_divergence(P, Q)  # D_KL(P||Q)\n\ncat(sprintf(\"H(P)    = %.4f bit\\n\", H_P))\n#&gt; H(P)    = 1.2955 bit\ncat(sprintf(\"H(P,Q)  = %.4f bit\\n\", H_PQ))\n#&gt; H(P,Q)  = 1.3533 bit\ncat(sprintf(\"H(P,Q)-H(P) = %.4f bit (D_KL)\\n\", H_PQ - H_P))\n#&gt; H(P,Q)-H(P) = 0.0578 bit (D_KL)\ncat(sprintf(\"D_KL(P||Q)  = %.4f bit (controllo)\\n\", DKL))\n#&gt; D_KL(P||Q)  = 0.0578 bit (controllo)\n\nInterpretazione\n\n\n\\(H(P)\\) è il limite inferiore: la miglior compressione ottenibile conoscendo la verità (\\(P\\)).\n\n\n\\(H(P,Q)\\) è la compressione che otterremmo usando il modello (\\(Q\\)).\n\nLa loro differenza è esattamente \\(D_{\\text{KL}}(P\\parallel Q)\\): la quantità di informazione “sprecata” in media per evento usando \\(Q\\) al posto di \\(P\\).\n\n\n\n\n\n\n\n\n\n\n\nEsempio: Entropia incrociata (2)\n\n\n\n\n\nIn due esempi successivi rendiamo \\(Q\\) sempre più diverso da \\(P\\) e osserviamo come cambiano entropia incrociata e divergenza KL.\n\n# Distribuzione vera fissata\nP  &lt;- c(0.1, 0.6, 0.3)\nH_P &lt;- entropy(P)  # costante rispetto al modello\n\n# Due modelli: uno moderatamente errato (Q1), uno molto errato (Q2)\nQ1 &lt;- c(0.35, 0.30, 0.35)\nQ2 &lt;- c(0.60, 0.30, 0.10)\n\n# Calcolo di entropia incrociata e divergenza KL\nH_PQ1 &lt;- cross_entropy(P, Q1)\nH_PQ2 &lt;- cross_entropy(P, Q2)\n\nKL1 &lt;- kl_divergence(P, Q1)\nKL2 &lt;- kl_divergence(P, Q2)\n\ncat(sprintf(\"H(P)     = %.4f bit (fissa)\\n\", H_P))\n#&gt; H(P)     = 1.2955 bit (fissa)\ncat(sprintf(\"H(P,Q1)  = %.4f bit   -&gt; D_KL(P||Q1) = %.4f bit\\n\", H_PQ1, KL1))\n#&gt; H(P,Q1)  = 1.6480 bit   -&gt; D_KL(P||Q1) = 0.3525 bit\ncat(sprintf(\"H(P,Q2)  = %.4f bit   -&gt; D_KL(P||Q2) = %.4f bit\\n\", H_PQ2, KL2))\n#&gt; H(P,Q2)  = 2.1125 bit   -&gt; D_KL(P||Q2) = 0.8170 bit\n\nInterpretazione\nPoiché \\(H(P)\\) non cambia, quando \\(Q\\) si allontana da \\(P\\) cresce \\(H(P,Q)\\) e, di conseguenza, aumenta\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P) .\n\\]\n\nQ1: il modello redistribuisce massa probabilistica, sottostimando l’esito più probabile e sovrastimando gli altri. Gli errori sugli esiti che \\(P\\) considera frequenti pesano di più nella media, aumentando \\(H(P,Q1)\\) e quindi \\(D_{\\text{KL}}\\).\nQ2: l’errore è estremo: la probabilità più alta viene assegnata all’esito meno probabile secondo \\(P\\). I contributi positivi (sottostima degli esiti comuni) dominano, facendo crescere molto \\(D_{\\text{KL}}\\).\n\nQuesto esempio mostra che minimizzare \\(H(P,Q)\\) (e quindi \\(D_{\\text{KL}}\\)) significa allineare il più possibile le probabilità del modello con quelle “vere”, soprattutto per gli esiti a cui \\(P\\) assegna più massa.\n\n\n\n\n\n\n\n\n\nDimostrazione: dalla differenza di entropie alla formula della D-KL\n\n\n\n\n\nPartiamo dalla definizione come differenza tra entropia incrociata ed entropia vera:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P).\n\\]\nSostituendo: \\[\nH(P,Q) = -\\sum_x p(x) \\log_2 q(x), \\quad\nH(P)   = -\\sum_x p(x) \\log_2 p(x),\n\\]\nottieni:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\left[ - \\sum_x p(x) \\log_2 q(x) \\right]\n- \\left[ - \\sum_x p(x) \\log_2 p(x) \\right].\n\\]\nEliminando i segni negativi:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\sum_x p(x) \\log_2 p(x) - \\sum_x p(x) \\log_2 q(x).\n\\]\nRaccogliendo in un’unica somma:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\sum_x p(x) \\left[ \\log_2 p(x) - \\log_2 q(x) \\right].\n\\]\nApplicando la proprietà dei logaritmi:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\sum_x p(x) \\log_2 \\frac{p(x)}{q(x)}.\n\\]\nInterpretazione: questa è la forma esplicita più usata della \\(D_{\\text{KL}}\\). Mostra chiaramente che si tratta di una media ponderata secondo \\(P\\) della differenza di informazione tra \\(P\\) e \\(Q\\) per ciascun esito \\(x\\).\n\n\n\n\n42.2.3 Interpretazione della divergenza KL\nLa divergenza \\(D_{\\text{KL}}(P \\parallel Q)\\) misura l’inefficienza media che si introduce quando si usa la distribuzione \\(Q\\) per descrivere dati che in realtà seguono \\(P\\). In termini informativi, rappresenta il costo aggiuntivo di sorpresa: quanti bit in più, in media, servono per codificare gli eventi generati da \\(P\\) se utilizziamo un codice ottimizzato per \\(Q\\) invece che per \\(P\\).\nQuesta quantità:\n\nè sempre non negativa: il modello vero (\\(P\\)) non può mai essere peggiore, in media, del modello approssimato (\\(Q\\));\nè asimmetrica: \\(D_{\\text{KL}}(P \\parallel Q) \\neq D\\_{\\text{KL}}(Q \\parallel P)\\). L’ordine è importante: invertire \\(P\\) e \\(Q\\) cambia il significato della misura, perché cambia quale distribuzione stiamo trattando come “vera”.\n\nPer questo motivo, la divergenza KL non è una “distanza” in senso geometrico, ma una misura direzionale di perdita di informazione o di inefficienza di codifica.\n\n42.2.4 Proprietà fondamentali della divergenza KL\n\nNon-negatività: \\(D_{\\text{KL}}(P \\parallel Q) \\geq 0\\) per ogni coppia di distribuzioni \\(P\\) e \\(Q\\). Il valore minimo (0) si ottiene se e solo se \\(P = Q\\).\nAsimmetria: \\(D_{\\text{KL}}(P \\parallel Q) \\neq D\\_{\\text{KL}}(Q \\parallel P)\\) in generale. Non soddisfa quindi le proprietà di una distanza simmetrica.\n\nUnità di misura: dipende dalla base del logaritmo:\n\nbase 2 → misura in bit;\nbase \\(e\\) → misura in nat (unità naturale di informazione).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#uso-della-divergenza-d_textkl-nella-selezione-di-modelli",
    "href": "chapters/entropy/02_kl.html#uso-della-divergenza-d_textkl-nella-selezione-di-modelli",
    "title": "42  La divergenza di Kullback-Leibler",
    "section": "\n42.3 Uso della divergenza \\(D_{\\text{KL}}\\) nella selezione di modelli",
    "text": "42.3 Uso della divergenza \\(D_{\\text{KL}}\\) nella selezione di modelli\nIn teoria, la selezione del modello consiste nello scegliere il modello \\(Q\\) che minimizza la divergenza dalla distribuzione vera \\(P\\):\n\\[\n\\text{Modello ottimale} = \\arg\\min_Q D_{\\text{KL}}(P \\parallel Q).\n\\]\nIn altre parole, il modello ideale è quello che si avvicina di più a \\(P\\) e quindi riduce al minimo la perdita media di informazione quando lo usiamo per descrivere i dati.\nProblema: nella pratica, \\(P\\) è sconosciuta — non possiamo osservare direttamente la distribuzione vera che ha generato i dati. Di conseguenza, non possiamo calcolare \\(D_{\\text{KL}}\\) in modo esatto.\n\n42.3.1 Come procedere nella pratica\nAnche se \\(P\\) è ignota, possiamo comunque confrontare modelli in termini di divergenza KL sfruttando il legame con l’entropia incrociata \\(H(P,Q)\\). Infatti, ricordiamo che:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P,Q) - H(P).\n\\]\nL’entropia \\(H(P)\\) non dipende dal modello \\(Q\\): è una costante rispetto al confronto tra modelli. Se prendiamo la differenza di divergenza KL tra due modelli \\(Q_1\\) e \\(Q_2\\), questa costante si annulla:\n\\[\nD_{\\text{KL}}(P \\parallel Q_1) - D_{\\text{KL}}(P \\parallel Q_2)\n= H(P,Q_1) - H(P,Q_2).\n\\tag{42.5}\\]\nQuindi, per confrontare modelli non serve conoscere \\(H(P)\\): basta confrontare le loro entropie incrociate \\(H(P,Q)\\), che dipendono solo da \\(Q\\) e che possono essere stimate dai dati.\nNel prossimo capitolo vedremo due strumenti dell’approccio bayesiano che stimano proprio \\(H(P,Q)\\) (o, più precisamente, il suo opposto \\(-H(P,Q)\\)):\n\n\nLeave-One-Out Cross-Validation (LOO-CV) – valuta quanto bene il modello predice dati non usati nella stima;\n\nExpected Log Predictive Density (ELPD) – fornisce la stima della qualità predittiva media del modello.\n\nQuesti metodi permettono di confrontare modelli in termini di differenza di divergenza KL, avvicinandoci così alla scelta del modello che, tra quelli considerati, è più vicino alla distribuzione vera \\(P\\).\n\n\n\n\n\n\nEsempio psicologico\n\n\n\n\n\nImmaginiamo di voler prevedere il punteggio di ansia settimanale di uno studente.\n\n\nModello A: utilizza come predittore solo il punteggio di coping (capacità di fronteggiare lo stress).\n\n\nModello B: utilizza coping + supporto sociale.\n\nSupponiamo che, valutando le loro prestazioni predittive, entrambi i modelli ottengano buoni risultati, ma il Modello B presenti una divergenza KL leggermente inferiore rispetto al Modello A.\nInterpretazione:\n\nla divergenza KL più bassa del Modello B indica che, in media, le sue previsioni sono leggermente più vicine alla distribuzione “vera” dei dati (minore perdita di informazione);\ntuttavia, se la differenza è piccola, potremmo preferire il Modello A per la sua maggiore semplicità e interpretabilità, applicando il principio di parsimonia (o rasoio di Occam).\n\nQuesto esempio illustra che la selezione del modello non dipende solo dalla precisione predittiva, ma anche dal bilanciamento tra accuratezza e complessità.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#riflessioni-conclusive",
    "href": "chapters/entropy/02_kl.html#riflessioni-conclusive",
    "title": "42  La divergenza di Kullback-Leibler",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo approfondito un concetto fondamentale della teoria dell’informazione: la divergenza di Kullback–Leibler. Nata in origine per valutare l’efficienza dei codici di trasmissione, la D-KL è oggi uno strumento essenziale anche nella statistica moderna, perché misura in modo preciso quanto una distribuzione di probabilità approssimata \\(Q\\) (cioè un modello) si discosti dalla distribuzione vera \\(P\\) che genera i dati.\nAbbiamo visto che la D-KL può essere interpretata come:\n\n\nperdita media di informazione quando si usa \\(Q\\) invece di \\(P\\);\n\neccesso di sorpresa o inefficienza di codifica introdotta da un modello imperfetto;\ndifferenza tra entropia incrociata e entropia vera, il che rende possibile stimarla indirettamente.\n\nQuesto legame con l’entropia incrociata è cruciale: sebbene \\(P\\) non sia nota e la D-KL non possa essere calcolata in valore assoluto, possiamo confrontare modelli stimando le differenze di D-KL, perché la componente costante \\(H(P)\\) si annulla nel confronto.\nNel prossimo capitolo ci concentreremo proprio su come effettuare questi confronti in pratica. Vedremo come strumenti come la Leave-One-Out Cross-Validation (LOO-CV) e l’Expected Log Predictive Density (ELPD) permettano di stimare la capacità predittiva dei modelli e di identificare quello che, tra le alternative considerate, è il più vicino alla distribuzione vera dei dati.\n\n\n\n\n\n\nSintesi finale\n\n\n\n\nLa divergenza KL quantifica la perdita media di informazione usando \\(Q\\) al posto di \\(P\\).\nSi può scrivere come \\(\\sum_x p(x) \\log \\frac{p(x)}{q(x)}\\) o come \\(H(P,Q) - H(P)\\).\nÈ uno strumento chiave per valutare quanto bene un modello rappresenta la realtà.\nIn pratica, può essere confrontata tra modelli stimando \\(H(P,Q)\\) con tecniche come LOO-CV ed ELPD.\n\n\n\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nCosideriamo due distribuzioni di probabilità discrete, \\(p\\) e \\(q\\):\n\np &lt;- c(0.2, 0.5, 0.3)\nq &lt;- c(0.1, 0.2, 0.7)\nSi calcoli l’entropia di \\(p\\), l’entropia incrociata tra \\(p\\) e \\(q\\), la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).\nSi consideri q = c(0.2, 0.55, 0.25) e si calcoli di nuovo a divergenza di Kullback-Leibler da \\(p\\) a \\(q\\). Si confronti con il risultato precedente e si interpreti.\n\nSia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\). Sia \\(q_1\\) una approssimazione a \\(p\\): q1 = c(0.46, 0.42, 0.10, 0.01, 0.01). Sia \\(q_2\\) una distribuzione uniforme: q2 &lt;- rep(0.2, 5). Si calcoli la divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) e da \\(q_2\\) da \\(p\\) e si interpretino i risultati.\n\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#bibliografia",
    "href": "chapters/entropy/02_kl.html#bibliografia",
    "title": "42  La divergenza di Kullback-Leibler",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKullback, S., & Leibler, R. A. (1951). On information and sufficiency. The Annals of Mathematical Statistics, 22(1), 79–86.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html",
    "href": "chapters/entropy/03_model_comparison.html",
    "title": "43  Valutare i modelli bayesiani",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo visto due concetti fondamentali: l’entropia, che misura l’incertezza insita in una distribuzione, e la divergenza di Kullback–Leibler (\\(D_{\\text{KL}}\\)), che quantifica la distanza tra due distribuzioni di probabilità. Ora possiamo fare un passo ulteriore: usare queste idee per valutare e confrontare modelli statistici nel contesto bayesiano.\nIl punto di partenza è una domanda cruciale: quanto bene il modello riesce a prevedere nuovi dati? Un buon modello non deve solo adattarsi ai dati osservati, ma deve anche saper generalizzare a situazioni future. Questa distinzione – adattamento vs. generalizzazione – è il cuore della valutazione predittiva.\nImmaginiamo, ad esempio, di sviluppare un test psicologico per stimare l’ansia degli studenti prima di un esame. Non basta sapere che il modello descrive bene il campione usato per costruirlo: vogliamo essere ragionevolmente sicuri che le stesse previsioni funzionino anche per studenti che non hanno partecipato allo studio. In psicologia, scegliere tra due modelli è simile a decidere quale test usare: in entrambi i casi si cerca lo strumento che fornisce previsioni più affidabili.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#introduzione",
    "href": "chapters/entropy/03_model_comparison.html#introduzione",
    "title": "43  Valutare i modelli bayesiani",
    "section": "",
    "text": "Panoramica del capitolo\nPer rispondere alla domanda fondamentale sulla qualità predittiva, seguiremo un percorso logico che ci condurrà dagli strumenti teorici ai metodi pratici:\n\n\nPrima costruiremo la base teorica: vedremo come la distribuzione predittiva posteriore incorpora l’incertezza sui parametri nelle nostre previsioni\n\nPoi definiremo le misure di accuratezza: il log-score per valutare la bontà delle previsioni punto per punto\n\nDistingueremo tra valutazione in-sample e out-of-sample: LPPD (sui dati osservati) vs. ELPD (capacità di generalizzazione)\n\nCollegheremo tutto alla divergenza KL: per capire perché massimizzare l’ELPD equivale a trovare il modello più vicino alla realtà\n\nImplementeremo metodi pratici: LOO-CV per stimare l’ELPD senza conoscere la vera distribuzione dei dati\n\nConfronteremo con altri criteri: AIC, BIC, WAIC e i loro ambiti di applicazione\n\nL’obiettivo è fornire strumenti pratici e un quadro concettuale chiaro per guidare la scelta del modello più adatto al problema in esame.\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nPer comprendere appieno questo capitolo è utile leggere il capitolo 7 Ulysses’ Compass di Statistical Rethinking (McElreath (2020)).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nlibrary(gt)\nlibrary(conflicted)\nlibrary(brms)\nlibrary(loo)\nconflicts_prefer(rstan::loo)",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#il-punto-di-partenza-dalle-previsioni-deterministiche-a-quelle-probabilistiche",
    "href": "chapters/entropy/03_model_comparison.html#il-punto-di-partenza-dalle-previsioni-deterministiche-a-quelle-probabilistiche",
    "title": "43  Valutare i modelli bayesiani",
    "section": "\n43.1 Il punto di partenza: dalle previsioni deterministiche a quelle probabilistiche",
    "text": "43.1 Il punto di partenza: dalle previsioni deterministiche a quelle probabilistiche\nPrima di addentrarci nei dettagli tecnici, facciamo un passo indietro per capire perché la valutazione predittiva bayesiana è diversa da quella frequentista classica.\nNell’approccio classico, una volta stimati i parametri (ad esempio con la massima verosimiglianza), li trattiamo come “veri” e fissi. Se \\(\\hat{\\theta}\\) è la nostra stima, la previsione per un nuovo dato \\(\\tilde{y}\\) è semplicemente:\n\\[\np(\\tilde{y} \\mid \\hat{\\theta}).\n\\] Questo approccio ignora completamente l’incertezza sulla stima dei parametri.\nNell’approccio bayesiano, invece, riconosciamo che i parametri sono incerti. Anche dopo aver osservato i dati, la nostra conoscenza di \\(\\theta\\) è descritta da un’intera distribuzione posteriore \\(p(\\theta \\mid y)\\), non da un singolo valore. Le previsioni devono quindi riflettere questa incertezza.\n\n\n\n\n\n\nAnalogia didattica\n\n\n\nImmaginiamo di dover prevedere il tempo domani. L’approccio “classico” è come consultare un solo meteorologo e fidarsi completamente della sua previsione. L’approccio bayesiano è come consultare tutti i meteorologi disponibili, pesare le loro opinioni in base alla loro affidabilità passata, e costruire una previsione che tenga conto di tutti i punti di vista plausibili.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#distribuzione-predittiva-posteriore-il-cuore-delle-previsioni-bayesiane",
    "href": "chapters/entropy/03_model_comparison.html#distribuzione-predittiva-posteriore-il-cuore-delle-previsioni-bayesiane",
    "title": "43  Valutare i modelli bayesiani",
    "section": "\n43.2 Distribuzione predittiva posteriore: il cuore delle previsioni bayesiane",
    "text": "43.2 Distribuzione predittiva posteriore: il cuore delle previsioni bayesiane\nNel capitolo sul modello beta–binomiale l’abbiamo già incontrata: è lo strumento che, nell’approccio bayesiano, consente di prevedere nuovi dati incorporando sia la struttura del modello sia l’incertezza sui parametri. La logica è elegante nella sua semplicità: dopo aver osservato i dati \\(y\\), non otteniamo un singolo “miglior” valore dei parametri, ma una distribuzione posteriore \\(p(\\theta \\mid y)\\) che quantifica i valori plausibili di \\(\\theta\\) e la nostra incertezza.\n\nEsempio concreto: Uno psicologo che stima il livello medio di ansia in una popolazione, invece di affermare “la media è 4.7”, dirà: “il valore più plausibile è 4.7, ma è ragionevole che sia tra 4.2 e 5.1”, riflettendo la variabilità della distribuzione a posteriori.\n\n\n43.2.1 La formula fondamentale\nPer prevedere un nuovo dato \\(\\tilde{y}\\), non fissiamo \\(\\theta\\). Mediamo invece tutte le previsioni condizionate \\(p(\\tilde{y} \\mid \\theta)\\) pesandole con la densità posteriore \\(p(\\theta\\mid y)\\):\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta\n\\tag{43.1}\\] Questa è la distribuzione predittiva posteriore, e rappresenta la nostra migliore previsione per dati futuri dato quello che abbiamo osservato.\n\n43.2.2 Decomposizione dell’integrale: cosa significa realmente\nL’Equazione 43.1 può sembrare astratta, ma ha un’interpretazione intuitiva molto chiara:\n\n\n\\(p(\\tilde{y} \\mid \\theta)\\): se conoscessimo il vero valore di \\(\\theta\\), questa sarebbe la nostra previsione per \\(\\tilde{y}\\);\n\n\\(p(\\theta \\mid y)\\): questa è la nostra incertezza su quale sia il vero valore di \\(\\theta\\);\n\nL’integrale: combina le previsioni per tutti i possibili valori di \\(\\theta\\), pesandole secondo quanto crediamo che ciascun valore sia plausibile.\n\n\n\n\n\n\n\nIntuizione dettagliata\n\n\n\n\n\nSe conoscessimo il valore vero di \\(\\theta\\), potremmo prevedere i dati futuri usando la distribuzione predittiva condizionata:\n\\[\np(\\tilde y \\mid \\theta).\n\\] Il problema è che \\(\\theta\\) non lo conosciamo: abbiamo soltanto la distribuzione a posteriori \\(p(\\theta\\mid y)\\). Perciò, la distribuzione predittiva posteriore si costruisce combinando le previsioni condizionate per ogni valore possibile di \\(\\theta\\), pesandole con quanto ciascun valore è plausibile a posteriori:\n\\[\np(\\tilde y\\mid y) = \\int p(\\tilde y\\mid \\theta)\\,p(\\theta\\mid y)\\,d\\theta.\n\\] Per fare un esempio concreto, consideriamo il caso binomiale. Supponiamo che i dati futuri siano generati da una Binomiale con \\(m\\) prove e parametro \\(\\theta\\):\n\\[\np(\\tilde y = x \\mid \\theta) = \\binom{m}{x}\\,\\theta^x(1-\\theta)^{m-x}.\n\\] La distribuzione predittiva posteriore diventa:\n\\[\np(\\tilde y = x \\mid y) = \\int \\binom{m}{x}\\,\\theta^x(1-\\theta)^{m-x}\\,p(\\theta\\mid y)\\,d\\theta.\n\\] In alcuni casi particolari (per esempio con prior Beta e dati binomiali) questo integrale si può risolvere analiticamente, ottenendo la Beta–Binomiale. Ma in generale non c’è una formula chiusa e serve un’approssimazione numerica.\nApprossimazione numerica con il metodo su griglia: L’idea è semplice: sostituire l’integrale con una somma pesata su una griglia di valori possibili di \\(\\theta\\). I passaggi algoritmici sono i seguenti.\n\n\nDefinire una griglia di valori di \\(\\theta\\), ad esempio 1000 punti equispaziati tra 0 e 1:\n\\[\n\\theta_1, \\theta_2, \\dots, \\theta_J.\n\\]\n\n\nCalcolare la posteriore su ciascun punto della griglia. Nel caso Beta–Binomiale:\n\\[\np(\\theta_j \\mid y) \\propto \\theta_j^{\\,k+a-1}(1-\\theta_j)^{n-k+b-1}.\n\\]\nPoi normalizzare per avere somme che valgono 1:\n\\[\nw_j = \\frac{p(\\theta_j \\mid y)}{\\sum_{\\ell=1}^J p(\\theta_\\ell \\mid y)}.\n\\]\n\n\nCombinare le predizioni condizionate. Per ogni valore futuro \\(x=0,\\dots,m\\), si calcola:\n\\[\np(\\tilde y = x \\mid y) \\approx \\sum_{j=1}^J w_j \\, \\binom{m}{x}\\theta_j^x(1-\\theta_j)^{m-x}.\n\\]\n\n\nInterpretazione: la pmf ottenuta è la nostra approssimazione numerica della distribuzione predittiva posteriore. Da essa possiamo:\n\ncalcolare probabilità,\ngenerare campioni di \\(\\tilde y\\),\nconfrontare la predizione con i dati osservati.\n\n\n\nDa ricordare:\n\nLa predittiva non si ottiene facendo la media dei valori di \\(\\tilde y\\), ma costruendo un’intera distribuzione di probabilità.\nIl metodo su griglia è il più semplice: discretizza \\(\\theta\\), pesa ogni valore con la sua plausibilità a posteriori, e combina le predizioni condizionate.\nIn problemi più complessi, la stessa logica viene implementata tramite MCMC: invece di usare una griglia fissa, si usano campioni \\(\\theta^{(s)}\\) dalla posteriore.\n\n\n\n\n\n\n\n\n\n\nEsempio numerico completo\n\n\n\n\n\nEsaminiamo ora uno script in R che implementa passo per passo l’approssimazione della distribuzione predittiva posteriore binomiale con il metodo su griglia.\n\n# ESEMPIO DIDATTICO: predittiva posteriore per Binomiale con metodo su griglia\n# Dati e prior\nk &lt;- 10     # successi osservati\nn &lt;- 50     # prove osservate\na &lt;- 1      # prior Beta(a, b)\nb &lt;- 1\nm &lt;- 10     # numero di prove future per la predizione (scelta didattica)\nJ &lt;- 2000   # numero di punti griglia su theta in [0,1]\n\n# -------------------------------------------------------------\n# PASSAGGIO 1: Griglia su theta\n# -------------------------------------------------------------\n\ntheta &lt;- seq(0, 1, length.out = J)\n\n# -------------------------------------------------------------\n# PASSAGGIO 2: Densità posteriore non normalizzata su ogni punto di griglia\n# -------------------------------------------------------------\n\n# Posteriore ~ Beta(a + k, b + n - k)  -&gt; densità proporzionale a theta^(a+k-1) (1-theta)^(b+n-k-1)\npost_unnorm &lt;- theta^(a + k - 1) * (1 - theta)^(b + n - k - 1)\n\n# Normalizzazione per ottenere pesi che sommano a 1\nw &lt;- post_unnorm / sum(post_unnorm)\n\n# -------------------------------------------------------------\n# PASSAGGIO 3: combinare le predittive condizionate p(tilde y | theta)\n# -------------------------------------------------------------\n# Obiettivo: costruire la pmf predittiva p(tilde y = x | y) \n# per ogni x = 0,...,m come media pesata (sulla griglia di θ) \n# delle pmf condizionate binomiali.\n\n# 1) Definiamo i valori futuri possibili di tilde y\nx_vals &lt;- 0:m\n\n# 2) Inizializziamo una matrice vuota: \n#    - J righe (una per ciascun θ_j della griglia)\n#    - (m+1) colonne (una per ogni valore possibile di x)\npx_given_theta &lt;- matrix(NA_real_, nrow = J, ncol = m + 1)\n\n# 3) Riempiamo la matrice: per ogni θ_j (riga j) e per ogni x (colonna i)\n#    calcoliamo P(tilde y = x | θ_j) = Binomiale(x | m, θ_j)\nfor (j in 1:J) {\n  for (i in 1:(m + 1)) {\n    x &lt;- x_vals[i]\n    px_given_theta[j, i] &lt;- dbinom(x, size = m, prob = theta[j])\n  }\n}\n\n# 4) Combinazione pesata:\n#    p(tilde y = x | y) ≈ somma_j w_j * P(tilde y = x | θ_j).\n#    Per ciascun valore di x (colonna i), facciamo la somma pesata.\npred_pmf &lt;- numeric(m + 1)\nfor (i in 1:(m + 1)) {\n  pred_pmf[i] &lt;- sum(w * px_given_theta[, i])\n}\n\n# Nota didattica:\n# - Ogni colonna della matrice px_given_theta contiene le probabilità condizionate \n#   P(tilde y = x_i | θ_j) per tutti i valori di griglia θ_j.\n# - Moltiplicando riga per riga queste probabilità per i pesi posteriori w_j \n#   e sommando, otteniamo la probabilità predittiva p(tilde y = x_i | y).\n# - In questo modo l'integrale viene approssimato da una somma pesata.\n\n# -------------------------------------------------------------\n# PASSAGGIO 4: Risultato: una pmf su {0,1,...,m}\n# -------------------------------------------------------------\n\npred_df &lt;- data.frame(x = x_vals, p = pred_pmf)\nprint(pred_df)\n#&gt;     x          p\n#&gt; 1   0 0.11391218\n#&gt; 2   1 0.25060680\n#&gt; 3   2 0.27617892\n#&gt; 4   3 0.19946255\n#&gt; 5   4 0.10397516\n#&gt; 6   5 0.04068593\n#&gt; 7   6 0.01205509\n#&gt; 8   7 0.00266151\n#&gt; 9   8 0.00041780\n#&gt; 10  9 0.00004200\n#&gt; 11 10 0.00000205\n\n\nsum(pred_df$p)  # dovrebbe essere ~1\n#&gt; [1] 1\n\n\n# (Opzionale) campionamento dalla predittiva posteriore approssimata\n# Estrae N valori da {0,...,m} con le probabilità 'p'\nset.seed(123)\nN &lt;- 5000\ntilde_y_samples &lt;- sample(pred_df$x, size = N, replace = TRUE, prob = pred_df$p)\n\n# Controllo: istogramma delle simulazioni vs pmf teorica approssimata\nggplot() +\n  geom_histogram(\n    data = data.frame(x = tilde_y_samples), aes(x = x, y = after_stat(density)),\n    binwidth = 1, breaks = seq(-0.5, m + 0.5, by = 1), fill = \"skyblue\", \n    color = \"black\") +\n  geom_point(data = pred_df, aes(x = x, y = p), pch = 19, cex = 3) + \n  geom_line(data = pred_df, aes(x = x, y = p), lwd = 1.5) + \n  ylim(0, max(pred_df$p) * 1.1) +\n  labs(\n    title = \"Posterior Predictive (grid) – m=10\",\n    x = expression(tilde(y)),\n    y = \"Density\")\n\n\n\n\n\n\n\n\nNota: il vettore pred_df$p è la pmf della predittiva posteriore approssimata; da qui si leggono probabilità, si calcolano quantità riassuntive e si può estrarre \\(\\tilde y\\).\n\nVerifica quando esiste la formula chiusa: Quando prior e likelihood sono coniugate (Beta + Binomiale), la predittiva è Beta–Binomiale. Possiamo usarla solo come verifica didattica:\n\n# Confronto con Beta-Binomiale (se applicabile)\na_post &lt;- a + k\nb_post &lt;- b + n - k\n\n# pmf beta-binomial (con funzione base: dbetabinom in VGAM, altrimenti la implementiamo)\ndbetabinom &lt;- function(x, m, a, b) {\n  # Beta-Binomiale: choose(m, x) * Beta(x+a, m-x+b) / Beta(a, b)\n  choose(m, x) * beta(x + a, m - x + b) / beta(a, b)\n}\n\nbb_pmf &lt;- sapply(0:m, function(x) dbetabinom(x, m, a_post, b_post))\ncbind(grid = pred_df$p, beta_binom = bb_pmf)[1:6, ]  # prime 6 righe a confronto\n#&gt;        grid beta_binom\n#&gt; [1,] 0.1139     0.1139\n#&gt; [2,] 0.2506     0.2506\n#&gt; [3,] 0.2762     0.2762\n#&gt; [4,] 0.1995     0.1995\n#&gt; [5,] 0.1040     0.1040\n#&gt; [6,] 0.0407     0.0407\n\n\nmax(abs(pred_df$p - bb_pmf))   # lo scarto massimo (dovrebbe essere ~0 con J grande)\n#&gt; [1] 1.68e-15\n\n\n\n\n\n43.2.3 Notazione e terminologia\nNotazione: Useremo talvolta la forma compatta \\(p(\\cdot \\mid y)\\) per indicare la predittiva posteriore del modello. Quando ci servirà evidenziare la previsione marginale per una singola osservazione \\(y_i\\), scriveremo:\n\\[\np(y_i \\mid y) = \\int p(y_i \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta,\n\\] cioè la verosimiglianza \\(p(y_i\\mid\\theta)\\) integrata rispetto alla posteriore \\(p(\\theta\\mid y)\\).\nIdea chiave: La predittiva posteriore propaga l’incertezza sui parametri alle previsioni. È questo passaggio a rendere le valutazioni predittive coerenti con il principio bayesiano, e quindi utilizzabili nel confronto tra modelli e nella stima di quantità legate alla “distanza” dal generatore dei dati.\n\n\n\n\n\n\nMappa concettuale\n\n\n\n\n\n\n\n\n\n\nQuantità\nSignificato\nUso principale\n\n\n\n\\(p(y_i \\mid \\theta)\\)\nVerosimiglianza\nCalcolo predittivo\n\n\n\\(p(\\theta \\mid y)\\)\nDistribuzione posteriore\nPonderazione\n\n\n\\(p(y_i \\mid y)\\)\nPredizione bayesiana media\nLog-score, LPPD\n\n\n\\(p(y_i \\mid y_{-i})\\)\nPredizione LOO (leave-one-out)\nELPD\n\n\n\\(p(\\tilde{y} \\mid y)\\)\nDistribuzione predittiva complessiva\nDivergenza KL, confronto modelli",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#il-problema-fondamentale-della-valutazione-predittiva",
    "href": "chapters/entropy/03_model_comparison.html#il-problema-fondamentale-della-valutazione-predittiva",
    "title": "43  Valutare i modelli bayesiani",
    "section": "\n43.3 Il problema fondamentale della valutazione predittiva",
    "text": "43.3 Il problema fondamentale della valutazione predittiva\nOra che sappiamo come costruire previsioni bayesiane, affrontiamo la domanda centrale: come valutiamo la qualità di queste previsioni?\n\n43.3.1 Il dilemma teorico\nQuando costruiamo un modello, vogliamo sapere quanto bene riesce a predire dati futuri. In altre parole: se ripetessimo l’esperimento o raccogliessimo nuovi dati, quanto sarebbero vicine le predizioni del modello a quei dati?\nPer formalizzare questa idea, distinguiamo tra due distribuzioni:\n\n\nla distribuzione vera dei dati futuri \\(p(\\tilde{y})\\), che purtroppo non conosciamo,\n\nla distribuzione predittiva del modello \\(p(\\tilde{y} \\mid y)\\), cioè le predizioni basate sui dati osservati \\(y\\).\n\nL’obiettivo è misurare quanto \\(p(\\tilde{y} \\mid y)\\) si avvicina a \\(p(\\tilde{y})\\).\n\n43.3.2 Una misura di distanza: la divergenza di Kullback–Leibler\nLa divergenza di Kullback–Leibler (KL) fornisce una misura di questa distanza:\n\\[\nD_{\\text{KL}}(p \\parallel q) = \\mathbb{E}_{p} \\left[ \\log \\frac{p(\\tilde{y})}{q(\\tilde{y} \\mid y)} \\right].\n\\tag{43.2}\\] Interpretazione intuitiva:\n\nse \\(q\\) (il nostro modello) assegna probabilità alte agli stessi eventi che sono probabili in \\(p\\) (la realtà), la distanza sarà piccola,\nse invece \\(q\\) “sbaglia bersaglio”, assegnando probabilità alte a eventi che in realtà sono rari, la distanza sarà grande.\n\n\n\n\n\n\n\nIdea chiave. La KL divergence misura quanta informazione perdiamo se usiamo le predizioni del modello \\(q\\) al posto della distribuzione vera \\(p\\).\n\n\n\n\n43.3.3 Un ostacolo pratico insormontabile\nIl problema è che \\(p(\\tilde{y})\\) non lo conosciamo mai: non abbiamo accesso alla “vera” distribuzione dei dati futuri. Questa è la sfida fondamentale della validazione predittiva: come possiamo valutare la qualità delle nostre previsioni senza conoscere la verità?\nPer questo dobbiamo ricorrere a strategie di approssimazione, come la validazione incrociata e criteri predittivi come ELPD, che vedremo nelle prossime sezioni.\n\n43.3.3.1 Mini-esempio intuitivo\nImmagina una moneta truccata che dà testa il 70% delle volte.\nVogliamo confrontare due modelli:\n\n\nModello A: ipotizza una moneta equa (\\(p = 0.5\\)),\n\nModello B: ipotizza una probabilità leggermente sbilanciata (\\(p = 0.65\\)).\n\nSe sapessimo che la probabilità “vera” è \\(p = 0.7\\), sarebbe chiaro che il Modello B è più vicino alla realtà. La divergenza di Kullback–Leibler serve proprio a quantificare quanta informazione perdiamo quando ci affidiamo a un modello meno accurato (come A) invece che a uno più vicino alla verità (come B).\nIl punto cruciale è che nella pratica non conosciamo mai la probabilità vera della moneta. Abbiamo soltanto i dati osservati, cioè gli esiti dei lanci. Per decidere quale modello predice meglio dobbiamo quindi basarci sui dati disponibili: è qui che entrano in gioco i metodi di confronto predittivo che studieremo.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#sec-logscore",
    "href": "chapters/entropy/03_model_comparison.html#sec-logscore",
    "title": "43  Valutare i modelli bayesiani",
    "section": "\n43.4 Il log-score: misurare l’accuratezza predittiva punto per punto",
    "text": "43.4 Il log-score: misurare l’accuratezza predittiva punto per punto\nAbbiamo definito la distribuzione predittiva posteriore e il problema teorico della valutazione. Ora introduciamo il primo strumento pratico: il log-score.\n\n43.4.1 La domanda di base\nPer ogni osservazione nei nostri dati, vogliamo sapere: quanto il nostro modello considerava plausibile questo specifico risultato? Il log-score risponde proprio a questa domanda.\n\n43.4.2 Definizione formale\nIl log-score per un’osservazione \\(y_i\\) è semplicemente il logaritmo della probabilità che il modello assegnava a quell’osservazione:\n\\[\n\\text{Log-score}(y_i) = \\log p(y_i \\mid y) ,\n\\tag{43.3}\\] dove \\(p(y_i \\mid y)\\) è la distribuzione predittiva posteriore che abbiamo appena imparato a calcolare:\n\\[\np(y_i \\mid y) = \\int p(y_i \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta .\n\\]\n\n43.4.3 Interpretazione: “scommettere” sui dati\nIl log-score può essere interpretato come quanto il modello avrebbe “scommesso” su quel particolare risultato:\n\n\nse il modello assegna alta probabilità* a \\(y_i\\)*: \\(p(y_i \\mid y) \\approx 1\\), quindi \\(\\log p(y_i \\mid y) \\approx 0\\) (buono);\n\nse il modello assegna bassa probabilità* a \\(y_i\\)*: \\(p(y_i \\mid y) \\approx 0\\), quindi \\(\\log p(y_i \\mid y) \\ll 0\\) (molto negativo, scarso).\n\n\n\n\n\n\n\nPerché il logaritmo?\nIl logaritmo trasforma prodotti di probabilità in somme. Così possiamo sommare contributi punto per punto dei dati invece di moltiplicarli; inoltre stabilizza i numeri molto piccoli tipici delle verosimiglianze.\n\n\n\n\n43.4.4 Dal singolo dato al punteggio totale\nPer avere una visione complessiva della performance del modello, sommiamo i log-score su tutte le osservazioni:\n\\[\nS = \\sum_{i=1}^n \\log p(y_i \\mid y) .\n\\tag{43.4}\\] Più \\(S\\) è alto (meno negativo), più il modello “scommette” bene sui dati osservati (in-sample).\n\n43.4.5 Due filosofie a confronto: parametri fissi vs. incerti\nIl calcolo del log-score può seguire due approcci concettualmente diversi, che riflettono due filosofie statistiche diverse.\n\n43.4.5.1 Approccio classico: parametri fissi\nNell’impostazione frequentista classica, usiamo una stima puntuale dei parametri (ad es. Massima Verosimiglianza o MAP) e ignoriamo l’incertezza:\n\\[\n\\text{Log-score classico} = \\log p(y_i \\mid \\hat{\\theta}).\n\\]\n\n43.4.5.2 Approccio bayesiano: gestione dell’incertezza sui parametri\nNell’approccio bayesiano non fissiamo i parametri a un singolo valore stimato, ma li trattiamo come incerti. Questo significa che, invece di calcolare la verosimiglianza con un $$, “mescoliamo” tutte le verosimiglianze possibili, pesandole in base alla loro plausibilità a posteriori:\n\\[\n\\begin{align}\n\\text{Log-score bayesiano} &= \\log p(y_i \\mid y) \\\\\n&= \\log \\int p(y_i \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta .\n\\end{align}\n\\tag{43.5}\\]\nIn altre parole, la probabilità predittiva di \\(y_i\\) non dipende da un solo \\(\\theta\\), ma dalla media delle predizioni condizionate su tutti i valori plausibili dei parametri.\n\n\n\n\n\n\nDifferenza chiave\n- L’approccio frequentista chiede: “Quanto sono plausibili i dati se i parametri valgono esattamente \\(\\hat{\\theta}\\)?”\n- L’approccio bayesiano chiede: “Quanto sono plausibili i dati, in media, considerando tutti i valori di \\(\\theta\\) compatibili con i dati osservati?”\nLa seconda prospettiva è più onesta perché riconosce l’incertezza sui parametri.\n\n\n\n\n43.4.6 Implementazione pratica con il metodo MCMC\nL’integrale nell’nell’Equazione 43.5 raramente ha una soluzione analitica (cioè non si può calcolare con una formula esatta). Possiamo però stimarlo in modo pratico ed efficiente utilizzando i campioni generati da un algoritmo MCMC (Markov Chain Monte Carlo).\nSupponiamo di avere una serie di campioni di parametri, \\(\\theta^{(1)},\\dots,\\theta^{(S)}\\), estratti dalla distribuzione a posteriori \\(p(\\theta\\mid y)\\). Il procedimento per approssimare la probabilità predittiva si articola in due semplici passi:\n\n43.4.6.1 Passo 1: calcolare la verosimiglianza per ogni campione\nPer ogni set di parametri \\(\\theta^{(s)}\\) che abbiamo campionato, calcoliamo la probabilità (verosimiglianza) di osservare il dato \\(y_i\\) sotto quei parametri:\n\\[\np\\bigl(y\\_i \\mid \\theta^{(s)}\\bigr).\n\\]\nFare questo per tutti i campioni \\(S\\) ci fornisce un insieme di valori:\n\\[\n\\bigl\\{\\, p(y\\_i \\mid \\theta^{(1)}),\\; p(y\\_i \\mid \\theta^{(2)}),\\; \\dots,\\; p(y\\_i \\mid \\theta^{(S)}) \\,\\bigr\\}\n\\] Questa collezione rappresenta come la plausibilità del dato \\(y_i\\) cambi al variare dei parametri, ponderata per la loro probabilità a posteriori.\n\n43.4.6.2 Passo 2: calcolare la media dei valori ottenuti\nLa probabilità predittiva per \\(y_i\\) (che tiene conto di tutta l’incertezza sui parametri) è approssimata semplicemente calcolando la media aritmetica dell’insieme di valori ottenuti nel passo precedente:\n\\[\np(y_i \\mid y) \\;\\approx\\; \\frac{1}{S}\\sum_{s=1}^S p\\bigl(y_i \\mid \\theta^{(s)}\\bigr).\n\\tag{43.6}\\]\nIl risultato è un singolo valore numerico (uno scalare) che sintetizza in una previsione probabilistica tutto ciò che abbiamo appreso sull’incertezza dei parametri del modello.\n\n43.4.7 La LPPD: una misura bayesiana di bontà della previsione\nPer valutare la capacità predittiva dell’intero modello su tutti i dati, ripetiamo il procedimento per ogni osservazione \\(y_i\\) e procediamo così:\n\nper ogni osservazione \\(y_i\\), calcoliamo la sua probabilità predittiva media \\(p(y_i \\mid y)\\);\nprendiamo il logaritmo naturale di questa probabilità. (Usiamo il logaritmo per motivi computazionali e perché trasforma prodotti in somme);\nsommiamo i logaritmi di tutte le \\(n\\) osservazioni.\n\nIl risultato di questo processo è la Log Pointwise Predictive Density (LPPD):\n\\[\n\\text{LPPD} = \\sum_{i=1}^n \\log \\left[ \\frac{1}{S} \\sum_{s=1}^S p\\bigl(y_i \\mid \\theta^{(s)}\\bigr) \\right].\n\\tag{43.7}\\]\nConfronto e Sintesi:\n\nIl log-score classico (usato nella statistica frequentista) valuta la previsione utilizzando un unico valore stimato dei parametri (ad esempio, la stima di massima verosimiglianza \\(\\hat{\\theta}\\)). Questo ignora completamente l’incertezza esistente sulla stima dei parametri.\nLa LPPD bayesiana compie la stessa operazione fondamentale, ma in modo più robusto: invece di usare un singolo valore dei parametri, media le previsioni su tutte le migliaia di valori plausibili dei parametri campionati dalla distribuzione a posteriori. In questo modo, la misura di bontà predittiva incorpora in modo naturale tutta l’incertezza del modello.\n\n43.4.8 Il problema nascosto: overfitting in-sample\nLa LPPD è calcolata sugli stessi dati usati per stimare il modello: modelli molto flessibili possono “scommettere bene” anche sul rumore, gonfiando la LPPD in-sample.\nAnalogia: È come valutare uno studente facendogli ripetere gli stessi esercizi che ha già risolto durante lo studio. Otterrà un punteggio alto, ma non sappiamo se sarebbe altrettanto bravo con problemi nuovi.\nPer valutare la capacità di generalizzazione, serve una stima out-of-sample. Nelle prossime sezioni introdurremo la validazione incrociata leave-one-out (LOO-CV) e l’ELPD (Expected Log Pointwise Predictive Density), che forniscono una versione “fuori campione” della LPPD per il confronto predittivo tra modelli.\n\n\n\n\n\n\nEsempio pratico del calcolo LPPD\n\n\n\n\n\nConsideriamo un singolo dato \\(y_i = 3\\) successi su \\(n=5\\) tentativi (Binomiale). Abbiamo tre valori plausibili per \\(\\theta\\) dalla posterior, con pesi didattici \\(w^{(s)}\\) (nella pratica MCMC i pesi sono uguali):\n\n\n\\(\\theta^{(1)}=0.3\\) con \\(w^{(1)}=0.2\\)\n\n\n\\(\\theta^{(2)}=0.5\\) con \\(w^{(2)}=0.5\\)\n\n\n\\(\\theta^{(3)}=0.7\\) con \\(w^{(3)}=0.3\\)\n\n\nPer ogni campione \\(\\theta^{(s)}\\) calcoliamo \\(p(y_i \\mid \\theta^{(s)})\\), otteniamo la collezione di likelihood \\(\\{p(y_i\\mid \\theta^{(s)})\\}_{s=1}^S\\), poi facciamo la media pesata (eq. Equazione 43.6) per ottenere \\(p(y_i\\mid y)\\), e infine il log-score \\(\\log p(y_i\\mid y)\\) (eq. Equazione 43.3).\n\n# Dato osservato (un solo punto)\ny_i  &lt;- 3\nn_i  &lt;- 5\n\n# \"Campioni\" posteriori (qui pochi e con pesi espliciti per chiarezza didattica)\ntheta_vals        &lt;- c(0.3, 0.5, 0.7)      # θ^(1), θ^(2), θ^(3)\nposterior_weights &lt;- c(0.2, 0.5, 0.3)      # w^(1), w^(2), w^(3); in MCMC tipicamente uguali\n\n# (1) Likelihood punto-per-punto: p(y_i | θ^(s))\nlikelihoods &lt;- dbinom(y_i, size = n_i, prob = theta_vals)\nlikelihoods  # questa è la collezione { p(y_i | θ^(s)) }_s\n#&gt; [1] 0.132 0.312 0.309\n\n# (2) Media (pesata) sulle likelihood ⇒ p(y_i | y) ≈ Σ_s w^(s) p(y_i | θ^(s))\np_yi_given_y &lt;- sum(posterior_weights * likelihoods)\n\n# (3) Log-score (per un solo dato coincide con la LPPD del singolo punto)\nlog_score_i &lt;- log(p_yi_given_y)\n\n# Stampa riassuntiva con notazione coerente\ncat(\"Campioni θ^{(s)}:        \", theta_vals, \"\\n\")\n#&gt; Campioni θ^{(s)}:         0.3 0.5 0.7\ncat(\"Likelihood p(y_i|θ^{(s)}):\", round(likelihoods, 4), \"\\n\")\n#&gt; Likelihood p(y_i|θ^{(s)}): 0.132 0.312 0.309\ncat(\"p(y_i|y) (media pesata):  \", round(p_yi_given_y, 4), \"\\n\")\n#&gt; p(y_i|y) (media pesata):   0.275\ncat(\"log p(y_i|y):             \", round(log_score_i, 4), \"\\n\")\n#&gt; log p(y_i|y):              -1.29\n\nNota didattica: Nella pratica con MCMC i pesi sono uguali, \\(w^{(s)}=\\tfrac{1}{S}\\), quindi \\(p(y_i\\mid y) \\approx \\tfrac{1}{S}\\sum_{s=1}^S p(y_i\\mid \\theta^{(s)})\\) (Equazione 43.6). Con più osservazioni \\(\\{y_i\\}_{i=1}^n\\), la LPPD è la somma dei log-score punto-per-punto (Equazione 43.7).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#la-svolta-dalladattamento-alla-generalizzazione",
    "href": "chapters/entropy/03_model_comparison.html#la-svolta-dalladattamento-alla-generalizzazione",
    "title": "43  Valutare i modelli bayesiani",
    "section": "\n43.5 La svolta: dall’adattamento alla generalizzazione",
    "text": "43.5 La svolta: dall’adattamento alla generalizzazione\n\n43.5.1 Il problema dell’overfitting spiegato\nImmagina di voler valutare la capacità di uno studente di riconoscere emozioni nei volti.\n\n\nScenario A: lo testi sempre con le stesse fotografie che ha già visto molte volte durante l’allenamento.\n\nScenario B: lo testi con nuove fotografie di persone mai viste prima.\n\nNel primo caso, lo studente probabilmente avrà un punteggio molto alto, ma non sapremo se ha davvero imparato a riconoscere le emozioni o se si limita a ricordare quelle immagini specifiche. Il secondo scenario, invece, è più onesto: misura la capacità di generalizzare la competenza a stimoli nuovi.\nLo stesso accade con i modelli statistici.\n\nLa LPPD corrisponde allo Scenario A: valuta il modello sugli stessi dati usati per adattarlo, rischiando di dare un’illusione di performance eccellente.\nPer sapere se il modello sa davvero “generalizzare”, serve testarlo come nello Scenario B: con dati nuovi o tramite tecniche di validazione incrociata.\n\n43.5.2 Guardare oltre i dati osservati\nQuando valutiamo un modello, non ci basta sapere quanto bene spiega i dati che ha già visto. La vera domanda è: quanto bene predirebbe dati nuovi, mai osservati?\nLa Expected Log Predictive Density (ELPD) risponde a questa domanda. La logica è la stessa della LPPD, ma con una differenza cruciale: la previsione di ogni osservazione \\(y_i\\) viene fatta senza usare \\(y_i\\) per stimare il modello. Questa tecnica si chiama Leave-One-Out (LOO):\n\\[\n\\text{ELPD} = \\sum_{i=1}^n \\log p(y_i \\mid y_{-i}),\n\\tag{43.8}\\] dove \\(y_{-i}\\) indica il dataset a cui è stata tolta l’osservazione \\(i\\).\n\n43.5.2.1 Un esempio concreto per chiarire la differenza\nImmagina di voler costruire un modello che predice i punteggi di memoria a breve termine degli studenti a partire dal loro livello di concentrazione.\n\nCon la LPPD, il modello viene valutato sugli stessi studenti che sono serviti per stimarlo. È come dire: “quanto bene il modello spiega questi dati noti?”.\n\nCon la ELPD, invece, ogni volta togliamo uno studente dal campione, stimiamo il modello sugli altri e proviamo a predire il punteggio di quello escluso. È come chiedere: “quanto bene il modello predirebbe un nuovo studente, mai visto prima?”.\n\n43.5.2.2 Procedura passo per passo\n\nPrendiamo il primo studente ed escludiamolo dal dataset.\n\nAdattiamo il modello usando i dati dei rimanenti studenti.\n\nPrediciamo il punteggio di memoria dello studente escluso.\n\nRipetiamo lo stesso procedimento per ogni studente, uno alla volta.\n\nSommiamo tutti i log-score ottenuti: questo è l’ELPD.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#il-collegamento-con-la-divergenza-kl",
    "href": "chapters/entropy/03_model_comparison.html#il-collegamento-con-la-divergenza-kl",
    "title": "43  Valutare i modelli bayesiani",
    "section": "\n43.6 Il collegamento con la divergenza KL",
    "text": "43.6 Il collegamento con la divergenza KL\n\n43.6.1 La teoria che unifica tutto\nAbbiamo visto che l’ELPD fornisce una misura empirica della capacità predittiva di un modello. Esiste, tuttavia, una giustificazione teorica profonda e unificante che spiega il motivo per cui massimizzare l’ELPD è il principio corretto per la selezione dei modelli. Questa giustificazione poggia sul concetto di divergenza di Kullback-Leibler (KL).\n\n43.6.1.1 Cosa misura la divergenza KL?\nLa divergenza KL, indicata come \\(D_{\\text{KL}}\\), misura la “distanza” informazionale tra la distribuzione vera dei dati, \\(p(\\tilde{y})\\) (la realtà che vogliamo catturare), e la distribuzione predittiva del nostro modello, \\(q(\\tilde{y} \\mid y)\\) (la nostra approssimazione). È definita come:\n\\[\nD_{\\text{KL}}(p \\parallel q) = \\mathbb{E}_p \\left[ \\log \\frac{p(\\tilde{y})}{q(\\tilde{y} \\mid y)} \\right],\n\\] dove l’aspettativa \\(\\mathbb{E}_p\\) è calcolata rispetto alla distribuzione vera \\(p(\\tilde{y})\\).\n\n43.6.1.2 Scomponiamo la divergenza KL\nPer comprendere a fondo, espandiamo la definizione:\n\\[\nD_{\\text{KL}}(p \\parallel q) = \\underbrace{\\mathbb{E}_p[\\log p(\\tilde{y})]}_{\\text{(1) Entropia}} - \\underbrace{\\mathbb{E}_p[\\log q(\\tilde{y} \\mid y)]}_{\\text{(2) Accuratezza predittiva}}.\n\\tag{43.9}\\]\nAnalizziamo i due termini:\n\n\n\\(\\mathbb{E}_p[\\log p(\\tilde{y})]\\) (Entropia): Rappresenta il contenuto informativo intrinseco della distribuzione vera. È una quantità fissa, immutabile e, soprattutto, indipendente dal modello che stiamo considerando. È una costante.\n\n\\(-\\mathbb{E}_p[\\log q(\\tilde{y} \\mid y)]\\) (Log-verosimiglianza attesa): Questo è il termine cruciale. Misura quanto è buona la nostra distribuzione predittiva \\(q\\) nel prevedere nuovi dati provenienti dalla vera distribuzione \\(p\\). Nota: questo è esattamente l’opposto della quantità che stimiamo con l’ELPD \\((\\sum \\log q(\\tilde{y} \\mid y))\\).\n\n43.6.1.3 Il collegamento fondamentale\nPoiché il primo termine dell’Equazione 43.9 è una costante, minimizzare la divergenza KL \\(D_{\\text{KL}}(p \\parallel q)\\) equivale esattamente a massimizzare il secondo termine, ovvero l’accuratezza predittiva attesa. Questo risultato si traduce in una regola pratica potentissima per il confronto tra modelli. Date due distribuzioni predittive, \\(q_A\\) e \\(q_B\\), la differenza nelle loro divergenze KL è:\n\\[\n\\begin{aligned}\nD_{\\text{KL}}(p \\parallel q_A) - D_{\\text{KL}}(p \\parallel q_B) &= \\left( \\cancel{\\mathbb{E}_p[\\log p(\\tilde{y})]} - \\mathbb{E}_p[\\log q_A(\\tilde{y} \\mid y)] \\right) \\notag\\\\\n&\\qquad - \\left( \\cancel{\\mathbb{E}_p[\\log p(\\tilde{y})]} - \\mathbb{E}_p[\\log q_B(\\tilde{y} \\mid y)] \\right) \\\\\n&= \\mathbb{E}_p[\\log q_B(\\tilde{y} \\mid y)] - \\mathbb{E}_p[\\log q_A(\\tilde{y} \\mid y)] \\\\\n&= \\text{ELPD}(q_B) - \\text{ELPD}(q_A)\n\\end{aligned}\n\\] dove abbiamo cancellato il termine entropia costante.\n\n43.6.1.4 Conclusione teorica fondamentale\nIl risultato precedente ci porta alla conclusione chiave di tutta la teoria:\n\\[\n\\text{Massimizzare l'ELPD} \\;\\; \\equiv \\;\\; \\text{Minimizzare la divergenza KL dalla verità}.\n\\] In altre parole, quando preferiamo il modello con l’ELPD più alto, non stiamo solo seguendo un criterio empirico. Stiamo scegliendo consapevolmente il modello la cui distribuzione predittiva è, in media, più vicina alla realtà sottostante in senso informazionale. Questo principio unifica la teoria dell’informazione con la pratica della valutazione e selezione dei modelli predittivi.\n\n\n\n\n\n\nEsempio: collegamento ELPD-KL in pratica\n\n\n\n\n\nVogliamo confrontare due modelli predittivi per il numero di “teste” in \\(n=10\\) lanci. Supponiamo che\n\nla distribuzione vera è \\(p(y)=\\text{Binom}(n=10,\\;p=0.6)\\),\nil modello candidato prevede \\(q(y)=\\text{Binom}(n=10,\\;q=0.5)\\).\n\nL’ELPD di un modello è l’aspettativa, rispetto alla distribuzione vera \\(p\\), del log-score del modello: \\(\\mathrm{ELPD}(q)=\\mathbb{E}_{p}[\\log q(Y)]\\). Nel caso discreto, l’aspettativa diventa una somma su tutti i possibili valori \\(y=0,\\dots,n\\).\n\n# Parametri del problema\nn &lt;- 10          # numero di lanci\np &lt;- 0.6         # probabilità vera di \"testa\"\nq &lt;- 0.5         # probabilità ipotizzata dal modello candidato\n\n# 1) Supporto dei possibili esiti\ny_vals &lt;- 0:n\n\n# 2) Distribuzione vera p(y) su tutto il supporto\np_y &lt;- dbinom(y_vals, size = n, prob = p)\n\n# 3) Log-predittiva del modello candidato q su tutto il supporto\nlog_q_y &lt;- log(dbinom(y_vals, size = n, prob = q))\n\n# 4) ELPD del modello candidato: somma dei log q(y) pesati da p(y)\nelpd_q &lt;- sum(p_y * log_q_y)\n\n# 5) \"Modello vero\": usa q = p. Log-predittiva del modello vero\nlog_p_y &lt;- log(dbinom(y_vals, size = n, prob = p))\n\n# 6) ELPD del modello vero: somma dei log p(y) pesati da p(y)\nelpd_p &lt;- sum(p_y * log_p_y)\n\n# 7) Divergenza KL tra p e q: somma p(y) * log [p(y)/q(y)]\nkl_pq &lt;- sum(p_y * (log_p_y - log_q_y))\n\ncat(sprintf(\"ELPD modello candidato (q=0.5): %.4f\\n\", elpd_q))\n#&gt; ELPD modello candidato (q=0.5): -2.0549\ncat(sprintf(\"ELPD modello vero      (q=0.6): %.4f\\n\", elpd_p))\n#&gt; ELPD modello vero      (q=0.6): -1.8536\ncat(sprintf(\"Differenza ELPD (vero - candidato): %.4f\\n\", elpd_p - elpd_q))\n#&gt; Differenza ELPD (vero - candidato): 0.2014\ncat(sprintf(\"KL(p || q): %.4f\\n\", kl_pq))\n#&gt; KL(p || q): 0.2014\n\nCosa stiamo verificando?\n\n\\(\\mathrm{ELPD}(q)=\\sum_y p(y)\\log q(y)\\) è più basso (più negativo) del valore ottenuto dal modello vero \\(\\mathrm{ELPD}(p)=\\sum_y p(y)\\log p(y)\\). → Il modello con \\(q=0.6\\) è più predittivo di quello con \\(q=0.5\\).\nLa differenza tra i due ELPD è uguale (vicina numericamente) alla divergenza di Kullback–Leibler:\n\n\\[\n\\begin{align}\n\\mathrm{ELPD}(p)-\\mathrm{ELPD}(q) &= \\sum_y p(y)\\big[\\log p(y)-\\log q(y)\\big] \\notag\\\\\n&= D_{\\mathrm{KL}}(p\\|q)\\;&gt;\\;0.\n\\end{align}\n\\] Questo mostra algebricamente e numericamente il legame: massimizzare l’ELPD equivale a minimizzare la divergenza KL.\nIn pratica: In questo esempio abbiamo potuto calcolare l’ELPD vero perché conoscevamo l’intera distribuzione generatrice \\(p(y)\\) e potevamo integrare esattamente. Nella realtà, \\(p(y)\\) è sconosciuta: disponiamo solo di un campione osservato. In questi casi stimiamo l’ELPD empiricamente, ad esempio con la Leave-One-Out Cross-Validation (LOO-CV), che sostituisce l’aspettativa rispetto a \\(p\\) con una media sui dati raccolti, lasciando fuori una osservazione alla volta.\n\n\n\n\n\n\n\n\n\nCollegamento chiave.\nL’ELPD è una stima empirica (con segno cambiato) della divergenza di Kullback–Leibler. Più alto è l’ELPD, migliore è la capacità predittiva del modello.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#stimare-lelpd-nella-pratica-la-leave-one-out-cross-validation",
    "href": "chapters/entropy/03_model_comparison.html#stimare-lelpd-nella-pratica-la-leave-one-out-cross-validation",
    "title": "43  Valutare i modelli bayesiani",
    "section": "\n43.7 Stimare l’ELPD nella pratica: la Leave-One-Out Cross-Validation",
    "text": "43.7 Stimare l’ELPD nella pratica: la Leave-One-Out Cross-Validation\nAbbiamo chiarito che l’ELPD è la misura ideale della bontà predittiva di un modello, perché è direttamente collegata alla divergenza KL. Il problema è che, per definizione, richiede un’aspettativa rispetto alla vera distribuzione dei dati futuri \\(p(\\tilde{y})\\), che non conosciamo mai.\nCome possiamo allora stimarlo? La soluzione più usata è la Leave-One-Out Cross-Validation (LOO-CV), che ci permette di avvicinarci all’ELPD teorico usando soltanto i dati osservati.\n\n43.7.1 L’idea alla base della LOO-CV\nIl principio è semplice: trattare ogni osservazione del dataset come se fosse “nuova” e verificare se il modello, addestrato sui dati rimanenti, riesce a prevederla.\nIl procedimento è questo:\n\nSi prende un’osservazione \\(y_i\\).\nLa si rimuove temporaneamente dal dataset.\nSi stima il modello sui dati rimanenti \\(y_{-i}\\).\nSi calcola la densità predittiva che il modello assegna al dato escluso: \\(p(y\\_i \\mid y_{-i})\\).\nSi ripete per tutte le osservazioni e si sommano i logaritmi.\n\nIn formula:\n\\[\n\\text{ELPD}_{\\text{LOO}} = \\sum_{i=1}^n \\log p(y_i \\mid y_{-i}) .\n\\tag{43.10}\\]\nCosì otteniamo una stima out-of-sample: il modello viene valutato su dati che non ha mai visto.\n\n43.7.2 Perché funziona\nLa LOO-CV funziona perché sostituisce l’aspettativa teorica rispetto a \\(p(\\tilde{y})\\) con una media empirica sulle osservazioni reali. Ogni \\(y_i\\) viene trattata come un nuovo dato proveniente da \\(p\\), e la media dei log-score fuori campione fornisce una stima della capacità predittiva attesa:\n\\[\n\\text{ELPD}_{\\text{LOO}} \\approx \\mathbb{E}_p[\\log q(\\tilde{y}\\mid y)] .\n\\tag{43.11}\\]\n\n43.7.3 Confrontare i modelli con LOO-CV\nUna volta stimato l’ELPD-LOO, possiamo confrontare due modelli calcolando la differenza:\n\\[\n\\Delta \\text{ELPD} = \\text{ELPD}_{\\text{LOO}}(M_1) - \\text{ELPD}_{\\text{LOO}}(M_2).\n\\tag{43.12}\\]\nSe la differenza è positiva, il modello \\(M_1\\) ha una distribuzione predittiva più vicina alla realtà di quella di \\(M_2\\).\nÈ utile stimare anche un errore standard della differenza. Come regola empirica, una differenza di almeno due volte l’SE indica un vantaggio credibile di un modello sull’altro.\n\n43.7.4 Overfitting e vantaggio della LOO-CV\nSe valutassimo un modello sugli stessi dati usati per addestrarlo, la sua performance apparirebbe gonfiata (overfitting). La LOO-CV aggira questo problema: ogni osservazione viene valutata solo con modelli che non l’hanno vista. Il punteggio ottenuto è quindi una misura più realistica della capacità di generalizzare a nuovi dati.\n\n43.7.5 PSIS-LOO: la scorciatoia pratica\nUn limite della LOO tradizionale è che richiederebbe di riadattare il modello \\(n\\) volte, cosa spesso impraticabile. Per questo oggi si usa il metodo Pareto-Smoothed Importance Sampling (PSIS-LOO), che consente di stimare l’ELPD-LOO a partire da un unico adattamento del modello, sfruttando i campioni MCMC.\nIn R, tutto ciò è implementato nel pacchetto loo, già integrato in brms e rstanarm, attraverso funzioni come loo() e loo_compare(). Oltre ai valori di ELPD, queste funzioni forniscono anche diagnostiche (le Pareto k) per capire se la stima è affidabile.\n\n43.7.5.1 In sintesi\n\nL’ELPD misura la capacità predittiva del modello su dati futuri.\nNon conoscendo la distribuzione vera, usiamo la LOO-CV per stimarlo.\nLa differenza di ELPD-LOO tra modelli approssima la differenza nelle loro divergenze KL.\nPSIS-LOO rende il calcolo efficiente anche per modelli complessi.\nLa regola pratica: preferire il modello con ELPD-LOO più alto, tenendo conto anche della sua semplicità e interpretabilità.\n\n\n\n\n\n\n\nEsempio: confronto ELPD-LOO tra due modelli\n\n\n\n\n\nQuesto esempio mostra come passare dalla definizione teorica dell’ELPD alla stima pratica via Leave-One-Out, usando un caso elementare Beta–Bernoulli.\nDati: Cinque prove indipendenti: \\(y=\\{1,1,1,0,1\\}\\) (quattro “successi”, un “insuccesso”).\nModello A (Bayesiano adattato ai dati): Bernoulli\\((\\theta)\\) con prior \\(\\theta\\sim \\text{Beta}(1,1)\\) (uninformativa). Per LOO: * per ogni \\(i\\), escludiamo \\(y_i\\); * calcoliamo la posteriore \\(\\theta \\mid y_{-i} \\sim \\text{Beta}(1+s_{-i},\\,1+n_{-i}-s_{-i})\\), dove \\(s_{-i}\\) è il numero di successi tra i \\(n-1\\) rimanenti; * calcoliamo la probabilità predittiva per \\(y_i\\).\nModello B (di confronto): Moneta equa fissa (\\(q=0.5\\)): la predittiva è sempre \\(0.5\\), indipendentemente dai dati.\n\n# Dati\ny &lt;- c(1, 1, 1, 0, 1)\nn &lt;- length(y)\n\n# Log-predittiva LOO per Modello A (Beta(1,1) + Bernoulli)\nloo_log_pred_beta &lt;- function(i, y, a0 = 1, b0 = 1) {\n  yi &lt;- y[i]\n  s_minus &lt;- sum(y) - yi\n  n_minus &lt;- n - 1\n  alpha &lt;- a0 + s_minus\n  beta  &lt;- b0 + (n_minus - s_minus)\n  p1 &lt;- alpha / (alpha + beta)\n  p  &lt;- if (yi == 1) p1 else (1 - p1)\n  log(p)\n}\n\n# Log-predittive punto-per-punto\nlp_beta  &lt;- sapply(seq_along(y), loo_log_pred_beta, y = y)\nlp_fixed &lt;- rep(log(0.5), n)\n\n# ELPD-LOO\nelpd_beta  &lt;- sum(lp_beta)\nelpd_fixed &lt;- sum(lp_fixed)\n\n# Differenza e SE\ndiff_pt &lt;- lp_beta - lp_fixed\nse_diff &lt;- sqrt(n * var(diff_pt))\n\n# Tabella riassuntiva\nres &lt;- data.frame(\n  i = 1:n, y = y,\n  lp_beta = round(lp_beta, 6),\n  lp_fixed = round(lp_fixed, 6),\n  diff = round(diff_pt, 6)\n)\nprint(res)\n#&gt;   i y lp_beta lp_fixed   diff\n#&gt; 1 1 1  -0.405   -0.693  0.288\n#&gt; 2 2 1  -0.405   -0.693  0.288\n#&gt; 3 3 1  -0.405   -0.693  0.288\n#&gt; 4 4 0  -1.792   -0.693 -1.099\n#&gt; 5 5 1  -0.405   -0.693  0.288\ncat(sprintf(\"\\nELPD-LOO Modello A: %.6f\\n\", elpd_beta))\n#&gt; \n#&gt; ELPD-LOO Modello A: -3.413620\ncat(sprintf(\"ELPD-LOO Modello B: %.6f\\n\", elpd_fixed))\n#&gt; ELPD-LOO Modello B: -3.465736\ncat(sprintf(\"Differenza (A-B)  : %.6f\\n\", elpd_beta - elpd_fixed))\n#&gt; Differenza (A-B)  : 0.052116\ncat(sprintf(\"SE differenza     : %.6f\\n\", se_diff))\n#&gt; SE differenza     : 1.386294\n\nInterpretazione:\n\nOgni riga della tabella mostra la log-predittiva fuori campione per entrambi i modelli\nIn un campione con 4 successi su 5, il Modello A assegna più di 0.5 di probabilità ai successi, e meno di 0.5 all’unico insuccesso\nL’ELPD-LOO di A può risultare leggermente più alto di quello di B, ma l’errore standard è grande perché \\(n\\) è piccolo\n\n\nRegola pratica: una differenza \\(|\\Delta \\text{ELPD}|\\) di almeno 2 volte l’SE fornisce un’indicazione più affidabile di superiorità del modello. In esempi così piccoli l’obiettivo è puramente didattico: capire come si calcola e cosa significa.\n\n\n\n\n\n\n\n\n\n\nIn pratica: stimare e confrontare l’ELPD-LOO\n\n\n\n\n\nConcetto chiave\n\nL’ELPD valuta la capacità predittiva su dati non visti.\nLa LOO-CV lo stima in modo efficiente con PSIS-LOO.\n\nStrumenti\n\nFunzione loo() del pacchetto loo, integrata in brms e rstanarm.\nDiagnostica con Pareto k, confronto con loo_compare().\n\nWorkflow tipico in R\n\nAdattare ogni modello (brm() o stan_glm()).\nEstrarre log_lik() e calcolare loo().\nConfrontare modelli con loo_compare().\n\nDecisione\n\nPreferire l’ELPD-LOO più alto.\nDifferenza ≥ 2×SE → indicazione di vantaggio sostanziale.\nValutare anche semplicità e interpretabilità.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#criteri-di-informazione",
    "href": "chapters/entropy/03_model_comparison.html#criteri-di-informazione",
    "title": "43  Valutare i modelli bayesiani",
    "section": "\n43.8 Criteri di informazione",
    "text": "43.8 Criteri di informazione\nOltre alla convalida incrociata Leave-One-Out, la statistica offre altri strumenti per stimare la qualità predittiva di un modello senza conoscere la distribuzione vera dei dati. Molti di questi metodi affondano le loro radici teoriche nel concetto di divergenza di Kullback-Leibler, che misura la distanza tra la distribuzione generatrice dei dati e quella stimata dal nostro modello.\nL’obiettivo comune è valutare la capacità di un modello di generalizzare, ovvero di fare buone previsioni su dati non osservati, senza farsi trarre in inganno dall’overfitting. Tutti i criteri seguono una logica simile, bilanciando due componenti: una misura della bontà di adattamento ai dati e una penalità per la complessità del modello stesso. I vari criteri si distinguono proprio per come definiscono queste due componenti e per le assunzioni su cui si basano.\n\n43.8.1 Una panoramica dei criteri principali\nL’AIC (Akaike Information Criterion) approssima la distanza di Kullback-Leibler utilizzando la verosimiglianza massimizzata e applica una penalità semplice, proporzionale al numero di parametri. È un criterio veloce e ampiamente utilizzato, particolarmente utile per modelli regolari con campioni non troppo piccoli e privi di struttura gerarchica.\nIl BIC (Bayesian Information Criterion) segue una logica simile all’AIC, ma introduce una penalità per la complessità che cresce all’aumentare della dimensione del campione. Questo lo porta tendenzialmente a preferire modelli più parsimoniosi quando il numero di osservazioni è grande e, sotto specifiche ipotesi, può essere collegato alla verosimiglianza marginale.\nIl WAIC (Widely Applicable Information Criterion) rappresenta una versione pienamente bayesiana. Utilizza l’intera distribuzione predittiva a posteriori per valutare il fit e stima una penalità per la complessità effettiva del modello, che può differire dal semplice numero di parametri. È particolarmente adatto per modelli complessi o non regolari ed è concettualmente molto vicino alla stima LOO.\nInfine, il LOO-CV (Leave-One-Out Cross-Validation), specialmente nella sua efficiente implementazione PSIS-LOO, stima direttamente l’Expected Log Predictive Density (ELPD) escludendo un dato alla volta. È spesso considerato il gold standard per il confronto predittivo nell’ambito della modellazione bayesiana, grazie alla sua robustezza e alle utili diagnostiche che fornisce.\n\n43.8.1.1 Come orientarsi nella scelta\nUna regola pratica è che se l’obiettivo principale è la previsione fuori campione in un contesto bayesiano, il PSIS-LOO o il WAIC sono generalmente da preferire ad AIC e BIC. In un approccio frequentista classico, con modelli regolari e campioni di dimensioni medio-grandi, l’AIC rimane un buon compromesso, mentre il BIC può essere più appropriato quando si desidera enfatizzare la parsimonia.\nPer modelli bayesiani con obiettivo predittivo e dati reali (spesso non iid o gerarchici), il PSIS-LOO è la prima scelta, con il WAIC utile come riscontro. Con campioni piccoli, strutture complesse o unità dipendenti, è bene evitare criteri puramente asintotici come AIC e BIC, preferendo invece LOO o definendo con attenzione l’unità di esclusione (ad esempio, per soggetto o per gruppo). Nei modelli gerarchici o multilivello, LOO e WAIC possono essere applicati in modo coerente, prestando attenzione a non escludere singole osservazioni se queste non sono indipendenti, ma piuttosto interi cluster.\n\n43.8.1.2 Errori comuni e best practice\nUn errore frequente è utilizzare il Mean Squared Error (MSE) sul campione di addestramento come metro di giudizio, poiché questo valore non penalizza la complessità e tende quindi a favorire modelli eccessivamente flessibili e soggetti a overfitting. Allo stesso modo, è importante ricordare che AIC e BIC si basano su stime puntuali (MLE o MAP) e non catturano l’incertezza completa sui parametri, il che li rende meno ideali in un contesto bayesiano puro. WAIC e LOOCV, al contrario, sono espressamente concepiti per stimare la performance predittiva su dati nuovi.\nQuando si riporta un confronto tra modelli, è buona norma includere non solo il modello “vincente”, ma anche la differenza di ELPD con il suo errore standard, le diagnostiche sui parametri di Pareto-k, una stima della complessità effettiva e un commento sostantivo che spieghi il motivo della preferenza, che potrebbe risiedere nella parsimonia, nell’interpretabilità dei parametri o nella robustezza.\n\n43.8.1.3 In sintesi: il workflow essenziale\nUn mini-workflow consigliato per un approccio bayesiano prevede di: adattare i modelli; calcolare il LOO per ciascuno di essi e controllare i parametri di Pareto-k; se si riscontrano valori di k elevati, considerare una convalida incrociata K-fold o una LOO per cluster; confrontare i modelli con appositi strumenti e riportare le differenze di ELPD; opzionalmente, calcolare il WAIC come controllo incrociato; argomentare infine la scelta finale anche in base a parsimonia e interpretabilità.\nLa selezione del modello, in definitiva, ruota attorno a una domanda essenziale: quanto bene il modello predice dati che non ha mai visto? Il riferimento teorico è l’Expected Log Predictive Density (ELPD), che misura quanto la distribuzione predittiva del modello si avvicina alla vera distribuzione dei dati. Poiché quest’ultima è sconosciuta, l’ELPD va stimato con strumenti come LOO-CV e WAIC, che oggi rappresentano gli standard più affidabili per guidare una scelta consapevole, equilibrata e focalizzata sulla capacità di generalizzazione.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#riflessioni-conclusive",
    "href": "chapters/entropy/03_model_comparison.html#riflessioni-conclusive",
    "title": "43  Valutare i modelli bayesiani",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl principio fondamentale della modellazione bayesiana risiede nella valutazione della qualità di un modello attraverso la sua capacità di produrre previsioni probabilistiche robuste, rappresentate dalla distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\).\nLa misura che guida questa valutazione è l’Expected Log Predictive Density (ELPD), che quantifica la capacità predittiva del modello su dati non osservati. A differenza delle metriche in-sample, soggette a sovradattamento, l’ELPD fornisce una stima imparziale della capacità di generalizzazione. Teoricamente, massimizzare l’ELPD equivale a minimizzare la divergenza di Kullback-Leibler rispetto alla vera distribuzione generatrice dei dati.\nOperativamente, l’ELPD viene stimato mediante PSIS-LOO, integrato con i diagnostici Pareto-k. Il WAIC costituisce un’alternativa bayesiana solida, spesso coerente con LOO. Al contrario, criteri come AIC e BIC, sebbene computazionalmente efficienti, si basano su stime puntuali e approssimazioni asintotiche, risultando meno affidabili in contesti di campioni piccoli o modelli gerarchici.\nNel confronto tra modelli, è essenziale riportare non solo l’ELPD-LOO, ma anche le differenze ΔELPD e i relativi errori standard. Tuttavia, la selezione del modello non dovrebbe ridursi a un esercizio meccanico: differenze trascurabili nell’ELPD, specialmente se associate ad alta incertezza, possono essere irrilevanti sul piano sostanziale. Modelli meno performanti ma più parsimoniosi o teoricamente fondati possono rappresentare scelte migliori.\nL’obiettivo finale è bilanciare capacità predittiva e coerenza teorica, ricordando che lo scopo della modellazione non è solo prevedere, ma comprendere. La valutazione deve quindi integrare strumenti come il PSIS-LOO con considerazioni sull’incertezza statistica, la struttura dei dati e il contesto teorico di riferimento.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] gt_1.0.0              pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] xml2_1.4.0            RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.5.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_7.0.0              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.3    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.5.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#bibliografia",
    "href": "chapters/entropy/03_model_comparison.html#bibliografia",
    "title": "43  Valutare i modelli bayesiani",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Valutare i modelli bayesiani</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/conclusions_sec.html",
    "href": "chapters/entropy/conclusions_sec.html",
    "title": "Riflessioni conclusive della sezione",
    "section": "",
    "text": "Questa sezione ha aggiunto al nostro toolkit tre idee chiave:\n\nEntropia (Shannon). Una misura intrinsecamente probabilistica dell’incertezza: più la distribuzione è “piatta”, più informazione è necessaria per identificare l’esito. Oltre alla definizione formale, abbiamo visto esempi applicativi (stima dai campioni, collegamento alla codifica).\nDivergenza KL. Una metrica asimmetrica che quantifica il costo informativo dell’errore di modello: usare \\(Q\\) quando i dati provengono da \\(P\\) ci fa “spendere” bit extra in media. È il criterio teorico che giustifica perché preferiamo modelli che approssimano bene la generatrice dei dati senza sovra-adattarsi.\nValutazione predittiva bayesiana. Spostare l’attenzione dall’aderenza in-sample alla capacità di previsione out-of-sample: log-score punto-per-punto, ELPD come quantità da massimizzare e LOO-CV/WAIC come stime pratiche dell’ELPD. In questa cornice, il “modello migliore” è quello che prevede meglio nuovi dati, non quello che minimizza il residuo sui dati già visti.\n\nIl valore aggiunto, per la psicologia, è duplice:\n\nMetodologico. Entropia e KL offrono un linguaggio comune per discutere incertezza, complessità e generalizzazione, coerente con l’uso della distribuzione predittiva posteriore introdotta nei capitoli bayesiani.\nPratico. Gli strumenti come LOO-CV e WAIC si integrano naturalmente nel flusso di lavoro con brms/Stan: stimiamo il modello, calcoliamo l’ELPD, confrontiamo le specificazioni e scegliamo quella che massimizza l’accuratezza predittiva, prevenendo sia underfitting che overfitting.\n\nIn sintesi, questa sezione del libro ha reso esplicito il legame tra informazione e inferenza: quanto più un modello riduce l’incertezza (in senso predittivo) senza introdurre complessità superflua, tanto più è informativo. Questo prepara il terreno ai capitoli successivi, in cui la scelta e la valutazione dei modelli — anche meccanicistici e dinamici — saranno guidate da criteri predittivi e informazionali, non solo da adattamenti locali ai dati.",
    "crumbs": [
      "Entropia",
      "Riflessioni conclusive della sezione"
    ]
  },
  {
    "objectID": "chapters/formal_models/introduction_sec.html",
    "href": "chapters/formal_models/introduction_sec.html",
    "title": "Introduzione alla sezione",
    "section": "",
    "text": "Nei capitoli precedenti ci siamo concentrati soprattutto su modelli fenomenologici, capaci di descrivere le relazioni osservate tra variabili, senza però fornire una spiegazione dei processi che le hanno generate. Con questa sezione facciamo un passo decisivo: introduciamo i modelli formali e dinamici in psicologia, strumenti che non si limitano a riassumere i dati ma cercano di rappresentare i meccanismi cognitivi e comportamentali sottostanti.\nPartiremo con i modelli dinamici autoregressivi, che ci consentono di rappresentare la dipendenza di uno stato psicologico dal proprio passato. Questa prospettiva è cruciale per i dati longitudinali e per i compiti sperimentali ripetuti: l’idea che “oggi dipende da ieri” è intuitiva ma richiede formalizzazione rigorosa.\nEstenderemo poi questi modelli a versioni più ricche, introducendo concetti come stati latenti, rumore di processo e dinamiche di feedback, che permettono di simulare traiettorie psicologiche più realistiche e di interpretare i dati come esiti di un sistema complesso in continua evoluzione.\nInoltre, ci concentreremo su un modello storico e tuttora fondamentale: il Rescorla-Wagner. Questo modello di apprendimento associativo formalizza il principio dell’errore predittivo: la forza di un’associazione viene aggiornata in base alla differenza tra ciò che ci si aspettava e ciò che si è osservato. Pur nella sua semplicità, il modello Rescorla-Wagner ha avuto un impatto enorme, mostrando come poche regole matematiche possano spiegare fenomeni complessi di condizionamento.\nInfine, il capitolo dedicato al metodo di studio illustra come tradurre una teoria psicologica in un workflow modellistico completo: dalla formalizzazione delle ipotesi, alla simulazione dei dati, fino al confronto tra modelli alternativi. Questo esempio mostra concretamente come i modelli computazionali non siano meri strumenti statistici, ma veri e propri veicoli di teorie psicologiche, capaci di guidare nuove domande di ricerca e di chiarire le condizioni in cui un’ipotesi trova conferma o meno.\nIl filo conduttore della sezione è il passaggio dal descrivere i dati a simulare processi: ogni modello diventa una piccola teoria, implementata in termini matematici, capace di generare previsioni che possiamo confrontare con l’evidenza empirica.",
    "crumbs": [
      "Modelli",
      "Introduzione alla sezione"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html",
    "href": "chapters/formal_models/01_dynamic_models.html",
    "title": "44  Il modello di revisione degli obiettivi",
    "section": "",
    "text": "Introduzione\nMolti fenomeni psicologici sono intrinsecamente dinamici: non si esauriscono in una fotografia istantanea, ma si sviluppano e si trasformano nel tempo. L’apprendimento, l’adattamento agli errori, la regolazione degli obiettivi, l’insorgere o la remissione di sintomi clinici sono tutti esempi di processi temporali, nei quali ciò che osserviamo in un dato momento è il risultato di una storia pregressa.\nEppure, gran parte degli strumenti statistici più diffusi in psicologia tende a ignorare questa dimensione. Confrontiamo medie, calcoliamo correlazioni, stimiamo regressioni, trattando spesso le osservazioni come se fossero indipendenti tra loro. Questo approccio è utile per molte domande, ma risulta inadeguato quando l’obiettivo è comprendere l’evoluzione di un comportamento o di uno stato psicologico.\nSe vogliamo indagare come le persone modificano i propri obiettivi, cambiano strategia, o si adattano nel tempo a esperienze positive e negative, dobbiamo ricorrere a strumenti che considerino esplicitamente la sequenza degli eventi. Non ci basta descrivere uno stato: serve un modello che formalizzi le regole del cambiamento, ovvero il modo in cui il presente dipende dal passato e condiziona il futuro.\nIn questo capitolo introdurremo dunque i modelli dinamici, mostrando come essi permettano di spostare l’attenzione dalla semplice descrizione dei dati alla rappresentazione dei processi psicologici sottostanti.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#introduzione",
    "href": "chapters/formal_models/01_dynamic_models.html#introduzione",
    "title": "44  Il modello di revisione degli obiettivi",
    "section": "",
    "text": "Prerequisiti\n\n\n\n\n\n\nLeggere The role of the individual in the coming era of process-based therapy (Hayes et al., 2019).",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#perché-abbiamo-bisogno-di-modelli-dinamici",
    "href": "chapters/formal_models/01_dynamic_models.html#perché-abbiamo-bisogno-di-modelli-dinamici",
    "title": "44  Il modello di revisione degli obiettivi",
    "section": "\n44.1 Perché abbiamo bisogno di modelli dinamici?",
    "text": "44.1 Perché abbiamo bisogno di modelli dinamici?\nUn modello dinamico è una rappresentazione matematica che esplicita il modo in cui un sistema evolve nel tempo. La caratteristica distintiva di questi modelli è la presenza di dipendenze temporali: almeno una delle variabili dipende da valori passati, non solo da ciò che accade nel presente.\nQuesto è ciò che li differenzia dai modelli statici, dove ogni osservazione è trattata come indipendente dalle precedenti. Nei modelli dinamici, invece, esiste una memoria del passato, che influenza l’andamento futuro del processo. Nei modelli statici, la variabilità del comportamento è trattata come rumore o differenza individuale. Nei modelli dinamici, questa variabilità diventa informativa: è l’espressione dell’adattamento del sistema alle condizioni del contesto o alla propria storia passata.\nUna classe importante di variabili in questo contesto è costituita dalle variabili di stato (in inglese: state variables o stock variables), che rappresentano il livello accumulato di una certa quantità nel tempo: un obiettivo personale, un livello di motivazione, una credenza, o un sintomo. Queste variabili si aggiornano a ogni passo temporale secondo una regola di cambiamento che è definita in termini matematici.\n\n44.1.1 Come si costruisce un modello dinamico?\nFormulare un modello dinamico significa tradurre in termini espliciti una teoria del cambiamento. I passaggi fondamentali sono:\n\n\nIdentificare le variabili rilevanti: quali sono gli elementi del sistema che vogliamo modellare?\n\nStabilire le regole di aggiornamento: come cambia ciascuna variabile nel tempo in risposta a feedback o input esterni?\n\nFormalizzare il modello in equazioni: trasformare le regole in una struttura matematica coerente.\n\nValutare la validità del modello: confrontare le sue previsioni con i dati osservati, utilizzando metodi statistici appropriati.\n\nQuesto approccio è particolarmente adatto alla psicologia, dove l’interesse non riguarda solo il fatto che un comportamento cambi, ma anche il modo in cui evolve nel tempo.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#un-esempio-concreto-il-modello-di-revisione-degli-obiettivi",
    "href": "chapters/formal_models/01_dynamic_models.html#un-esempio-concreto-il-modello-di-revisione-degli-obiettivi",
    "title": "44  Il modello di revisione degli obiettivi",
    "section": "\n44.2 Un esempio concreto: il modello di revisione degli obiettivi",
    "text": "44.2 Un esempio concreto: il modello di revisione degli obiettivi\nPer chiarire meglio questo concetto, in questo e nel successivo capitolo considereremo un esempio concreto discusso da Knight et al. (2023): la regolazione degli obiettivi in base ai feedback. Immaginiamo un esperimento in cui i partecipanti devono svolgere un compito ripetitivo, come la classificazione di coppie di immagini. Prima di ogni prova (trial), ciascuno partecipante fissa un obiettivo personale, ad esempio migliorare la velocità o la precisione rispetto al tentativo precedente. Al termine di ogni prova, il partecipante riceve un feedback sulla propria performance e può quindi decidere se mantenere o modificare l’obiettivo per la prova successiva.\nQuesto ciclo – definizione dell’obiettivo, esecuzione, feedback, aggiustamento – è dinamico e si ripete in modo iterativo. Un buon modello dinamico riesce a catturare con precisione tale meccanismo, e, ad esempio, permette di stimare con quanta rapidità una persona riveda le proprie aspirazioni in risposta a successi o fallimenti.\nNel resto del capitolo, mostreremo come formalizzare matematicamente questo processo e come stimare i suoi parametri con un approccio bayesiano implementato in Stan.\n\n44.2.1 Come formalizzare questo processo?\nUna delle ipotesi più semplici, ma sorprendentemente potenti, è che le persone modifichino i propri obiettivi in funzione della discrepanza tra i risultati ottenuti (performance) e le aspettative (goal). Se la performance supera l’obiettivo, le aspettative tendono ad aumentare (ambizione crescente). Se la performance è inferiore, invece, si tende a ridurre le aspettative (aggiustamento conservativo).\nKnight et al. (2023) hanno formalizzato questa intuizione nel seguente modello dinamico lineare\n\\[\nG_t = G_{t-1} + \\alpha \\cdot (P_{t-1} - G_{t-1}) + \\beta ,\n\\tag{44.1}\\] dove:\n\n\n\\(G_t\\) è l’obiettivo fissato al trial \\(t\\),\n\n\\(G_{t-1}\\) è l’obiettivo del trial precedente,\n\n\\(P_{t-1}\\) è la performance osservata al trial precedente,\n\n\\(\\alpha\\) è un parametro che rappresenta la sensibilità alla discrepanza (quanto il goal viene aggiornato in risposta all’errore),\n\n\\(\\beta\\) è un bias sistematico. \\(\\beta &gt; 0\\) indica una deriva ambiziosa (es., pressione sociale), mentre \\(\\beta &lt; 0\\) indica una deriva cautelativa (es., affaticamento).\n\nIn altre parole, l’obiettivo del trial corrente (\\(G_t\\)) è determinato dall’obiettivo precedente (\\(G_{t-1}\\)), corretto per una frazione (\\(\\alpha\\)) della discrepanza (errore) tra la performance passata (\\(P_{t-1}\\)) e l’obiettivo passato (\\(G_{t-1}\\)). A questo risultato si aggiunge una tendenza sistematica (\\(\\beta\\)) a migliorare o peggiorare le proprie aspettative, indipendentemente dalla performance.\nSi noti che questo è un modello a livello di campione (sample-level), in quanto assume che tutti i partecipanti condividano gli stessi parametri \\(\\alpha\\) e \\(\\beta\\), i quali vengono stimati aggregando i dati dell’intero campione.\n\n44.2.2 Illustrazione numerica del modello\nPer esplorare il comportamento del modello, consideriamo due scenari contrastanti con gli stessi parametri:\n\n\n\\(\\alpha = 0.5\\): un tasso di apprendimento moderato, per cui il 50% della discrepanza osservata viene incorporato nel nuovo obiettivo.\n\n\\(\\beta = 2\\): un bias positivo che spinge sistematicamente l’obiettivo verso l’alto di 2 punti a ogni trial, indipendentemente dalla performance.\n\nScenario 1: Successo (Performance &gt; Obiettivo)\n\nobiettivo precedente (\\(G_{t-1}\\)): 50 punti;\nperformance (\\(P_{t-1}\\)): 60 punti (supera l’obiettivo di 10 punti).\n\nCalcolo: \\(G_t = 50 + 0.5 \\cdot (60 - 50) + 2 = 50 + 5 + 2 = \\mathbf{57}\\).\nInterpretazione: Il partecipante ha ottenuto un risultato superiore alle aspettative. Il nuovo obiettivo viene quindi aumentato per incorporare metà di questo successo (+5 punti, effetto di \\(\\alpha\\)). A questo si aggiunge la spinta ambiziosa sistematica data da \\(\\beta\\) (+2 punti). Il risultato è un aggiustamento ambizioso da 50 a 57 punti, in cui il bias \\(\\beta\\) amplifica l’effetto della performance positiva.\nScenario 2: Insuccesso (Performance &lt; Obiettivo)\n\nObiettivo precedente (\\(G_{t-1}\\)): 50 punti;\nperformance (\\(P_{t-1}\\)): 40 punti (inferiore di 10 punti rispetto all’obiettivo).\n\nCalcolo: \\(G_t = 50 + 0.5 \\cdot (40 - 50) + 2 = 50 - 5 + 2 = \\mathbf{47}\\).\nInterpretazione: Nonostante la performance deludente, l’aggiustamento è stato attenuato. La discrepanza negativa porta a una riduzione dell’obiettivo (-5 punti, effetto di \\(\\alpha\\)), ma il bias positivo \\(\\beta\\) (+2 punti) contrasta parzialmente tale riduzione. Questo meccanismo può modellare fenomeni come la resilienza (non penalizzare eccessivamente gli insuccessi) o l’effetto di una pressione esterna continua a migliorare.\n\n44.2.3 Il ruolo cruciale del parametro \\(\\beta\\)\n\nPer isolare l’effetto della deriva sistematica, confrontiamo i risultati dei due scenari con il caso in cui \\(\\beta = 0\\).\n\n\n\n\n\n\n\n\n\nScenario\nCon \\(\\beta=+2\\)\n\nCon \\(\\beta=0\\)\n\nDifferenza\nEffetto di \\(\\beta\\)\n\n\n\n\nSuccesso\n57\n55\n+2\nAmplifica il successo\n\n\nInsuccesso\n47\n45\n+2\nAttutisce il fallimento\n\n\n\nConclusioni e insight:\n\n\n\\(\\alpha\\) (Sensibilità) controlla l’adattamento reattivo: determina quanto rapidamente l’obiettivo “insegue” la performance passata.\n\n\\(\\beta\\) (Bias) introduce una tendenza proattiva spingendo l’obiettivo in una direzione specifica (in questo caso verso l’alto), indipendentemente dal feedback immediato;\n\n\n\\(\\beta &gt; 0\\): induce un’ambizione sistematica, spingendo a fare di più anche dopo un fallimento;\n\n\\(\\beta &lt; 0\\): riflette una cautela strutturale (es., affaticamento, avversione al rischio)e porta a ridurre le aspettative anche dopo un successo.\n\n\n\nSintesi delle interazioni: Un modello completo richiede entrambi i parametri per catturare sia le risposte locali ai feedback (\\(\\alpha\\)) sia le tendenze globali e motivazionali a lungo termine (\\(\\beta\\)). La loro interazione definisce la dinamica complessiva della fissazione degli obiettivi.\n\n44.2.4 Perché questo modello è importante?\nQuesto approccio rappresenta un ponte tra la psicologia e la modellizzazione matematica, trasformando ipotesi sui processi cognitivi—in particolare la regolazione degli obiettivi—in relazioni quantitative e verificabili. Sul piano metodologico, supera i limiti delle descrizioni qualitative attraverso una formalizzazione elegante: il parametro \\(\\alpha\\) quantifica la sensibilità individuale alla discrepanza tra prestazioni attese ed effettive, rivelando la prontezza nel ricalibrare gli obiettivi. Valori elevati denotano un adattamento rapido all’errore, mentre valori bassi indicano maggiore perseveranza. Parallelamente, \\(\\beta\\) cattura tendenze sistemiche indipendenti dalla performance, come un’ambizione costante (\\(\\beta &gt; 0\\)) o una deriva cautelativa (\\(\\beta &lt; 0\\)). Questa dualità consente di discriminare con precisione il peso relativo del feedback esperito rispetto a fattori contestuali intrinseci o ambientali.\nIl modello offre un notevole valore predittivo, rendendolo uno strumento operativo in contesti applicativi. Una volta stimati i parametri \\(\\alpha\\) e \\(\\beta\\) per un individuo o un gruppo, è possibile anticipare le risposte a specifici schemi di feedback, abilitando interventi su misura.\n\nIn ambito educativo, si possono progettare interventi che bilancino sostegno e sfida per ottimizzare la motivazione.\nIn contesti clinici, il modello aiuta a identificare schemi disfunzionali – come una combinazione di basso \\(\\alpha\\) (scarsa reattività al feedback) e \\(\\beta\\) negativo (deriva al ribasso) – tipici di stati depressivi o ansiosi.\nNel mondo organizzativo, permette di adattare sistemi di valutazione e incentivazione alle caratteristiche dei team.\n\nLa flessibilità del modello lo rende inoltre una base solida per esplorare complessità aggiuntive, come effetti non lineari, differenze individuali o influenze contestuali, mantenendo al contempo una struttura interpretabile.\nIn sintesi, questo modello fornisce un linguaggio comune per studiare, prevedere e influenzare i meccanismi cognitivi alla base della regolazione degli obiettivi, contribuendo così a una psicologia più rigorosa e a interventi più mirati.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#stima-dei-parametri-con-stan",
    "href": "chapters/formal_models/01_dynamic_models.html#stima-dei-parametri-con-stan",
    "title": "44  Il modello di revisione degli obiettivi",
    "section": "\n44.3 Stima dei parametri con Stan",
    "text": "44.3 Stima dei parametri con Stan\nPassando dalla teoria alla pratica, affrontiamo ora il cuore operativo della modellizzazione: la stima dei parametri che quantificano il processo di aggiornamento degli obiettivi. Il modello dinamico precedentemente descritto trova la sua concretizzazione statistica attraverso tre parametri chiave:\n\n\n\\(\\alpha\\): rappresenta la sensibilità alla discrepanza tra performance e obiettivi;\n\n\\(\\beta\\): cattura le tendenze sistemiche nel cambiamento degli obiettivi;\n\n\\(\\sigma\\): misura la variabilità residua non spiegata dal modello.\n\nPer farlo, traduciamo l’equazione teorica in un modello statistico e utilizziamo un approccio bayesiano per stimare la distribuzione a posteriori dei parametri.\n\n44.3.1 Dal modello teorico al modello statistico\nIl modello dinamico di base esprime la regola di aggiornamento degli obiettivi attraverso un’equazione deterministica\n\\[\nG_t = G_{t-1} + \\alpha (P_{t-1} - G_{t-1}) + \\beta .\n\\] Tuttavia, per trasformarla in un modello statistico adatto all’analisi empirica, dobbiamo considerare la componente stocastica del processo. Introduciamo quindi un termine di errore che catturi la variabilità naturale del processo di fissazione degli obiettivi, l’effetto di fattori non modellati esplicitamente e gli eventuali errori di misurazione. La versione statistica del modello diventa:\n\\[\n\\text{Goal osservato} \\sim \\mathcal{N}(G_t, \\sigma) .\n\\tag{44.2}\\] In altre parole, si assume che il goal osservato sia distribuito normalmente attorno al valore previsto con una certa variabilità, indicata con \\(\\sigma\\).\n\n44.3.2 Il vantaggio dell’approccio bayesiano per modelli dinamici\nLa natura ricorsiva dei modelli dinamici, in cui ogni stima dipende dal valore precedente, rende difficile l’applicazione dei metodi frequentisti tradizionali. L’inferenza bayesiana offre invece un quadro naturale per gestire sia le dipendenze temporali sia l’incertezza sui parametri. Stan rappresenta uno strumento particolarmente adatto a questo scopo, perché implementa algoritmi MCMC avanzati in grado di trattare in modo efficiente le correlazioni tra parametri, propagare l’incertezza lungo le catene temporali e incorporare le conoscenze pregresse attraverso distribuzioni a priori.\nA differenza degli approcci classici, l’output bayesiano non si riduce a una stima puntuale, ma fornisce l’intera distribuzione a posteriori, che riflette tutte le relazioni probabilistiche tra parametri e stati latenti. Questo permette di quantificare l’incertezza in modo rigoroso, formulare probabilità dirette per le ipotesi teoriche e sviluppare previsioni robuste che integrano le diverse fonti di variabilità presenti nei dati.\n\n44.3.3 Esempio: implementazione del modello in Stan\nIl codice Stan presentato qui di seguito segue esattamente la struttura logica del modello teorico:\n\ni dati in input sono il numero di trial, i goal osservati e le performance;\ni parametri da stimare sono \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\);\nla regola di aggiornamento è implementata in un ciclo for, trial per trial;\nla distribuzione normale collega il goal previsto a quello osservato;\nun blocco aggiuntivo (generated quantities) consente di generare dati simulati a partire dai parametri stimati.\n\n44.3.4 Il codice Stan\nDi seguito, riportiamo il modello completo implementato in Stan. Analizzeremo poi ciascuna parte.\n// MODELLO PER L'AGGIORNAMENTO DEGLI OBIETTIVI BASATO SULLA PERFORMANCE PRECEDENTE\n\n// ---------------------------\n// BLOCCO DEI DATI: COSA FORNIAMO AL MODELLO\n// ---------------------------\ndata {\n  int Ntotal;                      // Numero totale di osservazioni (es. 600 trial)\n  real trial[Ntotal];              // Numero del trial (es. 1, 2, 3, ..., 600)\n  real observed_goal[Ntotal];      // Obiettivo desiderato osservato in ciascun trial\n  real performance[Ntotal];        // Prestazione osservata in ciascun trial\n}\n\n// ---------------------------\n// PARAMETRI DEL MODELLO: COSA VOGLIAMO STIMARE\n// ---------------------------\nparameters {\n  real alpha;                      // Quanto il partecipante adatta il proprio obiettivo (apprendimento)\n  real beta;                       // Tendenza generale a incrementare l’obiettivo (motivazione costante)\n  real&lt;lower=0&gt; sigma;             // Variazione casuale attorno al goal previsto (rumore)\n}\n\n// ---------------------------\n// MODELLO: COME SI SPIEGANO I DATI\n// ---------------------------\nmodel {\n  real predicted_goal;             // Variabile temporanea per salvare la previsione del goal\n\n  // --- PRIORS: aspettative iniziali sui parametri ---\n  alpha ~ normal(0, 1);            // Alpha: in media 0, con incertezza (deviazione standard = 1)\n  beta ~ normal(0, 1);             // Beta: idem\n  sigma ~ normal(0, 1);            // Sigma: deviazione standard del rumore (deve essere positiva)\n\n  // --- CICLO PER OGNI TRIAL ---\n  for (i in 1:Ntotal) {\n\n    // Caso speciale: primo trial → nessuna previsione, usiamo direttamente il dato osservato\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    }\n\n    // Tutti i trial successivi → aggiornamento del goal basato sulla performance precedente\n    if (trial[i] &gt; 1) {\n      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;\n      // ↑ Questa è la \"regola di apprendimento\":\n      // - Se la performance precedente è migliore del goal → l’obiettivo aumenta\n      // - Se la performance è peggiore → l’obiettivo diminuisce\n      // - Quanto cambia? Dipende da alpha (quanto il partecipante si adatta)\n      // - A ogni passo si aggiunge anche un piccolo incremento costante (beta)\n    }\n\n    // Likelihood: assumiamo che il goal osservato sia vicino al goal previsto, con un po’ di rumore\n    observed_goal[i] ~ normal(predicted_goal, sigma);\n  }\n}\n\n// ---------------------------\n// BLOCCO PER GENERARE PREVISIONI (non necessario, ma utile per valutare il modello)\n// ---------------------------\ngenerated quantities {\n  real predicted_goal;              // Valore previsto dal modello\n  real sampled_goal[Ntotal];        // Goal \"simulati\", generati dal modello\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    }\n    if (trial[i] &gt; 1) {\n      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;\n    }\n\n    // Simuliamo un nuovo goal come se fosse stato osservato, aggiungendo variabilità\n    sampled_goal[i] = normal_rng(predicted_goal, sigma);\n  }\n}\n\n44.3.5 La Struttura del Codice Stan: Quattro Blocchi Logici\n\n44.3.5.1 1. data – “Cosa sappiamo”\n\ndata {\n  int Ntotal;                 // Numero di trial osservati\n  real trial[Ntotal];         // Indice del trial\n  real observed_goal[Ntotal]; // Obiettivi dichiarati\n  real performance[Ntotal];   // Performance ottenute\n}\nQui definiamo i dati raccolti nell’esperimento, cioè le informazioni che Stan utilizzerà per stimare il modello.\n\n44.3.5.2 2. parameters – “Cosa vogliamo scoprire”\n\nparameters {\n  real alpha;                 // Tasso di apprendimento (sensibilità al feedback)\n  real beta;                  // Tendenza sistematica\n  real&lt;lower=0&gt; sigma;        // Rumore decisionale\n}\nSono i parametri ignoti che Stan deve stimare sulla base dei dati.\n\n44.3.5.3 3. model – “Come funziona il processo”\n\nIn questo blocco specifichiamo sia le ipotesi a priori sia la dinamica trial-per-trial.\n(a) Priors: aspettative iniziali\nalpha ~ normal(0, 1);\nbeta  ~ normal(0, 1);\nsigma ~ normal(0, 1);\nPrima dei dati, ipotizziamo che \\(\\alpha\\) e \\(\\beta\\) siano vicini a zero, pur ammettendo un’ampia incertezza.\n(b) Aggiornamento sequenziale\nfor (i in 1:Ntotal) {\n  if (trial[i] == 1) {\n    predicted_goal = observed_goal[i]; // primo trial: usiamo l’osservato\n  } else {\n    predicted_goal += alpha * (performance[i-1] - predicted_goal) + beta;\n  }\n  observed_goal[i] ~ normal(predicted_goal, sigma);\n}\nAd ogni trial il modello aggiorna l’obiettivo previsto e lo confronta con quello effettivamente osservato.\n\n44.3.5.4 4. generated quantities – “E se simulassimo?”\n\nQuesto blocco permette di generare nuovi dati a partire dai parametri stimati, replicando la stessa dinamica ipotizzata dal modello.\ngenerated quantities {\n  real sampled_goal[Ntotal];\n  for (i in 1:Ntotal) {\n    sampled_goal[i] = normal_rng(predicted_goal, sigma);\n  }\n}\nLe traiettorie simulate hanno un duplice scopo: da un lato consentono i posterior predictive checks, cioè il confronto tra dati osservati e dati generati per valutare la plausibilità del modello; dall’altro offrono uno strumento per fare previsioni su come potrebbe evolvere il comportamento in situazioni nuove.\n\nIn sintesi, questo modello “apre la scatola nera” dei processi decisionali: trasforma osservazioni empiriche in parametri interpretabili, mostrando come feedback, tendenze personali e rumore si combinino nell’aggiornare gli obiettivi.\n\n44.3.5.5 Risultati finali e interpretazione\nL’analisi produce innanzitutto le distribuzioni posteriori dei parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma.\\) Queste non restituiscono un singolo valore, ma un insieme di possibilità plausibili da cui ricavare medie, intervalli credibili e sintesi utili all’interpretazione psicologica. In questo modo possiamo valutare quanto i partecipanti si adattino ai feedback (\\(\\alpha\\)), se mostrino derive sistematiche di crescita o declino negli obiettivi (\\(\\beta\\)) e quanta variabilità residua caratterizzi il loro processo decisionale (\\(\\sigma\\)).\nLa solidità delle stime viene garantita dagli indicatori diagnostici MCMC, come \\(\\hat{R}\\) per la convergenza e \\(n_{\\text{eff}}\\) per l’efficienza campionaria. Solo quando questi indici segnalano un campionamento affidabile le distribuzioni posteriori possono essere considerate attendibili.\nInfine, la validazione predittiva tramite i dati simulati nel blocco generated quantities consente un confronto diretto tra le traiettorie osservate e quelle generate dal modello. Questo passaggio, noto come posterior predictive check, è cruciale perché permette di verificare se il modello riproduce i pattern empirici e, quindi, di valutarne la plausibilità e la capacità esplicativa.\n\n44.3.6 Verso una modellizzazione più ricca: estensioni del modello base\nIl modello di base, pur essendo utile, è una rappresentazione semplificata. Per cogliere la reale eterogeneità del comportamento umano, sono state sviluppate diverse estensioni che mantengono il nucleo teorico originale, ma ne aumentano il potere esplicativo.\nModello a livello individuale. Stima parametri specifici (\\(\\alpha_i\\), \\(\\beta_i\\)) per ogni partecipante, consentendo di mappare differenze sistematiche nella sensibilità al feedback e nelle tendenze motivazionali.\nModelli gerarchici (multilevel). Stimano i parametri individuali come estratti da distribuzioni di gruppo. In questo modo si ottiene un duplice vantaggio: si preservano le differenze tra individui e, al tempo stesso, si guadagna robustezza statistica grazie alla condivisione di informazione (shrinkage). Ne risultano stime più stabili ed equilibrate, particolarmente preziose con campioni piccoli o dati rumorosi.\nModelli a gruppi noti. Permettono di stimare \\(\\alpha\\) e \\(\\beta\\) separatamente per diverse condizioni sperimentali (es., diversi tipi di incentivo), testando direttamente l’effetto di manipolazioni contestuali.\nModelli di mistura (Mixture Models). Identificano sottogruppi latenti di partecipanti con dinamiche distinte (es., “adattatori rapidi” vs. “perseveranti”) senza richiedere categorie predefinite.\nQueste estensioni, che approfondiremo nel capitolo successivo, spostano l’attenzione dalla semplice stima di una tendenza centrale alla modellizzazione della variabilità, trasformando le differenze individuali da rumore a informazione teoricamente cruciale. Il modello di base rimane un punto di riferimento concettuale, mentre le versioni avanzate ne aumentano la precisione nel catturare la complessità psicologica, mantenendo intatta l’idea centrale di un aggiornamento dinamico degli obiettivi guidato da feedback e inclinazioni personali.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#riflessioni-conclusive",
    "href": "chapters/formal_models/01_dynamic_models.html#riflessioni-conclusive",
    "title": "44  Il modello di revisione degli obiettivi",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’esempio discusso ha mostrato come concetti psicologici complessi, come la regolazione degli obiettivi, possano essere tradotti in modelli dinamici capaci di descrivere l’evoluzione temporale dei processi cognitivi. L’approccio integra tre componenti centrali: la formalizzazione teorica in equazioni, l’implementazione computazionale in Stan e l’inferenza bayesiana per stimare e valutare il modello sui dati.\nRispetto ai modelli statici, questa prospettiva consente di indagare non solo se il comportamento cambia, ma anche come e quando lo fa, e in risposta a quali condizioni. Pur nella sua semplicità, il modello discusso mette in evidenza il potenziale di una psicologia formale orientata a identificare i meccanismi generativi che sottendono i dati osservati.\nCome sottolineano Knight et al. (2023), un approccio di questo tipo si articola in tre passaggi: (1) la costruzione di un modello generativo che espliciti i meccanismi ipotizzati, (2) la traduzione delle ipotesi in codice eseguibile, e (3) la valutazione del modello non solo con indici statistici, ma anche attraverso il confronto tra dati osservati e simulati.\nUn modello può essere utile anche se semplice, purché soddisfi tre condizioni: si fonda su ipotesi teoriche esplicite, produce previsioni verificabili e resta estendibile per affrontare nuove domande di ricerca. Il modello sample-level discusso qui rappresenta dunque un punto di partenza che può evolvere introducendo parametri individuali, strutture gerarchiche o gruppi latenti per rilevare pattern nascosti.\nDal punto di vista didattico, questo capitolo mostra come le teorie psicologiche possano essere tradotte in equazioni formali da simulare, testare e validare empiricamente. Le ipotesi diventano così affermazioni quantitative verificabili, e l’attenzione si sposta dall’analisi di semplici correlazioni all’analisi dei processi dinamici.\nIn sintesi, la costruzione di modelli dinamici segna un passo verso una psicologia più rigorosa e cumulativa, capace di spiegare i fenomeni invece di limitarsi a descriverli, e di orientare la disciplina verso una vera scienza predittiva dei processi cognitivi e comportamentali.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n\nR version 4.5.1 (2025-06-13)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] C/UTF-8/C/C/C/C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.5.1    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.5.1       htmltools_0.5.8.1 rmarkdown_2.29    knitr_1.50       \n [9] jsonlite_2.0.0    xfun_0.53         digest_0.6.37     rlang_1.1.6      \n[13] evaluate_1.0.5",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#bibliografia",
    "href": "chapters/formal_models/01_dynamic_models.html#bibliografia",
    "title": "44  Il modello di revisione degli obiettivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHayes, S. C., Hofmann, S. G., Stanton, C. E., Carpenter, J. K., Sanford, B. T., Curtiss, J. E., & Ciarrochi, J. (2019). The role of the individual in the coming era of process-based therapy. Behaviour Research and Therapy, 117, 40–53.\n\n\nKnight, E., Neal, A., Palada, H., & Ballard, T. (2023). A Tutorial on Bayesian Modeling of Change Across Time, Individuals, and Groups. Computational Brain & Behavior, 6(4), 697–718.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html",
    "href": "chapters/formal_models/02_dynamic_models.html",
    "title": "45  Estensioni",
    "section": "",
    "text": "Introduzione\nSulla scia di Knight et al. (2023), in questo capitolo estendiamo il modello presentato in precedenza lungo tre direzioni complementari. Partiamo dal livello individuale (person-level), in cui stimiamo per ciascun partecipante i propri parametri \\((\\alpha_i, \\beta_i)\\). Questo passaggio consente di mappare l’eterogeneità interindividuale (sensibilità al feedback e deriva motivazionale), ma lascia le stime dei singoli isolate le une dalle altre.\nPer superare questo limite introduciamo la versione gerarchica (multilevel): i parametri dei singoli sono considerati estratti da distribuzioni di popolazione (es. normali) descritte da iper-parametri. In questo modo le informazioni vengono condivise tra individui, con il tipico effetto di shrinkage che stabilizza le stime, soprattutto quando i dati per soggetto sono pochi o rumorosi.\nInfine, consideriamo il caso dei gruppi noti (es. approach vs avoidance), stimando iper-parametri separati per ciascuna condizione. Questo permette di quantificare differenze sistematiche a livello di popolazione tra condizioni sperimentali, oltre alle differenze tra individui. Valuteremo i modelli con criteri predittivi (ELPD tramite LOO-CV), così da bilanciare in modo esplicito complessità e capacità di generalizzazione.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#introduzione",
    "href": "chapters/formal_models/02_dynamic_models.html#introduzione",
    "title": "45  Estensioni",
    "section": "",
    "text": "Panoramica del capitolo\n\n\nModello a livello individuale: stima di \\(\\alpha_i\\) e \\(\\beta_i\\) per ogni soggetto.\n\nModello gerarchico: parametri individuali estratti da distribuzioni di popolazione → shrinkage e maggiore robustezza.\n\nGruppi noti: iper-parametri specifici per condizione (approach vs avoidance).\n\nConfronto predittivo: ELPD e LOO-CV per scegliere il modello.\n\nImplicazioni psicologiche: quando e perché la gerarchia migliora l’inferenza.\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\nsuppressPackageStartupMessages({\n  library(cmdstanr)\n  library(bayesplot)\n  library(tidybayes)\n  library(posterior)\n  library(loo)\n  library(patchwork)\n  library(conflicted)\n})\n\nconflicts_prefer(loo::loo)\nconflicts_prefer(dplyr::count)\n\n\n\n\n\n45.0.1 Modello a livello individuale\nIl modello sample-level stima un unico insieme di parametri \\((\\alpha, \\beta)\\) per l’intero campione, ignorando le differenze individuali. Per cogliere questa eterogeneità, è possibile introdurre il modello a livello individuale (person-level), che stima parametri distinti \\((\\alpha_i, \\beta_i)\\) per ogni partecipante \\(i\\).\nIn questa formulazione:\n\nogni individuo possiede il proprio tasso di apprendimento \\(\\alpha_i\\) e la propria deriva motivazionale \\(\\beta_i\\);\nil parametro \\(\\sigma\\), che cattura la variabilità residua (rumore decisionale), rimane comune a tutti i soggetti.\n\nQuesto approccio consente di:\n\nmappare la variabilità interindividuale nei processi di aggiornamento degli obiettivi;\nidentificare profili comportamentali distinti (es. soggetti molto reattivi al feedback vs. poco adattivi);\nevitare l’assunzione – spesso irrealistica – che tutti i partecipanti rispondano allo stesso modo.\n\nTuttavia, il modello a livello individuale non incorpora alcun meccanismo di “condivisione dell’informazione” tra i soggettii, ma ogni partecipante viene modellato in modo indipendente dagli altri. Questa caratteristica lo distingue dal modello gerarchico (o multilevel), in cui i parametri individuali sono considerati provenienti da una distribuzione di gruppo, il che migliora la robustezza delle stime, soprattutto quando i dati sono limitati o rumorosi.\n\n45.0.2 Preparazione dei dati\n\n# Caricamento del dataset\ndat &lt;- rio::import(\"data/goal_data.csv\")\n\n# Ordina i dati per soggetto e per trial\ndat &lt;- dat |&gt; \n  arrange(subject, trial)\n\n# (Opzionale) Verifica che l'ordinamento sia corretto\nstr(dat)\n#&gt; 'data.frame':    600 obs. of  5 variables:\n#&gt;  $ subject    : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ condition  : chr  \"approach\" \"approach\" \"approach\" \"approach\" ...\n#&gt;  $ goal       : int  2 2 2 4 4 2 2 4 2 4 ...\n#&gt;  $ performance: int  0 2 2 4 2 0 4 2 4 4 ...\n#&gt;  $ trial      : int  1 2 3 4 5 6 7 8 9 10 ...\n\n\ntable(dat$subject)  # restituisce il numero di trial per soggetto\n#&gt; \n#&gt;  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n#&gt; 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 \n#&gt; 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 \n#&gt; 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 \n#&gt; 53 54 55 56 57 58 59 60 \n#&gt; 10 10 10 10 10 10 10 10\n\n\n# 1) Ordina per soggetto e trial\ndat &lt;- dat %&gt;% arrange(subject, trial)\n\n# 2) Salva scale originali (per eventuale back-transform)\ngoal_mean &lt;- mean(dat$goal, na.rm = TRUE); goal_sd &lt;- sd(dat$goal, na.rm = TRUE)\nperf_mean &lt;- mean(dat$performance, na.rm = TRUE); perf_sd &lt;- sd(dat$performance, na.rm = TRUE)\n\n# 3) Standardizza\ndat &lt;- dat %&gt;%\n  mutate(\n    goal_z = (goal - goal_mean) / goal_sd,\n    perf_z = (performance - perf_mean) / perf_sd\n  )\n\n# 4) Lista per Stan (condition è opzionale qui: non usata nel baseline)\nstan_data &lt;- list(\n  subject       = dat$subject,\n  trial         = dat$trial,\n  observed_goal = dat$goal_z,\n  performance   = dat$perf_z,\n  Nsubj         = dplyr::n_distinct(dat$subject),\n  Ntotal        = nrow(dat)\n)\n\nstr(stan_data)\n#&gt; List of 6\n#&gt;  $ subject      : int [1:600] 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ trial        : int [1:600] 1 2 3 4 5 6 7 8 9 10 ...\n#&gt;  $ observed_goal: num [1:600] -2 -2 -2 -1.07 -1.07 ...\n#&gt;  $ performance  : num [1:600] -2.89 -1.99 -1.99 -1.1 -1.99 ...\n#&gt;  $ Nsubj        : int 60\n#&gt;  $ Ntotal       : int 600\n\n\n45.0.3 Definizione del modello Stan\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; Ntotal;                 // es. 600\n  int&lt;lower=1&gt; Nsubj;                  // es. 60\n  array[Ntotal] int&lt;lower=1&gt; subject;  // indice soggetto (1..Nsubj)\n  array[Ntotal] int&lt;lower=1&gt; trial;    // 1..T per ciascun soggetto (ordinati)\n  vector[Ntotal] observed_goal;        // Z-score\n  vector[Ntotal] performance;          // Z-score\n}\n\nparameters {\n  vector[Nsubj] alpha;                 // guadagno per soggetto\n  vector[Nsubj] beta;                  // drift per soggetto\n  real&lt;lower=1e-6&gt; sigma;              // dev. std residua (comune)\n}\n\ntransformed parameters {\n  vector[Ntotal] ghat;                 // traiettoria predetta\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      // reset a inizio soggetto: primo stato = prima osservazione\n      ghat[i] = observed_goal[i];\n    } else {\n      int s = subject[i];\n      // ricorsione: usa predizione e performance del trial precedente (stesso soggetto se i dati sono ordinati)\n      ghat[i] = ghat[i - 1]\n                + alpha[s] * (performance[i - 1] - ghat[i - 1])\n                + beta[s];\n    }\n  }\n}\n\nmodel {\n  // Priors semplici coerenti con z-score\n  alpha ~ normal(0, 1);\n  beta  ~ normal(0, 1);\n  sigma ~ normal(0, 1);   // half-normal(1) per via del lower bound\n\n  // Likelihood\n  observed_goal ~ normal(ghat, sigma);\n}\n\ngenerated quantities {\n  vector[Ntotal] yrep;\n  vector[Ntotal] log_lik;\n\n  for (i in 1:Ntotal) {\n    yrep[i]   = normal_rng(ghat[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);\n  }\n}\n\"\n\nQuesto modello presuppone che i dati siano ordinati per soggetto e per trial, altrimenti la dinamica i - 1 non corrisponde al trial precedente dello stesso soggetto.\nEsaminiamo in dettaglio cosa significano alpha[subject[i]] e beta[subject[i]]. Nel modello Stan, ogni trial i è associato a un certo soggetto. Questa informazione è contenuta nel vettore:\narray[Ntotal] int&lt;lower=1&gt; subject;\n\nstan_data$subject\n#&gt;   [1]  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  3  3  3  3  3\n#&gt;  [26]  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5\n#&gt;  [51]  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8\n#&gt;  [76]  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10\n#&gt; [101] 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13\n#&gt; [126] 13 13 13 13 13 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15\n#&gt; [151] 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18\n#&gt; [176] 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20\n#&gt; [201] 21 21 21 21 21 21 21 21 21 21 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23\n#&gt; [226] 23 23 23 23 23 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25\n#&gt; [251] 26 26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 28 28 28 28 28\n#&gt; [276] 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30\n#&gt; [301] 31 31 31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 32 32 33 33 33 33 33\n#&gt; [326] 33 33 33 33 33 34 34 34 34 34 34 34 34 34 34 35 35 35 35 35 35 35 35 35 35\n#&gt; [351] 36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37 37 37 38 38 38 38 38\n#&gt; [376] 38 38 38 38 38 39 39 39 39 39 39 39 39 39 39 40 40 40 40 40 40 40 40 40 40\n#&gt; [401] 41 41 41 41 41 41 41 41 41 41 42 42 42 42 42 42 42 42 42 42 43 43 43 43 43\n#&gt; [426] 43 43 43 43 43 44 44 44 44 44 44 44 44 44 44 45 45 45 45 45 45 45 45 45 45\n#&gt; [451] 46 46 46 46 46 46 46 46 46 46 47 47 47 47 47 47 47 47 47 47 48 48 48 48 48\n#&gt; [476] 48 48 48 48 48 49 49 49 49 49 49 49 49 49 49 50 50 50 50 50 50 50 50 50 50\n#&gt; [501] 51 51 51 51 51 51 51 51 51 51 52 52 52 52 52 52 52 52 52 52 53 53 53 53 53\n#&gt; [526] 53 53 53 53 53 54 54 54 54 54 54 54 54 54 54 55 55 55 55 55 55 55 55 55 55\n#&gt; [551] 56 56 56 56 56 56 56 56 56 56 57 57 57 57 57 57 57 57 57 57 58 58 58 58 58\n#&gt; [576] 58 58 58 58 58 59 59 59 59 59 59 59 59 59 59 60 60 60 60 60 60 60 60 60 60\n\nOgni elemento subject[i] ci dice a quale soggetto appartiene il trial i, usando un numero intero da 1 a Nsubj. Quindi se subject[137] == 24, significa che il 137-esimo trial è del soggetto 24.\nOra, se abbiamo un vettore di parametri specifici per ogni soggetto\nvector[Nsubj] alpha;\nvector[Nsubj] beta;\nallora\n\n\nalpha[subject[i]] significa: prendi il valore del parametro alpha associato al soggetto a cui appartiene il trial i;\nlo stesso vale per beta[subject[i]].\n\nPer esempio, supponiamo\nsubject = [1, 1, 1, 2, 2, 3, 3]\nalpha = [0.5, 0.8, 1.1]  // Tre soggetti: 1, 2, 3\nallora\n\n\nalpha[subject[4]] = alpha[2] = 0.8, perché il 4° trial è del soggetto 2.\n\nbeta[subject[6]] = beta[3] = ..., perché il 6° trial è del soggetto 3.\n\nIn sintesi, la sintassi alpha[subject[i]] (e beta[subject[i]]) indica: “Nel trial i, usa il valore del parametro alpha (o beta) del soggetto indicato da subject[i]”. È un modo compatto per associare ogni osservazione ai parametri della persona corrispondente.\n\n45.0.4 Compilazione ed esecuzione del modello\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\n\nfit1 &lt;- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 5000,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  seed = 4790\n)\n\n\n45.0.5 Analisi dei risultati\nQuesto modello genera un insieme di campioni posteriori per i parametri \\(\\alpha\\) e \\(\\beta\\), uno per ciascun partecipante.\nEstrazione dei campioni in formato “draws_matrix” (per summary tabellari):\n\nstandraws &lt;- fit1$draws(format = \"draws_matrix\")\n\nStatistiche descrittive compatte per \\(\\alpha_i\\), \\(\\beta_i\\) e \\(\\sigma\\): media, mediana e intervalli credibili al 95% (2.5% - 97.5%):\n\nstandraws |&gt; \n  subset_draws(variable = c(\"alpha\", \"beta\", \"sigma\")) |&gt; \n  summarise_draws(\n    mean,\n    ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n  ) |&gt; \n  print()\n#&gt; # A tibble: 121 × 5\n#&gt;    variable   mean `2.5%` `50%` `97.5%`\n#&gt;    &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1 alpha[1]  0.662  0.161 0.683   1.022\n#&gt;  2 alpha[2]  0.181 -0.265 0.178   0.595\n#&gt;  3 alpha[3]  0.167 -0.251 0.186   0.507\n#&gt;  4 alpha[4]  0.300 -0.515 0.303   0.950\n#&gt;  5 alpha[5]  0.400  0.056 0.399   0.744\n#&gt;  6 alpha[6]  0.586 -0.001 0.613   1.043\n#&gt;  7 alpha[7]  0.408  0.121 0.406   0.750\n#&gt;  8 alpha[8]  0.119 -0.077 0.109   0.343\n#&gt;  9 alpha[9]  0.487  0.009 0.487   0.927\n#&gt; 10 alpha[10] 0.811  0.440 0.811   1.109\n#&gt; # ℹ 111 more rows\n\nDiagnostica rapida (Rhat ed ESS):\n\n# Se qualche Rhat &gt; 1.01 o ESS basso, considerare run più lunghi o reparametrizzazioni\nfit1$summary(variables = c(\"alpha\", \"beta\", \"sigma\")) |&gt;\n  dplyr::select(variable, rhat, ess_bulk, ess_tail) |&gt;\n  dplyr::arrange(dplyr::desc(rhat)) |&gt;\n  print(n = 10)\n#&gt; # A tibble: 121 × 4\n#&gt;    variable   rhat ess_bulk ess_tail\n#&gt;    &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 alpha[34] 1.177   14.956   10.927\n#&gt;  2 beta[47]  1.168   15.789   17.071\n#&gt;  3 beta[34]  1.168   15.618   11.197\n#&gt;  4 alpha[47] 1.163   16.778   17.192\n#&gt;  5 beta[46]  1.157   17.028   18.453\n#&gt;  6 beta[56]  1.141   19.034   26.829\n#&gt;  7 alpha[56] 1.141   19.378   43.006\n#&gt;  8 beta[40]  1.124   21.218   71.730\n#&gt;  9 beta[32]  1.122   20.397   22.425\n#&gt; 10 beta[26]  1.120   20.658   27.604\n#&gt; # ℹ 111 more rows\n\nEstrazione “tidy” dei parametri livello-persona con tidybayes::spread_draws. Questo produce le colonne: .draw, subject, alpha, beta.\n\nposteriors_person = spread_draws(fit1, alpha[subject], beta[subject])\n\nCalcolo della media e dell’intervallo credibile al 95% per ciascun soggetto:\n\n# Calcolo media e intervallo credibile al 95% per ciascun soggetto\nCIs_person &lt;- posteriors_person %&gt;%\n  group_by(subject) %&gt;%\n  summarise(\n    across(c(alpha, beta), list(\n      lower = ~quantile(.x, 0.025),\n      mean  = ~mean(.x),\n      upper = ~quantile(.x, 0.975)\n    ), .names = \"{.col}_{.fn}\")\n  ) %&gt;%\n  arrange(alpha_mean) %&gt;%\n  mutate(alpha_order = row_number()) %&gt;%\n  arrange(beta_mean) %&gt;%\n  mutate(beta_order = row_number())\n\nGrafico 1: CI al 95% per \\(\\alpha_i\\), ordinati per alpha_mean:\n\nplot_person_alpha = ggplot(data=CIs_person) +\n  geom_point(aes(y=alpha_order,x=alpha_mean)) +\n  geom_errorbarh(aes(y=alpha_order,xmin=alpha_lower,xmax=alpha_upper),color=\"red\") +\n  labs(x= expression(alpha) ,y=\"Subject\") \n\n\n\n\n\n\n\n\n\nGrafico 2: CI al 95% per \\(\\beta_i\\), ordinati per beta_mean:\n\nplot_person_beta &lt;- ggplot(data = CIs_person) +\n  geom_point(aes(y = beta_order, x = beta_mean)) +\n  geom_errorbarh(aes(y = beta_order, xmin = beta_lower, xmax = beta_upper), color = \"red\") +\n  labs(x = expression(beta), y = \"Subject\") \n\n\n\n\n\n\n\n\n\nGrafico 3: Dispersione bivariata (alpha_mean vs beta_mean) + croci di CI 95%. Le barre (verticali e orizzontali) danno il colpo d’occhio sulla (co)variabilità individuale:\n\nplot_person_alphabeta = ggplot(data=CIs_person) +\n  geom_point(aes(x=alpha_mean,y=beta_mean)) +\n  geom_errorbar(aes(x=alpha_mean,ymin=beta_lower,ymax=beta_upper),color=\"red\",alpha=0.25) +\n  geom_errorbarh(aes(y=beta_mean,xmin=alpha_lower,xmax=alpha_upper),color=\"red\",alpha=0.25) +\n  labs(x= expression(alpha) ,y=expression(beta)) \n\n\n\n\n\n\n\n\n\nI grafici mostrano una marcata eterogeneità tra i partecipanti nei parametri \\(\\alpha\\) (tasso di apprendimento) e \\(\\beta\\) (drift motivazionale), con intervalli credibili al 95% calcolati per ciascun \\(\\alpha_i\\) e \\(\\beta_i\\).\n\n\nPer \\(\\alpha\\): i partecipanti mostrano valori distribuiti lungo quasi tutto l’intervallo [0,1]. Alcuni soggetti hanno \\(\\alpha\\) molto vicino a 0 (poca sensibilità al feedback), mentre altri si avvicinano a 1 (forte aggiornamento in risposta all’errore). L’ampiezza degli intervalli credibili varia, ma nella maggior parte dei casi suggerisce stime sufficientemente informative.\n\nPer \\(\\beta\\): i valori si distribuiscono attorno a 0, ma con differenze individuali marcate: alcuni soggetti mostrano un drift positivo (tendenza ad aumentare sistematicamente gli obiettivi), altri un drift negativo (tendenza a ridurli). Gli intervalli credibili confermano questa eterogeneità.\nIl punto chiave è che questa variabilità non può essere colta dal modello sample-level. Quest’ultimo, stimando un unico \\(\\alpha\\) e un unico \\(\\beta\\) comuni a tutti, restituisce una sorta di “media” del comportamento dei partecipanti. In pratica:\n\nun soggetto con \\(\\alpha \\approx 0\\) e uno con \\(\\alpha \\approx 0.9\\) verrebbero descritti dallo stesso parametro \\(\\alpha\\), che potrebbe cadere a metà strada ma non rappresenta bene né l’uno né l’altro;\nanalogamente, le derive motivazionali individuali \\(\\beta\\) (positive, negative o vicine a zero) verrebbero tutte appiattite su un valore medio.\n\nI grafici dimostrano quindi l’utilità del modello a livello individuale: esso permette di mappare differenze sostanziali tra soggetti, che nel modello a livello di campione vengono perse.\nIn sintesi:\n\nil modello sample-level offre una descrizione parsimoniosa, ma rischia di mascherare differenze psicologicamente importanti;\nil modello person-level mostra che i partecipanti non solo differiscono nel grado di apprendimento dal feedback (\\(\\alpha\\)), ma anche nella direzione e nell’intensità della deriva motivazionale (\\(\\beta\\));\nquesta eterogeneità costituisce un’informazione preziosa per comprendere i profili comportamentali individuali, impossibile da cogliere con un modello che assume parametri omogenei per tutto il campione.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#modello-gerarchico",
    "href": "chapters/formal_models/02_dynamic_models.html#modello-gerarchico",
    "title": "45  Estensioni",
    "section": "\n45.1 Modello gerarchico",
    "text": "45.1 Modello gerarchico\nStimare i parametri per ogni partecipante separatamente (come nel modello a livello individuale) permette di rappresentare le differenze individuali, ma presenta un limite cruciale: le stime rimangono isolate. Analizzare i dati “persona per persona” equivale a condurre un’analisi indipendente per ciascun soggetto, senza “riutilizzare” le informazioni presenti negli altri individui. Ciò riduce il potere statistico, aumenta la variabilità delle stime quando i dati per soggetto sono pochi e rende più difficile trarre conclusioni a livello di popolazione.\nIn molti contesti, però, l’interesse del ricercatore non è solo quello di descrivere le differenze tra gli individui, ma anche di cogliere le regolarità comuni alla popolazione. Per questo motivo, i modelli gerarchici bayesiani (o multilevel) offrono una soluzione particolarmente efficace (Turner et al., 2013; Vincent, 2016; Kruschke & Vanpaemel, 2015).\nL’idea di fondo è semplice:\n\ni parametri individuali (es. \\(\\alpha_s, \\beta_s\\)) sono trattati come variabili casuali, non come quantità del tutto indipendenti;\nciascuno di essi è estratto da una distribuzione a livello di popolazione, descritta da iper-parametri (\\(\\alpha_{\\text{mean}}, \\alpha_{\\text{sd}}\\), ecc.);\nin questo modo, le stime individuali sono “informate” sia dai dati del singolo soggetto sia dalla tendenza generale osservata nel campione (Lewandowsky & Farrell, 2011).\n\nIl risultato è una regolarizzazione: i valori estremi vengono attenuati verso la media di popolazione (shrinkage), riducendo il rischio che stime instabili o rumorose abbiano troppo peso. Si ottengono così inferenze più robuste e interpretabili, specialmente in campioni piccoli o con dati per soggetto limitati (Boehm et al., 2018; Rouder & Lu, 2005).\n\n45.1.1 Definizione del modello Stan\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; Ntotal;\n  int&lt;lower=1&gt; Nsubj;\n  array[Ntotal] int&lt;lower=1&gt; subject;\n  array[Ntotal] int&lt;lower=1&gt; trial;\n  vector[Ntotal] observed_goal;   // z-score\n  vector[Ntotal] performance;     // z-score\n}\n\nparameters {\n  // Iper-parametri di popolazione\n  real alpha_mean;\n  real&lt;lower=0&gt; alpha_sd;\n  real beta_mean;\n  real&lt;lower=0&gt; beta_sd;\n\n  // Non-centrato: fattori standard per i soggetti\n  vector[Nsubj] alpha_raw;\n  vector[Nsubj] beta_raw;\n\n  real&lt;lower=1e-6&gt; sigma;\n}\n\ntransformed parameters {\n  // Ricostruzione parametri individuali\n  vector[Nsubj] alpha_unconstrained = alpha_mean + alpha_sd * alpha_raw;\n  vector[Nsubj] beta  = beta_mean  + beta_sd  * beta_raw;\n\n  // Vincolo morbido su alpha per stabilità\n  vector[Nsubj] alpha = 0.95 * tanh(alpha_unconstrained);\n\n  vector[Ntotal] ghat;\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      ghat[i] = observed_goal[i];\n    } else {\n      int s = subject[i];\n      ghat[i] = ghat[i - 1]\n                + alpha[s] * (performance[i - 1] - ghat[i - 1])\n                + beta[s];\n    }\n  }\n}\n\nmodel {\n  // Iper-priori debolmente informativi (coerenti con z-score)\n  alpha_mean ~ normal(0, 0.5);\n  alpha_sd   ~ exponential(1);\n  beta_mean  ~ normal(0, 0.5);\n  beta_sd    ~ exponential(1);\n\n  alpha_raw  ~ normal(0, 1);\n  beta_raw   ~ normal(0, 1);\n\n  sigma ~ student_t(3, 0, 0.5);\n\n  // Likelihood\n  observed_goal ~ normal(ghat, sigma);\n}\n\ngenerated quantities {\n  vector[Ntotal] yrep;\n  vector[Ntotal] log_lik;\n  for (i in 1:Ntotal) {\n    yrep[i]    = normal_rng(ghat[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);\n  }\n}\n\"\n\n\n45.1.2 Differenza chiave rispetto al modello precedente\nNel Person-Level Model i parametri individuali sono stimati in modo indipendente; qui, invece, valgono relazioni del tipo:\n\\[\n\\alpha_s \\sim \\mathcal{N}(\\alpha_{\\text{mean}}, \\alpha_{\\text{sd}}), \\quad\n\\beta_s \\sim \\mathcal{N}(\\beta_{\\text{mean}}, \\beta_{\\text{sd}})\n\\]\nQuesta struttura gerarchica introduce un livello di vincolo che collega i soggetti tra loro. Il vantaggio è duplice:\n\nsi mantengono le differenze individuali;\nsi sfrutta la somiglianza tra soggetti per ottenere stime più stabili e inferenze a livello di popolazione.\n\n45.1.3 Compilazione ed esecuzione\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\n\nfit2 &lt;- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  chains = 4, parallel_chains = 4,\n  seed = 4790,\n  refresh = 500,\n  adapt_delta = 0.995,  # riduce divergenze\n  max_treedepth = 15\n)\n\n\n45.1.4 Analisi dei risultati\nEseguiamo l’analisi dei risultati seguendo lo schema usato sopra.\n\n# Estrazione dei campioni posteriori come matrice \nstandraws &lt;- fit2$draws(format = \"draws_matrix\")\n\n\n# Statistiche descrittive aggregate\nstandraws |&gt; \n  subset_draws(variable = c(\"alpha\", \"beta\", \"sigma\", \"alpha_mean\", \"beta_mean\", \"alpha_sd\", \"beta_sd\")) |&gt; \n  summarise_draws(\n    mean,\n    ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n  )\n#&gt; # A tibble: 125 × 5\n#&gt;    variable   mean `2.5%` `50%` `97.5%`\n#&gt;    &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1 alpha[1]  0.576  0.292 0.587   0.795\n#&gt;  2 alpha[2]  0.385  0.059 0.393   0.664\n#&gt;  3 alpha[3]  0.320  0.019 0.328   0.582\n#&gt;  4 alpha[4]  0.490  0.145 0.505   0.749\n#&gt;  5 alpha[5]  0.367  0.096 0.371   0.621\n#&gt;  6 alpha[6]  0.552  0.257 0.563   0.775\n#&gt;  7 alpha[7]  0.467  0.215 0.471   0.704\n#&gt;  8 alpha[8]  0.221  0.015 0.216   0.459\n#&gt;  9 alpha[9]  0.510  0.209 0.520   0.754\n#&gt; 10 alpha[10] 0.637  0.425 0.644   0.812\n#&gt; # ℹ 115 more rows\n\n\n# Estrai le draw per i parametri individuali (alpha e beta per ciascun soggetto)\nposteriors_person &lt;- spread_draws(fit2, alpha[subject], beta[subject])\n\n\n# Calcolo degli intervalli credibili per ciascun soggetto\nCIs_person &lt;- posteriors_person %&gt;%\n  group_by(subject) %&gt;%\n  summarise(\n    across(c(alpha, beta), list(\n      lower = ~quantile(.x, 0.025),\n      mean  = ~mean(.x),\n      upper = ~quantile(.x, 0.975)\n    ), .names = \"{.col}_{.fn}\")\n  ) %&gt;%\n  arrange(alpha_mean) %&gt;%\n  mutate(alpha_order = row_number()) %&gt;%\n  arrange(beta_mean) %&gt;%\n  mutate(beta_order = row_number())\n\n\n# Grafico: intervalli credibili per alpha\nplot_person_alpha &lt;- ggplot(CIs_person) +\n  geom_point(aes(y = alpha_order, x = alpha_mean)) +\n  geom_errorbarh(aes(y = alpha_order, xmin = alpha_lower, xmax = alpha_upper), color = \"red\") +\n  labs(x = expression(alpha), y = \"Soggetto\") \n\n# Grafico: intervalli credibili per beta\nplot_person_beta &lt;- ggplot(CIs_person) +\n  geom_point(aes(y = beta_order, x = beta_mean)) +\n  geom_errorbarh(aes(y = beta_order, xmin = beta_lower, xmax = beta_upper), color = \"red\") +\n  labs(x = expression(beta), y = \"Soggetto\") \n\n# Grafico: relazione tra alpha e beta per ciascun soggetto\nplot_person_alphabeta &lt;- ggplot(CIs_person) +\n  geom_point(aes(x = alpha_mean, y = beta_mean)) +\n  geom_errorbar(aes(x = alpha_mean, ymin = beta_lower, ymax = beta_upper), color = \"red\", alpha = 0.25) +\n  geom_errorbarh(aes(y = beta_mean, xmin = alpha_lower, xmax = alpha_upper), color = \"red\", alpha = 0.25) +\n  labs(x = expression(alpha), y = expression(beta)) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInfine, calcoliamo le stime a posteriori degli iper-parametri:\n\n# Riassunto per alpha_mean e beta_mean con intervallo al 95%\nstandraws |&gt;\n  subset_draws(variable = c(\"alpha_mean\", \"beta_mean\")) |&gt;\n  summarise_draws(\n    mean,\n    ~quantile(.x, probs = c(0.025, 0.975))\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   variable    mean `2.5%` `97.5%`\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 alpha_mean 0.621  0.521   0.732\n#&gt; 2 beta_mean  0.114  0.049   0.176\n\n\n45.1.4.1 Interpretazione\nIl modello gerarchico bayesiano fornisce inferenze a due livelli:\n\n\nLivello individuale: parametri \\(\\alpha_s\\) e \\(\\beta_s\\) per ciascun partecipante, con i relativi intervalli credibili.\n\nLivello di popolazione: distribuzioni a priori/posteriori degli iper-parametri \\(\\alpha_{\\text{mean}}, \\alpha_{\\text{sd}}, \\beta_{\\text{mean}}, \\beta_{\\text{sd}}\\), più il parametro residuo \\(\\sigma\\).\n\nI grafici per \\(\\alpha\\) e \\(\\beta\\) mostrano chiaramente l’eterogeneità interindividuale, mentre gli iper-parametri descrivono la tendenza generale.\nRispetto a un modello puramente individuale, gli intervalli credibili delle stime soggettive risultano meno dispersi e più regolari. Questo fenomeno è noto come shrinkage: le stime dei singoli soggetti sono “attirate” verso la media della popolazione, riducendo l’impatto dei dati rumorosi o scarsi.\nNel grafico bivariato, lo shrinkage si traduce in una distribuzione più compatta dei punti attorno al centro della distribuzione collettiva. L’effetto principale è una maggiore robustezza delle inferenze: le stime estreme vengono mitigate, la variabilità non plausibile è penalizzata e la capacità di generalizzare a nuovi dati risulta rafforzata (Boehm et al., 2018).",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#differenze-tra-gruppi",
    "href": "chapters/formal_models/02_dynamic_models.html#differenze-tra-gruppi",
    "title": "45  Estensioni",
    "section": "\n45.2 Differenze tra gruppi",
    "text": "45.2 Differenze tra gruppi\nIn questo terzo modello estendiamo la struttura gerarchica introducendo le condizioni sperimentali (approach vs avoidance). L’idea è che i parametri individuali \\(\\alpha_s\\) e \\(\\beta_s\\) non siano estratti da un’unica distribuzione comune, ma da distribuzioni diverse a seconda del gruppo di appartenenza del soggetto.\nIn questo modo possiamo stimare, per ciascuna condizione, una media e una deviazione standard a livello di popolazione:\n\n\n\\(\\alpha_{\\text{mean},c}, \\alpha_{\\text{sd},c}\\),\n\n\\(\\beta_{\\text{mean},c}, \\beta_{\\text{sd},c}\\) con \\(c \\in \\{1,2\\}\\).\n\n\n45.2.1 Preparazione dei dati\n\n# 1) Ordina per soggetto e trial\ndat &lt;- dat %&gt;% arrange(subject, trial)\n\n# 2) Codifica la condizione come intero (1 = approach, 2 = avoidance)\ndat &lt;- dat %&gt;%\n  mutate(cond_id = as.integer(factor(condition)))\n\n# Verifica che ogni soggetto appartenga a una sola condizione\nchk &lt;- dat %&gt;% distinct(subject, cond_id) %&gt;% count(subject) %&gt;% filter(n &gt; 1)\nstopifnot(nrow(chk) == 0)  # se fallisce, il design non è between-subject\n\n# 3) Standardizza goal e performance su tutto il dataset\ngoal_mean &lt;- mean(dat$goal, na.rm = TRUE); goal_sd &lt;- sd(dat$goal, na.rm = TRUE)\nperf_mean &lt;- mean(dat$performance, na.rm = TRUE); perf_sd &lt;- sd(dat$performance, na.rm = TRUE)\n\ndat &lt;- dat %&gt;%\n  mutate(\n    goal_z = (goal - goal_mean) / goal_sd,\n    perf_z = (performance - perf_mean) / perf_sd\n  )\n\n# 4) Vettore che assegna a ciascun soggetto la sua condizione\nsubjects &lt;- sort(unique(dat$subject))\nsubj_cond &lt;- dat %&gt;%\n  group_by(subject) %&gt;%\n  summarise(cond = first(cond_id), .groups = \"drop\") %&gt;%\n  arrange(subject) %&gt;%\n  pull(cond)\n\n# 5) Lista per Stan\nstan_data &lt;- list(\n  Ntotal        = nrow(dat),\n  Nsubj         = length(subjects),\n  C             = length(unique(dat$cond_id)),   # numero condizioni\n  subject       = dat$subject,\n  trial         = dat$trial,\n  observed_goal = dat$goal_z,\n  performance   = dat$perf_z,\n  subj_cond     = subj_cond\n)\n\nstr(stan_data)\n#&gt; List of 8\n#&gt;  $ Ntotal       : int 600\n#&gt;  $ Nsubj        : int 60\n#&gt;  $ C            : int 2\n#&gt;  $ subject      : int [1:600] 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ trial        : int [1:600] 1 2 3 4 5 6 7 8 9 10 ...\n#&gt;  $ observed_goal: num [1:600] -2 -2 -2 -1.07 -1.07 ...\n#&gt;  $ performance  : num [1:600] -2.89 -1.99 -1.99 -1.1 -1.99 ...\n#&gt;  $ subj_cond    : int [1:60] 1 2 2 1 2 1 2 1 2 1 ...\n\n\n45.2.2 Definizione del modello Stan\n\nstancode &lt;- \"\n// Modello gerarchico con iper-parametri specifici per condizione\ndata {\n  int&lt;lower=1&gt; Ntotal;\n  int&lt;lower=1&gt; Nsubj;\n  int&lt;lower=1&gt; C;                            // numero condizioni\n  array[Ntotal] int&lt;lower=1&gt; subject;        // 1..Nsubj\n  array[Ntotal] int&lt;lower=1&gt; trial;          // 1..T all'interno di soggetto\n  vector[Ntotal] observed_goal;              // z-score\n  vector[Ntotal] performance;                // z-score\n  array[Nsubj] int&lt;lower=1, upper=C&gt; subj_cond; // condizione per soggetto\n}\n\nparameters {\n  // Iper-parametri per condizione\n  vector[C] alpha_mean;\n  vector&lt;lower=0&gt;[C] alpha_sd;\n  vector[C] beta_mean;\n  vector&lt;lower=0&gt;[C] beta_sd;\n\n  // Non-centrato: fattori standard per soggetti\n  vector[Nsubj] alpha_raw;\n  vector[Nsubj] beta_raw;\n\n  real&lt;lower=1e-6&gt; sigma;\n}\n\ntransformed parameters {\n  vector[Nsubj] alpha_uncon;\n  vector[Nsubj] beta;\n  vector[Nsubj] alpha;           \n  vector[Ntotal] ghat;\n\n  // Ricostruzione dei parametri individuali in base alla condizione\n  for (s in 1:Nsubj) {\n    int c = subj_cond[s];\n    alpha_uncon[s] = alpha_mean[c] + alpha_sd[c] * alpha_raw[s];\n    beta[s]        = beta_mean[c]  + beta_sd[c]  * beta_raw[s];\n    alpha[s]       = 0.95 * tanh(alpha_uncon[s]); // vincolo di stabilità\n  }\n\n  // Dinamica\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      ghat[i] = observed_goal[i];\n    } else {\n      int s = subject[i];\n      ghat[i] = ghat[i - 1]\n                + alpha[s] * (performance[i - 1] - ghat[i - 1])\n                + beta[s];\n    }\n  }\n}\n\nmodel {\n  // Iper-priori debolmente informativi\n  alpha_mean ~ normal(0, 0.5);\n  alpha_sd   ~ exponential(1);\n  beta_mean  ~ normal(0, 0.5);\n  beta_sd    ~ exponential(1);\n\n  alpha_raw  ~ normal(0, 1);\n  beta_raw   ~ normal(0, 1);\n\n  sigma ~ student_t(3, 0, 0.5);\n\n  // Likelihood\n  observed_goal ~ normal(ghat, sigma);\n}\n\ngenerated quantities {\n  vector[Ntotal] yrep;\n  vector[Ntotal] log_lik;\n  for (i in 1:Ntotal) {\n    yrep[i]    = normal_rng(ghat[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | ghat[i], sigma);\n  }\n}\n\"\n\n\n45.2.3 Come funziona la distinzione tra gruppi\n\nAssegnazione condizione Nel blocco data, il vettore subj_cond assegna a ciascun soggetto il numero della condizione (1 = approach, 2 = avoidance).\n\nParametri di gruppo Gli iper-parametri alpha_mean[c], alpha_sd[c], beta_mean[c], beta_sd[c] sono specifici per condizione. Ad esempio:\n\n\nalpha_mean[1] = media di \\(\\alpha\\) per il gruppo approach\n\n\nalpha_mean[2] = media di \\(\\alpha\\) per il gruppo avoidance\n\n\n\nParametri individuali In transformed parameters, i parametri dei singoli soggetti vengono generati in base alla condizione di appartenenza. Così, i soggetti approach e quelli avoidance condividono rispettivamente due diverse distribuzioni di partenza.\n\nIn sintesi, il modello permette di stimare non solo le differenze tra individui, ma anche le differenze sistematiche tra condizioni sperimentali.\n\n45.2.4 Compilazione ed esecuzione\n\nstanmod &lt;- cmdstan_model(write_stan_file(stancode), compile = TRUE)\n\n\nfit3 &lt;- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 5000,\n  chains = 4, parallel_chains = 4,\n  seed = 123,\n  adapt_delta = 0.999,   # ↑ riduce divergenze\n  max_treedepth = 15\n)\n\n\n45.2.5 Risultati\n\n45.2.5.1 Ispezione rapida delle variabili (opzionale)\n\ndraws_df &lt;- as_draws_df(fit3$draws())   # oppure: fit3$draws(format = \"df\")\nnames(draws_df)[grepl(\"alpha_mean|beta_mean|alpha\\\\[|beta\\\\[\", names(draws_df))]\n#&gt;   [1] \"alpha_mean[1]\" \"alpha_mean[2]\" \"beta_mean[1]\"  \"beta_mean[2]\" \n#&gt;   [5] \"beta[1]\"       \"beta[2]\"       \"beta[3]\"       \"beta[4]\"      \n#&gt;   [9] \"beta[5]\"       \"beta[6]\"       \"beta[7]\"       \"beta[8]\"      \n#&gt;  [13] \"beta[9]\"       \"beta[10]\"      \"beta[11]\"      \"beta[12]\"     \n#&gt;  [17] \"beta[13]\"      \"beta[14]\"      \"beta[15]\"      \"beta[16]\"     \n#&gt;  [21] \"beta[17]\"      \"beta[18]\"      \"beta[19]\"      \"beta[20]\"     \n#&gt;  [25] \"beta[21]\"      \"beta[22]\"      \"beta[23]\"      \"beta[24]\"     \n#&gt;  [29] \"beta[25]\"      \"beta[26]\"      \"beta[27]\"      \"beta[28]\"     \n#&gt;  [33] \"beta[29]\"      \"beta[30]\"      \"beta[31]\"      \"beta[32]\"     \n#&gt;  [37] \"beta[33]\"      \"beta[34]\"      \"beta[35]\"      \"beta[36]\"     \n#&gt;  [41] \"beta[37]\"      \"beta[38]\"      \"beta[39]\"      \"beta[40]\"     \n#&gt;  [45] \"beta[41]\"      \"beta[42]\"      \"beta[43]\"      \"beta[44]\"     \n#&gt;  [49] \"beta[45]\"      \"beta[46]\"      \"beta[47]\"      \"beta[48]\"     \n#&gt;  [53] \"beta[49]\"      \"beta[50]\"      \"beta[51]\"      \"beta[52]\"     \n#&gt;  [57] \"beta[53]\"      \"beta[54]\"      \"beta[55]\"      \"beta[56]\"     \n#&gt;  [61] \"beta[57]\"      \"beta[58]\"      \"beta[59]\"      \"beta[60]\"     \n#&gt;  [65] \"alpha[1]\"      \"alpha[2]\"      \"alpha[3]\"      \"alpha[4]\"     \n#&gt;  [69] \"alpha[5]\"      \"alpha[6]\"      \"alpha[7]\"      \"alpha[8]\"     \n#&gt;  [73] \"alpha[9]\"      \"alpha[10]\"     \"alpha[11]\"     \"alpha[12]\"    \n#&gt;  [77] \"alpha[13]\"     \"alpha[14]\"     \"alpha[15]\"     \"alpha[16]\"    \n#&gt;  [81] \"alpha[17]\"     \"alpha[18]\"     \"alpha[19]\"     \"alpha[20]\"    \n#&gt;  [85] \"alpha[21]\"     \"alpha[22]\"     \"alpha[23]\"     \"alpha[24]\"    \n#&gt;  [89] \"alpha[25]\"     \"alpha[26]\"     \"alpha[27]\"     \"alpha[28]\"    \n#&gt;  [93] \"alpha[29]\"     \"alpha[30]\"     \"alpha[31]\"     \"alpha[32]\"    \n#&gt;  [97] \"alpha[33]\"     \"alpha[34]\"     \"alpha[35]\"     \"alpha[36]\"    \n#&gt; [101] \"alpha[37]\"     \"alpha[38]\"     \"alpha[39]\"     \"alpha[40]\"    \n#&gt; [105] \"alpha[41]\"     \"alpha[42]\"     \"alpha[43]\"     \"alpha[44]\"    \n#&gt; [109] \"alpha[45]\"     \"alpha[46]\"     \"alpha[47]\"     \"alpha[48]\"    \n#&gt; [113] \"alpha[49]\"     \"alpha[50]\"     \"alpha[51]\"     \"alpha[52]\"    \n#&gt; [117] \"alpha[53]\"     \"alpha[54]\"     \"alpha[55]\"     \"alpha[56]\"    \n#&gt; [121] \"alpha[57]\"     \"alpha[58]\"     \"alpha[59]\"     \"alpha[60]\"\n\n\n45.2.5.2 Differenze tra condizioni sugli iper-parametri\nL’obiettivo è verificare se i parametri di popolazione \\(\\alpha\\) (tasso di aggiornamento) e \\(\\beta\\) (drift/tendenza) differiscono tra le due condizioni sperimentali (approach vs avoidance). Per rispondere a questa domanda procediamo in quattro passaggi:\n1. recuperiamo le etichette delle condizioni dal dataset;\n2. calcoliamo il contrasto tra condizioni (\\(\\Delta =\\) condizione\\(_2\\) − condizione\\(_1\\));\n3. stimiamo la media della differenza, il 95% CrI e la probabilità a posteriori che la differenza sia negativa;\n4. visualizziamo i risultati per facilitarne l’interpretazione.\n\n45.2.5.2.1 Step 1. Etichette di condizione\n\ncond_labels &lt;- dat %&gt;%\n  distinct(cond_id, condition) %&gt;%\n  arrange(cond_id) %&gt;%\n  pull(condition)\n\ncond_labels\n#&gt; [1] \"approach\"  \"avoidance\"\n# Esempio: c(\"approach\", \"avoidance\")\n\n\n45.2.5.2.2 Step 2. Contrasto su α (media per condizione)\nCalcoliamo \\(\\Delta_\\alpha = \\alpha_{\\text{avoidance}} - \\alpha_{\\text{approach}}\\).\n\ndelta_alpha &lt;- fit3 |&gt;\n  spread_draws(alpha_mean[cond]) |&gt;\n  mutate(cond = factor(cond, levels = 1:2, labels = cond_labels)) |&gt;\n  pivot_wider(names_from = cond, values_from = alpha_mean, names_prefix = \"alpha_mean_\") |&gt;\n  mutate(delta_alpha_mean = alpha_mean_avoidance - alpha_mean_approach)\n\ndelta_alpha |&gt; \n  summarise(\n    mean   = mean(delta_alpha_mean),\n    low95  = quantile(delta_alpha_mean, 0.025),\n    upp95  = quantile(delta_alpha_mean, 0.975),\n    p_lt0  = mean(delta_alpha_mean &lt; 0)\n  )\n#&gt; # A tibble: 1 × 4\n#&gt;     mean  low95   upp95 p_lt0\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 -0.247 -0.481 -0.0349 0.989\n\n\n45.2.5.2.3 Step 3. Contrasto su β (media per condizione)\nIn modo analogo, calcoliamo \\(\\Delta_\\beta = \\beta_{\\text{avoidance}} - \\beta_{\\text{approach}}\\).\n\ndelta_beta &lt;- fit3 |&gt;\n  spread_draws(beta_mean[cond]) |&gt;\n  mutate(cond = factor(cond, levels = 1:2, labels = cond_labels)) |&gt;\n  pivot_wider(names_from = cond, values_from = beta_mean, names_prefix = \"beta_mean_\") |&gt;\n  mutate(delta_beta_mean = beta_mean_avoidance - beta_mean_approach)\n\ndelta_beta |&gt; \n  summarise(\n    mean   = mean(delta_beta_mean),\n    low95  = quantile(delta_beta_mean, 0.025),\n    upp95  = quantile(delta_beta_mean, 0.975),\n    p_lt0  = mean(delta_beta_mean &lt; 0)\n  )\n#&gt; # A tibble: 1 × 4\n#&gt;     mean  low95   upp95 p_lt0\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 -0.126 -0.251 0.00152 0.974\n\n\n45.2.5.2.4 Step 4. Visualizzazione delle posterior\n\npost_alpha &lt;- fit3 |&gt;\n  spread_draws(alpha_mean[cond]) |&gt;\n  mutate(parameter = \"alpha_mean\",\n         condition = factor(cond, levels = 1:2, labels = cond_labels)) |&gt;\n  rename(value = alpha_mean)\n\npost_beta &lt;- fit3 |&gt;\n  spread_draws(beta_mean[cond]) |&gt;\n  mutate(parameter = \"beta_mean\",\n         condition = factor(cond, levels = 1:2, labels = cond_labels)) |&gt;\n  rename(value = beta_mean)\n\nposterior_both &lt;- bind_rows(post_alpha, post_beta)\n\nggplot(posterior_both, aes(x = value, fill = condition)) +\n  geom_density(alpha = 0.6) +\n  facet_wrap(~parameter, scales = \"free\") +\n  labs(x = \"Posterior mean\", y = \"Density\", fill = \"Condition\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n45.2.5.2.5 Risultati numerici\n\nprob_delta_alpha_neg &lt;- mean(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]` &lt; 0)\nprob_delta_beta_neg  &lt;- mean(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]` &lt; 0)\n\ncat(\"P(delta_alpha_mean &lt; 0):\", round(prob_delta_alpha_neg, 3), \"\\n\")\n#&gt; P(delta_alpha_mean &lt; 0): 0.989\ncat(\"P(delta_beta_mean &lt; 0):\", round(prob_delta_beta_neg, 3), \"\\n\")\n#&gt; P(delta_beta_mean &lt; 0): 0.974\n\nsummary_df &lt;- tibble(\n  parameter = c(\"alpha_mean\", \"beta_mean\"),\n  delta_mean = c(\n    mean(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`),\n    mean(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`)\n  ),\n  lower_95 = c(\n    quantile(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`, 0.025),\n    quantile(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`, 0.025)\n  ),\n  upper_95 = c(\n    quantile(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`, 0.975),\n    quantile(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`, 0.975)\n  ),\n  prob_below_0 = c(prob_delta_alpha_neg, prob_delta_beta_neg)\n)\n\nsummary_df\n#&gt; # A tibble: 2 × 5\n#&gt;   parameter  delta_mean lower_95 upper_95 prob_below_0\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1 alpha_mean     -0.247   -0.481 -0.0349         0.989\n#&gt; 2 beta_mean      -0.126   -0.251  0.00152        0.974\n\n\nsummary_df |&gt; \n  ggplot(aes(x = parameter, y = delta_mean)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", width = 0.5) +\n  geom_errorbar(aes(ymin = lower_95, ymax = upper_95), width = 0.2) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(\n    x = \"Parametro\",\n    y = \"Differenza media\\n(cond2 - cond1)\"\n  )\n\n\n\n\n\n\n\n\n45.2.5.2.6 Interpretazione dei risultati\n\n\\(\\Delta_\\alpha\\) (avoidance − approach) Media = −0.247; CrI 95% = [−0.481, −0.035]; \\(P(\\Delta&lt;0) = 0.989\\). → Evidenza forte che l’aggiornamento (\\(\\alpha\\)) è più basso in avoidance. L’effetto è moderato (≈0.25 SD).\n\\(\\Delta_\\beta\\) (avoidance − approach) Media = −0.126; CrI 95% = [−0.251, 0.002]; \\(P(\\Delta&lt;0) = 0.974\\). → La probabilità che \\(\\beta\\) sia più basso in avoidance è elevata, ma l’intervallo credibile include lo zero. Evidenza suggestiva ma non conclusiva.\n\n45.2.5.2.7 Significato sostantivo\n\nIn avoidance, i partecipanti aggiornano più lentamente le loro credenze (α più basso).\nAnche la tendenza (β) appare più bassa, ma con incertezza residua.\n\nQuesti risultati indicano che la manipolazione sperimentale ha un impatto soprattutto sulla velocità di apprendimento, mentre l’effetto sulla componente di drift resta da confermare con più dati o modelli più sensibili.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#confronto-tra-modelli",
    "href": "chapters/formal_models/02_dynamic_models.html#confronto-tra-modelli",
    "title": "45  Estensioni",
    "section": "\n45.3 Confronto tra modelli",
    "text": "45.3 Confronto tra modelli\nPer valutare quale modello descriva meglio i dati abbiamo utilizzato la cross-validazione leave-one-out (LOO-CV), che stima la expected log predictive density (ELPD). Un ELPD più alto indica predizioni più accurate.\n\nlog_lik1 &lt;- fit1$draws(variables = \"log_lik\", format = \"matrix\")\nlog_lik2 &lt;- fit2$draws(variables = \"log_lik\", format = \"matrix\")\nlog_lik3 &lt;- fit3$draws(variables = \"log_lik\", format = \"matrix\")\n\n# Calcola LOO per ciascun modello\nloo1 &lt;- loo(log_lik1)\nloo2 &lt;- loo(log_lik2)\nloo3 &lt;- loo(log_lik3)\n\n# Confronto tra i modelli\nmodel_comparison &lt;- loo_compare(loo1, loo2, loo3)\nprint(model_comparison)\n#&gt;        elpd_diff se_diff\n#&gt; model3   0.0       0.0  \n#&gt; model2  -4.7       3.9  \n#&gt; model1 -23.2       7.6\n\nIl modello gerarchico con condizione (Model 3) ottiene la predizione migliore. Tuttavia, il confronto con il modello gerarchico senza condizione (Model 2) mostra una differenza di ELPD pari a −4.7, con un errore standard di 3.9. Questa differenza è piccola rispetto all’incertezza della stima, quindi non possiamo affermare con sicurezza che includere la condizione migliori la predizione, anche se la tendenza è in quella direzione.\nDiverso il discorso per il modello non gerarchico (Model 1): la perdita di ELPD rispetto a Model 3 è molto ampia (−23.3, con SE = 7.6). In questo caso la differenza è sufficientemente grande da concludere che Model 1 produce predizioni nettamente peggiori.\n\n45.3.0.1 Cosa impariamo\n\nLa gerarchia è cruciale: i modelli gerarchici (Model 2 e 3) descrivono i dati molto meglio del modello non gerarchico. Questo conferma l’importanza di “condividere informazione” tra soggetti per ottenere stime più stabili e predizioni più accurate.\nL’effetto della condizione è plausibile, ma non certo: il modello con condizione (Model 3) tende a comportarsi meglio, ma il vantaggio rispetto al modello gerarchico semplice (Model 2) non è statisticamente robusto. Questo risultato è coerente con le stime dei parametri: la differenza tra condizioni sembra più marcata per \\(\\alpha\\), meno per \\(\\beta\\).\n\nScelta del modello:\n\nse l’obiettivo principale è la parsimonia, Model 2 è già soddisfacente;\nse vogliamo testare esplicitamente l’effetto della condizione, Model 3 è preferibile, anche se il guadagno predittivo rimane incerto.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#riflessioni-conclusive",
    "href": "chapters/formal_models/02_dynamic_models.html#riflessioni-conclusive",
    "title": "45  Estensioni",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo seguito un percorso dal singolo al collettivo, aumentando la struttura del modello in modo controllato:\n\nPerson-level: stime soggetto-specifiche di \\((\\alpha_i, \\beta_i)\\) rivelano una marcata eterogeneità tra individui (diversa velocità di aggiornamento e diversa deriva). Il prezzo da pagare è l’assenza di condivisione dell’informazione: le stime restano fragili quando i dati per soggetto sono scarsi.\nGerarchico: trattando i parametri individuali come variabili casuali provenienti da distribuzioni di popolazione, otteniamo inferenze più stabili e generalizzabili. Lo shrinkage attenua gli estremi non supportati dai dati, migliora le stime dei singoli e fornisce contemporaneamente un quadro di popolazione.\nGruppi noti: introducendo iper-parametri per condizione, isoliamo differenze sistematiche tra gruppi a livello di popolazione. I risultati indicano effetti credibili soprattutto su \\(\\alpha\\) (velocità di aggiornamento), con evidenza più incerta su \\(\\beta\\), coerentemente con l’idea che la manipolazione sperimentale incida primariamente sui processi di apprendimento.\n\nSul piano predittivo, il confronto tramite ELPD/LOO-CV mostra che la gerarchia è cruciale: i modelli multilevel predicono i dati sensibilmente meglio del modello non gerarchico. Il vantaggio del modello con condizione rispetto al gerarchico semplice è orientato nella direzione attesa ma di entità modesta rispetto all’incertezza della stima: utile quando l’obiettivo è testare l’effetto sperimentale, meno decisivo se si privilegia la parsimonia.\nTre messaggi metodologici:\n\n\nProgettare la struttura: scegliere un livello di complessità che rifletta la dipendenza naturale dei dati (tra individui e tra condizioni), evitando sia l’eccesso di libertà sia il vincolo eccessivo.\n\nInferenza come integrazione: combinare informazione individuale e di popolazione produce stime più affidabili e interpretazioni più chiare.\n\nValutazione predittiva: selezionare i modelli con criteri out-of-sample (ELPD/LOO) allinea la scelta del modello all’obiettivo della generalizzazione.\n\nIn sintesi, passare da person-level a gerarchie con gruppi noti non è solo un affinamento tecnico: è un cambiamento concettuale verso modelli che rappresentano la popolazione, rispettano l’eterogeneità e quantificano con rigore le differenze tra condizioni. Questo impianto pone basi solide per ulteriori estensioni (p.es. mixture per identificare sottogruppi latenti, strutture più ricche di dipendenza temporale), mantenendo come bussola la capacità predittiva e la coerenza psicologica delle ipotesi.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] R.utils_2.13.0        Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [46] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [49] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [58] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [64] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [73] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [76] R.methodsS3_1.8.2     digest_0.6.37         TH.data_1.1-4        \n#&gt; [79] htmlwidgets_1.6.4     farver_2.1.2          R.oo_1.27.1          \n#&gt; [82] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#bibliografia",
    "href": "chapters/formal_models/02_dynamic_models.html#bibliografia",
    "title": "45  Estensioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKnight, E., Neal, A., Palada, H., & Ballard, T. (2023). A Tutorial on Bayesian Modeling of Change Across Time, Individuals, and Groups. Computational Brain & Behavior, 6(4), 697–718.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html",
    "href": "chapters/formal_models/03_rescorla_wagner.html",
    "title": "46  Il modello di Rescorla–Wagner",
    "section": "",
    "text": "Introduzione\nQuesto capitolo introduce il modello di Rescorla–Wagner (RW) con regola di scelta Softmax (Rescorla & Wagner, 1972), come naturale estensione del modello di revisione degli obiettivi discusso nel capitolo precedente. Nel modello precedente l’aggiornamento era un termine additivo guidato da una discrepanza osservata; qui l’aggiornamento diventa esplicitamente guidato dall’errore di predizione del rinforzo (reward prediction error, RPE), ossia la differenza tra rinforzo ottenuto e rinforzo atteso. Questa formulazione è più psicologicamente plausibile e allineata all’evidenza in psicologia e neuroscienze: si impara proporzionalmente a quanto l’esito sorprende le aspettative.\nAccanto al livello di apprendimento (aggiornamento dei valori associativi \\(Q\\)), introduciamo il livello decisionale: le scelte non sono deterministiche, ma riflettono un compromesso fra sfruttamento dell’opzione migliore ed esplorazione di alternative. Con due opzioni, la Softmax si riduce a una logistica della differenza \\(Q_B-Q_A\\), modulata dal parametro di inverse temperature \\(\\tau\\): valori alti di \\(\\tau\\) rendono le scelte più coerenti con \\(Q\\), valori bassi più esplorative.\nQuesta distinzione apprendimento–decisione è cruciale: consente di separare il meccanismo che aggiorna le aspettative (parametro \\(lr\\)) dal meccanismo che le traduce in probabilità di scelta (parametro \\(\\tau\\)). Nei paragrafi successivi mostreremo come simulare dati (es. probabilistic reversal learning), stimare i parametri con Stan e interpretare i profili individuali e di gruppo.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#introduzione",
    "href": "chapters/formal_models/03_rescorla_wagner.html#introduzione",
    "title": "46  Il modello di Rescorla–Wagner",
    "section": "",
    "text": "Preparazione del Notebook",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#il-modello-di-rescorlawagner",
    "href": "chapters/formal_models/03_rescorla_wagner.html#il-modello-di-rescorlawagner",
    "title": "46  Il modello di Rescorla–Wagner",
    "section": "\n46.1 Il Modello di Rescorla–Wagner",
    "text": "46.1 Il Modello di Rescorla–Wagner\nIl modello di Rescorla–Wagner (RW) è uno dei modelli più influenti nello studio dell’apprendimento associativo. Esso descrive come gli individui aggiornino le proprie aspettative in base all’esperienza, introducendo un meccanismo semplice ma potente che spiega fenomeni come acquisizione, estinzione e blocking.\nL’idea di fondo è che l’apprendimento si realizzi attraverso l’aggiornamento della forza associativa \\(Q_t(s)\\) di uno stimolo \\(s\\) al tempo \\(t\\), in funzione della discrepanza tra ciò che ci si aspettava e ciò che si è effettivamente osservato.\n\n46.1.1 Aggiornamento delle aspettative\nDopo ogni prova, la stima del valore viene modificata secondo la regola:\n\\[\nQ_{t+1}(s) \\;=\\; Q_t(s) \\;+\\; \\alpha \\, \\delta_t ,\n\\] dove\n\\[\n\\delta_t \\;=\\; R_t - Q_t(s)\n\\] è l’errore di previsione (prediction error), cioè la differenza tra la ricompensa ottenuta \\(R_t\\) e l’aspettativa precedente \\(Q_t(s)\\).\n\nSe \\(\\delta_t &gt; 0\\): la ricompensa è stata migliore del previsto → l’associazione si rafforza.\nSe \\(\\delta_t &lt; 0\\): la ricompensa è stata peggiore del previsto → l’associazione si indebolisce.\nSe \\(\\delta_t = 0\\): ciò che si è osservato coincide con l’attesa → nessun aggiornamento.\n\nIl parametro $ $ rappresenta il tasso di apprendimento (qui lo indichiamo con lr). Con lr alto l’aggiornamento è rapido; con lr basso è lento e più “conservativo”.\n\n\n\n\n\n\nVariante (facoltativa): tassi distinti per PE positivo/negativo\n\n\n\n\n\nIn alcune applicazioni si usano due tassi distinti \\(\\alpha^+\\) e \\(\\alpha^-\\) per apprendere diversamente da buone e cattive notizie. Questa distinzione consente di modellare la diversa sensibilità di individui o gruppi alle ricompense inattese rispetto alle punizioni o ai premi. Nel presente tutorial adottiamo un unico lr per semplicità e coerenza con il codice Stan.\n\n\n\n\n46.1.2 Dalla valutazione alla decisione\nAvere valori \\(Q_t(A)\\) e \\(Q_t(B)\\) diversi non implica che la scelta sia sempre deterministica. Gli individui possono alternare tra sfruttamento (scegliere l’opzione con valore atteso maggiore) ed esplorazione (provare opzioni alternative).\nCon due opzioni (A, B), la scelta è modellata come logistica della differenza di valore:\n\\[\nP(\\text{scegliere B}) = \\text{inv\\_logit}\\!\\big(\\tau \\,[Q_t(B)-Q_t(A)]\\big).\n\\] All’aumentare di \\(\\tau\\), anche piccole differenze \\(Q_t(B)-Q_t(A)\\) producono scelte quasi deterministiche; con \\(\\tau\\) bassa il comportamento è più esplorativo.\nIn sintesi, il modello di Rescorla–Wagner fornisce una descrizione formale e compatta di come gli individui apprendono in modo flessibile dalle proprie esperienze, adattando le aspettative e le decisioni in risposta ai cambiamenti dell’ambiente.\n\n\n\n\n\n\nApprofondimento: esplorazione vs. sfruttamento (logit a 2 opzioni)\n\n\n\n\n\nCon due opzioni, la Softmax si riduce a una logistica sulla differenza di valore. Useremo quindi \\(\\Delta Q = Q_B - Q_A\\) e modelleremo la probabilità di scegliere B come\n\\[\nP(B) = \\text{inv\\_logit}\\big(\\tau \\,\\Delta Q\\big),\n\\] dove \\(\\tau&gt;0\\) (inverse temperature) regola il compromesso esplorazione–sfruttamento:\n\n\n\\(\\tau\\) basso → comportamento esplorativo: anche differenze modeste non portano scelte deterministiche.\n\n\\(\\tau\\) alto → comportamento di sfruttamento: piccole differenze in \\(\\Delta Q\\) bastano per preferenze quasi certe.\n\nNel grafico seguente mostriamo la relazione tra \\(\\Delta Q\\) e \\(P(B)\\) per due valori di \\(\\tau\\).\n\n# Differenze di valore (coerenti con Q in [0,1] → ΔQ in [-1, 1])\ndq &lt;- seq(-1, 1, length.out = 201)\n\n# Logit a 2 opzioni (equivalente alla Softmax con K=2)\np_choose_B &lt;- function(dq, tau) plogis(tau * dq)\n\ndf &lt;- data.frame(\n  dq = rep(dq, 2),\n  prob_B = c(p_choose_B(dq, tau = 0.5),\n             p_choose_B(dq, tau = 5)),\n  tau = factor(rep(c(\"τ = 0.5 (alta esplorazione)\",\n                     \"τ = 5 (alto sfruttamento)\"),\n                   each = length(dq)))\n)\n\nggplot(df, aes(x = dq, y = prob_B, color = tau)) +\n  geom_line(size = 1.2) +\n  labs(\n    x = expression(Delta*Q[B-A]),\n    y = \"Probabilità di scegliere B\"\n  )\n\n\n\n\n\n\n\nLettura del grafico\n\n\nSe \\(\\Delta Q = 0.5\\):\n\ncon \\(\\tau = 0.5\\), \\(P(B) \\approx \\text{inv\\_logit}(0.25) \\approx 0.56\\) → decisione ancora esplorativa;\ncon \\(\\tau = 5\\), \\(P(B) \\approx \\text{inv\\_logit}(2.5) \\approx 0.92\\) → prevale lo sfruttamento.\n\n\n\nSe \\(\\Delta Q = 1\\):\n\ncon \\(\\tau = 0.5\\), \\(P(B) \\approx \\text{inv\\_logit}(0.5) \\approx 0.62\\);\ncon \\(\\tau = 5\\), \\(P(B) \\approx \\text{inv\\_logit}(5) \\approx 0.993\\), scelta quasi deterministica.\n\n\n\nQuesto esempio mostra come \\(\\tau\\) controlli la transizione tra esplorazione e sfruttamento nel caso binario (logit), coerente con il modello Stan usato nel tutorial.\n\n\n\n\n46.1.3 Identificabilità e scaling\nNella funzione Softmax conta solo la differenza tra i valori \\(Q\\). Se aggiungiamo la stessa costante \\(c\\) a entrambi (cioè \\(Q_t(s) + c\\)), le probabilità di scelta non cambiano.\nPer questo motivo:\n\nsi inizializzano di solito i valori in modo simmetrico (ad esempio \\(Q_0(A) = Q_0(B) = 0.5\\));\n\nsi mantengono i rinforzi nel range \\(\\{0,1\\}\\);\n\noppure si fissa un valore iniziale di riferimento, o si pongono vincoli su \\(\\beta\\).\n\nQueste scelte servono solo a rendere il modello ben definito, senza influenzare il comportamento osservato.\nNel presente tutorial il rinforzo è codificato come \\(R_t \\in \\{0,1\\}\\). In questo caso i valori \\(Q\\) convergono a stime di probabilità di ricompensa e risultano naturalmente in \\([0,1]\\). Con codifiche \\(\\{-1,+1\\}\\), i \\(Q\\) convergono a valori attesi in \\([-1,+1]\\) e occorre tenerne conto nell’interpretazione.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#simulazione",
    "href": "chapters/formal_models/03_rescorla_wagner.html#simulazione",
    "title": "46  Il modello di Rescorla–Wagner",
    "section": "\n46.2 Simulazione",
    "text": "46.2 Simulazione\nSimuliamo i dati in un compito di Probabilistic Reversal Learning (PRL). In questo compito il partecipante deve scegliere ripetutamente tra due stimoli:\n\nuno ricco, con probabilità di ricompensa \\(p=0.7\\);\nuno povero, con probabilità \\(1-p=0.3\\).\n\nA metà esperimento le probabilità vengono invertite (reversal): lo stimolo che prima era ricco diventa povero e viceversa. Il partecipante deve quindi adattarsi al cambiamento per massimizzare le ricompense.\n\n# Simulatore PRL (RW + logit) allineato al modello Stan (choice in 0/1)\nsimulate_prl_rw_binary &lt;- function(\n  n_trials        = 160,\n  p_reward_rich   = 0.7,\n  reversal_trial  = 80,            # se NULL, nessun reversal\n  lr              = 0.15,          # learning rate unico\n  tau             = 2,             # inverse temperature (decision noise)\n  Q0              = c(A = 0.0, B = 0.0),\n  seed            = 1234\n){\n  stopifnot(length(Q0) == 2, all(c(\"A\",\"B\") %in% names(Q0)))\n  set.seed(seed)\n  Q &lt;- Q0\n\n  choice   &lt;- integer(n_trials)   # 0 = A, 1 = B\n  reward   &lt;- integer(n_trials)   # 0/1\n  rich_is_A &lt;- rep.int(1L, n_trials) # 1 = A ricco, 0 = B ricco (inizio A ricco)\n  if (!is.null(reversal_trial)) {\n    rich_is_A[(reversal_trial + 1):n_trials] &lt;- 0L\n  }\n\n  Q_A &lt;- Q_B &lt;- pB_seq &lt;- pe_seq &lt;- numeric(n_trials)\n\n  for (t in seq_len(n_trials)) {\n    # probabilità di scegliere B (softmax logit a due opzioni)\n    pB &lt;- plogis(tau * (Q[\"B\"] - Q[\"A\"]))\n    choice[t] &lt;- rbinom(1, 1, pB)   # 1=B, 0=A\n\n    a_idx &lt;- if (choice[t] == 1L) 2L else 1L\n\n    # probabilità di ricompensa per l’opzione scelta\n    chosen_is_rich &lt;- (choice[t] == 0L && rich_is_A[t] == 1L) ||  \n                      (choice[t] == 1L && rich_is_A[t] == 0L)\n    pr &lt;- if (chosen_is_rich) p_reward_rich else (1 - p_reward_rich)\n\n    reward[t] &lt;- rbinom(1, 1, pr)\n\n    # prediction error e aggiornamento RW\n    pe &lt;- reward[t] - Q[a_idx]\n    Q[a_idx] &lt;- Q[a_idx] + lr * pe\n\n    Q_A[t]   &lt;- Q[\"A\"]\n    Q_B[t]   &lt;- Q[\"B\"]\n    pB_seq[t] &lt;- pB\n    pe_seq[t] &lt;- pe\n  }\n\n  tibble::tibble(\n    trial     = seq_len(n_trials),\n    choice    = choice,    # 0=A, 1=B\n    reward    = reward,    # 0/1\n    rich_is_A = rich_is_A, # 0/1\n    Q_A = Q_A, Q_B = Q_B, pB = pB_seq, pe = pe_seq\n  )\n}\n\nsim &lt;- simulate_prl_rw_binary()\n\nNota. La probabilità simulata coincide con quella dello Stan: \\(P(B)=\\text{inv\\_logit}\\!\\big(\\tau [Q(B)-Q(A)]\\big)\\). Anche l’aggiornamento usa lo stesso lr.\nVisualizziamo l’evoluzione dei valori associativi \\(Q\\):\n\n\n\n\n\n\n\n\n\n46.2.1 Interpretazione del grafico\nNella prima fase (trial 1–80), lo stimolo ricco (linea blu) riceve più ricompense e quindi accumula un valore \\(Q\\) più alto rispetto allo stimolo povero (linea verde).\nAl momento del reversal (linea verticale tratteggiata), le probabilità si invertono. Lo stimolo blu smette di essere vantaggioso e il suo valore \\(Q\\) scende, mentre lo stimolo verde cresce.\nQuesto andamento riflette il principio base del modello di Rescorla–Wagner:\n\ni valori associativi \\(Q\\) non sono fissi,\nvengono aggiornati trial per trial con una regola di apprendimento molto semplice:\n\n\\[\nQ_{\\text{nuovo}} = Q_{\\text{vecchio}} + lr \\times (reward - Q_{\\text{vecchio}}).\n\\] Il termine \\(reward - Q_{\\text{vecchio}}\\) è il prediction error (PE): la differenza tra ciò che si è osservato e ciò che ci si aspettava.\n\nSe il feedback è migliore del previsto (PE&gt;0), il valore \\(Q\\) aumenta.\nSe è peggiore del previsto (PE&lt;0), il valore diminuisce.\nIl learning rate lr regola di quanto il valore cambia a ogni prova.\n\nIl parametro tau controlla invece quanto le scelte sono “guidate” dai valori Q:\n\nse tau è grande → scelte più deterministiche (si sceglie quasi sempre lo stimolo con Q maggiore);\nse tau è piccolo → scelte più esplorative o rumorose.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#stima-bayesiana-con-stan",
    "href": "chapters/formal_models/03_rescorla_wagner.html#stima-bayesiana-con-stan",
    "title": "46  Il modello di Rescorla–Wagner",
    "section": "\n46.3 Stima Bayesiana con Stan",
    "text": "46.3 Stima Bayesiana con Stan\nNella simulazione conoscevamo i parametri generativi (lr=0.15, tau=2). Nella realtà, però, abbiamo solo i dati osservati:\n\nper ogni trial sappiamo quale scelta è stata fatta (choice=0 per A, choice=1 per B),\ne se il feedback è stato positivo o negativo (reward=1 oppure 0).\n\nI valori interni \\(Q\\) e i parametri del modello non sono osservabili: dobbiamo inferirli.\nL’ipotesi è che i dati derivino da un processo di tipo Rescorla–Wagner con regola di scelta logistica. L’obiettivo è quindi stimare, a partire dai soli dati:\n\nil learning rate lr, che regola la velocità di aggiornamento dei valori;\nl’inverse temperature tau, che controlla quanto le scelte sono coerenti con i valori Q.\n\n\n46.3.1 Codice Stan\n\nstancode_rw &lt;- \"\ndata {\n  int&lt;lower=1&gt; nTrials;                   // numero di prove\n  array[nTrials] int&lt;lower=0,upper=1&gt; choice; // scelte osservate (0=A, 1=B)\n  array[nTrials] real&lt;lower=0,upper=1&gt; reward; // ricompense osservate (0/1)\n}\n\ntransformed data {\n  vector[2] initV = rep_vector(0.0, 2);   // valori Q iniziali\n}\n\nparameters {\n  real&lt;lower=0,upper=1&gt; lr;   // learning rate\n  real&lt;lower=0,upper=3&gt; tau;  // inverse temperature (softmax / decision noise)\n}\n\nmodel {\n  vector[2] v = initV;        // valori Q correnti\n  real pe;                    // prediction error\n  real p;                     // probabilità di scelta =1 (stimolo B)\n\n  // Priors deboli ma informative\n  lr ~ beta(2, 10);           // learning rate vicino a valori piccoli\n  tau ~ lognormal(log(2), 0.5); // inverse temperature positiva\n\n  for (t in 1:nTrials) {\n    // Probabilità di scegliere B: logit della differenza Q_B - Q_A\n    p = inv_logit(tau * (v[2] - v[1]));\n    choice[t] ~ bernoulli(p);\n\n    // Prediction error e aggiornamento\n    int a = choice[t] + 1;     // 0→1 (A), 1→2 (B)\n    pe = reward[t] - v[a];\n    v[a] += lr * pe;\n  }\n}\n\"\n\nI prior scelti sono debolmente informativi ma coerenti con compiti PRL tipici (apprendimento moderato e scelte non eccessivamente rumorose). Possono essere resi più o meno conservativi in base al compito.\n\n46.3.2 Commento al codice Stan\n\nInizializzazione. All’inizio i due valori \\(Q[1]\\) e \\(Q[2]\\) (per A e B) sono fissati a 0. Rappresentano l’aspettativa iniziale: “nessuna preferenza”.\n\nProbabilità della scelta. Al trial \\(t\\), confrontiamo i due valori:\n\\[\np(B) = \\text{inv\\_logit}\\big(\\tau \\cdot (Q_B - Q_A)\\big).\n\\]\nQuesto significa che se \\(Q_B &gt; Q_A\\), aumenta la probabilità di scegliere B. Il parametro tau regola la “determinazione”:\n\nse tau è grande, basta una piccola differenza tra i due Q per portare a scelte quasi certe;\nse tau è piccolo, anche differenze grandi lasciano spazio all’esplorazione.\n\n\nValutazione della scelta osservata. La riga choice[t] ~ bernoulli(p) confronta la scelta osservata con la probabilità prevista. Questa è la verosimiglianza: se la scelta osservata è coerente con i Q correnti, il modello “ottiene credito”; se è incoerente, viene “penalizzato”.\n\nOsservazione dell’esito e prediction error. Dopo aver osservato il feedback, calcoliamo:\n\\[\nPE = reward[t] - Q[\\text{scelta}],\n\\]\nossia la differenza tra il risultato ricevuto e quello atteso.\n\n\nAggiornamento dei valori. Solo il Q corrispondente all’opzione scelta viene aggiornato:\n\\[\nQ_{\\text{nuovo}} = Q_{\\text{vecchio}} + lr \\cdot PE.\n\\]\n\nSe il feedback è migliore del previsto (PE&gt;0), il valore cresce.\nSe è peggiore del previsto (PE&lt;0), il valore diminuisce.\nIl learning rate lr determina di quanto cambia il valore a ogni trial.\n\n\n\n46.3.3 Esempio intuitivo\nImmagina di avere \\(Q_A = 0.6\\), \\(Q_B = 0.3\\) e tau=2. La differenza \\(Q_B - Q_A = -0.3\\). Il logit vale \\(-0.6\\), e quindi:\n\\[\np(B) = \\text{inv\\_logit}(-0.6) \\approx 0.35.\n\\] Quindi, il modello si aspetta che A venga scelto nel 65% dei casi.\nSe il soggetto sceglie effettivamente A, la verosimiglianza è alta. Se sceglie B, è possibile ma meno probabile: il modello aggiorna i valori interni in base al feedback ricevuto.\nIn questo tutorial useremo i dati simulati in precedenza:\n\nstan_data &lt;- list(\n  nTrials = nrow(sim),\n  choice  = as.integer(sim$choice),\n  reward  = as.numeric(sim$reward)   # 0/1 come real per coerenza con &lt;lower=0,upper=1&gt;\n)\nglimpse(stan_data)\n#&gt; List of 3\n#&gt;  $ nTrials: int 160\n#&gt;  $ choice : int [1:160] 0 1 1 0 1 1 0 0 0 0 ...\n#&gt;  $ reward : num [1:160] 1 0 0 1 0 0 0 0 1 1 ...\n\nCompiliamo il modello e eseguiamo il campionamento:\n\nmod_rw &lt;- cmdstanr::cmdstan_model(write_stan_file(stancode_rw))\nfit_rw &lt;- mod_rw$sample(\n  data = stan_data,\n  seed = 42,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 4000,\n  refresh = 200\n)\n\nEseguiamo le diagnostiche di campionamento:\n\nfit_rw$cmdstan_diagnose()  # controlli rapidi cmdstan\n#&gt; Checking sampler transitions treedepth.\n#&gt; Treedepth satisfactory for all transitions.\n#&gt; \n#&gt; Checking sampler transitions for divergences.\n#&gt; No divergent transitions found.\n#&gt; \n#&gt; Checking E-BFMI - sampler transitions HMC potential energy.\n#&gt; E-BFMI satisfactory.\n#&gt; \n#&gt; Rank-normalized split effective sample size satisfactory for all parameters.\n#&gt; \n#&gt; Rank-normalized split R-hat values satisfactory for all parameters.\n#&gt; \n#&gt; Processing complete, no problems detected.\n\nEsaminiamo la distribuzione a posteriori dei parametri:\n\nfit_rw$summary(c(\"lr\",\"tau\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lr       0.155  0.149 0.045 0.043 0.091 0.236 1.001 7735.557 7858.989\n#&gt; 2 tau      2.407  2.435 0.350 0.382 1.790 2.927 1.000 6866.231 4320.660",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#interpretazione-dei-risultati",
    "href": "chapters/formal_models/03_rescorla_wagner.html#interpretazione-dei-risultati",
    "title": "46  Il modello di Rescorla–Wagner",
    "section": "\n46.4 Interpretazione dei risultati",
    "text": "46.4 Interpretazione dei risultati\nLe distribuzioni a posteriori stimano quanto bene il modello è riuscito a recuperare i parametri generativi usati nella simulazione (lr = 0.15, tau = 2).\n\n\nlr (learning rate) regola la rapidità con cui il soggetto aggiorna le proprie aspettative dopo ogni feedback.\n\nValori alti → aggiornamenti rapidi: anche un singolo feedback può cambiare molto la stima del valore associato a uno stimolo.\nValori bassi → aggiornamenti lenti: il soggetto “conserva” più a lungo le esperienze passate, adattandosi solo gradualmente ai cambiamenti.\n\n\n\ntau (inverse temperature) controlla la coerenza delle scelte rispetto ai valori \\(Q\\).\n\nCon tau alto → le scelte sono quasi deterministiche: basta una piccola differenza tra \\(Q_A\\) e \\(Q_B\\) per indurre una preferenza netta.\nCon tau basso → il comportamento appare più esplorativo o rumoroso: anche se uno stimolo ha un valore più alto, non sempre viene scelto.\n\n\n\nNei grafici delle distribuzioni posteriori:\n\nle linee tratteggiate rappresentano i valori “veri” usati per simulare i dati,\nle distribuzioni stimate mostrano l’incertezza del modello sulle possibili soluzioni.\n\nQuando la distribuzione è ben centrata sulla linea tratteggiata e piuttosto stretta, significa che il modello ha recuperato bene il parametro. Distribuzioni più larghe o spostate indicano maggiore incertezza o possibili trade-off tra parametri (ad esempio: un lr leggermente diverso può essere compensato da un tau più basso o più alto producendo previsioni simili).\n\ndraws_df &lt;- fit_rw$draws(c(\"lr\",\"tau\")) |&gt;\n  as_draws_df() |&gt;\n  tibble::as_tibble()\n\ncols &lt;- c(lr = \"#5d5349\", tau = \"#4682B4\")\n\nplot_post &lt;- function(draws, param, col) {\n  ggplot(draws, aes(x = .data[[param]])) +\n    geom_histogram(aes(y = after_stat(density)), bins = 40,\n                   fill = col, color = \"black\", alpha = 0.6) +\n    geom_density(color = col, linewidth = 1) +\n    labs(x = param, y = \"Densità\", title = paste(\"Posterior di\", param))\n}\n\np_lr  &lt;- plot_post(draws_df, \"lr\",  cols[\"lr\"])\np_tau &lt;- plot_post(draws_df, \"tau\", cols[\"tau\"])\n\n\ntrue_vals &lt;- c(lr = 0.15, tau = 2)\np_lr  + geom_vline(xintercept = true_vals[\"lr\"],  linetype = 2)\n\n\n\n\n\n\np_tau + geom_vline(xintercept = true_vals[\"tau\"], linetype = 2)\n\n\n\n\n\n\n\nAttenzione ai possibili trade-off: in dataset brevi o con scarsa esplorazione, combinazioni diverse di lr e tau possono produrre predizioni simili (identificabilità parziale). Conviene sempre ispezionare tracce, R-hat, ESS e, se possibile, condurre posterior predictive checks.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#dal-parametro-allo-stile-cognitivo",
    "href": "chapters/formal_models/03_rescorla_wagner.html#dal-parametro-allo-stile-cognitivo",
    "title": "46  Il modello di Rescorla–Wagner",
    "section": "\n46.5 Dal parametro allo stile cognitivo",
    "text": "46.5 Dal parametro allo stile cognitivo\nI parametri del modello non sono soltanto numeri: possono essere interpretati come indicatori di stili di apprendimento e decisione.\n\n\nLearning rate (lr)\n\nUn soggetto con lr alto è molto sensibile ai singoli feedback: aggiorna le proprie aspettative in modo rapido e può adattarsi velocemente a un reversal. Esempio: basta un paio di esiti negativi perché abbandoni l’opzione che prima sembrava migliore.\nUn soggetto con lr basso aggiorna più lentamente: dà più peso all’esperienza accumulata e tende a mantenere le proprie scelte anche di fronte a segnali contrari. Esempio: continua a scegliere lo stimolo “vecchio ricco” anche dopo alcuni esiti negativi, adattandosi solo gradualmente.\n\n\n\nInverse temperature (tau)\n\nUn soggetto con tau alto si comporta in modo deterministico: sceglie quasi sempre l’opzione con il valore Q più alto. Questo corrisponde a uno stile “sfruttatore” (exploiter), focalizzato sul massimizzare subito i guadagni.\nUn soggetto con tau basso mostra un comportamento più esplorativo o rumoroso: anche se una delle due opzioni è chiaramente più vantaggiosa, di tanto in tanto sceglie l’altra. Questo stile può sembrare “incoerente”, ma in certi contesti favorisce l’esplorazione di alternative.\n\n\n\n\n46.5.1 Messaggio chiave\nL’approccio bayesiano permette di stimare, per ogni individuo, un profilo fatto di apprendimento (quanto velocemente aggiorna le proprie aspettative) e decisione (quanto coerentemente agisce in base a quelle aspettative).\nDifferenze sistematiche nei parametri tra gruppi sperimentali (es. stimoli emozionanti vs. neutri) o tra popolazioni cliniche e di controllo possono rivelare stili cognitivi distintivi:\n\ndifficoltà nell’adattarsi a nuovi feedback (lr basso),\noppure scelte troppo rigide o troppo esplorative (tau troppo alto o troppo basso).\n\nIn questo modo, un modello computazionale semplice come il Rescorla–Wagner con regola logistica non solo descrive i dati, ma fornisce anche una chiave di lettura psicologica dei processi sottostanti.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#contextual-bandits-e-compiti-food-vs.-neutral",
    "href": "chapters/formal_models/03_rescorla_wagner.html#contextual-bandits-e-compiti-food-vs.-neutral",
    "title": "46  Il modello di Rescorla–Wagner",
    "section": "\n46.6 Contextual Bandits e compiti food vs. neutral\n",
    "text": "46.6 Contextual Bandits e compiti food vs. neutral\n\nIl modello di Rescorla–Wagner con regola logistica, come visto nel tutorial, assume due parametri stabili per tutto il compito:\n\n\nlr, che regola la velocità con cui i valori \\(Q\\) vengono aggiornati,\n\ntau, che governa la coerenza delle scelte rispetto a tali valori.\n\nLa famiglia dei banditi contestuali rappresenta un’estensione naturale: i parametri non sono più fissi, ma possono variare in funzione del contesto. In pratica, lo stesso schema RW + logit viene applicato separatamente a diverse condizioni sperimentali (es. stimoli food vs. stimoli neutral, per un campione di pazienti anoressiche) o a diversi gruppi di partecipanti (es. clinici vs. controlli).\nQuesta estensione è stata applicata con successo nello studio dei disturbi alimentari. Analisi recenti hanno mostrato che i deficit di apprendimento in anoressia nervosa non sono globali, ma specifici del contesto alimentare:\n\ndi fronte a stimoli legati al cibo, le persone con anoressia tendono a mostrare un learning rate più basso, cioè aggiornano le aspettative più lentamente;\nnegli stessi compiti con stimoli neutri, invece, i parametri risultano simili a quelli dei controlli (Colpizzi et al., 2025).\n\nQuesta evidenza suggerisce che la vulnerabilità non consista in un deficit generale dei processi di apprendimento, ma in un’alterazione selettiva e contestuale, che contribuisce al mantenimento del disturbo.\nFormalmente, per il contesto \\(c \\in \\{\\text{food},\\text{neutral}\\}\\) si stima: \\[\nP_c(B_t)=\\text{inv\\_logit}\\!\\big(\\tau_c [Q_{c,t}(B)-Q_{c,t}(A)]\\big),\n\\] \\[\nQ_{c,t+1}(s)=Q_{c,t}(s)+lr_c \\,[R_{c,t}-Q_{c,t}(s)].\n\\] Il confronto tra \\(lr_{\\text{food}}\\) e \\(lr_{\\text{neutral}}\\) (e analogamente per \\(\\tau\\)) quantifica le differenze contestuali.\n\n46.6.1 Limiti e varianti minime\nIl modello di Rescorla–Wagner estende la semplice dinamica di aggiornamento introducendo un livello decisionale, che trasforma i valori appresi (Q-values) in probabilità di scelta. Questo ci permette di distinguere due componenti fondamentali del comportamento:\n\n\nApprendimento dagli esiti (learning), controllato dal parametro lr (learning rate), che determina quanto rapidamente il soggetto aggiorna le proprie aspettative in base all’errore di predizione (la differenza tra quanto atteso e quanto effettivamente ottenuto).\n\nUn valore basso di lr corrisponde a un apprendimento più lento e stabile, ma meno reattivo ai cambiamenti.\nUn valore alto di lr corrisponde a un adattamento veloce, ma a una maggiore sensibilità al rumore.\n\n\n\nPolitica decisionale (decision policy), governata dal parametro tau (inverse temperature), che regola la coerenza tra le scelte e i valori appresi.\n\n\ntau alto: scelte deterministiche e coerenti con l’opzione migliore (alto sfruttamento).\n\ntau basso: comportamento più esplorativo e meno prevedibile.\n\n\n\nQuesta distinzione è cruciale in ambito clinico. In uno studio sull’anoressia nervosa e l’apprendimento, ad esempio, abbiamo osservato che le difficoltà non sono generalizzate, ma specifiche del contesto alimentare: le pazienti presentano un tasso di apprendimento ridotto (lr più basso) quando gli stimoli sono legati al cibo, mentre il loro comportamento è simile a quello dei controlli in contesti neutri (Colpizzi et al., 2025).\nIl modello RW offre quindi un’analisi più ricca della semplice prestazione media:\n\nconsente di identificare differenze nei meccanismi di apprendimento (lr) tra diverse condizioni;\npermette di verificare se a queste diffeerenze si associano anche differenze nello stile decisionale (tau).\n\nPer uno psicologo, questo si traduce in due vantaggi concreti:\n\n\nChiarezza teorica: permette di formulare ipotesi precise e separate sui processi di apprendimento e sulle strategie decisionali, andando oltre le semplici misure di accuratezza.\n\nRilevanza clinica: distinguere un deficit nell’apprendimento da uno nella scelta ha implicazioni dirette per la progettazione di interventi mirati (es., potenziare la sensibilità al feedback o riequilibrare l’esplorazione e lo sfruttamento).\n\nIn sintesi, il modello Rescorla-Wagner non è solo uno strumento computazionale: è un ponte fra comportamento osservato e processi mentali, fondamentale per isolare deficit contestuali specifici e comprendere come le strategie decisionali varino tra individui e gruppi clinici.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [64] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [67] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [70] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [73] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [76] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [79] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#bibliografia",
    "href": "chapters/formal_models/03_rescorla_wagner.html#bibliografia",
    "title": "46  Il modello di Rescorla–Wagner",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nColpizzi, I., Sica, C., Marchetti, I., Guidi, L., Danti, S., Lucchesi, S., Giusti, E., Di Meglio, M., Ballardini, D., Mazzoni, C., et al. (2025). Food-specific decision-making in anorexia nervosa: a comparative study of clinical, at-risk, and healthy control groups. Eating Disorders, 1–19.\n\n\nRescorla, R. A., & Wagner, A. R. (1972). A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and non-reinforcement. Classical conditioning II, Current research and theory, 2, 64–69.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/04_study_method.html",
    "href": "chapters/formal_models/04_study_method.html",
    "title": "47  Decisione ottimale e utilità attesa: l’approccio bayesiano",
    "section": "",
    "text": "Introduzione\nL’analisi decisionale bayesiana offre un approccio strutturato per affrontare le scelte in condizioni di incertezza. L’idea di fondo è semplice: ogni alternativa possibile genera diversi esiti, ciascuno con una certa probabilità e con un valore associato in termini di utilità (quanto è desiderabile) o di perdita (quanto è costoso). La decisione migliore è quella che massimizza l’utilità attesa, oppure minimizza la perdita attesa, tenendo conto della distribuzione predittiva degli esiti.\nIn questo capitolo applicheremo questo quadro teorico a un problema vicino all’esperienza degli studenti di psicologia: la scelta del metodo di studio. Considereremo tre possibili strategie, che si differenziano per impegno richiesto ed efficacia prevista:\nGli esiti che ci interessano sono due: il voto d’esame (\\(g \\in [0,100]\\)) e le ore di studio necessarie (\\(h \\geq 0\\)). Entrambi sono caratterizzati da incertezza, legata sia alle differenze individuali (abilità, motivazione, stile di apprendimento), sia alla variabilità intrinseca del processo di studio.\nIl framework bayesiano ci consentirà di stimare la distribuzione congiunta di \\((g,h)\\) per ciascun metodo, di combinare voto e tempo in un’unica misura tramite una funzione di utilità. Per la discussione presente scegliamo la seguente funzione:\n\\[\nU(g,h;\\lambda) = g - \\lambda h,\n\\] dove \\(\\lambda \\geq 0\\) indica quanto “costa” un’ora di studio in termini di punti di voto. In questo modo potremo calcolare l’utilità attesa di ciascun metodo, integrando l’incertezza attraverso simulazioni, e infine identificare l’opzione che ha maggiore probabilità di rappresentare la scelta ottimale.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Decisione ottimale e utilità attesa: l’approccio bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/04_study_method.html#introduzione",
    "href": "chapters/formal_models/04_study_method.html#introduzione",
    "title": "47  Decisione ottimale e utilità attesa: l’approccio bayesiano",
    "section": "",
    "text": "Metodo classico: studio individuale su testi ed esercizi, senza supporti interattivi.\n\nMetodo di gruppo: lo stesso approccio classico, arricchito da discussioni in piccoli gruppi per chiarire e consolidare i contenuti.\n\nMetodo con AI tutor: studio su testi integrato con spiegazioni alternative, chat interattiva ed esercizi generati automaticamente da un tutor basato su intelligenza artificiale.\n\n\n\n\nPanoramica del capitolo\n\nLe quattro fasi dell’analisi decisionale bayesiana.\n\nModellare la distribuzione predittiva degli esiti.\n\nFormulare e interpretare una funzione di utilità.\n\nIdentificare la decisione ottimale.\n\nLimiti del modello lineare.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nPer un’introduzione alla loss function, si rimanda al capitolo Sampling the Imaginary di Statistical Rethinking (McElreath, 2020).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Additional packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(brms, posterior, loo, cmdstanr, stringr, tidyr)",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Decisione ottimale e utilità attesa: l’approccio bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/04_study_method.html#schema-in-quattro-passi",
    "href": "chapters/formal_models/04_study_method.html#schema-in-quattro-passi",
    "title": "47  Decisione ottimale e utilità attesa: l’approccio bayesiano",
    "section": "\n47.1 Schema in quattro passi",
    "text": "47.1 Schema in quattro passi\nSeguendo l’impostazione proposta da Gelman et al. (2013), l’analisi decisionale bayesiana si articola in quattro fasi: definizione del problema, modellazione degli esiti, specificazione della funzione di utilità e scelta della decisione ottimale. Nel nostro caso, queste fasi vengono applicate alla scelta del metodo di studio.\n1. Definizione delle alternative e degli esiti Le decisioni possibili sono tre: metodo classico, studio di gruppo e AI tutor. Ogni decisione porta a due esiti di interesse: il voto d’esame \\(g\\) (tra 0 e 100) e le ore di studio \\(h\\) (con \\(h \\geq 0\\)).\n2. Modellazione della distribuzione predittiva Per descrivere la variabilità dei risultati usiamo un modello gerarchico stimato da dati storici (ad esempio, i registri di studenti dell’anno precedente). Assumiamo che le ore di studio seguano una distribuzione lognormale, adatta a variabili non negative e asimmetriche, mentre il voto dipende dalle ore in modo sublineare, riflettendo rendimenti decrescenti: inizialmente ogni ora extra produce un buon guadagno, ma col tempo l’effetto si attenua.\n3. Funzione di utilità Per confrontare i metodi su un’unica scala, combiniamo voto e ore in una funzione di utilità lineare:\n\\[\nU(g,h;\\lambda) = g - \\lambda h,\n\\] dove \\(\\lambda\\) esprime quanto pesa il tempo rispetto al voto. Ad esempio, con \\(\\lambda=0\\) conta solo il voto, mentre con \\(\\lambda=2\\) ogni ora di studio “costa” due punti d’esame.\n4. Decisione ottimale L’alternativa migliore è quella che massimizza l’utilità attesa, calcolata integrando l’incertezza sia sui parametri del modello sia sulla variabilità predittiva degli esiti. In pratica, questa integrazione si realizza tramite simulazioni dalla distribuzione predittiva posteriore, così da ottenere un confronto robusto tra le opzioni disponibili.\n\n47.1.1 Simulazione dei dati\nPer illustrare il funzionamento dell’analisi decisionale bayesiana, iniziamo simulando un dataset. Questo ci permette di sapere quali sono i “veri” parametri del mondo simulato e di verificare se il modello bayesiano riesce a recuperarli. Il campione simulato comprende 300 studenti, ciascuno assegnato casualmente a uno dei tre metodi di studio: classico, AI tutor e gruppo.\n\nset.seed(123)\n\n# Numero di studenti\nN &lt;- 300\nmethod_names &lt;- c(\"classico\",\"AI\",\"gruppo\")\nd &lt;- sample(1:3, N, replace = TRUE)\n\nPer rendere l’esempio più realistico, ipotizziamo che le ore di studio (\\(H\\)) seguano una distribuzione lognormale, che garantisce valori non negativi e una coda a destra (alcuni studenti studiano molto di più della media). Ogni metodo ha una diversa mediana e variabilità: il metodo classico richiede meno ore, l’AI tutor un impegno intermedio, e il gruppo più ore e con maggiore dispersione.\n\nmu_h_true    &lt;- log(c(8,   12,  16))   # mediane circa: 8, 12, 16 ore\nsigma_h_true &lt;- c(0.30, 0.40, 0.50)\n\nIl voto d’esame (\\(G\\)) dipende dalle ore di studio con rendimenti decrescenti, modellati tramite la funzione logaritmica. Ogni metodo ha parametri diversi: l’AI tutor è più efficace, il metodo di gruppo offre buoni risultati ma a caro prezzo in termini di ore, e il metodo classico è il meno performante.\n\nalpha_true    &lt;- c(55,  64,  61)\nbeta_true     &lt;- c(5.5, 8.0, 6.5)\nsigma_g_true  &lt;- 7\n\nInfine, specifichiamo il costo orario in termini di punti d’esame, fissato a \\(\\lambda = 0.65\\):\n\nlambda &lt;- 0.65\n\nCon questi ingredienti generiamo le osservazioni simulate:\n\nh  &lt;- rlnorm(N, meanlog = mu_h_true[d], sdlog = sigma_h_true[d])\nmu &lt;- alpha_true[d] + beta_true[d] * log1p(h)\ng  &lt;- rnorm(N, mu, sigma_g_true)\ng  &lt;- pmin(pmax(g, 0), 100)  # vincola i voti in [0,100]\n\nCalcoliamo poi l’utilità vera per ciascuno studente e verifichiamo come si distribuisce nei tre gruppi:\n\nu_true &lt;- g - lambda * h\ndf_sim &lt;- data.frame(\n  method = factor(method_names[d], levels = method_names),\n  g = g, \n  h = h, u = u_true\n)\n\nggplot(df_sim, aes(x = u, fill = method)) +\n  geom_density(alpha = 0.35) +\n  labs(x = \"Utilità\", y = \"Densità\")\n\n\n\n\n\n\n\nQuesto grafico mostra come, in base ai parametri scelti, i metodi producano distribuzioni diverse di utilità. È una prima verifica che il modello simulato genera differenze plausibili e interpretabili, prima di passare alla stima vera e propria con Stan.\nPrepariamo i dati per Stan:\n\nstan_data &lt;- list(N = N, d = as.integer(d), h = h, g = g, lambda = lambda)\nglimpse(stan_data)\n#&gt; List of 5\n#&gt;  $ N     : num 300\n#&gt;  $ d     : int [1:300] 3 3 3 2 3 2 2 2 3 1 ...\n#&gt;  $ h     : num [1:300] 41.4 22.8 23.1 20.7 12 ...\n#&gt;  $ g     : num [1:300] 83.9 85.5 84 93.5 70.5 ...\n#&gt;  $ lambda: num 0.65\n\n\n47.1.2 Specificazione del modello Stan\nIl modello bayesiano viene implementato in Stan seguendo una struttura modulare che riflette le componenti concettuali del problema decisionale. La specificazione del codice procede attraverso i seguenti blocchi fondamentali:\nBlocco delle funzioni: definisce la funzione di utilità \\(U(g, h; \\lambda) = g - \\lambda h\\), che combina voti e ore in un unico indice di preferenza.\nBlocco dei dati: dichiara le variabili osservate, tra cui il numero di osservazioni \\(N\\), il metodo di studio scelto \\(d\\), le ore di studio \\(h\\), i voti ottenuti \\(g\\) e il parametro di trade-off \\(\\lambda\\).\nBlocco dei parametri: include i parametri da stimare, specifici per ciascun metodo:\n\nparametri della distribuzione lognormale per le ore di studio (\\(\\mu_h\\), \\(\\sigma_h\\)),\ncoefficienti della relazione tra log(ore) e voto (\\(\\alpha\\), \\(\\beta\\)),\ndeviazione standard residua del voto (\\(\\sigma_g\\)).\n\nBlocco del modello: specifica le distribuzioni a priori debolmente informative e la verosimiglianza dei dati. Le ore seguono una distribuzione lognormale, mentre i voti sono modellati con una normale la cui media dipende dal logaritmo delle ore.\nBlocco delle quantità generate: simula valori predittivi per ore e voti per ciascun metodo, calcolando quindi l’utilità corrispondente. Queste simulazioni permettono di stimare l’utilità attesa e confrontare i metodi.\n\nstancode &lt;- \"\nfunctions {\n  real U(real g, real h, real lambda) {\n    return g - lambda * h;\n  }\n}\ndata {\n  int&lt;lower=0&gt; N;                     // numero osservazioni\n  array[N] int&lt;lower=1, upper=3&gt; d;   // decisione osservata: 1=classico, 2=AI, 3=gruppo\n  vector&lt;lower=0&gt;[N] h;               // ore osservate\n  vector&lt;lower=0, upper=100&gt;[N] g;    // voto osservato (clippato 0..100 a valle)\n  real&lt;lower=0&gt; lambda;               // costo orario in punti-voto\n}\nparameters {\n  // ore ~ lognormal per metodo\n  vector[3] mu_h;                     // location log(ore) per metodo\n  vector&lt;lower=0&gt;[3] sigma_h;         // scale log(ore) per metodo\n\n  // voto | (h, metodo) ~ Normal\n  vector[3] alpha;                    // intercetta per metodo\n  vector[3] beta;                     // pendenza su log1p(h) per metodo\n  real&lt;lower=0&gt; sigma_g;              // sd residua del voto\n}\nmodel {\n  // Priors debolmente informativi\n  mu_h ~ normal(log(10), 1);  // ore tipiche ~ e^N(log(10),1) ≈ 10 ore medie\n  sigma_h ~ normal(0, 0.5);  // &gt;0; log-sd moderata\n\n  alpha ~ normal(60, 20);  // voto tipico ~60 (ampio)\n  beta ~ normal(5, 5);   // più ore =&gt; voto più alto (a priori)\n  sigma_g ~ student_t(3, 0, 10);  // rumore voto\n\n  // Likelihood\n  for (n in 1:N) {\n    h[n] ~ lognormal(mu_h[d[n]], sigma_h[d[n]]);\n    g[n] ~ normal(alpha[d[n]] + beta[d[n]] * log1p(h[n]), sigma_g);\n  }\n}\ngenerated quantities {\n  // utilità predittiva una-estrazione per ciascun metodo \n  array[3] real util;\n  array[3] real g_tilde;\n  array[3] real h_tilde;\n\n  for (k in 1:3) {\n    h_tilde[k] = lognormal_rng(mu_h[k], sigma_h[k]);\n    real mu_g  = alpha[k] + beta[k] * log1p(h_tilde[k]);\n    g_tilde[k] = normal_rng(mu_g, sigma_g);\n    util[k]    = U(g_tilde[k], h_tilde[k], lambda);\n  }\n}\n\"\n\nIl modello integra quindi tre componenti essenziali: (1) una funzione di utilità che sintetizza il trade-off tra risultati accademici e impegno temporale; (2) un meccanismo generativo che cattura la relazione tra ore di studio e performance; (3) simulazioni predittive che incorporano l’incertezza parametrica e la variabilità intrinseca degli esiti.\nQuesta implementazione consente non solo di stimare i parametri del modello, ma anche di confrontare le alternative decisionali attraverso il calcolo dell’utilità attesa, fornendo così una base quantitativa solida per la scelta del metodo di studio ottimale.\n\n47.1.3 Compilazione ed esecuzione del modello\nCompiliamo il modello Stan:\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\nEseguiamo il campionamento MCMC:\n\nfit &lt;- stanmod$sample(\n  data = stan_data,\n  seed = 2025,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 2000,\n  refresh = 200\n)\n\nRiepilogo dei parametri principali:\n\nprint(fit$summary(c(\"mu_h\",\"sigma_h\",\"alpha\",\"beta\",\"sigma_g\")))\n#&gt; # A tibble: 13 × 10\n#&gt;    variable     mean median    sd   mad     q5    q95  rhat  ess_bulk ess_tail\n#&gt;    &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 mu_h[1]     2.060  2.061 0.029 0.030  2.011  2.108 1.001  8799.832 6022.465\n#&gt;  2 mu_h[2]     2.424  2.424 0.046 0.046  2.349  2.498 1.001  9771.434 5748.160\n#&gt;  3 mu_h[3]     2.744  2.744 0.048 0.048  2.665  2.823 1.000  8858.073 5913.963\n#&gt;  4 sigma_h[1]  0.309  0.308 0.021 0.021  0.277  0.344 1.000  9632.056 5815.072\n#&gt;  5 sigma_h[2]  0.466  0.465 0.034 0.033  0.414  0.524 1.001  8735.263 5292.249\n#&gt;  6 sigma_h[3]  0.462  0.459 0.035 0.033  0.408  0.524 1.000 10539.108 5879.366\n#&gt;  7 alpha[1]   55.716 55.682 4.632 4.638 48.194 63.271 1.001  5453.435 5227.550\n#&gt;  8 alpha[2]   64.053 64.014 3.807 3.840 57.687 70.275 1.000  5815.791 5159.801\n#&gt;  9 alpha[3]   54.795 54.802 4.382 4.360 47.524 62.102 1.001  5614.951 5345.316\n#&gt; 10 beta[1]     5.205  5.217 2.097 2.095  1.791  8.616 1.001  5438.111 5194.190\n#&gt; 11 beta[2]     7.764  7.761 1.494 1.496  5.314 10.235 1.000  5798.738 5291.496\n#&gt; 12 beta[3]     8.579  8.559 1.536 1.524  6.055 11.141 1.001  5508.905 4994.723\n#&gt; 13 sigma_g     6.728  6.724 0.279 0.277  6.280  7.205 1.000  8493.763 5783.980\n\n\n47.1.4 Estrazione e analisi delle utilità predittive\nDopo aver adattato il modello in Stan, estraiamo le utilità predittive per ciascun metodo. Queste derivano dalle simulazioni MCMC e incorporano sia l’incertezza sui parametri sia la variabilità intrinseca degli esiti.\n\nmethod_names &lt;- c(\"classico\", \"AI\", \"gruppo\")\n\n# Estrazione della matrice delle utilità\nUmat &lt;- fit$draws(variables = \"util\", format = \"draws_matrix\") |&gt; \n  as.matrix()\ncolnames(Umat) &lt;- method_names\n\n\n47.1.4.1 Utilità attesa e metodo ottimale\nCalcoliamo la media delle utilità per ciascun metodo e identifichiamo quello con valore più alto, cioè l’alternativa ottimale per il valore di \\(\\lambda\\) scelto.\n\nU_means &lt;- colMeans(Umat)\nU_means\n#&gt; classico       AI   gruppo \n#&gt;     61.7     75.3     67.7\nbest_method &lt;- names(U_means)[which.max(U_means)]\nbest_method\n#&gt; [1] \"AI\"\n\n\n47.1.4.2 Probabilità di optimalità\nOltre al confronto delle medie, possiamo stimare la probabilità che ciascun metodo sia davvero il migliore. Questo si ottiene verificando, in ogni simulazione, quale metodo raggiunge l’utilità massima e calcolando le frequenze relative.\n\nbest_idx &lt;- max.col(Umat, ties.method = \"first\")\np_opt &lt;- prop.table(table(factor(best_idx, levels = 1:3, labels = method_names)))\np_opt\n#&gt; \n#&gt; classico       AI   gruppo \n#&gt;   0.0494   0.7456   0.2050\n\n\n47.1.4.3 Analisi delle distribuzioni\nPer avere un quadro completo non basta confrontare le medie: è utile osservare anche la forma delle distribuzioni delle utilità predittive. Possiamo calcolare statistiche descrittive e visualizzare le densità per ciascun metodo.\n\nutil_long &lt;- as.data.frame(Umat) |&gt;\n  tibble::rownames_to_column(var = \".draw\") |&gt;\n  mutate(.draw = as.integer(.draw)) |&gt;\n  pivot_longer(cols = all_of(method_names),\n               names_to = \"method\", values_to = \"util\")\n\nutil_sum &lt;- util_long |&gt;\n  group_by(method) |&gt;\n  summarize(mean = mean(util),\n            sd   = sd(util),\n            q05  = quantile(util, 0.05),\n            q50  = median(util),\n            q95  = quantile(util, 0.95),\n            .groups = \"drop\")\n\nutil_sum\n#&gt; # A tibble: 3 × 6\n#&gt;   method    mean    sd   q05   q50   q95\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 AI        75.3  6.88  63.8  75.4  86.6\n#&gt; 2 classico  61.7  6.78  50.5  61.7  73.0\n#&gt; 3 gruppo    67.7  7.17  55.7  67.8  79.0\n\n\n47.1.4.4 Visualizzazione grafica\n\nggplot(util_long, aes(x = util, fill = method)) +\n  geom_density(alpha = 0.4) +\n  labs(x = \"Utilità predittiva\", y = \"Densità\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set1\", name = \"Metodo\")\n\n\n\n\n\n\n\n\n47.1.5 Interpretazione dei risultati\nIl grafico presenta la distribuzione dell’utilità predittiva associata a ciascun metodo di studio, calcolata mediante la relazione:\n\\[\nU = G - \\lambda H\n\\] dove \\(G\\) rappresenta il voto ottenuto e \\(H\\) le ore di studio investite. Valori elevati di utilità indicano combinazioni favorevoli caratterizzate da voti alti ottenuti con un impegno temporale contenuto, mentre valori ridotti segnalano esiti meno soddisfacenti, dovuti a performance modeste e/o a un elevato numero di ore dedicate.\nL’analisi delle distribuzioni consente di valutare tre aspetti fondamentali. La posizione centrale dell’utilità (sintetizzata dalla media o dalla mediana) fornisce una stima del vantaggio atteso associato a ciascun metodo, indicando quale approccio tende a produrre i risultati più desiderabili in condizioni medie.\nLa dispersione della distribuzione riflette invece il grado di incertezza e variabilità negli esiti possibili. Una maggiore dispersione segnala che i risultati individuali possono discostarsi significativamente dal valore atteso, mentre una distribuzione più concentrata suggerisce outcomes più prevedibili.\nInfine, la sovrapposizione tra le distribuzioni dei diversi metodi rivela in quali scenari le alternative producono risultati simili. Aree di sovrapposizione estesa indicano che la scelta tra metodi potrebbe essere meno netta in certe condizioni, mentre distribzioni ben separate suggeriscono differenze più marcate nelle performance attese.\nQuesto approccio analitico supera la semplice identificazione del “miglior metodo in media” per considerare l’intero spettro di possibili esiti, offrendo così una valutazione completa che tiene conto tanto del valore atteso quanto dell’incertezza predittiva.\n\n47.1.6 Analisi comparativa a parità di input\nPer confrontare i tre metodi in modo intuitivo, possiamo considerare due scenari:\n\nfissiamo il tempo di studio (\\(H\\)) e confrontiamo quale metodo produce il voto atteso più alto;\nfissiamo invece un obiettivo di voto (\\(G\\_0\\)) e vediamo quanto tempo richiede ciascun metodo per raggiungerlo.\n\n\n47.1.6.1 Confronto a ore costanti\nQuando manteniamo costanti le ore di studio, l’unica differenza tra metodi riguarda la performance attesa (\\(G\\)). A parità di tempo, il metodo che garantisce un voto più alto produce anche un’utilità maggiore.\nUn esempio numerico lo chiarisce: con \\(\\lambda = 0.5\\) (due ore di studio equivalgono a un punto di voto) e \\(H=12\\) ore per tutti:\n\n\n\n\n\n\n\n\nMetodo\nVoto atteso \\(G\\)\n\nOre \\(H\\)\n\nUtilità \\(U = G - \\lambda H\\)\n\n\n\n\nClassico\n78\n12\n72\n\n\nAI\n82\n12\n76\n\n\nGruppo\n79\n12\n73\n\n\n\nIn questo scenario il metodo AI prevale. Tuttavia, se richiedesse più tempo (ad esempio 15 ore anziché 12), l’utilità si ridurrebbe a:\n\nG_AI &lt;- 82\nH_AI &lt;- 15\nlambda &lt;- 0.5\nU_AI &lt;- G_AI - lambda * H_AI\nU_AI\n#&gt; [1] 74.5\n\nPur restando vantaggioso rispetto al metodo classico (72), il margine si ridurrebbe sensibilmente.\n\n47.1.6.2 Confronto a voto costante\nUn’altra prospettiva è chiedersi quante ore servono per raggiungere un certo voto obiettivo. Questo ci permette di valutare l’efficienza temporale dei metodi.\nPartiamo stimando i parametri del modello e fissiamo tre obiettivi di voto:\n\n# Estrazione dei parametri stimati\npars &lt;- c(paste0(\"alpha[\",1:3,\"]\"), paste0(\"beta[\",1:3,\"]\"))\ndraws &lt;- fit$draws(variables = pars, format = \"draws_matrix\") |&gt; as.matrix()\n\n# Obiettivi di voto\nG_targets &lt;- c(75, 80, 85)\nmethod_names &lt;- c(\"classico\", \"AI\", \"gruppo\")\n\nCalcoliamo quindi le ore richieste per ogni obiettivo:\n\n# Funzione: ore necessarie per raggiungere G0\nHreq_fun &lt;- function(G0, alpha, beta) {\n  pmax(exp((G0 - alpha)/beta) - 1, 0)\n}\n\n# Calcoli su tutti i target e metodi\nout &lt;- lapply(G_targets, function(G0) {\n  Hreq_mat &lt;- sapply(1:3, function(k) {\n    alpha_k &lt;- draws[, paste0(\"alpha[\", k, \"]\")]\n    beta_k  &lt;- draws[, paste0(\"beta[\", k, \"]\")]\n    Hreq_fun(G0, alpha_k, beta_k)\n  })\n  colnames(Hreq_mat) &lt;- method_names\n  as_tibble(Hreq_mat) |&gt; mutate(G0 = G0, .draw = row_number())\n}) |&gt; bind_rows()\n\nRiassumiamo i risultati con mediane e intervalli interquartili:\n\nHreq_summary &lt;- out |&gt;\n  pivot_longer(all_of(method_names), names_to = \"metodo\", values_to = \"Hreq\") |&gt;\n  group_by(G0, metodo) |&gt;\n  summarize(\n    mediana = median(Hreq),\n    q25 = quantile(Hreq, 0.25),\n    q75 = quantile(Hreq, 0.75),\n    .groups = \"drop\"\n  )\n\nVisualizziamo i confronti:\n\nggplot(Hreq_summary, aes(x = factor(G0), y = mediana, fill = metodo)) +\n  geom_col(position = position_dodge(width = 0.8)) +\n  geom_errorbar(aes(ymin = q25, ymax = q75),\n                position = position_dodge(width = 0.8),\n                width = 0.2) +\n  labs(x = \"Voto obiettivo (G0)\",\n       y = \"Ore di studio necessarie\\n(mediana con IQR)\",\n       fill = \"Metodo\") \n\n\n\n\n\n\n\n\n47.1.7 Interpretazione\n\n\nEfficienza a parità di ore: il metodo AI tende a produrre voti più alti e quindi maggiore utilità, ma il vantaggio può ridursi se richiede più tempo.\n\nEfficienza a parità di voto: i metodi che necessitano meno ore per raggiungere lo stesso obiettivo sono più efficienti; il grafico mostra chiaramente queste differenze.\n\nIncertezza: gli intervalli interquartili (IQR) indicano che non c’è una separazione netta: alcuni studenti possono ottenere risultati simili con metodi diversi.\n\nIn questo modo, il confronto tra metodi diventa più ricco: non ci fermiamo a dire “chi è il migliore”, ma vediamo in quali condizioni un metodo può risultare più vantaggioso.\n\n47.1.8 Verso modelli più realistici: oltre la funzione di utilità lineare\nLa funzione di utilità lineare qui adottata,\n\\[\nU(g,h;\\lambda) = g - \\lambda h, \\quad \\lambda \\geq 0,\n\\] presenta il pregio di una notevole semplicità interpretativa: ogni ora di studio viene infatti associata a un “costo” costante, pari a \\(\\lambda\\) punti di voto. Tuttavia, questa formulazione poggia su due ipotesi semplificatrici che possono discostarsi dal comportamento effettivo degli studenti. In primo luogo, la linearità nel voto implica che il valore marginale di ciascun punto sia identico a qualsiasi livello della scala di valutazione, equiparando ad esempio il passaggio da 60 a 61 a quello da 90 a 91. In secondo luogo, la linearità nel tempo presuppone che il disagio associato a un’ora aggiuntiva di studio rimanga invariato, indipendentemente dal numero di ore già dedicate.\nQueste assunzioni, sebbene utili in una fase introduttiva, possono risultare limitanti nel momento in cui si desideri cogliere la complessità delle preferenze individuali. È pertanto opportuno considerare alcune estensioni del modello in grado di conferirle maggiore realismo.\nUna prima direzione di sviluppo riguarda l’introduzione di non linearità nella componente relativa al voto. È plausibile, ad esempio, che i voti presentino rendimenti decrescenti, per cui guadagnare punti in prossimità della sufficienza venga percepito come più rilevante che incrementare il punteggio in regioni già elevate della scala. Allo stesso modo, si potrebbero incorporare soglie minime al di sotto delle quali un esito viene considerato inaccettabile, indipendentemente dal tempo investito.\nAnche la relazione tra utilità e tempo potrebbe essere arricchita per riflettere in modo più fedele l’esperienza soggettiva. La fatica associata allo studio tende infatti ad aumentare in modo non lineare con il numero di ore, suggerendo l’adozione di funzioni con esponente (quali \\(h^2\\) o \\(h^{1.5}\\)) in grado di catturare questa progressione.\nUlteriori aspetti rilevanti includono il ruolo degli obiettivi personali, poiché gli studenti potrebbero mostrare avversione alle perdite, attribuendo un peso maggiore al mancato raggiungimento di un traguardo rispetto al superamento dello stesso. Allo stesso modo, la gestione del rischio e dell’incertezza merita particolare attenzione: alcuni individui potrebbero preferire metodi che offrono risultati più stabili, anche se meno brillanti in media, richiedendo quindi di considerare non solo il valore atteso dell’utilità ma anche la sua variabilità o il suo comportamento in scenari sfavorevoli.\nInfine, è importante riconoscere che il trade-off tra voto e tempo può variare notevolmente tra diversi profili di studenti, come nel caso di lavoratori part-time rispetto a studenti a tempo pieno. Modelli gerarchici consentono di stimare tale variabilità individuale preservando al contempo una struttura comune.\nPer un ricercatore che si accinga ad affrontare questo tipo di analisi, si raccomanda un approccio progressivo. È preferibile iniziare con il modello lineare, apprezzabile per la sua trasparenza e facilità di comunicazione, per poi verificare—attraverso un’attenta analisi esplorativa dei dati—l’eventuale presenza di non linearità o altri effetti complessi. Solo in seguito all’identificazione di tali pattern dovrebbe essere contemplata l’introduzione di complessità aggiuntive, sempre nel rispetto di un equilibrio tra realismo e interpretabilità dei risultati.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Decisione ottimale e utilità attesa: l’approccio bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/04_study_method.html#riflessioni-conclusive",
    "href": "chapters/formal_models/04_study_method.html#riflessioni-conclusive",
    "title": "47  Decisione ottimale e utilità attesa: l’approccio bayesiano",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo esplorato come l’analisi decisionale bayesiana offra un quadro coerente per integrare diverse componenti fondamentali: le previsioni sugli esiti, attraverso distribuzioni predittive che riflettono la nostra incertezza; la formalizzazione delle preferenze, mediante funzioni di utilità che quantificano la desiderabilità dei risultati; e infine un criterio di scelta razionale, rappresentato dalla massimizzazione dell’utilità attesa.\nAbbiamo iniziato con un modello semplice, caratterizzato da una funzione di utilità lineare sia nel voto che nel tempo. Questa scelta, sebbene simplificata, si è rivelata preziosa per introdurre i concetti cardine del metodo: tradurre in valori numerici il grado di soddisfazione associato a diversi esiti, calcolare utilità attese che incorporino l’incertezza predittiva e confrontare in modo sistematico alternative complesse. Successivamente, abbiamo discusso come estendere questo modello per cogliere aspetti più realistici del processo decisionale, come la presenza di rendimenti decrescenti nel voto, costi marginali crescenti del tempo di studio, il ruolo degli obiettivi personali e l’avversione al rischio, nonché la possibile eterogeneità delle preferenze tra individui.\nDal punto di vista applicativo, emerge con chiarezza il valore di un approccio incrementale. È consigliabile iniziare con un modello lineare semplice, che garantisce trasparenza e facilità di comunicazione, per poi verificare empiricamente—attraverso l’analisi dei dati—la validità delle sue assunzioni. Solo qualora emergano evidenze di non linearità, effetti soglia o sensibilità al rischio, ha senso considerare modelli più complessi, sempre mantenendo un attento equilibrio tra realismo e interpretabilità.\nIl vantaggio distintivo dell’approccio bayesiano risiede nella sua capacità di propagare in modo coerente tutte le fonti di incertezza—sui parametri del modello e sulla variabilità degli esiti—fino alla quantificazione dell’utilità attesa. Questo permette non solo di identificare l’opzione mediamente migliore, ma anche di valutare la robustezza di questa conclusione, esprimendo ad esempio la probabilità che una data alternativa sia da preferire.\nIn definitiva, l’analisi decisionale bayesiana si configura non solo come una tecnica per supportare scelte ottimali in condizioni di incertezza, ma anche come una metodologia per rendere esplicito, trasparente e criticabile il processo attraverso cui valutiamo e confrontiamo le alternative a nostra disposizione.\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] stringr_1.5.1         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.13.0      patchwork_1.3.2       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.14.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.1      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            sessioninfo_1.2.3    \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           pkgconfig_2.0.3       arrayhelpers_1.1-0   \n#&gt; [13] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [16] utf8_1.2.6            rmarkdown_2.29        ps_1.9.1             \n#&gt; [19] ragg_1.5.0            purrr_1.1.0           xfun_0.53            \n#&gt; [22] cachem_1.1.0          jsonlite_2.0.0        broom_1.0.9          \n#&gt; [25] parallel_4.5.1        R6_2.6.1              stringi_1.8.7        \n#&gt; [28] RColorBrewer_1.1-3    lubridate_1.9.4       estimability_1.5.1   \n#&gt; [31] knitr_1.50            zoo_1.8-14            pacman_0.5.1         \n#&gt; [34] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [37] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [40] codetools_0.2-20      curl_7.0.0            processx_3.8.6       \n#&gt; [43] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          \n#&gt; [46] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       \n#&gt; [49] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     \n#&gt; [52] checkmate_2.3.3       stats4_4.5.1          distributional_0.5.0 \n#&gt; [55] generics_0.1.4        rprojroot_2.1.1       rstantools_2.5.0     \n#&gt; [58] scales_1.4.0          xtable_1.8-4          glue_1.8.0           \n#&gt; [61] emmeans_1.11.2-8      tools_4.5.1           data.table_1.17.8    \n#&gt; [64] mvtnorm_1.3-3         grid_4.5.1            QuickJSR_1.8.0       \n#&gt; [67] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [70] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [73] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [76] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [79] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Decisione ottimale e utilità attesa: l’approccio bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/04_study_method.html#bibliografia",
    "href": "chapters/formal_models/04_study_method.html#bibliografia",
    "title": "47  Decisione ottimale e utilità attesa: l’approccio bayesiano",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Decisione ottimale e utilità attesa: l’approccio bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/conclusions_sec.html",
    "href": "chapters/formal_models/conclusions_sec.html",
    "title": "Riflessioni conclusive della sezione",
    "section": "",
    "text": "Con questa sezione abbiamo compiuto un salto qualitativo nell’approccio alla modellizzazione in psicologia.\n\nDai modelli statici ai modelli dinamici. Abbiamo visto come l’andamento di una variabile non possa essere compreso appieno senza tener conto della sua dipendenza temporale. I modelli AR e le loro estensioni formalizzano questa idea, permettendo di distinguere tra variabilità casuale e persistenza degli stati psicologici.\nDai dati agli stati latenti. Introdurre variabili latenti significa riconoscere che ciò che osserviamo (una risposta corretta, una scelta, un punteggio) è solo la manifestazione esterna di processi interni più complessi. I modelli dinamici ci permettono di stimare e simulare questi processi nascosti.\nIl ruolo dei modelli meccanicistici. Con il modello Rescorla-Wagner abbiamo visto un esempio paradigmatico di modello meccanicistico: non si limita a dire che due variabili sono associate, ma specifica come e perché l’associazione cambia nel tempo, seguendo una regola di aggiornamento basata sull’errore di predizione.\nTeoria e simulazione. Un punto fondamentale è che questi modelli possono essere simulati: possiamo generare dati artificiali e verificare se le dinamiche prodotte dal modello somigliano a quelle osservate empiricamente. Questo ci avvicina a un approccio veramente esplicativo, in cui i modelli non sono solo strumenti statistici ma vere e proprie ipotesi teoriche formalizzate.\n\nDal punto di vista metodologico, la lezione principale è che un modello è utile quando soddisfa tre condizioni: (a) si fonda su ipotesi teoriche esplicite, (b) produce previsioni controllabili, (c) resta estendibile per affrontare nuove domande.\nDal punto di vista applicativo, abbiamo visto come la modellizzazione computazionale apra la strada a una psicologia più rigorosa e predittiva, in cui i dati empirici non sono solo riassunti, ma spiegati attraverso meccanismi plausibili.\nIn sintesi, l’integrazione tra modelli dinamici, approcci gerarchici e simulazioni ci ha mostrato come passare dalla descrizione alla spiegazione e, in prospettiva, sarà sempre più cruciale per indagare la variabilità individuale, distinguere deficit contestuali specifici da quelli generali e progettare interventi mirati.",
    "crumbs": [
      "Modelli",
      "Riflessioni conclusive della sezione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nLa psicologia, insieme ad altre discipline scientifiche, sta attraversando una Riforma Metodologica scaturita da una crisi profonda: l’incapacità di replicare risultati di ricerche precedentemente pubblicati. Questa crisi di replicazione, che mina la credibilità della scienza, ha portato a un ripensamento radicale delle pratiche di ricerca, degli standard metodologici e degli incentivi accademici (Korbmacher et al., 2023). Siti come Retraction Watch, che monitorano le ritrattazioni di studi scientifici, testimoniano l’entità del problema, evidenziando casi di frodi, manipolazioni statistiche e pratiche di ricerca opache.\nLe Cause della Crisi.\nTra le cause principali vi sono incentivi distorti (come la pressione a pubblicare rapidamente), l’utilizzo acritico di tecniche inferenziali frequentiste – che facilitano la proliferazione di falsi positivi – e la scarsa attenzione alla dimensione campionaria. Come dimostrato da Altmejd et al. (2019), alcuni elementi superficiali permettono di prevedere la replicabilità di uno studio:\nSorprendentemente, prevedere se uno studio sarà replicabile non richiede competenze avanzate. Camerer et al. (2018) ha mostrato che scienziati coinvolti in un “mercato delle scommesse” predicevano con precisione quali studi di scienze sociali si sarebbero replicati. Ancora più significativo è il lavoro di Hoogeveen et al. (2020): partecipanti senza formazione specifica, esposti a semplici descrizioni di studi psicologici, hanno identificato con successo ricerche a rischio di fallimento replicativo. Ciò suggerisce che molti studi presentano difetti metodologici evidenti, riconoscibili persino a un pubblico non esperto.\nLa Diffusione degli Errori nella Letteratura Scientifica.\nLa pubblicazione peer-reviewed non garantisce l’affidabilità di una ricerca. Yang et al. (2020) ha rilevato che studi non replicabili vengono citati con la stessa frequenza di quelli validi, alimentando un ciclo di errori. Questo paradosso – scienziati capaci di riconoscere studi fragili ma inclini a citarli – riflette una cultura accademica disfunzionale (Smaldino & McElreath, 2016), dove la quantità di pubblicazioni prevale sulla qualità e gli incentivi premiano scorciatoie metodologiche.\nEsempi Emblematici e la Crisi di Validità.\nLa crisi non riguarda solo la replicazione, ma anche la validità delle misure e delle teorie. Ricerche influenti, come quelle sul pre-cognition di Ritchie et al. (2012) o sugli effetti del priming inconscio di John Bargh, si sono rivelate basate su evidenze fragili (Schimmack, 2012). Anche concetti consolidati, come l’esaurimento dell’autocontrollo (ego depletion) legato ai livelli di glucosio, sono stati criticati per mancanza di supporto empirico (Vadillo et al., 2016). Persino opere di autori celebri, come Thinking: Fast and Slow di Daniel Kahneman, contengono affermazioni basate su risultati non replicabili (Schimmack, 2020).\nVerso una Soluzione: Oltre l’Inferenza Frequentista.\nQuesta sezione della dispensa si concentra su uno dei nodi metodologici alla base della crisi: i limiti dell’inferenza frequentista (Baker, 2016). Concetti come gli errori di tipo S (conclusioni errate sulla direzione di un effetto) e di tipo M (sovrastima dell’entità di un effetto), introdotti da Gelman & Carlin (2014), illuminano le insidie delle tecniche statistiche tradizionali. Per affrontare la crisi, è necessario adottare approcci alternativi: preregistrazione degli studi, utilizzo di metodi bayesiani, e una valutazione critica della credibilità cumulativa della letteratura (Schimmack, 2020).\nConclusioni.\nLa crisi della replicabilità non è solo un problema tecnico, ma il sintomo di un sistema scientifico da ripensare. Riviste accademiche, istituzioni e ricercatori devono promuovere integrità, trasparenza e una cultura che valorizzi la robustezza rispetto alla novità. Solo così la psicologia potrà riconquistare il ruolo di scienza empirica rigorosa, capace di produrre conoscenza affidabile.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637–644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267–285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nRitchie, S. J., Wiseman, R., & French, C. C. (2012). Failing the future: Three unsuccessful attempts to replicate Bem’s ‘Retroactive Facilitation of Recall’Effect. PloS one, 7(3), e33423.\n\n\nSchimmack, U. (2012). The ironic effect of significant results on the credibility of multiple-study articles. Psychological methods, 17(4), 551–566.\n\n\nSchimmack, U. (2020). A meta-psychological perspective on the decade of replication failures in social psychology. Canadian Psychology/Psychologie Canadienne, 61(4), 364–376.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society Open Science, 3(9), 160384.\n\n\nVadillo, M. A., Gold, N., & Osman, M. (2016). The bitter truth about sugar and willpower: The limited evidential value of the glucose model of ego depletion. Psychological Science, 27(9), 1207–1214.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762–10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "48  La crisi della replicazione",
    "section": "",
    "text": "48.1 Introduzione\nIl presente capitolo introduce la crisi di replicazione che affligge la ricerca psicologica, analizzandone le cause precipue e ponendo in rilievo il ruolo che l’approccio statistico frequentista ha avuto nel concorrere a tale problematica. Il contenuto di questo capitolo costituisce una sintesi rielaborata del testo A student’s guide to open science: Using the replication crisis to reform psychology (Pennington, 2023).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#i-pilastri-della-scienza-psicologica-ideale",
    "href": "chapters/replication_crisis/01_crisis.html#i-pilastri-della-scienza-psicologica-ideale",
    "title": "48  La crisi della replicazione",
    "section": "\n48.2 I Pilastri della Scienza Psicologica Ideale",
    "text": "48.2 I Pilastri della Scienza Psicologica Ideale\nAffinché la psicologia sia riconosciuta come scienza rigorosa, deve aderire a principi fondamentali:\n\n48.2.1 A. Replicabilità e Riproducibilità\n\n\n\nDefinizione: Un effetto empirico è considerato valido solo se replicabile da ricercatori indipendenti, con metodologie analoghe e campioni adeguati.\n\n\nEsempio: Lo studio classico di Asch sul conformismo (1951) è stato replicato in contesti cross-culturali, rafforzandone la validità.\n\n48.2.2 B. Attributi Essenziali della Ricerca\n\nLa scienza ideale dovrebbe essere:\n\n\n\n\n\n\n\nPrincipio\nDescrizione\nImplicazioni per la Psicologia\n\n\n\nCredibile\nSottoposizione delle ipotesi a verifica rigorosa e peer review trasparente.\nEvitare p-hacking e HARKing (Hypothesizing After Results are Known).\n\n\nAffidabile\nRisultati accurati e privi di distorsioni (bias).\nUtilizzo di preregistrazione e open data.\n\n\nTrasparente\nDescrizione dettagliata di metodi, analisi e risultati.\nAdozione di registered reports e condivisione di materiali supplementari.\n\n\nAccessibile\nDemocratizzazione della conoscenza (es. open access).\nPiattaforme come PsyArXiv per preprint o OSF per la condivisione di protocolli.\n\n\nInclusiva\nPartecipazione equa di gruppi sottorappresentati (etnici, di genere, ecc.).\nStudi con campioni diversificati (es. non solo WEIRD: Western, Educated, Industrialized, Rich, Democratic).\n\n\nCollaborativa\nSuperamento della competizione accademica a favore di reti di ricerca.\nProgetti multi-lab (es. Many Labs in psicologia sociale).\n\n\nAutocorrettiva\nRevisione continua degli errori e ritrattazione di risultati non validi.\nDatabase come Retraction Watch e correzioni pubbliche negli articoli.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-disconnessione-tra-ideale-e-realtà",
    "href": "chapters/replication_crisis/01_crisis.html#la-disconnessione-tra-ideale-e-realtà",
    "title": "48  La crisi della replicazione",
    "section": "\n48.3 La Disconnessione tra Ideale e Realtà",
    "text": "48.3 La Disconnessione tra Ideale e Realtà\nPennington (2023) utilizza un esercizio retorico per criticare la prassi scientifica tradizionale:\n\nVisualizzate lo stereotipo dello scienziato: un uomo bianco, in un laboratorio con cartelli ‘DIVIETO DI ACCESSO’, che tratta i dati come proprietà privata. Questa immagine riflette una scienza chiusa, competitiva e non allineata ai valori di trasparenza e collaborazione.\n\n\n48.3.1 Problemi Emersi\n\n\nSegretezza: Ricercatori che occultano dati per paura di critiche o “furti” di idee.\n\n\nCrisi di replicazione: Il 50-70% degli studi psicologici non è replicabile (Collaboration, 2015).\n\n\nPressioni accademiche: Focus su pubblicazioni “rivoluzionarie” a scapito di solidità metodologica.\n\n48.3.2 Verso una Psicologia più Rigorosa\nPer affrontare le criticità emerse nella ricerca psicologica, sono state avanzate diverse proposte concrete. Una delle direzioni più promettenti è l’adozione diffusa delle pratiche di Open Science, che includono la preregistrazione degli studi (per evitare il p-hacking), la condivisione aperta dei dati (open data) e l’utilizzo di strumenti gratuiti e trasparenti, come il software JASP per le analisi statistiche. Questi approcci non solo aumentano l’affidabilità dei risultati, ma favoriscono anche una cultura di collaborazione anziché di segretezza.\nUn altro passo fondamentale riguarda la formazione dei ricercatori. Introdurre corsi obbligatori su etica della ricerca e metodi quantitativi avanzati potrebbe ridurre errori metodologici e comportamenti opportunistici, preparando una nuova generazione di psicologi a standard più rigorosi.\nInfine, è essenziale ripensare il sistema di valutazione accademica. Invece di premiare la mera quantità di pubblicazioni – che spesso spinge verso risultati “sensazionali” ma poco replicabili – sarebbe più produttivo incentivare la qualità, la trasparenza e l’impatto a lungo termine del lavoro scientifico.\nUn esempio concreto di questo cambiamento è il progetto ManyBabies, un’iniziativa internazionale che coinvolge decine di laboratori nello studio dello sviluppo infantile. Grazie alla collaborazione su larga scala e alla condivisione di protocolli standardizzati, ManyBabies ha dimostrato come sia possibile produrre risultati più solidi e generalizzabili, superando i limiti dei piccoli studi isolati. Questo caso illustra perfettamente i benefici di una psicologia più aperta, cooperativa e metodologicamente rigorosa.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "href": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "title": "48  La crisi della replicazione",
    "section": "\n48.4 La Crisi della Replicazione in Psicologia",
    "text": "48.4 La Crisi della Replicazione in Psicologia\nNegli ultimi decenni, la psicologia si è trovata al centro di una crisi che ha messo in discussione molte delle sue basi epistemologiche e metodologiche: la crisi della replicazione. Questo fenomeno indica l’incapacità di replicare con successo un’ampia parte degli studi pubblicati, con implicazioni rilevanti per la cultura accademica e il modo di concepire la ricerca scientifica (Parsons et al., 2022).\nPer fallimento della replicazione si intende il caso in cui uno studio, ripetuto da altri ricercatori seguendo le stesse procedure e utilizzando campioni simili, non riesce a ottenere risultati comparabili a quelli originali. Questo ha portato alla luce problemi sistemici legati alla metodologia di ricerca, all’interpretazione dei dati e alle dinamiche del sistema accademico. La crisi della replicazione ha dunque evidenziato la necessità di un cambiamento strutturale nella pratica scientifica, sottolineando l’urgenza di un approccio più trasparente, rigoroso e collaborativo.\nNelle sezioni seguenti vengono presentati gli eventi chiave di quella che possiamo chiamare la storia della crisi della replicazione.\n\n48.4.1 2005: “Perché la maggior parte dei risultati pubblicati è falsa” (Ioannidis)\nUn primo momento cruciale è stato l’articolo di “Why Most Published Research Findings Are False” (Ioannidis, 2005) che ha evidenziato come molti risultati scientifici fossero in realtà falsi positivi. Ioannidis attribuì questo fenomeno a campioni di piccole dimensioni, un’eccessiva enfasi sui valori-p per indicare significatività, flessibilità nei metodi di analisi e la competizione per produrre risultati “innovativi”. Questo articolo ha messo in luce problemi che trascendono la psicologia, ma che in seguito sarebbero emersi come centrali anche per questa disciplina.\n\n48.4.2 2011: Lo Studio di Daryl Bem, “Feeling the Future”\nUno degli eventi più controversi è stato lo studio di Daryl Bem “Feeling the Future” (Bem, 2011), che suggeriva l’esistenza della precognizione, ovvero la capacità di “sentire” eventi futuri. Attraverso nove esperimenti, Bem pubblicò risultati statisticamente significativi che sembravano sfidare le leggi della causalità.\nLo studio di Bem si inseriva nella tradizione degli esperimenti di “priming”, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ’70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio è lo studio di John Bargh del 1996, che dimostrò come l’esposizione a parole associate all’età avanzata inducesse i soggetti a camminare più lentamente (Bargh et al., 1996). Un altro studio del 2006 rivelò che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilità della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali (Leys, 2024). Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in metà delle prove, il priming avveniva dopo che i soggetti avevano già visto e valutato l’immagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano più veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l’ipotesi nulla.\nBem interpretò questi risultati come prova della chiaroveggenza, una conclusione che suscitò notevoli controversie e ridicolizzò la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l’ordine temporale invertito, mostrarono risultati altrettanto statisticamente significativi.\nQuesti risultati ponevano la comunità scientifica di fronte a un dilemma: accettare l’esistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validità dei suoi risultati come prova dell’esistenza di capacità precognitive.\nSebbene pubblicato su una rivista prestigiosa, lo studio sollevò enormi dubbi metodologici. Le repliche successive non riuscirono a confermare i risultati di Bem, mostrando come pratiche discutibili, quali il p-hacking (modifiche al metodo di analisi per ottenere risultati significativi), potessero produrre falsi positivi apparentemente robusti.\n\n48.4.3 2011: Il Caso di Frode di Diederik Stapel\nNello stesso anno, Diederik Stapel, una figura di spicco della psicologia sociale, fu accusato di aver falsificato dati in decine di studi pubblicati. Tra i suoi esperimenti più famosi vi era quello secondo cui ambienti disordinati aumenterebbero il razzismo. Un altro studio suggeriva che mangiare carne rendeva le persone più antisociali. Tuttavia, si scoprì che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti né raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati. Questo scandalo scosse profondamente la comunità accademica e divenne un simbolo della crisi.\n\n48.4.4 2011: La Meta-ricerca e le Pratiche di Ricerca Discutibili (QRPs)\nLa meta-ricerca è un campo di studio che si concentra sul modo in cui viene condotta la ricerca scientifica. Comprende temi come i metodi, la trasparenza nella comunicazione, la riproducibilità, la valutazione e i sistemi di incentivi che regolano la scienza (Ioannidis et al., 2015). Questo ambito è emerso con urgenza dopo una serie di casi controversi e di frodi conclamate, come gli studi di Daryl Bem e Diederik Stapel, che hanno evidenziato falle nei processi di ricerca. I ricercatori hanno così iniziato ad analizzare pratiche note come Questionable Research Practices (QRPs, Pratiche di Ricerca Discutibili), che sfruttano aree grigie nelle norme scientifiche per raccogliere e analizzare i dati.\nSimmons et al. (2011) hanno dimostrato come la flessibilità nella raccolta, analisi e comunicazione dei dati permetta ai ricercatori di far apparire “significativo” praticamente qualsiasi risultato. Tra le pratiche discusse, spiccano:\n\n\nOptional stopping: Interrompere la raccolta dei dati non appena si raggiunge la significatività statistica, invece di seguire un piano prestabilito.\n\n\nP-hacking: Condurre molteplici test non pianificati, selezionando variabili o analisi solo quando producono un valore p inferiore a 0.05.\n\n\nHARKing (Hypothesizing After Results are Known): Modificare le ipotesi a posteriori per adattarle ai risultati ottenuti, presentandole come ipotesi iniziali.\n\nQueste pratiche non solo compromettono l’integrità scientifica, ma rendono estremamente facile produrre falsi positivi. Per dimostrarlo, Simmons e colleghi hanno condotto simulazioni al computer e due esperimenti, rivelando quanto fosse “troppo facile” raccogliere prove a sostegno di ipotesi false.\nLa portata di queste pratiche è sorprendente. Simmons et al. hanno scoperto che:\n\nUsare una sola QRP può quasi raddoppiare il tasso di falsi positivi, portandolo dal 5% al 10%.\n\nCombinare più QRPs può far salire questa percentuale oltre il 60%.\n\nPer sottolineare il problema, i ricercatori hanno dimostrato, in modo volutamente ironico, che ascoltare la canzone dei Beatles “When I’m Sixty-Four” potrebbe far apparire le persone più giovani di quanto fossero prima di ascoltarla. Questa dimostrazione satirica evidenziava che inseguire la significatività statistica senza un rigore metodologico può produrre risultati assurdi.\nJohn et al. (2012) hanno condotto un’indagine su larga scala, intervistando 2000 ricercatori per comprendere la diffusione delle QRPs. Con un approccio innovativo, hanno chiesto ai partecipanti non solo di riferire le proprie pratiche, ma anche quelle dei colleghi. I risultati sono stati sconvolgenti:\n\nOltre il 60% degli intervistati ha ammesso di non aver riportato tutte le variabili dipendenti misurate.\n\nPiù del 50% ha interrotto la raccolta dati non appena ottenuti risultati significativi (optional stopping).\n\nPiù del 40% ha selezionato e riportato solo esperimenti “riusciti”.\n\nSorprendentemente, i ricercatori tendevano a dichiarare che i colleghi adottavano queste pratiche più frequentemente di loro stessi. Molti giustificavano queste pratiche come “norme accademiche” del tempo.\nLa meta-ricerca ha giocato un ruolo cruciale nell’aprire gli occhi della comunità scientifica sui pericoli di queste decisioni apparentemente “banali”. In un contesto in cui le QRPs erano ampiamente accettate, la meta-ricerca ha evidenziato come queste pratiche possano seriamente danneggiare il progresso scientifico. Grazie al movimento dell’Open Science, si stanno introducendo norme che migliorano la credibilità della ricerca, spostando l’enfasi dalla produzione di risultati “significativi” alla conduzione di studi rigorosi e trasparenti.\n\n48.4.5 2012: La Crisi di Fiducia della Psicologia\nSiamo nel 2012, un anno segnato da una serie di eventi che spingono Harold Pashler ed Eric-Jan Wagenmakers a dichiarare che la psicologia sta affrontando una “crisi di fiducia”. In un numero speciale della rivista Perspectives on Psychological Science (PoPs), i due autori raccolgono una molteplicità di prospettive sulla nascente crisi della replicazione, cercando di individuarne le cause e le implicazioni.\nLe reazioni alla crisi sono variegate e, in alcuni casi, contrastanti. Alcuni studiosi sostengono che le affermazioni di una crisi siano premature (Stroebe e Strack, 2014) e che i problemi di replicazione non siano un fenomeno nuovo (Spellman, 2015). Altri, invece, sottolineano come incentivare e valorizzare gli studi di replicazione rappresenti un metodo efficace e diretto per migliorare la qualità della scienza psicologica (Koole e Lakens, 2012).\nIl numero speciale evidenzia anche iniziative in corso per affrontare il problema. Tra queste, l’Open Science Collaboration (OSC), un progetto di larga scala avviato nel 2012, si propone di verificare empiricamente se la psicologia sia effettivamente alle prese con una crisi della replicazione. L’obiettivo del progetto è ambizioso: replicare numerosi studi pubblicati per valutare la robustezza dei risultati originari. Sebbene i risultati di questa iniziativa non fossero ancora disponibili al momento della pubblicazione del numero speciale, il progetto rappresentava già una pietra miliare per la disciplina.\nNonostante le preoccupazioni, il numero speciale si chiude con una nota positiva, destinata a risuonare nella comunità scientifica. I casi di frode, le pratiche di ricerca discutibili (QRPs) e i fallimenti nei tentativi di replicazione, sebbene dannosi, hanno aperto la strada a una riflessione critica. Questo processo ha permesso alla psicologia di affrontare i propri limiti, correggere errori, superare i bias e costruire una letteratura più affidabile e trasparente.\nQuesto periodo storico segna un punto di svolta: la crisi di fiducia ha messo in discussione le fondamenta della disciplina, ma ha anche creato l’opportunità per un rinnovamento scientifico, stimolando pratiche più rigorose e una maggiore attenzione alla replicabilità e alla trasparenza.\n\n48.4.6 2014: Il Progetto “Many Labs”\nNel 2014 fu pubblicato il primo tentativo su larga scala di replicare risultati psicologici: il progetto “Many Labs”. Questo imponente sforzo collaborativo, guidato da Klein et al. (2014), testò la replicabilità di 13 risultati classici della psicologia, coinvolgendo 6344 partecipanti in 12 paesi. Gli studi selezionati rispettavano tre criteri principali: erano relativamente brevi, avevano un design semplice e potevano essere facilmente condotti online.\nTra i fenomeni esaminati figurava la fallacia del costo irrecuperabile (sunk cost fallacy), secondo cui le persone tendono a proseguire un’attività quando vi hanno già investito tempo, sforzi o denaro. Un esempio classico: se hai acquistato un biglietto per vedere la tua squadra di calcio preferita e, il giorno della partita, inizia a piovere a dirotto, sarai più propenso a partecipare perché hai già speso i soldi per il biglietto (Oppenheimer e Monin, 2009).\nAltri studi replicati includevano:\n\nL’influenza del framing dei guadagni e delle perdite sul rischio (Tversky e Kahneman, 1981).\n\nLe differenze di genere negli atteggiamenti impliciti verso la matematica e le arti (Nosek et al., 2002).\n\nI risultati sembravano promettenti: il 77% degli studi replicò con successo i risultati originali (10 su 13). Tuttavia, non tutti gli studi fornirono lo stesso livello di evidenza. Ad esempio:\n\nUno studio sull’efficacia del contatto sociale immaginato nel ridurre i pregiudizi (Husnu e Crisp, 2010) mostrò supporto limitato, con solo 4 campioni su 36 che evidenziarono un effetto significativo.\n\nDue studi di priming non furono replicati. Nel primo, i ricercatori non trovarono che l’esposizione alla bandiera americana aumentasse il conservatorismo (Carter et al., 2011). Nel secondo, il priming con concetti legati al denaro non portò a un incremento delle credenze o dei comportamenti capitalistici (Caruso et al., 2013).\n\nSebbene i risultati fossero accolti come una vittoria per la replicabilità, alcuni ricercatori sottolinearono limiti nel progetto Many Labs 1. Gli stessi autori riconobbero che molti degli studi selezionati erano già noti per essere altamente replicabili. Secondo alcuni critici, il principale contributo di questo progetto era dimostrare che almeno dieci effetti psicologici erano replicabili, ma non forniva una panoramica più ampia sulla replicabilità complessiva nella psicologia (Yarkoni, 2013).\nQuesto progetto rappresentò comunque un passo fondamentale per affrontare la crisi della replicazione, sottolineando l’importanza della collaborazione scientifica e del rigore metodologico.\n\n48.4.7 2015: Il Progetto di Riproducibilità della Open Science Collaboration\nNel 2015, la Open Science Collaboration (OSC) pubblicò i risultati del Reproducibility Project: Psychology, dimostrando che la buona scienza richiede tempo e rigore. Superando i limiti del progetto Many Labs 1, un team composto da oltre 270 ricercatori internazionali si impegnò a replicare 100 studi scelti casualmente da riviste di punta nel campo della psicologia.\nPer garantire risultati solidi e inattaccabili, il team adottò una metodologia rigorosa:\n- Consultazione con gli autori originali: gli autori degli studi originali furono coinvolti per confermare il design sperimentale e ridurre al minimo eventuali discrepanze.\n- Aumento delle dimensioni campionarie: i campioni furono ampliati per garantire una potenza statistica sufficiente.\n- Registrazione preventiva dei metodi: i piani di analisi e raccolta dati furono registrati in anticipo per prevenire bias da parte dei ricercatori.\nGli studi selezionati per la replicazione includevano domande di ricerca come:\n\nLa convinzione che il comportamento umano sia predeterminato incoraggia il tradimento?\n\nI bambini seguono automaticamente lo sguardo per trovare oggetti nascosti?\n\nÈ possibile osservare un “effetto after-motion” da fotografie fisse che rappresentano movimento?\n\nI risultati del progetto fecero scalpore e conquistarono i titoli dei giornali a livello globale. Solo il 36% degli studi replicò con successo, ottenendo un valore-p inferiore a 0.05. La psicologia sociale si rivelò particolarmente problematica, con un tasso di replicazione del 25%, rispetto al 50% degli studi di psicologia cognitiva.\nPer contestualizzare questi numeri, se gli effetti originali fossero stati realmente validi, il tasso minimo di replicazione atteso sarebbe stato dell’89% (Field et al., 2019). Anche tra gli studi replicati, le dimensioni degli effetti risultarono dimezzate rispetto a quelle riportate negli studi originali.\nQuesti risultati provocarono una forte reazione nella comunità scientifica. Ci si chiedeva: era la fine della psicologia? La disciplina avrebbe mai recuperato credibilità? Sebbene i dati fossero allarmanti, aprirono un dibattito più ampio. Come sottolineato da Kuhn (1962) e Redish et al. (2018), fallimenti nella replicazione possono segnare l’inizio di una rivoluzione scientifica, stimolando un ripensamento dei metodi, delle ipotesi e delle pratiche di ricerca.\nIl Reproducibility Project: Psychology non solo mise in luce le fragilità della disciplina, ma divenne un punto di partenza per migliorare la trasparenza, la collaborazione e la robustezza nella ricerca psicologica.\n\n48.4.7.1 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca più recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell’arco di vent’anni. Questa ricerca suggerisce che poco più della metà di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilità (Collaboration, 2015). Questo dato è in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilità degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente più incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i più bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalità hanno mostrato tassi leggermente più incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilità dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell’apparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilità che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilità di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, più in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilità di molti risultati ritenuti consolidati, ma anche la necessità di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche è ancora in atto.\n\n48.4.8 2015: 1500 Scienziati Sollevano il Velo sulla Riproducibilità\nI risultati del progetto Collaboration (2015) colpirono il mondo della psicologia come un fulmine a ciel sereno. Molti risultati psicologici, considerati affidabili, crollarono improvvisamente, generando un’ondata di discussioni nei dipartimenti universitari: quale sarebbe stato il prossimo “effetto” a fallire? Tuttavia, nonostante la psicologia fosse diventata l’emblema delle repliche fallite, presto si comprese che non era un problema esclusivo della disciplina.\nNel 2016, Baker condusse un’indagine su 1500 scienziati provenienti da diverse discipline, tra cui chimica, medicina, fisica e ingegneria, per esplorare le preoccupazioni riguardo alla replicazione e alla riproducibilità (Baker, 2016). I risultati furono sorprendenti: circa il 90% dei partecipanti concordò sull’esistenza di una crisi di riproducibilità, definita come significativa dal 52% e lieve dal 38%.\nUn dato particolarmente allarmante emerse dall’indagine:\n\nIn media, il 40% degli scienziati aveva riscontrato difficoltà nel riprodurre i propri esperimenti.\n\nQuesta percentuale saliva a oltre il 60% quando si tentava di riprodurre gli esperimenti di altri ricercatori.\n\nTra le discipline, la chimica risultò la più problematica, con oltre l’85% dei ricercatori che riportavano fallimenti nel riprodurre i risultati altrui.\nL’articolo di Baker riportava anche esperienze personali che riflettevano il senso di smarrimento generato da questa crisi. Il professor Marcus Munafò, per esempio, descrisse così il suo percorso:\n\nHo cercato di replicare ciò che dalla letteratura sembrava semplice, ma non ci sono riuscito. Ho avuto una crisi di fiducia, e poi ho scoperto che questa esperienza non era affatto rara. (Baker, 2016)\n\nL’indagine di Baker non si limitò a evidenziare il problema, ma esplorò anche le possibili cause della crisi, come pratiche metodologiche inadeguate e pressioni accademiche, offrendo al contempo suggerimenti per interventi correttivi.\nL’indagine segnò un momento cruciale: la crisi della riproducibilità, inizialmente confinata a discussioni accademiche, raggiunse una visibilità globale. Non era più solo un problema della psicologia, ma un fenomeno che colpiva l’intero mondo scientifico, portando con sé la necessità di una trasformazione radicale delle pratiche di ricerca.\nQuesto evento contribuì a consolidare il riconoscimento della crisi della riproducibilità come una sfida centrale per tutta la scienza, spingendo verso un cambiamento culturale che mettesse al centro trasparenza, rigore e collaborazione.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "48  La crisi della replicazione",
    "section": "\n48.5 La Cultura della Frode nel Sistema Accademico",
    "text": "48.5 La Cultura della Frode nel Sistema Accademico\nIn alcuni casi, la crisi della replicazione si intreccia con episodi di frode scientifica, rivelando un lato oscuro della ricerca accademica. Uno degli aspetti più preoccupanti è che il sistema accademico, con i suoi meccanismi di incentivo basati su pubblicazioni frequenti e finanziamenti competitivi, può indirettamente favorire comportamenti disonesti. Questo sistema, orientato al publish or perish (pubblica o scompari), crea pressioni che talvolta spingono i ricercatori a compromettere l’integrità scientifica per raggiungere i propri obiettivi di carriera.\n\n48.5.1 Il Caso Brian Wansink\nUn caso emblematico è quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l’amministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di più in presenza di donne o sull’effetto dei nomi “attraenti” dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero “espressioni di preoccupazione”, e quindici furono corretti. Nel 2019, Wansink si dimise dalla Cornell University dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n48.5.2 Il Caso Sylvain Lesné\nUn altro esempio rilevante riguarda Sylvain Lesné e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell’ipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesné.\nNel 2022, il neuroscienziato Matthew Schrag scoprì immagini manipolate in questo e in molti altri articoli di Lesné, inclusi quelli che sostenevano l’ipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell’articolo del 2006 alla fine accettarono di ritirarlo, ma non Lesné stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesné continui a essere finanziato dal National Institutes of Health e impiegato presso l’Università del Minnesota, dimostra un fallimento sistemico nell’affrontare la cattiva condotta scientifica.\n\n48.5.3 Altri Casi di Rilievo\nNel mondo accademico, diversi altri recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all’indagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\n\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonestà e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonestà.\nFrancesca Gino, docente presso la Harvard Business School, è stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che è in “administrative leave”.\n\n\n\nL’inefficacia delle istituzioni accademiche nel gestire la frode scientifica sembra riflettere un problema culturale di carattere sistemico. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell’integrità scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene premiato con finanziamenti, promozioni e prestigio accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "title": "48  La crisi della replicazione",
    "section": "\n48.6 Cosa Significa “Fallimento della Replicazione”?",
    "text": "48.6 Cosa Significa “Fallimento della Replicazione”?\nIl fallimento della replicazione non coincide necessariamente con l’idea che il fenomeno studiato sia inesistente. Al contrario, le cause di un esito negativo in un tentativo di replicazione possono essere molteplici e spesso difficili da individuare con precisione. Comprendere queste ragioni è fondamentale per identificare le criticità metodologiche, migliorare il rigore scientifico e favorire il progresso della conoscenza. Al di là dei casi evidenti di frode, i fallimenti della replicazione rappresentano un’opportunità per riflettere sulla qualità delle pratiche di ricerca.\n\n48.6.1 Possibili Cause di Fallimento nella Replicazione\n\nFalsi positivi nello studio originale\nUn fallimento può indicare che lo studio originale abbia rilevato un effetto inesistente per puro caso. Questo rischio è particolarmente elevato in studi con campioni di piccole dimensioni e bassa potenza statistica, dove gli effetti riportati risultano spesso sovrastimati o instabili.\n\nFalsi negativi nella replica\nIl fallimento può derivare da un falso negativo, ovvero la mancata rilevazione di un effetto realmente esistente. Le cause principali includono:\n\nDifferenze metodologiche o di popolazione tra studio originale e replica.\n\nConfondenti metodologici o una potenza statistica insufficiente.\n\nPresenza di variabili moderatrici che influenzano l’intensità dell’effetto in determinati contesti.\n\n\n\n48.6.2 La Scienza tra Incertezza e Riproducibilità\nLa scienza raramente offre certezze assolute. Come evidenziato dall’Open Science Collaboration, un singolo studio, sia esso originale o di replica, non è sufficiente a fornire una risposta definitiva. Solo replicazioni multiple e sistematiche possono distinguere effetti reali da errori casuali, offrendo una visione più affidabile di un fenomeno. Questo approccio richiede tempo e risorse, ma rappresenta il cuore del metodo scientifico.\n\n48.6.3 Psicologia e Altri Campi\nSebbene la crisi della replicazione sia stata ampiamente discussa in psicologia, problemi simili affliggono molte altre discipline scientifiche. Studi di replicazione hanno evidenziato risultati preoccupanti: in oncologia, meno della metà degli studi replicati ha prodotto risultati coerenti, con tassi di riproducibilità estremamente bassi in alcuni casi; nelle neuroscienze, i tentativi di replicare correlazioni cervello-comportamento hanno mostrato un altissimo tasso di insuccesso. Anche in discipline come l’economia e la filosofia sperimentale, pur registrando tassi di replicazione relativamente più elevati, permangono dubbi sulla selezione degli studi replicati e sulla rappresentatività dei risultati (Pennington, 2023).\nQuesti dati dimostrano che la problematica della replicazione non è esclusiva della psicologia, ma comune a diverse aree del sapere. Tuttavia, sollevano anche un interrogativo critico: è corretto parlare di “crisi” o si tratta piuttosto di una fase di trasformazione necessaria per migliorare il rigore e la trasparenza nella ricerca scientifica?",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "title": "48  La crisi della replicazione",
    "section": "\n48.7 Dibattito sulla Natura della Crisi",
    "text": "48.7 Dibattito sulla Natura della Crisi\nIl tema della crisi della replicazione ha suscitato un dibattito acceso e opinioni contrastanti all’interno della comunità scientifica:\n\nApproccio alle repliche: Alcuni ricercatori ritengono che le repliche esatte siano poco significative, preferendo le repliche concettuali che possano approfondire la comprensione di un fenomeno. Altri, invece, sostengono che solo repliche rigorose ed esatte siano in grado di verificare la robustezza di un effetto, garantendo maggiore affidabilità.\nInterpretazione dei dati dell’Open Science Collaboration (OSC): Il tasso di successo delle repliche riportato dall’OSC, pari al 36%, ha alimentato ulteriori discussioni. Alcuni attribuiscono questo risultato a differenze metodologiche tra studi originali e tentativi di replica, come campioni diversi o contesti modificati. Tuttavia, ricerche successive hanno smentito queste ipotesi, indicando che tali variazioni non spiegano interamente i bassi tassi di replicazione.\n\nInvece di considerare i fallimenti di replicazione come una crisi, molti studiosi li interpretano come un’opportunità per rafforzare la scienza. La replicazione, infatti, rappresenta un elemento fondamentale del metodo scientifico: permette di identificare i limiti di un fenomeno e di migliorare la comprensione delle condizioni in cui si manifesta. Ogni fallimento diventa, così, uno stimolo per il progresso.\nQuesta visione ha dato origine a un movimento noto come “rivoluzione della credibilità”, che punta a migliorare la qualità della ricerca attraverso trasparenza, autocorrezione e valorizzazione delle repliche. Progetti come il Loss of Confidence dimostrano che riconoscere i limiti e le incertezze degli studi precedenti non rappresenta una debolezza, ma un segno di integrità scientifica.\nIl passaggio dalla percezione di crisi a una rivoluzione della credibilità rappresenta un profondo cambiamento culturale nella comunità accademica. La scienza non è un processo statico, ma un percorso dinamico che evolve grazie al confronto critico e alla riflessione. In questa prospettiva, ogni fallimento nella replicazione non è un punto d’arrivo, ma un trampolino di lancio verso una conoscenza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "title": "48  La crisi della replicazione",
    "section": "\n48.8 Cause della Crisi",
    "text": "48.8 Cause della Crisi\n\n48.8.1 Incentivi Accademici e la Dominanza della Quantità sulla Qualità\nPer comprendere a fondo le problematiche che affliggono il mondo della ricerca, è essenziale considerare il contesto lavorativo in cui operano i ricercatori. Sebbene spesso vengano idealizzati come figure obiettive e razionali, è fondamentale ricordare che sono anche esseri umani, soggetti a pressioni professionali, responsabilità economiche e ambizioni di carriera. Il loro lavoro è costantemente sottoposto a valutazione: oltre a gestire attività didattiche e amministrative, devono pubblicare articoli su riviste di prestigio e assicurarsi finanziamenti per sostenere i loro gruppi di ricerca. Questo sistema premia la quantità a discapito della qualità, favorendo una mentalità di “pubblica o perisci”.\nLa pressione a pubblicare incessantemente è una delle principali cause dei problemi che alimentano la crisi di replicazione nella scienza. La cultura del “publish or perish” spinge i ricercatori a produrre rapidamente risultati rilevanti, spesso a scapito della rigorosità metodologica e della riproducibilità (Gopalakrishna et al., 2022; Grimes et al., 2018).\nQuesta situazione genera un paradosso: ciò che favorisce la carriera individuale di uno scienziato non sempre coincide con gli interessi del progresso scientifico. Le motivazioni intrinseche di contribuire alla conoscenza vengono spesso offuscate da motivazioni estrinseche legate a indicatori di produttività accademica. Non sorprende, quindi, che oltre il 60% dei ricercatori individui questa pressione come una delle principali cause dei problemi legati alla replicazione e alla riproducibilità.\n\n48.8.2 Bias Cognitivi e Distorsioni nella Ricerca\nI bias cognitivi rappresentano un ulteriore ostacolo alla qualità della ricerca. Tra i principali si trovano:\n\n\nBias di conferma: la tendenza a cercare o interpretare informazioni che confermano le proprie ipotesi iniziali, trascurando dati contrari.\n\nApofenia: il riconoscimento di schemi in dati casuali, spesso combinato con una preferenza per risultati positivi.\n\nBias retrospettivo: la convinzione che un evento fosse prevedibile solo dopo che si è verificato, portando i ricercatori a presentare risultati in modo fuorviante.\n\nQuesti bias favoriscono la ricerca di risultati positivi a scapito di quelli nulli o contrari, contribuendo a creare un problema più grande: il bias di pubblicazione.\n\n48.8.3 Bias di Pubblicazione e il Problema dei “File Drawer”\nIl sistema di pubblicazione accademica incentiva risultati innovativi e positivi, spesso trascurando studi con risultati nulli o repliche. Questo bias, noto come file drawer problem, descrive la tendenza a relegare nei “cassetti” studi non statisticamente significativi, rendendoli inaccessibili e distorcendo la letteratura scientifica.\nIn psicologia, l’impatto di questo fenomeno è particolarmente grave. Studi hanno rilevato che oltre il 90% degli articoli in psicologia riporta risultati positivi, una percentuale notevolmente più alta rispetto ad altre discipline. Questo non solo crea una rappresentazione distorta della realtà, ma amplifica il rischio di undead theories, teorie prive di solide basi empiriche che continuano a dominare il dibattito scientifico.\n\n48.8.4 Pratiche di Ricerca Dubbiamente Etiche\nLa pressione a pubblicare ha portato all’emergere di comportamenti noti come Questionable Research Practices (QRPs). Tra questi:\n\n\nP-hacking: manipolazione dei dati o analisi fino a ottenere un p-value significativo (&lt; 0.05).\n\nHARKing (Hypothesizing After Results are Known): modificare l’ipotesi iniziale per adattarla ai risultati ottenuti.\n\nStopping opzionale: interrompere la raccolta dei dati quando si raggiunge un p-value desiderato.\n\nQueste pratiche, pur non essendo sempre considerate frodi, distorcono i risultati e compromettono la replicabilità degli studi, creando teorie difficili da falsificare.\n\n48.8.5 La Centralità dei Valori-p e la Crisi della Significatività Statistica\nIl valore-p, elemento centrale della metodologia scientifica basata sull’ipotesi nulla (Null Hypothesis Significance Testing), è diventato una “valuta” per la pubblicazione. Tuttavia, affidarsi esclusivamente ai valori-p presenta gravi limiti:\n\n\nParadosso di Lindley: con campioni di grandi dimensioni, valori-p vicini a 0.05 possono supportare l’ipotesi nulla invece di confutarla.\n\nDistorsioni da QRPs: l’utilizzo di pratiche discutibili può produrre falsi positivi statisticamente significativi.\n\nBenché alcuni studiosi abbiano proposto l’abbassamento della soglia di significatività statistica a 0.005 o l’integrazione dei valori-p con stime degli effetti e intervalli di confidenza, il punto centrale continua ad essere il fatto che l’enfasi dovrebbe spostarsi dai risultati statistici alla qualità metodologica degli studi.\nPer affrontare questi problemi, è necessario un cambiamento culturale e strutturale. La trasparenza, l’autocorrezione e l’adozione di pratiche come la preregistrazione degli studi possono aiutare a ridurre l’impatto dei bias e delle QRPs. Inoltre, incentivare repliche rigorose e promuovere un sistema di pubblicazione che premi la qualità rispetto alla quantità sono passi fondamentali per migliorare la credibilità della scienza.\n\n48.8.6 Campioni Troppo Piccoli\nUno dei fattori chiave che contribuiscono alla crisi della replicazione in psicologia è l’uso di campioni di dimensioni ridotte. Questo approccio ha permesso ai ricercatori di massimizzare la quantità di pubblicazioni a scapito della qualità e dell’affidabilità degli effetti rilevati. Higginson e Munafò (2016) sottolineano come questo fenomeno rappresenti una “selezione naturale della cattiva scienza”, dove incentivi strutturali premiano metodologie di ricerca poco rigorose.\nContrariamente a quanto si potrebbe pensare, ottenere un effetto significativo con un campione piccolo non garantisce che lo stesso effetto rimanga significativo con un campione più grande. Questo problema è strettamente legato alla potenza statistica, che rappresenta la probabilità, nel lungo periodo, di rifiutare correttamente l’ipotesi nulla quando l’ipotesi alternativa è vera. Una potenza statistica bassa comporta un’elevata probabilità di errori di Tipo II (falsi negativi) e, allo stesso tempo, riduce la probabilità che un risultato significativo rifletta un effetto reale.\nIn psicologia, la potenza statistica viene solitamente fissata a un minimo dell’80%, il che significa che, nel lungo termine, uno studio dovrebbe avere l’80% di possibilità di rilevare un effetto reale. Tuttavia, molti studi più datati raramente menzionano la potenza statistica, nonostante il concetto sia noto dagli anni ’30. Questo ha contribuito a generare una letteratura scientifica con effetti sovrastimati o poco affidabili.\nIn un approccio frequentista, per calcolare la potenza di uno studio, è necessario conoscere almeno due dei seguenti tre parametri: dimensione dell’effetto atteso, criterio di significatività e dimensione del campione pianificata. Per esempio, un ricercatore che si aspetta di trovare un effetto “medio” (Cohen’s d = 0.50) con un criterio di significatività di p &lt; .05 può determinare la dimensione del campione necessaria per garantire una potenza sufficiente. Tuttavia, molti studi psicologici hanno ignorato questo tipo di pianificazione, basandosi su campioni troppo piccoli per rilevare effetti affidabili.\nL’uso di campioni piccoli, combinato con pratiche discutibili di ricerca (Questionable Research Practices, QRPs) e bias di pubblicazione, ha portato a una letteratura scientifica piena di effetti inflazionati. Ad esempio, meta-analisi iniziali sul concetto di esaurimento dell’ego (ego depletion) stimavano un effetto medio (d = 0.62). Tuttavia, repliche successive hanno trovato effetti molto più piccoli, spesso inferiori a d = 0.10. Allo stesso modo, il progetto dell’Open Science Collaboration (2015) ha evidenziato che le dimensioni degli effetti nelle repliche erano, in media, dimezzate rispetto agli studi originali.\nCampioni di piccole dimensioni non solo riducono la probabilità di rilevare effetti reali, ma compromettono anche la credibilità dei risultati significativi. Una bassa potenza statistica mina l’obiettivo fondamentale della ricerca scientifica, limitando la capacità di trarre conclusioni solide e contribuendo alla crisi della replicazione. Per migliorare la qualità della scienza, è essenziale adottare pratiche di ricerca più rigorose, pianificando adeguatamente la dimensione del campione e garantendo una potenza statistica sufficiente.\n\n48.8.7 La Misurazione: Un Problema Sottovalutato\nOltre alle dimensioni campionarie inadeguate, la psicologia potrebbe soffrire di problemi legati alla misurazione. Per rispondere a domande scientifiche, i ricercatori devono definire e misurare con precisione il costrutto oggetto di indagine. Ad esempio, per investigare se una mentalità di crescita possa migliorare l’intelligenza, un ricercatore deve prima definire e poi misurare sia la mentalità che l’intelligenza. Tuttavia, la misurazione è un processo complesso e impegnativo.\nL’intelligenza è un costrutto latente, il che significa che, a differenza dell’altezza di una persona, non può essere osservata o misurata direttamente. Gli psicologi inferiscono l’intelligenza stimando il quoziente intellettivo (QI) di un individuo, basandosi sulle risposte a numerose domande di un test di intelligenza, adattate all’età del partecipante. Ma come possiamo sapere se il QI rappresenta un buon indicatore dell’intelligenza? È necessario valutare la validità di costrutto, definita come la capacità di una misura di comportarsi in modo coerente con le ipotesi teoriche (Cronbach e Meehl, 1955; Fink, 2010). Alcuni ricercatori hanno sostenuto che una spiegazione spesso trascurata della crisi della replicazione risieda nella scarsa validità di costrutto delle nostre misure (Lilienfeld e Strother, 2020; Loken e Gelman, 2017).\nPer evidenziare il problema della misurazione in psicologia, Flake e colleghi hanno condotto una revisione di articoli pubblicati in una rivista prestigiosa. La loro analisi ha mostrato che molte scale di misurazione utilizzate non avevano una chiara fonte dichiarata, mentre altre erano state sviluppate senza una documentazione adeguata. Inoltre, una parte significativa delle scale citate era stata modificata rispetto alla versione originale, rendendo sconosciute le loro proprietà psicometriche.\nGli autori hanno anche rilevato l’uso di Pratiche di Misurazione Discutibili (Questionable Measurement Practices, QMPs), che includono la mancata divulgazione di informazioni sulla validità delle misure quando questa non risulta soddisfacente. Questi problemi suggeriscono che molti costrutti psicologici non siano adeguatamente validati, un fattore che potrebbe contribuire alle difficoltà di replicazione degli studi.\nAltri ricercatori hanno argomentato che problemi di validità interna ed esterna possano contribuire alla crisi della replicazione (Fabrigar et al., 2020). La validità interna si riferisce a come uno studio stabilisce una relazione di causa-effetto tra le variabili indipendenti e dipendenti (Cook e Campbell, 1979). Fabrigar et al. suggeriscono che un tentativo di replicazione possa fallire se:\n\nLo studio originale ha sofferto di minacce alla validità che hanno causato un effetto spurio (alta validità interna nella replica).\nI ricercatori introducono elementi assenti nello studio originale (bassa validità interna nella replica).\n\nLa validità esterna riguarda la possibilità di generalizzare i risultati di uno studio ad altri contesti o popolazioni. Questo può influenzare le repliche se, ad esempio, la replica viene condotta su una popolazione diversa o se i materiali dello studio sono tradotti da un’altra lingua, causando incomprensioni nei partecipanti.\nPer sintetizzare questi problemi, Flake e Fried (2020) li definiscono “measurement schmeasurement”, espressione che descrive la mancanza di attenzione verso la validità delle misure nella scienza psicologica. Se le misure utilizzate in uno studio non sono valide, ne consegue che anche i risultati e le conclusioni tratte non possono essere considerati affidabili. Quando tali studi vengono replicati, potrebbero essere destinati al fallimento ancor prima di iniziare.\n\n48.8.8 La Novità a Scapito della Replicazione: Una Distorsione nella Ricerca\nL’enfasi eccessiva sui risultati innovativi e il valore attribuito alle scoperte significative stanno incentivando pratiche di ricerca distorte, favorendo la sovrarappresentazione di risultati positivi e una mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munafò, 2015).\nLa psicologia sperimentale, nata nel 1879 con il primo laboratorio fondato da Wilhelm Wundt, si trova oggi a fronteggiare una crisi di replicazione nonostante oltre un secolo di progresso scientifico. Una delle principali cause è la scarsa attenzione dedicata agli studi di replicazione, storicamente poco valorizzati e raramente premiati nelle scienze sociali.\nLa cultura accademica attuale privilegia la novità e i risultati positivi, relegando i risultati nulli e gli studi di replicazione a un ruolo marginale. Questo fenomeno riflette ciò che Antonakis (2017) definisce significosis – un’ossessione per i risultati significativi – e neofilia – un’eccessiva enfasi sulla novità. Già Sterling (1959) aveva messo in guardia contro il rischio che i ricercatori testassero ripetutamente un’ipotesi fino a ottenere, per puro caso, un risultato significativo, senza verificarlo attraverso replicazioni. In assenza di queste verifiche, interi ambiti di studio possono essere costruiti su un numero allarmante di affermazioni non supportate da dati solidi.\nQuesto squilibrio si riflette non solo nella letteratura scientifica, ma anche nei progetti di ricerca condotti dagli studenti. Le tesi di laurea in psicologia, spesso realizzate in autonomia, senza finanziamenti e con tempistiche ridotte, soffrono degli stessi problemi della ricerca accademica: campioni di piccole dimensioni, studi sottopotenziati e un’elevata probabilità di falsi positivi. Se pubblicati selettivamente, questi progetti rischiano di premiare la fortuna più della qualità scientifica.\nIniziative come il Collaborative Replications and Education Project (CREP) rappresentano un passo verso un cambiamento culturale. CREP incoraggia gli studenti a condurre studi di replicazione come parte del loro percorso formativo, promuovendo una scienza più collaborativa, rigorosa e orientata alla verifica dei risultati, contrastando così la prevalenza della novità fine a se stessa.\n\n48.8.9 La scienza non si autocorregge come dovrebbe\nUn principio cardine della scienza è l’autocorrezione, ma nella pratica accademica moderna, questo processo sembra spesso ostacolato da incentivi e preoccupazioni reputazionali. I ricercatori, pressati dalle scadenze per nuovi progetti o richieste di finanziamento, raramente dedicano il tempo necessario a rivedere e correggere i propri lavori passati. Questo mancato impegno rappresenta una delle spiegazioni della crisi di replicazione.\nUn esempio significativo è il Registered Replication Report dello studio di Srull e Wyer (1979), replicato da McCarthy et al. (2018). Lo studio originale aveva mostrato che il priming con stimoli aggressivi portava i partecipanti a interpretare un comportamento ambiguo come più ostile. Tuttavia, il tentativo di replicazione ha rilevato un effetto trascurabile. Una possibile spiegazione è che alcune statistiche dello studio originale fossero riportate in modo errato, un errore che, nonostante tutto, non è mai stato corretto. Similmente, altri casi documentano gravi discrepanze nei dati riportati in letteratura, come dimostrato da van der Zee et al. (2017) nel loro riesame di articoli del Cornell Food Lab, che ha rivelato oltre 150 incongruenze.\nLa microbiologa Elizabeth Bik ha inoltre evidenziato che la manipolazione di immagini scientifiche è diventata una forma emergente di cattiva condotta, volta a rendere i risultati più impressionanti o a mascherare dati problematici. Sebbene alcuni casi di manipolazione portino a ritrazioni o correzioni, il lavoro di revisione è spesso svolto da altri ricercatori come attività volontaria, suggerendo che la scienza sia più “eterocorrettiva” che autocorrettiva.\nNonostante le difficoltà, il processo di autocorrezione è fondamentale per il progresso scientifico. Vazire (2020) sostiene che il disagio provocato dalla revisione critica sia salutare e necessiti di una maggiore umiltà intellettuale da parte dei ricercatori. Questo include il riconoscimento pubblico delle limitazioni dei propri studi e, quando necessario, la pubblicazione di correzioni o dichiarazioni di perdita di fiducia nei risultati originali.\n\n48.8.10 La Scienza Chiusa come Ostacolo alla Replicazione\nUno degli ostacoli principali alla replicazione è la mancanza di trasparenza e dettaglio negli studi precedenti. In un sistema di “scienza chiusa,” in cui dati e metodi sono trattati come segreti industriali, ricreare esperimenti e verificare analisi diventa un’impresa ardua, se non impossibile. Questa opacità interessa molti aspetti della ricerca, dai materiali utilizzati ai dati raccolti, fino alle scelte analitiche effettuate durante lo studio.\nPratiche come la reportistica selettiva e la flessibilità non dichiarata nei metodi e nei dati compromettono l’integrità della scienza. La riluttanza a condividere dati e materiali, insieme al bias di pubblicazione che favorisce i risultati significativi rispetto a quelli nulli, amplifica ulteriormente il problema (Bruton et al., 2020; Nosek et al., 2012).\nUn esempio concreto riguarda le decisioni prese durante l’analisi dei dati, come la gestione dei valori anomali o le correzioni per analisi multiple. Queste scelte possono avere un impatto notevole sui risultati, ma se non vengono documentate in modo trasparente, altri ricercatori non saranno in grado di replicare gli stessi risultati. Questo problema è noto come il giardino dei sentieri che si biforcano (garden of forking paths), dove una serie di decisioni non esplicitate porta a risultati divergenti e difficili da verificare (Gelman & Loken, 2013).\n\n\n\n\n\n\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: “Gli studenti appassionati di cucina hanno una maggiore probabilità di essere figli unici?” o “Gli studenti provenienti da famiglie battiste sono più inclini a partecipare a club politici scolastici?”. Meehl evidenziò che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno Il Giardino dei Sentieri che si Biforcano [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libertà a disposizione del ricercatore nell’analisi dei dati. Come nell’esempio di Meehl, è possibile esaminare le differenze intergruppo (se questo è l’oggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno “statisticamente significative”. Ciò indica che, in quello specifico campione, quel particolare aspetto dei dati è rilevante. Tuttavia, questa differenza “statisticamente significativa” non sarà necessariamente generalizzabile ad un altro campione, il quale presenterà le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman & Loken (2013), l’approccio basato sul test dell’ipotesi nulla si limita a “descrivere il rumore”. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all’avanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un’ottica di inferenza statistica, questo problema è riconducibile al concetto di “p-hacking” o “data dredging”, dove l’esplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati può portare a falsi positivi e a una sovrastima della significatività statistica.\n\n\n\nLa soluzione è chiara: promuovere una cultura di apertura, rendendo dati e metodi accessibili. Nonostante i progressi tecnologici che facilitano la condivisione, questa pratica rimane poco diffusa. Sebbene esistano ragioni valide per non condividere i dati, come la tutela dell’anonimato dei partecipanti, tali motivazioni dovrebbero essere dichiarate in modo esplicito e rigoroso.\nQuesti ostacoli sottolineano l’urgenza di una trasformazione culturale all’interno della comunità scientifica, che favorisca trasparenza e collaborazione. Affrontare queste limitazioni strutturali è essenziale per superare la crisi di replicazione, permettendo alla scienza di avanzare in modo più affidabile e autoregolarsi nel tempo.\n\n48.8.11 La Probabilità Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora più profonda e risieda nell’approccio statistico stesso, ampiamente adottato dalla comunità scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficoltà nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un’interpretazione e un’applicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L’approccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilità di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilità di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso “p-value” è un esempio di questa logica: esso indica la probabilità di ottenere risultati estremi quanto o più estremi di quelli osservati, supponendo che l’ipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto è probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una “probabilità inferenziale”, cioè la probabilità che l’ipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l’approccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilità inferenziale. L’approccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le “prior”) relative all’ipotesi in esame.\nLa differenza tra questi due approcci è cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l’ipotesi nulla è vera, l’approccio bayesiano ci fornisce la probabilità che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n48.8.12 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L’uso esclusivo dell’approccio frequentista può portare a sovrastimare la forza delle evidenze a favore di un’ipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significatività statistica, rendendo più difficile dichiarare un risultato “significativo”.\nRichiedere la preregistrazione delle ipotesi per prevenire l’HARKing (Hypothesizing After Results are Known).\nFar sì che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo “positivi” o “nuovi”.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell’interpretazione delle evidenze statistiche. L’adozione di un approccio bayesiano offre una soluzione più radicale, fornendo un quadro più completo e realistico della forza delle evidenze a favore o contro un’ipotesi scientifica.\n\n48.8.12.1 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua – osservare i risultati man mano che vengono raccolti nell’approccio frequentista – possa avere conseguenze significative sulle conclusioni di uno studio. In particolare, questa pratica può influire sulla probabilità di ottenere un risultato statisticamente significativo.\nNella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l’“ipotesi nulla” è vera: non c’è differenza tra le medie delle popolazioni. Tuttavia, a causa della variabilità campionaria, il p-valore risulta fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\nsimulate_t_tests &lt;- function(seed, max_sample_size, mu = 0, sigma = 1) {\n  set.seed(seed)\n\n  # Intervallo di grandezza campionaria\n  sample_sizes &lt;- seq(2, max_sample_size, by = 2)\n  p_values &lt;- numeric(length(sample_sizes))\n\n  # Genera due campioni grandi iniziali da una distribuzione normale\n  full_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n  full_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n  # Simulazione\n  for (i in seq_along(sample_sizes)) {\n    n &lt;- sample_sizes[i]\n\n    # Estrai sottoinsiemi incrementali dai campioni completi\n    sample1 &lt;- full_sample1[1:n]\n    sample2 &lt;- full_sample2[1:n]\n\n    # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n    t_test &lt;- t.test(sample1, sample2, var.equal = TRUE)\n    p_values[i] &lt;- t_test$p.value\n  }\n\n  # Crea il grafico del p-valore in funzione della grandezza campionaria\n  plot(\n    sample_sizes, p_values, type = \"l\", col = \"#b97c7c\",\n    xlab = \"Grandezza Campionaria\", ylab = \"P-valore\",\n    main = \"P-valore in funzione della grandezza campionaria\"\n  )\n  abline(h = 0.05, col = \"#8f2727\", lty = 2, lwd = 1.5)\n  legend(\"topright\", legend = \"Significatività a 0.05\", col = \"#8f2727\", lty = 2, cex = 0.8)\n}\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambi progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). È evidente come il p-valore vari drasticamente con l’aggiunta di nuove osservazioni ai campioni. Inoltre, in alcune configurazioni, il p-valore può scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato “statisticamente significativo”, pur avendo campioni estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed = 1234, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\nsimulate_t_tests(seed = 2, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\n\nQuesta simulazione mette in evidenza una limitazione fondamentale dell’approccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questo rende il processo decisionale estremamente volatile, poiché, teoricamente, ad ogni nuovo studio si “dimentica” tutta l’informazione derivante dagli studi precedenti.\n\n48.8.12.2 Analisi Bayesiana\nL’approccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cioè, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l’informazione a priori (ciò che sapevamo prima dell’esperimento) con la verosimiglianza (ciò che i dati ci dicono). Questo equilibrio è particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l’informazione a priori assume un ruolo più rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l’analisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l’approccio frequentista, forniscono un risultato “statisticamente significativo”, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilità al 95% compreso tra -0.52 e 1.12. Poiché questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c’è una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l’approccio bayesiano è più resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l’analisi bayesiana fornisce una rappresentazione più sfumata e realistica dell’incertezza associata alle nostre conclusioni.\nInoltre, l’approccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\n# Imposta il seme per la riproducibilità\nset.seed(12)\n\n# Parametri della distribuzione normale\nmu &lt;- 0\nsigma &lt;- 2\nmax_sample_size &lt;- 50\n\n# Genera due campioni indipendenti\nfull_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\nfull_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n\n# Prepara i dati per Stan\nstan_data &lt;- list(\n  N1 = length(full_sample1),\n  N2 = length(full_sample2),\n  y1 = full_sample1,\n  y2 = full_sample2\n)\n\n# Visualizza i dati preparati\nprint(stan_data)\n#&gt; $N1\n#&gt; [1] 50\n#&gt; \n#&gt; $N2\n#&gt; [1] 50\n#&gt; \n#&gt; $y1\n#&gt;  [1] -2.9611  3.1543 -1.9135 -1.8400 -3.9953 -0.5446 -0.6307 -1.2565 -0.2129\n#&gt; [10]  0.8560 -1.5554 -2.5878 -1.5591  0.0239 -0.3048 -1.4069  2.3778  0.6810\n#&gt; [19]  1.0139 -0.5866  0.4473  4.0144  2.0240 -0.6049 -2.0505 -0.5348 -0.3982\n#&gt; [28]  0.2622  0.2916  0.7241  1.3480  4.1441 -1.0821 -2.1410 -0.7449 -0.9703\n#&gt; [37]  0.5496 -0.9590  1.5962 -2.0089  0.2100 -2.3120  1.1563 -3.1913 -0.6170\n#&gt; [46]  0.8989 -1.9541  0.3800  1.4629 -0.9852\n#&gt; \n#&gt; $y2\n#&gt;  [1] -0.08537 -0.22534  0.91365  4.04067 -2.10178  1.46930  1.07850 -2.62855\n#&gt;  [9] -0.50008  0.62841  0.81309  1.98884  1.71154  0.39426  1.66865  1.69358\n#&gt; [17]  3.90821 -4.29852  1.94224  2.29012 -1.05080  0.50064 -0.85881 -0.36504\n#&gt; [25] -0.20662 -1.26768 -2.54211 -0.76790  1.03351 -0.35594  0.00852 -2.54812\n#&gt; [33] -0.40422  2.32893 -0.04676  1.79431 -0.35345  2.22742 -1.08378 -1.92680\n#&gt; [41]  0.75290 -1.96935  1.79512  0.25853  2.06741 -0.68458  0.90456 -1.38948\n#&gt; [49] -0.47803 -2.01460\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"two_means_diff.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\nmod$code() # Stampa il codice del modello\n#&gt;  [1] \"data {\"                                                                \n#&gt;  [2] \"  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\"             \n#&gt;  [3] \"  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\"             \n#&gt;  [4] \"  vector[N1] y1; // Dati del gruppo 1\"                                 \n#&gt;  [5] \"  vector[N2] y2; // Dati del gruppo 2\"                                 \n#&gt;  [6] \"}\"                                                                     \n#&gt;  [7] \"parameters {\"                                                          \n#&gt;  [8] \"  real mu1; // Media del gruppo 1\"                                     \n#&gt;  [9] \"  real delta; // Differenza tra le medie\"                              \n#&gt; [10] \"  real&lt;lower=0&gt; sigma; // Deviazione standard comune\"                  \n#&gt; [11] \"  real&lt;lower=0&gt; nu; // Gradi di libertà per la distribuzione t\"        \n#&gt; [12] \"}\"                                                                     \n#&gt; [13] \"transformed parameters {\"                                              \n#&gt; [14] \"  real mu2; // Media del gruppo 2\"                                     \n#&gt; [15] \"  mu2 = mu1 + delta;\"                                                  \n#&gt; [16] \"}\"                                                                     \n#&gt; [17] \"model {\"                                                               \n#&gt; [18] \"  // Priori\"                                                           \n#&gt; [19] \"  mu1 ~ normal(0, 5);\"                                                 \n#&gt; [20] \"  delta ~ normal(0, 2); // Priore su delta\"                            \n#&gt; [21] \"  sigma ~ cauchy(0, 5);\"                                               \n#&gt; [22] \"  nu ~ gamma(2, 0.1); // Priore sulla t-student\"                       \n#&gt; [23] \"  \"                                                                    \n#&gt; [24] \"  // Verosimiglianza\"                                                  \n#&gt; [25] \"  y1 ~ student_t(nu, mu1, sigma);\"                                     \n#&gt; [26] \"  y2 ~ student_t(nu, mu2, sigma);\"                                     \n#&gt; [27] \"}\"                                                                     \n#&gt; [28] \"generated quantities {\"                                                \n#&gt; [29] \"  real diff; // Differenza tra le medie (alias di delta per chiarezza)\"\n#&gt; [30] \"  diff = delta;\"                                                       \n#&gt; [31] \"}\"\n\nEsegui il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nRiassumi i risultati per mu1, mu2 e delta:\n\nfit_summary &lt;- fit$summary(variables = c(\"mu1\", \"mu2\", \"delta\"))\nprint(fit_summary)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu1      -0.320 -0.319 0.244 0.240 -0.725 0.075 1.001 5564.826 5622.504\n#&gt; 2 mu2       0.161  0.159 0.242 0.243 -0.233 0.561 1.000 9267.197 7120.562\n#&gt; 3 delta     0.481  0.479 0.343 0.341 -0.081 1.046 1.000 5332.071 5542.274\n\nEstrai i campioni di delta:\n\ndelta_samples &lt;- fit$draws(variables = \"delta\", format = \"matrix\")[, 1]\n\nDisegna la distribuzione a posteriori di delta:\n\ndelta_df &lt;- data.frame(delta = delta_samples)\n\nggplot(delta_df, aes(x = delta)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"#b97c7c\", alpha = 0.75) +\n  geom_vline(\n    xintercept = mean(delta_samples),\n    linetype = \"dashed\",\n    linewidth = 1.2,\n    label = paste(\"Mean:\", round(mean(delta_samples), 2))\n  ) +\n  labs(\n    x = \"delta\",\n    y = \"Density\",\n    title = \"Posterior distribution of delta\"\n  ) \n\n\n\n\n\n\n\nPuoi calcolare l’intervallo di credibilità usando per un intervallo al 95%:\n\nquantile(delta_samples, probs = c(0.025, 0.975))\n#&gt;   2.5%  97.5% \n#&gt; -0.188  1.164\n\n\n48.8.12.3 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l’ipotesi nulla o non la si rifiuta. Ciò implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, è inevitabile trovare qualche effetto, anche se di minima entità.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell’effetto e di fornire una distribuzione di probabilità. Una distribuzione di probabilità è una rappresentazione grafica delle diverse possibilità che potrebbero verificarsi. In questo contesto, si tratta della “probabilità inversa”, ovvero della plausibilità dell’ipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed è il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l’aggiornamento bayesiano. Il parametro \\(\\delta\\) è la nostra ipotesi sulla differenza tra le due medie, e l’inferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL’approccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell’ipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di “significatività statistica”, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l’approccio frequentista sia spesso considerato “ingenuo” da molti ricercatori, adottare l’approccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualità. Un principio fondamentale della ricerca è “Garbage in, garbage out”. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualità delle misurazioni è insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, può trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "48  La crisi della replicazione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico è rappresentato dallo studio di Karataş & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un’interpretazione del perché lo studio di Karataş & Cutright (2023) non sia stato replicato con successo.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\n1) Sulla “Crisi della Replicazione” in Psicologia\nChe cosa si intende quando si parla di “crisi della replicazione” in psicologia?\n\n\nA. La difficoltà di molti laboratori nel reperire fondi per la ricerca.\n\n\nB. L’incapacità o la grave difficoltà di replicare, con risultati simili, una parte consistente degli studi pubblicati.\n\n\nC. La tendenza di alcuni scienziati a pubblicare risultati simili ad altri per sfruttare la loro notorietà.\n\n\nD. Lo scarso interesse degli editori di riviste nel pubblicare studi teorici.\n\n\nE. La mancanza di strumenti statistici adeguati per l’analisi dei dati qualitativi.\n\n2) Cosa significa “fallimento della replicazione”?\nQuale delle seguenti opzioni descrive correttamente il “fallimento della replicazione”?\n\n\nA. Non riuscire a pubblicare uno studio su una rivista ad alto impatto.\n\n\nB. Non riuscire a confermare la robustezza metodologica dello studio originale in sede di peer-review.\n\n\nC. Riportare risultati che confermano un’ipotesi già discussa in letteratura.\n\n\nD. Non ottenere, con procedure simili e campioni simili, risultati paragonabili a quelli dello studio originale.\n\n\nE. Non riuscire a reclutare un numero sufficiente di partecipanti in una nuova ricerca.\n\n3) Quale studio scatenò polemiche sulla precognizione?\nNel 2011, un autore pubblicò uno studio che sembrava dimostrare capacità “paranormali” nei partecipanti, scatenando polemiche e dubbi. Chi fu?\n\n\nA. Diederik Stapel, che usò dati inventati.\n\n\nB. John Ioannidis, autore di “Why Most Published Research Findings Are False”.\n\n\nC. Daryl Bem, con l’articolo “Feeling the Future” sulle facoltà precognitive.\n\n\nD. Brian Wansink, con studi su etichette “attraenti” delle verdure.\n\n\nE. Daniel Kahneman, con esperimenti sui bias cognitivi e di giudizio.\n\n4) Cosa si intende per “p-hacking”?\nLa pratica denominata p-hacking (nell’ambito della crisi di replicazione) consiste nel:\n\n\nA. Interrompere la raccolta dati nel momento in cui si ottiene un risultato in linea con l’ipotesi.\n\n\nB. Manipolare, in maniera fraudolenta, immagini o grafici.\n\n\nC. Tradurre erroneamente i questionari in più lingue, alterando i risultati.\n\n\nD. Utilizzare molteplici analisi e combinazioni di variabili fino a ottenere un valore-(p) inferiore a 0.05.\n\n\nE. Avere più autori su uno stesso manoscritto per dividerne la responsabilità.\n\n5) Qual è il tasso di replicazione emerso dal “Reproducibility Project: Psychology” (2015)?\nSecondo i dati dell’Open Science Collaboration (2015), approssimativamente quanti studi di psicologia replicarono con successo (ottenendo risultati “significativi” simili agli originali)?\n\n\nA. Circa il 36%.\n\n\nB. Circa il 65%.\n\n\nC. Quasi il 90%.\n\n\nD. Nessuno studio è stato replicato con successo.\n\n\nE. Circa il 10%.\n\n6) Cosa sono le Questionable Research Practices (QRPs)?\nQuale definizione descrive meglio le “QRPs” (Questionable Research Practices)?\n\n\nA. Pratiche statistiche avanzate che aumentano la robustezza dei risultati.\n\n\nB. Metodologie di campionamento probabilistico trasparenti e preregistrate.\n\n\nC. Pratiche di ricerca discutibili, come “optional stopping” e selezione post-hoc di ipotesi, che influiscono negativamente sull’integrità scientifica.\n\n\nD. Strumenti di meta-analisi per combinare risultati di studi diversi.\n\n\nE. Procedure di controllo etico per proteggere i diritti dei partecipanti.\n\n7) Perché i campioni troppo piccoli sono considerati problematici?\nNella letteratura sulla crisi di replicazione, perché avere campioni di dimensione ridotta costituisce una criticità?\n\n\nA. Perché rendono più facile l’analisi statistica, riducendo la possibilità di trovare p &lt; .05.\n\n\nB. Perché riducono la potenza statistica, aumentando il rischio di sovrastimare effetti e di ottenere risultati non replicabili.\n\n\nC. Perché il costo di reclutamento è troppo basso, compromettendo l’interesse dei revisori.\n\n\nD. Perché obbligano a utilizzare necessariamente test non-parametrici.\n\n\nE. Perché la psicologia preferisce dataset qualitativi, non quantitativi.\n\n8) Che cosa significa “bias di pubblicazione”?\nCon l’espressione “bias di pubblicazione” (o publication bias), ci si riferisce a:\n\n\nA. La tendenza dei revisori a selezionare articoli soltanto se ben scritti.\n\n\nB. L’inclinazione delle riviste di settore a pubblicare preferibilmente i lavori dei ricercatori senior.\n\n\nC. La propensione alla pubblicazione di studi con risultati innovativi e statisticamente positivi, trascurando invece studi con risultati nulli.\n\n\nD. L’obbligo di pubblicare i protocolli di studio in forma open.\n\n\nE. Una norma deontologica che impone di nascondere i metodi inediti per evitare furti di idee.\n\n9) Quale scopo principale ha il movimento dell’Open Science?\nNel contesto della crisi di replicazione, qual è l’obiettivo cardine promosso dal movimento per la Scienza Aperta (Open Science)?\n\n\nA. Aumentare il controllo sugli studi, rendendo segreti i metodi di analisi.\n\n\nB. Pubblicare soltanto studi che abbiano ottenuto finanziamenti pubblici.\n\n\nC. Rendere i dati, i materiali e le procedure il più possibile trasparenti e accessibili, favorendo le repliche e la verifica indipendente.\n\n\nD. Abolire completamente l’uso di test statistici e valori-p.\n\n\nE. Prediligere esclusivamente studi qualitativi in ambito psicologico.\n\n10) Perché la scienza non si autocorregge come si afferma?\nSecondo quanto discusso, come mai la scienza non risulta sempre “autocorrettiva” nella pratica reale?\n\n\nA. Perché gli editori impongono di inserire errori per testare la capacità dei revisori di individuarli.\n\n\nB. Perché è molto costoso usare software di statistica adeguati.\n\n\nC. Perché la pressione a pubblicare risultati nuovi prevale sull’attenzione a errori e correzioni; i ricercatori non hanno incentivi sufficienti a pubblicare smentite, ritrazioni o correzioni.\n\n\nD. Perché l’uso della statistica bayesiana ha complicato la procedura di revisione.\n\n\nE. Perché tutti gli studi di psicologia sono in realtà corretti al 99%.\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n\n\nB\n\n\nD\n\n\nC\n\n\nD\n\n\nA\n\n\nC\n\n\nB\n\n\nC\n\n\nC\n\nC\n\nLa crisi della replicazione in psicologia è il risultato di una combinazione di fattori sistemici e metodologici:\n\n\nIncentivi distorti (“publish or perish”), che spingono a privilegiare la novità rispetto alla qualità e alla rigorosità delle ricerche.\n\n\nPratiche di ricerca discutibili (QRPs), tra cui p-hacking e optional stopping, che producono un numero elevato di falsi positivi.\n\n\nBias di pubblicazione, che favorisce i risultati statistici significativi a scapito di studi con esiti non significativi o repliche.\n\n\nBassa potenza statistica e campioni di piccole dimensioni, che gonfiano o sovrastimano l’effetto di fenomeni psicologici.\n\n\nScarsa trasparenza e accessibilità (scienza “chiusa”), che rende difficile verificare e replicare i risultati originari.\n\nNonostante i numeri allarmanti riportati da studi di vasta portata (come il Reproducibility Project), questa situazione può essere vista come un’opportunità di “rivoluzione della credibilità”:\n\nSi stanno diffondendo pratiche di Open Science, con la condivisione di dati, protocolli, codici e materiali, favorendo così la replica e la validazione indipendente.\n\nLa cultura della replicazione viene valorizzata, incentivando studi più rigorosi e focalizzati sulla robustezza degli effetti.\n\nL’approccio statistico tradizionale (frequentista) è posto in discussione, evidenziando la possibilità di integrare o sostituire i test di ipotesi nulla con metodologie più robuste, tra cui quelle bayesiane, le analisi preregistrate e la valorizzazione di stime degli effetti con intervalli di credibilità.\n\nLa crisi di replicazione, quindi, non deve essere intesa come un fallimento totale, bensì come un momento critico che ha avviato un rinnovamento, mirato a rendere la scienza psicologica (e altre discipline) più rigorosa, trasparente e affidabile.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "48  La crisi della replicazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3         inline_0.3.21         sandwich_3.1-1       \n#&gt;  [4] rlang_1.1.6           magrittr_2.0.3        multcomp_1.4-28      \n#&gt;  [7] snakecase_0.11.1      compiler_4.5.1        systemfonts_1.2.3    \n#&gt; [10] vctrs_0.6.5           stringr_1.5.1         pkgconfig_2.0.3      \n#&gt; [13] arrayhelpers_1.1-0    fastmap_1.2.0         backports_1.5.0      \n#&gt; [16] labeling_0.4.3        utf8_1.2.6            rmarkdown_2.29       \n#&gt; [19] ps_1.9.1              ragg_1.5.0            purrr_1.1.0          \n#&gt; [22] xfun_0.53             cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [25] broom_1.0.9           parallel_4.5.1        R6_2.6.1             \n#&gt; [28] stringi_1.8.7         RColorBrewer_1.1-3    lubridate_1.9.4      \n#&gt; [31] estimability_1.5.1    knitr_1.50            zoo_1.8-14           \n#&gt; [34] pacman_0.5.1          Matrix_1.7-4          splines_4.5.1        \n#&gt; [37] timechange_0.3.0      tidyselect_1.2.1      abind_1.4-8          \n#&gt; [40] yaml_2.3.10           codetools_0.2-20      curl_7.0.0           \n#&gt; [43] processx_3.8.6        pkgbuild_1.4.8        lattice_0.22-7       \n#&gt; [46] withr_3.0.2           bridgesampling_1.1-2  coda_0.19-4.1        \n#&gt; [49] evaluate_1.0.5        survival_3.8-3        RcppParallel_5.1.11-1\n#&gt; [52] tensorA_0.36.2.1      checkmate_2.3.3       stats4_4.5.1         \n#&gt; [55] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [58] rstantools_2.5.0      scales_1.4.0          xtable_1.8-4         \n#&gt; [61] glue_1.8.0            emmeans_1.11.2-8      tools_4.5.1          \n#&gt; [64] data.table_1.17.8     mvtnorm_1.3-3         grid_4.5.1           \n#&gt; [67] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         \n#&gt; [70] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         \n#&gt; [73] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         \n#&gt; [76] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    \n#&gt; [79] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    \n#&gt; [82] lifecycle_1.0.4       MASS_7.3-65",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "title": "48  La crisi della replicazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531–1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232–244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science’s aversion to the null. Perspectives on Psychological Science, 7(6), 555–561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13–59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615–631.\n\n\nPennington, C. (2023). A student’s guide to open science: Using the replication crisis to reform psychology. McGraw-Hill Education (UK).\n\n\nWare, J. J., & Munafò, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4–8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "49  Limiti dell’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa, abbiamo approfondito il metodo “tradizionale” per il test di significatività dell’ipotesi nulla (NHST). Comprendere la logica sottostante all’approccio NHST è fondamentale, poiché esso ha rappresentato il principale strumento della statistica inferenziale sin dalla sua introduzione all’inizio del XX secolo, e la maggior parte dei ricercatori continua a basarsi su questa procedura per l’analisi dei dati. Tuttavia, negli ultimi anni, l’NHST è stato oggetto di crescenti critiche, con molti studiosi che sostengono che questo approccio possa generare più problemi di quanti ne risolva. Per questo motivo, è cruciale esaminare le critiche avanzate dalla comunità scientifica nei confronti della procedura inferenziale NHST. In questa sezione, analizzeremo alcuni dei principali dubbi e limiti emersi riguardo a tale metodologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "49  Limiti dell’inferenza frequentista",
    "section": "49.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "49.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo “Statistical Errors” (2014), Nuzzo mette in luce i limiti dell’approccio NHST nella pratica scientifica Nuzzo (2014). Sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ’20, egli non lo concepì mai come un test formale. Fisher lo considerava piuttosto uno strumento informale per valutare se l’evidenza empirica fosse “significativa” in senso colloquiale, ovvero meritevole di ulteriore attenzione. Nella pratica, Fisher suggeriva di assumere un’ipotesi nulla e di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello ottenuto, presupponendo che il risultato fosse interamente dovuto alla variabilità campionaria. Tuttavia, per Fisher, il valore-\\(p\\) non era una conclusione definitiva, ma uno strumento da integrare in un processo decisionale più ampio, che tenesse conto sia delle evidenze empiriche sia delle conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) era parte di un ragionamento scientifico, non il punto finale di tale ragionamento.\nVerso la fine degli anni ’20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l’obiettivo di renderle più rigorose e oggettive. Introdussero concetti come il potere statistico e il tasso di falsi positivi, ma si distanziarono dall’uso del valore-\\(p\\) proposto da Fisher. Le divergenze tra Fisher, Neyman e Pearson diedero vita a un acceso dibattito: Neyman definì il lavoro di Fisher “matematicamente peggiore dell’inutilità”, mentre Fisher bollò l’approccio di Neyman come “infantile” e “dannoso per la libertà intellettuale dell’Occidente”.\nNel frattempo, altri autori iniziarono a scrivere manuali di statistica per guidare i ricercatori. Tuttavia, molti di questi autori non erano statistici e avevano una comprensione superficiale delle differenze tra i vari approcci. Il risultato fu un sistema ibrido che combinava il valore-\\(p\\) di Fisher con il framework rigoroso di Neyman e Pearson. Fu in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne arbitrariamente definita come “statisticamente significativa”.\nStoricamente, tuttavia, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso rispetto a quello che gli viene attribuito oggi. Come abbiamo visto, per Fisher era uno strumento informale, da utilizzare all’interno di un processo decisionale più ampio e non come un criterio meccanico per stabilire la verità scientifica. L’uso del valore-\\(p\\) nel sistema ibrido adottato dai manuali di statistica è quindi privo di una solida giustificazione teorica.\nNel 2016, l’American Statistical Association (ASA) ha espresso forti preoccupazioni riguardo all’uso inappropriato del valore-\\(p\\) nella pratica scientifica contemporanea Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue sottolineando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as \\(p \\leq 0.05\\)) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "49  Limiti dell’inferenza frequentista",
    "section": "49.2 \\(P\\)-hacking",
    "text": "49.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta una delle principali criticità associate all’uso del valore-\\(p\\) ed è conosciuta anche con termini come data-dredging, snooping, fishing, significance-chasing o double-dipping. Secondo Uri Simonsohn, professore all’Università della Pennsylvania, il \\(P\\)-hacking consiste nel manipolare i dati o le analisi fino a ottenere un risultato statisticamente significativo, tipicamente con un valore-\\(p\\) inferiore a 0.05. Ad esempio, si potrebbe dire: “Quel risultato sembra frutto di \\(P\\)-hacking; gli autori hanno escluso una condizione per far diminuire il valore-\\(p\\) sotto la soglia di 0.05” oppure “Lei è un \\(P\\)-hacker, controlla continuamente i dati durante la raccolta per trovare un risultato significativo”.\nQuesta pratica trasforma uno studio esplorativo, che dovrebbe essere interpretato con estrema cautela, in uno studio confermativo (apparentemente robusto), i cui risultati, tuttavia, hanno una probabilità molto bassa di essere replicati in ricerche successive. Secondo le simulazioni condotte da Simonsohn, piccole modifiche nelle scelte analitiche possono aumentare il tasso di falsi positivi fino al 60% in un singolo studio.\nIl \\(P\\)-hacking è particolarmente diffuso negli studi che cercano di dimostrare effetti di piccola entità utilizzando dati molto rumorosi. Un’analisi della letteratura psicologica ha rivelato che i valori-\\(p\\) riportati tendono a concentrarsi appena al di sotto della soglia di 0.05, un fenomeno che può essere interpretato come un segnale di \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovarne uno che raggiunge la “significatività statistica” e poi riportano solo quello. Come evidenziato in figura, questa pratica non è limitata alla psicologia, ma è ampiamente diffusa in tutti i campi della ricerca scientifica, contribuendo a minare l’affidabilità dei risultati pubblicati.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "49  Limiti dell’inferenza frequentista",
    "section": "49.3 Critiche al valore-\\(p\\)",
    "text": "49.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato spesso paragonato a creature fastidiose e persistenti come le zanzare, oppure ai “vestiti nuovi dell’imperatore”, metafora che rappresenta la tendenza a ignorare problemi evidenti preferendo fingere che tutto vada bene. È stato anche definito un intellectual rake sterile, un termine che sottolinea la sua incapacità di produrre risultati utili. Non manca nemmeno l’ironia sul fatto che la procedura di statistical hypothesis inference testing venga chiamata così principalmente per l’acronimo che genera.\nIl valore-\\(p\\) promuove un modo di pensare distorto, spostando l’attenzione dal cuore della ricerca, ovvero la forza della manipolazione sperimentale, verso la dimostrazione di un’ipotesi nulla che si sa già essere falsa. Ad esempio, uno studio condotto su oltre 19,000 individui ha mostrato che le coppie che si incontrano online hanno una probabilità inferiore di divorziare (\\(p &lt; 0.002\\)) e riportano una maggiore soddisfazione nella vita matrimoniale (\\(p &lt; 0.001\\)) rispetto a quelle che si sono conosciute offline. Sebbene questi risultati possano sembrare interessanti, senza considerare la dimensione dell’effetto – come la riduzione del tasso di divorzio dal 7.67% al 5.96% o l’aumento dell’indice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti – il loro impatto pratico rischia di essere sopravvalutato. In generale, la domanda chiave non dovrebbe essere “c’è un effetto?”, ma piuttosto “quanto è grande l’effetto?”. Questo approccio permette di valutare meglio l’effettiva rilevanza dei risultati, andando oltre la semplice significatività statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "49  Limiti dell’inferenza frequentista",
    "section": "49.4 L’effetto sperimentale è esattamente nullo?",
    "text": "49.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più ricorrenti alla logica del test di verifica delle ipotesi statistiche riguarda l’assunzione irrealistica che l’effetto della manipolazione sperimentale sia esattamente nullo. Ad esempio, la fisica ci dimostra che persino lo spostamento di un grammo di massa in una stella distante anni luce dalla Terra può influenzare, seppur minimamente, il movimento delle molecole di un gas sul nostro pianeta (Borel, 1914). Questo esempio suggerisce che ogni manipolazione sperimentale, per quanto piccola, produca in qualche modo un effetto. Pertanto, come sottolinea Andrew Gelman, il problema non è tanto dimostrare che l’ipotesi nulla sia falsa – ovvero che la manipolazione sperimentale non abbia alcun effetto – quanto piuttosto valutare se la dimensione dell’effetto sia sufficientemente grande da avere un impatto pratico e se tale effetto sia riproducibile.\nIn questo contesto, la logica del test dell’ipotesi nulla risulta particolarmente problematica, specialmente quando si lavora con campioni piccoli ed effetti di modesta entità, come accade spesso negli studi psicologici. Questo approccio può portare a una sovrastima della dimensione dell’effetto e a una visione binaria dei risultati (vero/falso), distogliendo l’attenzione dalla stima accurata e non distorta della dimensione effettiva dell’effetto. In altre parole, la ricerca dovrebbe concentrarsi meno sul rifiutare un’ipotesi nulla spesso irrealistica e più sulla comprensione e quantificazione dell’impatto reale delle variabili studiate.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "49  Limiti dell’inferenza frequentista",
    "section": "49.5 Attenti al valore-\\(p\\)!",
    "text": "49.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Supponiamo di eseguire un \\(t\\)-test per due campioni indipendenti per verificare l’ipotesi nulla che le medie delle due popolazioni siano uguali. Fissiamo un livello di significatività \\(\\alpha = 0.05\\) e otteniamo un valore-\\(p\\) pari a \\(0.04\\). La domanda è: qual è la probabilità che i due campioni provengano da distribuzioni con la stessa media?\nLe opzioni sono:\n(a) \\(19/20\\); (b) \\(1/19\\); (c) \\(1/20\\); (d) \\(95/100\\); (e) sconosciuta.\nLa risposta corretta è: (e) sconosciuta. Questo perché la statistica frequentista calcola le probabilità dei dati condizionatamente alle ipotesi (assunte come vere), ma non permette di determinare la probabilità di un’ipotesi. In altre parole, il valore-\\(p\\) non fornisce informazioni sulla probabilità che l’ipotesi nulla sia vera o falsa; indica solo la probabilità di osservare i dati (o risultati più estremi) assumendo che l’ipotesi nulla sia vera.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "49  Limiti dell’inferenza frequentista",
    "section": "49.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "49.6 La crisi della riprodicibilità dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilità dei risultati della ricerca – inclusa quella psicologica – è emersa come un tema di grande rilevanza nel dibattito scientifico. In questo contesto, è stato evidenziato che alcuni aspetti del metodo scientifico, in particolare l’uso del valore-\\(p\\) e la pratica del test di significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a quella che è stata definita una “crisi della ricerca scientifica”. Un’analisi approfondita di questo problema è stata proposta da Gelman (2016), il quale sostiene che la NHST sia intrinsecamente problematica. Questo approccio, infatti, spinge i ricercatori a cercare di rigettare un’ipotesi “fantoccio” (straw-man), spesso già falsa a priori o di scarso interesse scientifico, a favore di un’ipotesi alternativa che il ricercatore preferisce. In generale, è più ragionevole affermare che la differenza tra due condizioni sia molto piccola piuttosto che esattamente uguale a zero, ma la NHST non è progettata per cogliere questa sfumatura.\nNei libri di statistica, la NHST viene spesso presentata come una sorta di “alchimia” che trasforma la casualità in una falsa certezza, utilizzando termini come “confidenza” e “significatività” (Gelman, 2016). Il processo di raccolta dei dati, analisi e inferenza statistica viene sintetizzato in una conclusione espressa in termini di valore-\\(p\\) e intervalli di confidenza che escludono lo zero. Tuttavia, questo può creare l’impressione errata che il ricercatore abbia una comprensione completa del fenomeno studiato. Il problema principale della NHST è che spesso produce risultati “statisticamente significativi” in contesti in cui le caratteristiche del fenomeno non giustificano le conclusioni tratte. Questo può portare a una bassa replicabilità dei risultati, contribuendo alla crisi di fiducia nella ricerca.\nLa comunità statistica ha sottolineato come la non replicabilità sia particolarmente evidente quando i ricercatori, utilizzando la NHST, traggono conclusioni errate basate su piccoli campioni ed effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono l’applicazione della NHST estremamente problematica. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia, un campo in cui gli effetti sono spesso modesti e i campioni limitati.\nLa statistica è stata definita come un metodo per prendere decisioni razionali in condizioni di incertezza. Gli statistici raccomandano ai ricercatori non solo di padroneggiare le tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la crescente sofisticazione degli strumenti disponibili. Conviverci significa evitare di pensare che ottenere un valore-\\(p\\) “statisticamente significativo” equivalga a risolvere un problema scientifico. Ma allora, come possiamo avere fiducia in ciò che apprendiamo dai dati? Una possibile strategia è la replicazione e la convalida esterna dei risultati, sebbene nella ricerca psicologica e nelle scienze sociali questo sia spesso difficile da realizzare a causa degli elevati costi e delle complessità pratiche. Il problema di quali strumenti metodologici e metodi statistici siano più adatti per indagare i fenomeni psicologici, senza cadere in errori di interpretazione, rimane quindi una questione aperta e di cruciale importanza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "49  Limiti dell’inferenza frequentista",
    "section": "49.7 Commenti e considerazioni finali",
    "text": "49.7 Commenti e considerazioni finali\nNon possiamo concludere senza affrontare la controversia che circonda il concetto di valore-\\(p\\). Nonostante sia ancora ampiamente utilizzato e spesso interpretato in modo errato, il valore-\\(p\\) conferisce solo una parvenza di legittimità a risultati dubbi, incoraggia cattive pratiche di ricerca e favorisce la produzione di falsi positivi. Inoltre, il suo significato è spesso frainteso, persino dagli esperti: quando chiamati a definire il valore-\\(p\\), molti forniscono risposte imprecise o sbagliate. Ciò che i ricercatori desiderano sapere è se i risultati di uno studio siano corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell’effetto, sulla forza dell’evidenza o sulla probabilità che il risultato sia frutto del caso. Allora, qual è il suo vero significato? Stuart Buck lo spiega in modo efficace:\n\nImmaginate di avere una moneta che sospettate sia truccata a favore della testa (l’ipotesi nulla è che la moneta sia equa). La lanciate 100 volte e ottenete più teste che croci. Il valore-\\(p\\) non vi dirà se la moneta è equa, ma vi indicherà la probabilità di ottenere almeno lo stesso numero di teste osservato se la moneta fosse equa. Questo è tutto – niente di più.\n\nIn sintesi, il valore-\\(p\\) risponde a una domanda molto specifica che, tuttavia, non ha alcuna rilevanza diretta per la validità scientifica dei risultati di una ricerca. In un’epoca in cui la crisi della riproducibilità dei risultati è sempre più evidente (Baker, 2016), il test dell’ipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema. Questo ha spinto molti ricercatori a cercare alternative metodologiche più robuste e informative, in grado di superare i limiti intrinseci del valore-\\(p\\) e di promuovere una scienza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "title": "49  Limiti dell’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nBorel, E. (1914). Introduction Géométrique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on «Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science». Journal of Statistical Research, 48-50(1), 11–12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "50  La grandezza dell’effetto",
    "section": "",
    "text": "50.1 Introduzione\nLa dimensione dell’effetto (effect size) è un concetto chiave nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura standardizzata descrive l’entità di un effetto, come quello di un intervento o di un trattamento, fornendo una valutazione quantitativa dell’importanza di un fenomeno osservato.\nÈ essenziale distinguere tra dimensione dell’effetto e significatività statistica. Un risultato può essere “statisticamente significativo” anche se l’effetto è di piccole dimensioni, e viceversa. La conoscenza di uno di questi aspetti non fornisce automaticamente informazioni sull’altro, evidenziando la necessità di considerare entrambi nell’analisi dei dati.\nL’importanza della dimensione dell’effetto è ampiamente riconosciuta nel mondo della ricerca scientifica. Il manuale dell’American Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di includere questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all’APA riporta la dimensione dell’effetto, solitamente indicata tra parentesi accanto al valore-\\(p\\).\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell’effetto. Molti ricercatori si limitano a comunicare questi valori senza analizzarli in profondità, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza riflette una sottovalutazione sistematica e una diffusa incomprensione del concetto di dimensione dell’effetto, persino tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "50  La grandezza dell’effetto",
    "section": "50.2 Misurazione dell’Effetto: Approcci e Applicazioni",
    "text": "50.2 Misurazione dell’Effetto: Approcci e Applicazioni\nTra le metriche più utilizzate per quantificare l’effetto di un trattamento o di una differenza tra gruppi troviamo il \\(d\\) di Cohen e l’\\(r\\) di Pearson. Il \\(d\\) di Cohen è particolarmente utile per descrivere le differenze tra le medie di due gruppi sperimentali, esprimendo tale differenza in termini di deviazione standard aggregata.\nLa differenza standardizzata tra le medie di due gruppi può essere calcolata con la seguente formula (equazione 5.1, Glass et al., 1981):\n\\[\nd_p = \\frac{M_1 - M_2}{S_p},\n\\]\ndove:\n\n\\(M_1\\) e \\(M_2\\) sono le medie dei due gruppi,\n\\(S_p\\) è la deviazione standard combinata.\n\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 è maggiore di quella del gruppo 2. La deviazione standard combinata \\(S_p\\) è calcolata come la radice quadrata della varianza media ponderata per i gradi di libertà (\\(df = n-1\\)) dei due gruppi (pp. 108, Glass et al., 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}},\n\\]\ndove:\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi,\n\\(S_1^2\\) e \\(S_2^2\\) sono le varianze (quadrato della deviazione standard) dei due gruppi.\n\nIl \\(d_p\\) di Cohen è strettamente correlato alla statistica \\(t\\) di un test \\(t\\) per campioni indipendenti. Infatti, è possibile calcolare \\(d_p\\) a partire dalla statistica \\(t\\) utilizzando la seguente formula (equazione 5.3, Glass et al., 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL’errore standard di \\(d_p\\) è dato da:\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nD’altra parte, la statistica \\(r\\) di Pearson misura il grado di correlazione lineare tra due variabili, indicando quanto una variabile possa predire l’altra. È interessante notare che queste due misure, \\(d\\) e \\(r\\), possono essere convertite l’una nell’altra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]\nQuesta conversione permette di passare da una misura di differenza tra medie a una misura di correlazione, offrendo una maggiore flessibilità nell’interpretazione dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "title": "50  La grandezza dell’effetto",
    "section": "50.3 Interpretazione della Dimensione dell’Effetto",
    "text": "50.3 Interpretazione della Dimensione dell’Effetto\nL’interpretazione della dimensione dell’effetto è un aspetto cruciale nell’analisi statistica, ma spesso viene affrontata in modi che possono risultare privi di significato o addirittura fuorvianti. Di seguito, esploriamo due approcci comuni e le loro criticità.\n\n50.3.1 Gli Standard di Cohen\nUno dei metodi più diffusi per interpretare la dimensione dell’effetto si basa sugli standard proposti da Jacob Cohen (1977, 1988). Cohen ha suggerito delle soglie arbitrarie per classificare l’effetto:\n\nr = 0.10 → effetto piccolo,\nr = 0.30 → effetto medio,\nr = 0.50 → effetto grande.\n\nTuttavia, come sottolineato da Funder (2019), queste soglie sono spesso utilizzate in modo acritico, senza considerare il contesto specifico. Lo stesso Cohen ha espresso rammarico per aver introdotto queste categorie, precisando che dovrebbero essere adottate solo in assenza di criteri più solidi.\nLe etichette “piccolo”, “medio” e “grande” sono prive di significato se non vengono contestualizzate. Per un’interpretazione corretta, è essenziale porsi due domande fondamentali:\n\nRispetto a cosa? Cosa rappresenta un effetto piccolo, medio o grande nel contesto specifico dello studio?\nA quale scopo? Qual è l’impatto pratico o teorico dell’effetto osservato?\n\nSenza rispondere a queste domande, l’uso degli standard di Cohen rischia di essere poco informativo o addirittura ingannevole.\n\n\n50.3.2 Elevare al Quadrato la Correlazione\nUn altro approccio comune, ma altrettanto problematico, consiste nell’elevare al quadrato il coefficiente di correlazione \\(r\\) per ottenere \\(r^2\\), interpretato come la “proporzione di varianza spiegata”. Ad esempio, una correlazione \\(r = 0.30\\) corrisponde a \\(r^2 = 0.09\\), spesso descritto come “solo il 9% della varianza spiegata”.\nTuttavia, come evidenziato da Funder & Ozer (2019), questa pratica è criticabile per due motivi principali:\n\nMancanza di interpretabilità: Mentre \\(r\\) rappresenta la pendenza di una regressione standardizzata, \\(r^2\\) è molto meno intuitivo, poiché riflette solo la proporzione di varianza condivisa tra due variabili.\nPotenziale fuorviante: Elevare al quadrato \\(r\\) può distorcere la percezione dell’effetto. Ad esempio, una correlazione \\(r = 0.30\\) (effetto medio secondo Cohen) diventa \\(r^2 = 0.09\\), che sembra trascurabile, ma in realtà potrebbe avere un impatto significativo nel contesto applicativo.\n\nUn esempio chiaro è fornito da Darlington (1990). Consideriamo un gioco in cui si lanciano due monete: un nickel (5¢) e un dime (10¢). Se esce testa, si vincono rispettivamente 5¢ o 10¢. Le correlazioni tra il valore delle monete e il pagamento sono:\n\nNickel: \\(r = 0.4472\\) (\\(r^2 = 0.20\\)),\nDime: \\(r = 0.8944\\) (\\(r^2 = 0.80\\)).\n\nSe interpretassimo \\(r^2\\) in modo letterale, potremmo erroneamente concludere che il dime “conta quattro volte più” del nickel. Tuttavia, le correlazioni originali mostrano che \\(0.8944\\) è esattamente il doppio di \\(0.4472\\), offrendo un confronto più accurato e informativo.\nIn sintesi, l’interpretazione della dimensione dell’effetto richiede cautela e contestualizzazione. Gli standard di Cohen, sebbene ampiamente utilizzati, sono arbitrari e possono essere fuorvianti se applicati in modo acritico. Allo stesso modo, elevare al quadrato la correlazione \\(r\\) per ottenere \\(r^2\\) rischia di distorcere la percezione dell’effetto, rendendolo meno interpretabile e potenzialmente fuorviante. Per un’analisi robusta, è essenziale considerare il contesto e l’impatto pratico dell’effetto osservato, evitando di affidarsi esclusivamente a metriche standardizzate o trasformazioni matematiche poco informative.\n\n\n50.3.3 Alternative migliori\nÈ cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder & Ozer (2019) propongono due strategie principali: l’adozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l’entità di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l’altezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell’importanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking può includere l’analisi di risultati considerati “classici” nel campo di interesse o la considerazione di dimensioni dell’effetto per risultati che hanno ottenuto un solido consenso nella comunità psicologica.\nIn un’ottica più ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell’effetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell’effetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio è l’efficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è di \\(r = .14\\).\n\nTali confronti illustrano come l’interpretazione delle dimensioni dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto più vasto, favorendo una valutazione più consapevole della loro rilevanza relativa.\n\n\n50.3.4 Alternative Migliori per Interpretare la Dimensione dell’Effetto\nPer arricchire il significato delle dimensioni dell’effetto, è essenziale adottare approcci che vadano oltre le metriche standardizzate e si basino su criteri di riferimento concreti e contestualizzati. Funder & Ozer (2019) propone due strategie principali: l’uso di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\n50.3.4.1 1. Utilizzare Criteri di Riferimento (Benchmark)\nUn modo efficace per interpretare la dimensione dell’effetto è confrontarla con risultati ben noti e ampiamente compresi, sia all’interno del campo di studio che in contesti più generali. Questo approccio è simile a come giudichiamo l’altezza di una persona confrontandola con quella di altre persone.\n\nConfronto con Risultati Classici: I ricercatori possono ottenere una percezione più accurata dell’importanza di un risultato confrontandolo con dimensioni dell’effetto di studi considerati “classici” nel proprio campo. Ad esempio, in psicologia, è possibile fare riferimento a risultati che hanno ottenuto un solido consenso nella comunità scientifica.\nMedie da Meta-Analisi: Alcuni ricercatori hanno proposto benchmark calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha analizzato 708 correlazioni ottenute meta-analiticamente, rilevando che la dimensione media dell’effetto \\(r\\) era di 0.19. Questo valore può servire come punto di riferimento per valutare l’entità di nuovi risultati.\nEsempi Trasversali: Anche conoscenze comuni o risultati di ricerche non psicologiche possono offrire benchmark utili. Ad esempio:\n\nL’efficacia degli antistaminici contro il comune raffreddore corrisponde a un \\(r = 0.11\\).\nL’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è pari a \\(r = 0.14\\).\n\n\nQuesti confronti mostrano come l’interpretazione della dimensione dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili.\n\n\n50.3.4.2 2. Valutare le Implicazioni Pratiche\nOltre ai benchmark, è fondamentale considerare le implicazioni pratiche dei risultati. Un effetto statisticamente piccolo può avere un impatto significativo se applicato a un contesto reale. Ad esempio:\n\nUn \\(r = 0.10\\) potrebbe sembrare trascurabile, ma se tradotto in un intervento su larga scala (ad esempio, un programma educativo o una politica sanitaria), potrebbe portare a benefici tangibili per un gran numero di persone.\n\nIn conclusione, l’interpretazione della dimensione dell’effetto può essere notevolmente migliorata attraverso l’uso di benchmark e la valutazione delle implicazioni pratiche. Confrontare i risultati con studi classici, medie di meta-analisi o esempi tratti da altri campi consente di inserire i nuovi risultati in un contesto più ampio e significativo. Questo approccio non solo arricchisce l’interpretazione, ma favorisce anche una valutazione più consapevole della rilevanza e dell’impatto delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "title": "50  La grandezza dell’effetto",
    "section": "50.4 Riflessioni Conclusive",
    "text": "50.4 Riflessioni Conclusive\nLa sovrastima della grandezza degli effetti in psicologia rappresenta un problema diffuso e significativo. Un principio spesso enfatizzato nella psicologia sociale e nell’economia comportamentale, specialmente nei media e nei corsi di business, è che piccoli interventi, o “nudge” (spinte gentili), possano produrre effetti sorprendentemente ampi sul comportamento. Questa idea ha portato a numerose affermazioni sensazionalistiche, come l’ipotesi che le elezioni possano essere influenzate dall’esito di partite di football o che stimoli subliminali, come una faccina sorridente, possano generare cambiamenti drastici negli atteggiamenti verso temi complessi come l’immigrazione.\nAlla base di queste affermazioni c’è un modello di mondo che non si limita al concetto di “effetto farfalla” (dove piccoli cambiamenti possono avere conseguenze imprevedibili e amplificate), ma suggerisce che piccoli interventi possano produrre effetti grandi e prevedibili. Questo approccio, talvolta definito “modello a pulsante” delle scienze sociali, presuppone che, facendo X, si possa aspettarsi di osservare Y in modo sistematico. Tuttavia, questa visione presenta diverse criticità:\n\n50.4.1 Problemi del Modello “a Pulsante”\n\nSovrastima degli effetti: Molti studi riportano effetti esagerati per interventi minimi, che spesso non vengono replicati in ricerche successive. Questo solleva dubbi sulla validità e sull’affidabilità di tali risultati.\nMancanza di considerazione delle interazioni: Se esistessero davvero molti effetti grandi e prevedibili, questi interferirebbero tra loro, rendendo difficile osservare risultati coerenti nei dati reali. La complessità del comportamento umano raramente si presta a relazioni lineari e isolate.\nInstabilità del sistema: Un sistema sociale caratterizzato da molti effetti grandi e prevedibili sarebbe intrinsecamente instabile e difficile da studiare, contraddicendo l’osservazione che le società tendono a mostrare una certa stabilità nel tempo.\nGeneralizzazione eccessiva: Spesso i risultati ottenuti in contesti di laboratorio altamente controllati vengono estesi a situazioni reali molto più complesse, senza considerare le differenze contestuali.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilità di essere pubblicati, creando una rappresentazione distorta della realtà e alimentando un ciclo di sovrastima.\n\n\n\n50.4.2 Verso un Approccio più Cauto e Sfumato\nNonostante queste criticità, è importante riconoscere che la psicologia ha identificato molti fenomeni robusti, specialmente in aree come la psicologia clinica e la psicologia della percezione. Tuttavia, è fondamentale adottare un approccio più cauto e riflessivo nell’interpretazione e nella comunicazione dei risultati della ricerca.\nLa consapevolezza di questi problemi ha portato a una serie di miglioramenti metodologici, tra cui:\n\nEnfasi sulla replicabilità: Maggiore attenzione alla riproducibilità degli studi per garantire che i risultati siano affidabili.\nUso di campioni più ampi: Studi condotti su campioni più grandi e diversificati per aumentare la validità esterna.\nMetodi statistici più robusti: Adozione di tecniche statistiche avanzate per ridurre il rischio di falsi positivi.\nApproccio critico e riflessivo: La comunità scientifica sta diventando sempre più consapevole della necessità di evitare semplificazioni eccessive e di riconoscere la complessità dei fenomeni psicologici.\n\nIn sintesi, mentre la psicologia offre intuizioni preziose sul comportamento umano, è essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realtà è spesso più complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi. Un approccio equilibrato, che combina rigore metodologico, contestualizzazione e umiltà scientifica, è fondamentale per avanzare nella comprensione dei fenomeni psicologici e per evitare di cadere in trappole interpretative che possono distorcere la nostra visione del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "href": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "title": "50  La grandezza dell’effetto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2(2), 156–168.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in Social Research. Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "51  Errori di segno e errori di grandezza",
    "section": "",
    "text": "51.1 Introduzione\nIn questo capitolo analizzeremo la relazione tra la crisi della replicabilità e le procedure decisionali statistiche proprie dell’approccio frequentista. In particolare, approfondiremo gli errori di tipo M (magnitude) e di tipo S (sign), discussi da Loken & Gelman (2017), e il loro impatto sulla validità dei risultati scientifici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "href": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "title": "51  Errori di segno e errori di grandezza",
    "section": "",
    "text": "Domande Iniziali\n\n\n\nPrima di esplorare le simulazioni e i risultati discussi in questo capitolo, prova a riflettere sulle seguenti domande. Ti invitiamo a formulare delle ipotesi sui risultati delle simulazioni prima di leggere le spiegazioni:\n\nSe si effettuano molteplici studi su un effetto molto piccolo utilizzando campioni di dimensioni ridotte, cosa pensi che accadrà ai risultati pubblicati che ottengono significatività statistica? Saranno accurati rispetto alla vera grandezza dell’effetto?\nIn uno scenario in cui non esiste alcuna differenza tra due gruppi, quanto spesso credi che un test t fornisca un risultato statisticamente significativo che verrà pubblicato? Quali fattori potrebbero influenzare questa probabilità?\nSupponiamo che in una serie di esperimenti alcuni studi trovino effetti significativi e altri no. Quale pensi sia la tendenza degli studi pubblicati rispetto a quelli non pubblicati? Quale impatto può avere questa tendenza sulla percezione della realtà scientifica?\nSe dovessi valutare la replicabilità di uno studio basato sulla significatività statistica, quali problemi potresti incontrare se l’effetto sottostante è molto piccolo?\n\nTieni a mente le tue risposte mentre esplori le simulazioni presentate in questo capitolo. Alla fine del capitolo, confronteremo le previsioni con i risultati effettivi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "title": "51  Errori di segno e errori di grandezza",
    "section": "\n51.2 Il Filtro della Significatività Statistica",
    "text": "51.2 Il Filtro della Significatività Statistica\nNel ?sec-crisis abbiamo esplorato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle significative implicazioni economiche legate alla pubblicazione su riviste scientifiche di alto prestigio. Questo fenomeno è spesso sottovalutato, poiché le riviste tendono a essere riluttanti nel riconoscere la necessità di correzioni o ritrattazioni degli articoli già pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilità dei risultati, un pilastro fondamentale del metodo scientifico. Tuttavia, le difficoltà nel replicare i risultati pubblicati non sono attribuibili esclusivamente a frodi o a “pratiche di ricerca disoneste” (Nelson et al., 2018). Un problema intrinseco risiede nel metodo statistico ampiamente adottato dai ricercatori: l’approccio del test di ipotesi nulla e della significatività statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la soglia di “significatività statistica” vengono scartati, mentre quelli che la superano sono considerati credibili, basandosi esclusivamente su questo criterio (Wagenmakers et al., 2008).\nTuttavia, l’idea che la significatività statistica sia un filtro affidabile per distinguere i risultati di ricerca “validi” da quelli “non validi” è fondamentalmente errata. Numerose evidenze dimostrano i limiti di questo approccio. Per approfondire questa problematica, esamineremo lo studio di Loken & Gelman (2017), che mette in luce la relazione tra la crisi della replicabilità e le procedure decisionali statistiche dell’approccio frequentista.\nUno dei principali problemi evidenziati da Loken & Gelman (2017) è che, in contesti di ricerca complessi, la significatività statistica fornisce prove molto deboli riguardo al segno (sign) o all’entità (magnitude) degli effetti sottostanti. In altre parole, il raggiungimento della significatività statistica non garantisce né la rilevanza né la consistenza dei risultati ottenuti. Questo solleva seri dubbi sull’affidabilità di tale criterio come unico strumento per valutare la validità delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "51  Errori di segno e errori di grandezza",
    "section": "\n51.3 Errori di tipo M e S\n",
    "text": "51.3 Errori di tipo M e S\n\nPer illustrare le implicazioni del processo decisionale basato sulla significatività statistica, Loken & Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno considerato uno scenario di ricerca ipotetico in cui era presente un effetto reale, sebbene molto debole, difficilmente rilevabile senza un ampio volume di dati. Utilizzando l’approccio frequentista, hanno cercato di identificare questo effetto valutando la significatività statistica.\nI risultati della simulazione hanno mostrato che, anche in presenza di un effetto reale (seppur debole), l’approccio frequentista riusciva a rilevare un effetto statisticamente significativo solo in una piccola percentuale dei casi. Inoltre, quando un effetto significativo veniva individuato, la stima della sua grandezza risultava altamente imprecisa e instabile.\nIn sintesi, la significatività statistica fornisce un’indicazione generica sulla presenza o assenza di un effetto, ma non offre informazioni affidabili sulla sua entità o replicabilità. Questo problema è particolarmente rilevante in campi come la psicologia e le scienze sociali, dove gli studi spesso si basano su campioni di dimensioni ridotte e gli effetti osservati tendono a essere modesti. In tali contesti, l’approccio frequentista rischia di produrre prove deboli e instabili, compromettendo la replicabilità e l’affidabilità dei risultati.\n\n51.3.1 Simulazione semplificata\nRiproduciamo qui, in forma semplificata, la simulazione condotta da Loken & Gelman (2017). Iniziamo importando le librerie necessarie.\nConsideriamo due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti rispettivamente dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\). La dimensione effettiva dell’effetto (\\(d\\)) per la differenza tra le medie dei due campioni è calcolata utilizzando la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) rappresentano le medie campionarie dei due gruppi, e \\(s_p\\) è la deviazione standard combinata, definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}.\n\\]\nIn questo caso specifico, la dimensione effettiva dell’effetto risulta molto piccola, indicando che la differenza osservata tra le medie dei due gruppi non ha una rilevanza pratica significativa. Ciò suggerisce che la distinzione tra i due gruppi, seppur statisticamente rilevabile, non ha un impatto sostanziale in contesti reali.\n\n# Parametri\nmu_1 &lt;- 102  # Media del primo gruppo\nmu_2 &lt;- 100  # Media del secondo gruppo\nsigma &lt;- 10  # Deviazione standard comune\nn1 &lt;- 20     # Numero di osservazioni nel primo gruppo\nn2 &lt;- 25     # Numero di osservazioni nel secondo gruppo\n\n# Calcolo della differenza media\nmean_difference &lt;- abs(mu_1 - mu_2)\n\n# Calcolo della deviazione standard pooled\npooled_sd &lt;- sqrt(((n1 - 1) * sigma^2 + (n2 - 1) * sigma^2) / (n1 + n2 - 2))\n\n# Calcolo di Cohen's d\ncohen_d &lt;- mean_difference / pooled_sd\n\n# Output del risultato\ncat(\"Dimensione dell'effetto (Cohen's d):\", cohen_d, \"\\n\")\n#&gt; Dimensione dell'effetto (Cohen's d): 0.2\n\nEsaminiamo ora le conclusioni che emergerebbero applicando l’approccio frequentista e la sua procedura di decisione statistica in questo contesto. Supponiamo di condurre una simulazione in cui vengono estratti due campioni: il primo composto da 20 osservazioni provenienti dalla prima popolazione e il secondo da 25 osservazioni provenienti dalla seconda popolazione. Successivamente, applichiamo il test \\(t\\) di Student per confrontare le medie dei due gruppi.\nNell’ambito dell’approccio frequentista, il valore-\\(p\\) ottenuto dal test determina la decisione statistica. Se il valore-\\(p\\) è superiore a 0.05, i risultati vengono considerati non significativi e, di conseguenza, scartati. Al contrario, se il valore-\\(p\\) è inferiore a 0.05, il risultato è ritenuto “pubblicabile” e si conclude che esiste una differenza statisticamente significativa tra i due gruppi.\nPer valutare in modo approfondito le conclusioni derivate da questa procedura, è necessario ripetere l’intero processo per un numero elevato di iterazioni, ad esempio 50.000 volte. Ciò significa che, in ciascuna iterazione, vengono estratti nuovi campioni, viene calcolato il test \\(t\\) di Student e viene determinato il corrispondente valore-\\(p\\). Ripetendo questo processo su larga scala, è possibile ottenere una distribuzione completa dei risultati, che consente di analizzare la frequenza con cui si ottengono risultati significativi e la stabilità delle stime prodotte dall’approccio frequentista in questo contesto.\n\n# Parametri\nn_samples &lt;- 50000\nmu_1 &lt;- 102\nmu_2 &lt;- 100\nsigma &lt;- 10\nn1 &lt;- 20\nn2 &lt;- 25\n\n# Inizializzazione del risultato\nres &lt;- c()\n\n# Simulazioni\nset.seed(123)  # Per la riproducibilità\nfor (i in 1:n_samples) {\n  # Generazione dei campioni casuali\n  y1 &lt;- rnorm(n1, mean = mu_1, sd = sigma)\n  y2 &lt;- rnorm(n2, mean = mu_2, sd = sigma)\n  \n  # Calcolo della dimensione dell'effetto\n  y1bar &lt;- mean(y1)\n  y2bar &lt;- mean(y2)\n  v1 &lt;- var(y1)\n  v2 &lt;- var(y2)\n  s &lt;- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))\n  efsize &lt;- (y1bar - y2bar) / s\n  \n  # Calcolo del valore p\n  t_test &lt;- t.test(y1, y2, var.equal = TRUE)\n  \n  # Salvataggio della dimensione dell'effetto solo per risultati \"statisticamente significativi\"\n  if (t_test$p.value &lt; 0.05) {\n    res &lt;- c(res, efsize)\n  }\n}\n\n\nres_df &lt;- data.frame(effect_size = res)\n\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(\n    xintercept = 0.2, color = \"red\", linetype = \"dashed\", \n    size = 1.2, label = \"True Effect Size\") +\n  labs(\n    x = \"Effect Size\",\n    y = \"Frequency\",\n    title = \"Histogram of Effect Sizes for\\n'Statistically Significant' Results\"\n  ) \n\n\n\n\n\n\n\nCome evidenziato da Loken & Gelman (2017), l’applicazione dell’approccio frequentista nella procedura di decisione statistica può condurre a due tipi di errori rilevanti. Il primo, noto come errore di magnitude (grandezza), si manifesta quando i risultati pubblicati tendono a sovrastimare la reale entità dell’effetto. Nella simulazione condotta, nonostante la vera grandezza dell’effetto fosse modesta (0.2), la media della grandezza dell’effetto per i risultati classificati come “statisticamente significativi” era circa 0.8, suggerendo un effetto di entità “ampia”. Questo indica una distorsione sistematica verso stime esagerate.\nIl secondo errore, chiamato errore di segno, si verifica quando, a causa della variabilità campionaria, la direzione dell’effetto viene stimata in modo errato. In tali casi, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realtà non è così. È importante sottolineare che, anche in queste situazioni, la grandezza assoluta dell’effetto risulta sovrastimata.\nUn aspetto degno di nota è che queste conclusioni rimarrebbero valide anche se si considerasse l’intervallo di confidenza per la differenza tra le medie. In sintesi, l’approccio frequentista introduce un errore sistematico nella stima della grandezza dell’effetto, che rappresenta la quantità più rilevante per il ricercatore. In alcuni casi, può persino portare a errori nella determinazione della direzione dell’effetto, compromettendo ulteriormente l’affidabilità delle conclusioni scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "title": "51  Errori di segno e errori di grandezza",
    "section": "\n51.4 Riflessioni Conclusive",
    "text": "51.4 Riflessioni Conclusive\nIn conclusione, l’approccio frequentista non rappresenta un metodo affidabile per valutare i risultati della ricerca e determinarne l’attendibilità o la necessità di scartarli (Gelman & Carlin, 2014; Loken & Gelman, 2017). Questa mancanza di affidabilità è dovuta all’introduzione di errori sistematici nella stima della grandezza degli effetti, che in alcuni casi possono persino portare a errori nella direzione dell’effetto stesso. Alla luce di queste criticità, non sembrano esserci motivi validi per continuare a fare affidamento su questo approccio.\nAl contrario, l’adozione dell’approccio bayesiano sembra offrire una soluzione più precisa e affidabile per l’analisi dei dati di ricerca. Questo metodo valuta la probabilità delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell’approccio frequentista e fornendo una base più solida per prendere decisioni informate sulla validità dei risultati. In questo modo, l’approccio bayesiano si presenta come un’alternativa più robusta e scientificamente rigorosa.\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nOra confrontiamo le previsioni con i risultati ottenuti dalle simulazioni:\n\nSovrastima della grandezza dell’effetto: I risultati pubblicati tendono a essere selezionati sulla base della significatività statistica, il che porta a una sovrastima sistematica della grandezza dell’effetto rispetto alla realtà. Questo fenomeno, noto come errore di tipo M (magnitude), si verifica perché solo gli effetti con valori estremi (per caso) superano la soglia di significatività statistica e vengono pubblicati.\nFalsi positivi e loro frequenza: In uno scenario in cui non esiste alcuna differenza tra i due gruppi (cioè la vera differenza è zero), il test t ha fornito risultati statisticamente significativi nel 5% dei casi, come previsto dalla soglia di α = 0.05. Tuttavia, la selezione dei risultati pubblicati amplifica questo problema, rendendo più probabile che i lettori incontrino falsi positivi nella letteratura scientifica.\nBias nella pubblicazione: Gli studi che riportano risultati significativi hanno maggiore probabilità di essere pubblicati rispetto a quelli che non trovano un effetto significativo. Questo porta a un effetto distorsivo nella letteratura scientifica, in cui i risultati pubblicati tendono a sovrastimare l’effetto reale. Il “filtro della significatività statistica” crea una percezione distorta della realtà scientifica, poiché gli effetti nulli o piccoli tendono a essere sottorappresentati nella letteratura.\nReplicabilità e significatività statistica: Gli studi con effetti piccoli e campioni ridotti sono particolarmente vulnerabili al fallimento della replicazione. Anche quando un effetto reale esiste, la probabilità di ottenerne una stima precisa è bassa, e la replicazione potrebbe risultare in un valore non significativo, generando confusione nella comunità scientifica.\n\nConsiderazioni Finali\nLe simulazioni evidenziano come la significatività statistica, utilizzata come criterio per la pubblicazione, contribuisca a un bias nella selezione dei risultati, distorcendo la percezione della realtà scientifica. Questo fenomeno, noto come “filtro della significatività statistica”, è una delle cause principali della crisi della replicabilità, poiché induce i ricercatori e i lettori a sovrastimare la grandezza e la presenza di effetti studiati.\nPer affrontare queste problematiche, approcci alternativi, come quelli bayesiani, possono offrire soluzioni più robuste, permettendo una valutazione più affidabile delle ipotesi alla luce dei dati osservati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "51  Errori di segno e errori di grandezza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nPerché la significatività statistica non è un criterio affidabile per valutare la validità dei risultati scientifici?\nSpiega il concetto di “filtro della significatività statistica” e il suo impatto sulla pubblicazione dei risultati.\nQual è la differenza tra errore di tipo M e errore di tipo S? Come influenzano l’interpretazione dei risultati?\nPerché i risultati pubblicati tendono a sovrastimare la grandezza dell’effetto rispetto alla realtà?\nQuali sono le conseguenze della pubblicazione selettiva dei risultati per la replicabilità degli studi?\nPerché gli studi con campioni di piccole dimensioni sono più vulnerabili a errori nella stima della grandezza dell’effetto?\nIn che modo la selezione dei risultati pubblicati altera la percezione della forza degli effetti studiati?\nPerché un test frequentista può portare a una falsa conclusione sulla direzione di un effetto?\nQuali sono le principali differenze tra l’approccio frequentista e quello bayesiano nella valutazione della significatività di un effetto?\nIn che modo l’approccio bayesiano può ridurre il rischio di errori dovuti alla selezione dei risultati basata sulla significatività statistica?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nLa significatività statistica non garantisce la validità di un risultato perché dipende dalla dimensione del campione e da soglie arbitrarie (come p &lt; 0.05). Inoltre, non misura la rilevanza pratica di un effetto, ma solo la probabilità che i dati osservati siano ottenuti sotto l’ipotesi nulla.\nIl “filtro della significatività statistica” si riferisce alla tendenza a pubblicare solo risultati con p &lt; 0.05, tralasciando studi con risultati non significativi. Questo porta a una distorsione nella letteratura scientifica e a una sovrastima della forza degli effetti riportati.\nErrore di tipo M (Magnitude) indica la sovrastima della grandezza dell’effetto nei risultati pubblicati, mentre errore di tipo S (Sign) si riferisce all’errata determinazione della direzione dell’effetto. Questi errori si verificano perché solo gli effetti più estremi tendono a superare il filtro della significatività statistica.\nI risultati pubblicati tendono a sovrastimare la grandezza dell’effetto perché solo gli effetti più grandi (anche per pura casualità) superano la soglia di significatività statistica e vengono pubblicati, mentre quelli più piccoli restano inediti.\nLa pubblicazione selettiva riduce la replicabilità perché introduce una distorsione sistematica nei risultati disponibili. Le repliche spesso non trovano effetti altrettanto grandi o significativi, creando instabilità nella conoscenza scientifica.\nI campioni piccoli aumentano la variabilità delle stime dell’effetto, rendendo più probabile che un risultato significativo sia solo un’oscillazione casuale dei dati piuttosto che un vero effetto replicabile.\nLa selezione dei risultati pubblicati altera la percezione della forza degli effetti perché induce i lettori a credere che gli effetti siano più forti e consistenti di quanto non siano realmente.\nUn test frequentista può portare a una falsa conclusione sulla direzione dell’effetto perché, in campioni piccoli, le stime dell’effetto possono essere fortemente influenzate dal rumore, portando a interpretazioni errate.\nL’approccio frequentista si basa sul valore-p e sulla soglia di significatività, mentre l’approccio bayesiano utilizza la probabilità a posteriori per aggiornare la credibilità delle ipotesi alla luce dei dati osservati. Il metodo bayesiano permette inferenze più flessibili e robuste.\nL’approccio bayesiano riduce il rischio di errori dovuti alla selezione dei risultati perché non si basa su una soglia arbitraria di significatività, ma fornisce un quadro probabilistico della forza dell’effetto, evitando distorsioni dovute alla pubblicazione selettiva.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nIn questo esercizio simuleremo più esperimenti, ognuno con 15 osservazioni, per comprendere come il filtro della significatività statistica possa distorcere le nostre conclusioni sugli effetti osservati.\nObiettivo\n\nComprendere come l’approccio frequentista possa portare a stime errate dell’effetto reale.\nEsplorare gli errori di tipo M (magnitude) e S (sign), derivanti dal filtro della significatività statistica.\n\nStruttura dell’esercizio\n\nSimuliamo esperimenti in cui il vero effetto tra due gruppi è piccolo (Cohen’s d = 0.2). Consideriamo i dati SWLS e due popolazioni che differiscono nel modo indicato. Ipotizziamo che le due popolazioni SWLS siano normali.\nEstraiamo 15 osservazioni per gruppo.\nUsiamo un test t per verificare se la differenza tra i gruppi è significativa.\nRegistriamo solo i risultati con p &lt; 0.05, calcolando la distribuzione degli effetti significativi.\nValutiamo se la stima dell’effetto nei risultati pubblicabili è gonfiata rispetto al vero effetto.\nContiamo i casi in cui il segno dell’effetto è invertito.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Librerie necessarie\nlibrary(ggplot2)\n\n# Impostazioni della simulazione\nset.seed(42)         # Per la riproducibilità\nn_sims &lt;- 50000      # Numero di simulazioni\nn_per_group &lt;- 15    # Numero di osservazioni per gruppo\ntrue_d &lt;- 0.2        # Vero effetto (Cohen's d)\nswls_mean &lt;- 25      # Media ipotizzata per il primo gruppo\nswls_sd &lt;- 5         # Deviazione standard ipotizzata per la SWLS\n\n# Calcolo della media del secondo gruppo sulla base di Cohen's d\nswls_mean_2 &lt;- swls_mean + true_d * swls_sd\n\n# Inizializziamo i vettori per registrare i risultati\neffect_sizes &lt;- c()\nfalse_sign_count &lt;- 0\n\n# Simulazioni\nfor (i in 1:n_sims) {\n  # Generazione dei due gruppi da distribuzioni normali\n  group1 &lt;- rnorm(n_per_group, mean = swls_mean, sd = swls_sd)\n  group2 &lt;- rnorm(n_per_group, mean = swls_mean_2, sd = swls_sd)\n  \n  # Calcolo della dimensione dell'effetto (Cohen's d)\n  mean_diff &lt;- mean(group2) - mean(group1)\n  pooled_sd &lt;- sqrt(((n_per_group - 1) * var(group1) + (n_per_group - 1) * var(group2)) / (2 * n_per_group - 2))\n  d_estimated &lt;- mean_diff / pooled_sd\n  \n  # Test t per confrontare le medie\n  t_test &lt;- t.test(group1, group2, var.equal = TRUE)\n  \n  # Consideriamo solo i risultati statisticamente significativi\n  if (t_test$p.value &lt; 0.05) {\n    effect_sizes &lt;- c(effect_sizes, d_estimated)\n    \n    # Conta i casi in cui il segno è invertito\n    if (d_estimated &lt; 0) {\n      false_sign_count &lt;- false_sign_count + 1\n    }\n  }\n}\n\n# Creazione di un dataframe per la visualizzazione\nres_df &lt;- data.frame(effect_size = effect_sizes)\n\n# Istogramma della dimensione dell'effetto tra i risultati \"significativi\"\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 30, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = true_d, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  labs(\n    x = \"Dimensione dell'effetto stimata\",\n    y = \"Frequenza\",\n    title = \"Distribuzione degli effetti significativi (SWLS)\"\n  ) +\n  theme_minimal()\n\n# Output di sintesi\ncat(\"Numero di risultati statisticamente significativi:\", length(effect_sizes), \"\\n\")\ncat(\"Media della dimensione dell'effetto tra i risultati pubblicati:\", mean(effect_sizes), \"\\n\")\ncat(\"Numero di risultati con segno invertito:\", false_sign_count, \"\\n\")\ncat(\"Proporzione di risultati con segno invertito:\", false_sign_count / length(effect_sizes), \"\\n\")\nInterpretazione dei Risultati\n\n\nErrore di tipo M (Magnitude): La media degli effetti stimati nei risultati pubblicati sarà molto più grande di 0.2 (il vero effetto), dimostrando come il filtro della significatività tenda a sovrastimare gli effetti reali.\n\nErrore di tipo S (Sign): Una percentuale dei risultati pubblicabili mostrerà effetti nella direzione sbagliata (d &lt; 0), dimostrando che il processo decisionale basato su p &lt; 0.05 può portare a conclusioni errate.\n\nVisualizzazione: L’istogramma mostrerà che la distribuzione degli effetti significativi è spostata rispetto al vero effetto (linea rossa tratteggiata).\n\nDomande di discussione:\n\nPerché la stima dell’effetto è gonfiata nei risultati pubblicabili?\nCome cambia la situazione aumentando il numero di osservazioni per gruppo?\nQuali strategie alternative potrebbero ridurre questi errori?\n\nApprofondimento:\n\nRipetere l’esperimento con n_per_group = 50 e osservare se l’errore di tipo M diminuisce.\nConfrontare questo approccio con un’analisi Bayesiana per evidenziare il ruolo dell’inferenza basata su probabilità posteriori.\n\nConclusione\nQuesto esercizio mostra chiaramente i problemi dell’approccio frequentista basato su p &lt; 0.05, evidenziando i limiti dell’uso della significatività statistica come filtro decisionale.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "51  Errori di segno e errori di grandezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           yaml_2.3.10           knitr_1.50           \n#&gt; [19] labeling_0.4.3        bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#&gt; [22] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#&gt; [25] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#&gt; [28] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#&gt; [31] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#&gt; [34] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#&gt; [37] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#&gt; [40] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#&gt; [43] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#&gt; [46] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#&gt; [49] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#&gt; [52] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#&gt; [55] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#&gt; [58] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#&gt; [61] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#&gt; [64] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#&gt; [67] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#&gt; [70] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#&gt; [73] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#&gt; [76] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#&gt; [79] pkgconfig_2.0.3",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "href": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "title": "51  Errori di segno e errori di grandezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s renaissance. Annual review of psychology, 69(1), 511–534.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008). Bayesian versus frequentist inference. Bayesian evaluation of informative hypotheses, 181–207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html",
    "href": "chapters/replication_crisis/05_p_values.html",
    "title": "\n52  La fragilità del p-valore\n",
    "section": "",
    "text": "52.1 Introduzione\nQuesto capitolo analizza la fragilità dei valori-\\(p\\) e la loro variabilità in diversi campioni. Attraverso una simulazione, dimostreremo come l’uso dei valori-\\(p\\) come criterio per valutare la rilevanza sostanziale di un risultato costituisca un errore metodologico. L’analisi si basa su un approccio critico ispirato da una discussione proposta da Andrew Gelman nel suo blog.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#simulazione",
    "href": "chapters/replication_crisis/05_p_values.html#simulazione",
    "title": "\n52  La fragilità del p-valore\n",
    "section": "\n52.2 Simulazione",
    "text": "52.2 Simulazione\nQuesta simulazione mira a dimostrare quanto i valori-\\(p\\) possano essere instabili e variare notevolmente da campione a campione, anche quando i dati provengono dalla stessa distribuzione. Ciò evidenzia come il valore-\\(p\\), comunemente utilizzato per valutare la significatività statistica di un effetto, possa essere fortemente influenzato dalla variabilità campionaria, specialmente in campioni di piccole dimensioni o con effetti deboli. Gelman & Stern (2006) esprimono questo concetto affermando che:\n\nLa differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa.\n\n\n52.2.1 Logica della Simulazione\n\n\nObiettivo:\n\nDimostrare la variabilità dei valori-\\(p\\) calcolati su diversi campioni estratti da una popolazione con una media molto vicina a zero.\nMostrare come, nonostante l’effetto reale sia piccolo, i valori-\\(p\\) possano variare notevolmente a seconda della variabilità della popolazione e delle dimensioni del campione.\n\n\n\nSetup della Simulazione:\n\nGeneriamo \\(J = 10\\) campioni indipendenti, ciascuno con un numero ridotto di osservazioni (\\(n = 10\\)), per massimizzare la variabilità dei risultati.\nOgni campione è generato da una distribuzione normale con una media vera di \\(\\mu = 0.05\\) e una deviazione standard di \\(\\sigma = 0.1\\). Questi parametri sono scelti per rendere la media dei campioni vicina a zero, mantenendo una certa variabilità.\n\n\n\nCalcolo della media campionaria:\n\nPer ciascun campione, calcoliamo la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nLa media del campione (\\(\\hat{\\mu}\\)) è utilizzata come stima del parametro.\n\n\n\nCalcolo del valore-\\(p\\):\n\nApplichiamo un \\(t\\)-test per ciascun campione per verificare l’ipotesi nulla (\\(H_0\\)) che la media del campione sia zero.\n\nIl valore-\\(p\\) viene calcolato utilizzando la formula classica del \\(t\\)-test:\n\\[\nt = \\frac{\\hat{\\mu}}{\\frac{\\hat{\\sigma}}{\\sqrt{n}}}\n\\]\ndove:\n\n\n\\(\\hat{\\mu}\\) è la media del campione,\n\n\\(\\hat{\\sigma}\\) è la deviazione standard del campione,\n\n\\(n\\) è il numero di osservazioni per campione.\n\n\n\nSuccessivamente, il valore-\\(p\\) è calcolato come:\n\\[\n\\text{p-value} = 2 \\times (1 - \\text{CDF}(|t|))\n\\]\ndove \\(\\text{CDF}\\) è la funzione cumulativa della distribuzione \\(t\\) con \\(n-1\\) gradi di libertà.\n\n\n\n\n52.2.2 Descrizione della Sintassi\nIl codice R è strutturato come segue:\n\n\nGenerazione dei campioni:\n\nCreiamo una lista di campioni (10 campioni in totale), ciascuno con 10 osservazioni, utilizzando la distribuzione normale con media 0.05 e deviazione standard 0.1.\n\n\n\nCalcolo delle medie e dei valori-\\(p\\):\n\nIteriamo su ciascun campione per calcolare la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nCalcoliamo il valore statistico \\(t\\) e il corrispondente valore-\\(p\\) utilizzando la distribuzione \\(t\\).\n\n\n\nStampa dei risultati:\n\nI valori-\\(p\\) vengono arrotondati e stampati per osservare la loro variabilità.\n\n\n\n\n# Imposta il seme per riproducibilità\nset.seed(1234)\n\n# Parametri della simulazione\nJ &lt;- 10              # Numero di campioni indipendenti\nn &lt;- 10              # Numero di osservazioni per campione\ntrue_mean &lt;- 0.05    # Media vera della popolazione\ntrue_sd &lt;- 0.1       # Deviazione standard della popolazione\n\n# Genera i campioni casuali\nsamples &lt;- replicate(J, rnorm(n, mean = true_mean, sd = true_sd), simplify = FALSE)\n\n# Calcola statistiche campionarie e p-valori\nresults &lt;- lapply(samples, function(sample) {\n  sample_mean &lt;- mean(sample)                         # Media campionaria\n  sample_sd &lt;- sd(sample)                             # Deviazione standard campionaria\n  t_statistic &lt;- sample_mean / (sample_sd / sqrt(n))  # Statistica t\n  p_value &lt;- 2 * (1 - pt(abs(t_statistic), df = n - 1))  # valore-$p$ bilaterale\n  list(mean = sample_mean, sd = sample_sd, t = t_statistic, p_value = p_value)\n})\n\n# Converti i risultati in un data frame per facilitarne la visualizzazione\nresults_df &lt;- do.call(rbind, lapply(results, as.data.frame))\nrownames(results_df) &lt;- paste(\"C\", 1:J)\n\n# Visualizza i risultati\nprint(results_df)\n#&gt;         mean     sd      t p_value\n#&gt; C 1   0.0117 0.0996  0.371 0.71918\n#&gt; C 2   0.0382 0.1067  1.131 0.28718\n#&gt; C 3   0.0112 0.0666  0.532 0.60758\n#&gt; C 4  -0.0266 0.0894 -0.941 0.37112\n#&gt; C 5  -0.0110 0.0787 -0.441 0.66955\n#&gt; C 6   0.0221 0.1186  0.590 0.56994\n#&gt; C 7   0.1117 0.1144  3.086 0.01301\n#&gt; C 8   0.0458 0.0924  1.567 0.15157\n#&gt; C 9   0.0342 0.0735  1.470 0.17575\n#&gt; C 10  0.1061 0.0984  3.409 0.00776\n\n\nggplot(results_df, aes(x = rownames(results_df), y = p_value)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Variabilità dei p-valori\",\n    x = \"Campioni\",\n    y = \"valore-p\"\n  ) \n\n\n\n\n\n\n\n\n52.2.3 Interpretazione dei Risultati\nIn un tipico esperimento, i risultati potrebbero variare notevolmente tra i diversi campioni analizzati. Alcuni campioni potrebbero essere pienamente compatibili con il rumore statistico, mentre altri potrebbero suggerire lievi evidenze contro l’ipotesi nulla. Altri ancora potrebbero addirittura apparire altamente significativi dal punto di vista statistico.\nTuttavia, la differenza tra ‘statisticamente significativo’ e ‘non significativo’ non sempre corrisponde a una distinzione scientificamente rilevante nel fenomeno studiato. Ad esempio, un valore-\\(p\\) di 0.003 potrebbe sembrare drasticamente diverso da uno di 0.336, ma questa discrepanza, di per sé, non implica un’effettiva differenza sostanziale.\nQuesta situazione estrema emerge quando non esiste alcuna vera variazione sottostante tra i campioni. In tali casi, un modello multilivello rivelerebbe che le apparenti differenze osservate non rappresentano un’effettiva variabilità degna di interesse, ma fluttuazioni casuali intorno a un effetto nullo.\n\n52.2.4 Punti Chiave\n\nIl valore-\\(p\\) descrive solo l’ipotesi nulla: È una misura relativa all’assenza di effetto, ma non ha necessariamente un significato diretto rispetto a un effetto reale, anche se piccolo.\nIl valore-\\(p\\) è altamente variabile: Essendo una trasformazione non lineare dello z-score, il valore-\\(p\\) può comportarsi in modi non intuitivi, soprattutto con campioni piccoli.\nLe simulazioni sono istruttive: Anche esperimenti semplici come questo possono essere estremamente utili per comprendere le limitazioni e l’interpretazione dei risultati.\n\n52.2.5 Un Avvertimento Importante\nAnche le inferenze bayesiane sono soggette a variabilità. Qualsiasi sintesi dei dati porta con sé un certo grado di incertezza. Il problema non risiede nei valori-\\(p\\) in sé, ma nel loro utilizzo scorretto. Interpretare un valore-\\(p\\) come una dichiarazione forte sulla realtà, invece di considerarlo un riassunto rumoroso di un esperimento specifico, è un errore comune.\nAllo stesso modo, fraintendimenti e sovrainterpretazioni possono verificarsi anche con approcci bayesiani. Ad esempio, l’adattamento di un modello con prior non informativi e l’interpretazione della probabilità posteriore di un parametro (ad esempio, maggiore di zero) sulla base di una soglia arbitraria può portare a conclusioni altrettanto problematiche. Questi risultati ci ricordano l’importanza di una sana cautela nell’interpretazione statistica, indipendentemente dal metodo utilizzato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "title": "\n52  La fragilità del p-valore\n",
    "section": "\n52.3 Riflessioni Conclusive",
    "text": "52.3 Riflessioni Conclusive\nLa simulazione mostra che, nonostante le medie dei campioni siano generate con una distribuzione simile, i valori-\\(p\\) possono variare drasticamente. Questo effetto è amplificato dalla scelta di campioni piccoli e di una media vera molto vicina all’ipotesi nulla (zero). Ciò dimostra quanto il valore-\\(p\\) possa essere influenzato da piccole variazioni nei dati e perché non sia sempre un indicatore affidabile per valutare l’efficacia o la presenza di un effetto.\nIn generale, la domanda importante dal punto di vista scientifico non è se in un particolare campione è stato ottenuto un risultato statisticamente significativo, ma se l’effetto osservato in quel campione sia generalizzabile ad altri campioni e a dati futuri. Solo in questo secondo caso possiamo concludere, con un certo grado di certezza, di aver compreso qualcosa di rilevante sul fenomeno studiato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n52  La fragilità del p-valore\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#&gt; [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#&gt; [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#&gt; [16] knitr_1.50            labeling_0.4.3        bridgesampling_1.1-2 \n#&gt; [19] htmlwidgets_1.6.4     curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [22] RColorBrewer_1.1-3    abind_1.4-8           multcomp_1.4-28      \n#&gt; [25] withr_3.0.2           purrr_1.1.0           grid_4.5.1           \n#&gt; [28] stats4_4.5.1          colorspace_2.1-1      xtable_1.8-4         \n#&gt; [31] inline_0.3.21         emmeans_1.11.2-8      scales_1.4.0         \n#&gt; [34] MASS_7.3-65           cli_3.6.5             mvtnorm_1.3-3        \n#&gt; [37] rmarkdown_2.29        ragg_1.5.0            generics_0.1.4       \n#&gt; [40] RcppParallel_5.1.11-1 cachem_1.1.0          stringr_1.5.1        \n#&gt; [43] splines_4.5.1         parallel_4.5.1        vctrs_0.6.5          \n#&gt; [46] V8_7.0.0              Matrix_1.7-4          sandwich_3.1-1       \n#&gt; [49] jsonlite_2.0.0        arrayhelpers_1.1-0    systemfonts_1.2.3    \n#&gt; [52] glue_1.8.0            codetools_0.2-20      distributional_0.5.0 \n#&gt; [55] lubridate_1.9.4       stringi_1.8.7         gtable_0.3.6         \n#&gt; [58] QuickJSR_1.8.0        htmltools_0.5.8.1     Brobdingnag_1.2-9    \n#&gt; [61] R6_2.6.1              textshaping_1.0.3     rprojroot_2.1.1      \n#&gt; [64] evaluate_1.0.5        lattice_0.22-7        backports_1.5.0      \n#&gt; [67] memoise_2.0.1         broom_1.0.9           snakecase_0.11.1     \n#&gt; [70] rstantools_2.5.0      coda_0.19-4.1         gridExtra_2.3        \n#&gt; [73] nlme_3.1-168          checkmate_2.3.3       xfun_0.53            \n#&gt; [76] zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "href": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "title": "\n52  La fragilità del p-valore\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Stern, H. (2006). The difference between «significant» and «not significant» is not itself statistically significant. The American Statistician, 60(4), 328–331.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "53  Riforma",
    "section": "",
    "text": "53.1 Introduzione\nLa crisi della riproducibilità ha stimolato un profondo dibattito sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non sono replicabili ha minato la fiducia nella ricerca scientifica, evidenziando carenze metodologiche e strutturali nel sistema accademico. In risposta a questa crisi, sono state avanzate diverse proposte di riforma per migliorare la qualità e l’affidabilità della ricerca scientifica.\nSecondo Korbmacher et al. (2023), sono necessarie riforme strutturali, cambiamenti procedurali e trasformazioni nella comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "53  Riforma",
    "section": "53.2 Riforme Strutturali",
    "text": "53.2 Riforme Strutturali\n\n53.2.1 Integrazione della Riproducibilità nei Curriculum Educativi\nUna proposta chiave per affrontare la crisi della riproducibilità è l’integrazione delle pratiche di riproducibilità nei curriculum delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non enfatizzano sufficientemente l’importanza della replicabilità e della trasparenza nella ricerca. Includere questi temi nei corsi di metodologia della ricerca può sensibilizzare le nuove generazioni di ricercatori sull’adozione di pratiche più rigorose e trasparenti. Alcuni programmi universitari hanno già iniziato a incorporare repliche di studi famosi nel percorso formativo, offrendo agli studenti l’opportunità di comprendere meglio i limiti e le potenzialità del processo scientifico.\n\n\n53.2.2 Incentivi per la Scienza Aperta\nUn altro aspetto cruciale è la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantità di pubblicazioni e la novità dei risultati, piuttosto che la loro qualità e replicabilità. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l’introduzione di riconoscimenti ufficiali, come badge di “open science” o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, uno studio di Scheel et al. (2021) ha confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, è emerso che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "53  Riforma",
    "section": "53.3 Cambiamenti Procedurali",
    "text": "53.3 Cambiamenti Procedurali\n\n53.3.1 Mercati di Previsione per la Credibilità della Ricerca\nI mercati di previsione sono stati proposti come strumento innovativo per valutare la credibilità della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilità che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato un’elevata accuratezza nella classificazione della replicabilità degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati è costosa o difficile, fornendo una prima indicazione sulla solidità dei risultati di ricerca.\n\n\n53.3.2 Strumenti di Valutazione Statistica\nUn’altra proposta riguarda l’adozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significatività statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n53.3.3 Analisi Multiverso\nL’analisi multiverso è un’altra proposta innovativa che mira a gestire la molteplicità di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l’esecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilità dei risultati. L’adozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilità nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "title": "53  Riforma",
    "section": "53.4 Cambiamenti nella Comunità",
    "text": "53.4 Cambiamenti nella Comunità\n\n53.4.1 Big Team Science\nIl concetto di “Big Team Science” rappresenta un cambiamento significativo nella modalità di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l’obiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l’efficienza della ricerca, ma promuove anche una maggiore diversità nei campioni e nei team di ricerca. Tuttavia, esistono anche criticità, come la possibilità di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficoltà nel riconoscere adeguatamente i contributi individuali all’interno di grandi consorzi.\n\n\n53.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualità della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione può ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni più solide e condivise all’interno della comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "title": "53  Riforma",
    "section": "53.5 Crisi della Generalizzabilità",
    "text": "53.5 Crisi della Generalizzabilità\nYarkoni (2022) affronta la questione critica della scarsa validità delle inferenze quantitative presenti nella letteratura psicologica pubblicata, proponendo tre strategie principali per migliorare la qualità della ricerca in psicologia.\n\n53.5.1 Do Something Else\nIl primo suggerimento è di considerare l’abbandono della ricerca psicologica quantitativa quando risulta troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L’autore critica la tendenza a concludere ogni contributo di ricerca con una nota positiva, indipendentemente dalle evidenze raccolte. In alcuni casi, potrebbe essere più saggio riconoscere i limiti della ricerca e scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi.\n\n\n53.5.2 Abbracciare l’Analisi Qualitativa\nLa seconda opzione proposta è continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L’autore sostiene che gran parte della scienza quantitativa in psicologia sia in realtà un’analisi qualitativa mascherata. In molti casi, l’analisi qualitativa potrebbe fornire risposte più profonde e significative rispetto a un approccio quantitativo superficiale.\n\n\n53.5.3 Adottare Standard Migliori\nLa terza strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla più rigorosa e affidabile. L’autore propone diverse pratiche, tra cui:\n\nInferenze più conservative: Evitare generalizzazioni ampie basate su dati limitati.\nRicerca descrittiva: Prendere più seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili.\nModelli statistici più espansivi: Utilizzare modelli che considerino una più ampia gamma di variabili e fattori.\nProgettare con la variazione in mente: Abbracciare la variabilità naturale delle condizioni sperimentali.\nStime della varianza: Porre maggiore enfasi sull’analisi delle componenti della varianza.\nPredizioni più rischiose: Formulare predizioni teoriche che comportino un alto grado di rischio.\nUtilità predittiva pratica: Concentrarsi sull’utilità pratica delle predizioni piuttosto che su considerazioni puramente teoriche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "53  Riforma",
    "section": "53.6 Sviluppare Teorie Formali",
    "text": "53.6 Sviluppare Teorie Formali\nOltre alle carenze metodologiche o statistiche, è stato spesso sottolineato che la crisi di replicabilità trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l’uso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se è inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "title": "53  Riforma",
    "section": "53.7 Riflessioni Conclusive",
    "text": "53.7 Riflessioni Conclusive\nL’ampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poiché attribuisce un’apparenza di rigore scientifico a inferenze che, in realtà, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilità a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilità ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l’adozione di standard metodologici più rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualità e la replicabilità dei risultati rispetto alla loro quantità e novità. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilità e la sostenibilità a lungo termine della disciplina.\nAffinché queste riforme abbiano un impatto duraturo, è essenziale un cambiamento strutturale a tutti i livelli della comunità scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche più rigorose e trasparenti, privilegiando la solidità metodologica e la replicabilità dei loro studi.\nGli enti finanziatori devono incentivare la qualità e la replicabilità degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all’impatto a lungo termine delle ricerche e alla loro solidità metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anziché limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilità offre un’opportunità unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia può emergere come una disciplina più robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#bibliografia",
    "href": "chapters/replication_crisis/06_changes.html#bibliografia",
    "title": "53  Riforma",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221–229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_degrees_of_freedom.html",
    "href": "chapters/replication_crisis/07_degrees_of_freedom.html",
    "title": "54  I gradi di libertà del ricercatore",
    "section": "",
    "text": "54.1 Introduzione\nLo studio di Gould et al. (2025), ripreso dalla rivista Science (O’Grady, 2025), mostra come le scelte analitiche dei ricercatori possano generare una variabilità significativa nei risultati, persino quando si utilizzano gli stessi dati e si affronta la medesima domanda di ricerca in ecologia e biologia evolutiva. Questa discrepanza supera di gran lunga l’errore statistico atteso, rivelando un problema sistemico che trascende i confini disciplinari.\nI risultati concordano con quelli di precedenti progetti “many analysts” – tra cui il pionieristico lavoro in psicologia di Silberzahn et al. (2018) – e sottolineano, come evidenziato dallo psicologo Eric Uhlmann, “il ruolo cruciale delle decisioni soggettive nella pratica scientifica”. Ciò conferma che la fragilità metodologica non è un’esclusiva della psicologia, ma riguarda settori come le neuroscienze, le scienze sociali e, appunto, l’ecologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_degrees_of_freedom.html#metodologia",
    "href": "chapters/replication_crisis/07_degrees_of_freedom.html#metodologia",
    "title": "54  I gradi di libertà del ricercatore",
    "section": "54.2 Metodologia",
    "text": "54.2 Metodologia\nGould et al. (2025) hanno coinvolto 174 team di ricerca (246 analisti) nell’analisi indipendente di due dataset inediti:\n\nEcologia evolutiva: relazione tra numero di fratelli e crescita dei pulcini di cinciallegra (Cyanistes caeruleus).\nEcologia della conservazione: impatto della copertura erbosa sul reclutamento di piantine di Eucalyptus.\n\nOgni team ha risposto a una domanda specifica:\n\nDataset cinciallegra: “Quanto la competizione tra fratelli influenza la crescita dei pulcini?”\nDataset eucalipto: “In che modo la copertura erbosa condiziona il reclutamento di piantine?”\n\nI ricercatori hanno fornito risultati, giustificazioni metodologiche, codice analitico e hanno sottoposto le procedure a peer review incrociata, creando un sistema di controllo reciproco.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_degrees_of_freedom.html#risultati",
    "href": "chapters/replication_crisis/07_degrees_of_freedom.html#risultati",
    "title": "54  I gradi di libertà del ricercatore",
    "section": "54.3 Risultati",
    "text": "54.3 Risultati\nLo studio ha evidenziato eterogeneità estrema nelle conclusioni, nonostante l’uniformità dei dati di partenza:\n\nCinciallegra: L’effetto medio negativo (più fratelli = minore crescita) nascondeva un’ampia dispersione, con stime da -0.8 a +0.2 (Figura 1a).\nEucalipto: La relazione media era debolmente negativa e non significativa, ma con outlier che invertivano la tendenza (Figura 1b).\n\n\n\n\n\n\n\nFigura 54.1: Distribuzione degli effetti standardizzati nei due dataset: crescita dei pulcini (sinistra) e reclutamento di piantine (destra) (adattata da Gould et al., 2025).\n\n\n\nSorprendentemente, né la selezione di variabili, né l’uso di effetti casuali, né il giudizio dei revisori correlavano con la distanza dalla media meta-analitica. In altre parole, risultati divergenti non erano associati a scelte metodologicamente “peggiori”, ma a combinazioni altrettanto valide di decisioni analitiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_degrees_of_freedom.html#il-problema-dei-gradi-di-libertà-del-ricercatore",
    "href": "chapters/replication_crisis/07_degrees_of_freedom.html#il-problema-dei-gradi-di-libertà-del-ricercatore",
    "title": "54  I gradi di libertà del ricercatore",
    "section": "54.4 Il Problema dei Gradi di Libertà del Ricercatore",
    "text": "54.4 Il Problema dei Gradi di Libertà del Ricercatore\nIl lavoro illustra chiaramente come i “gradi di libertà analitici” – le molteplici opzioni durante l’analisi dati – possano generare conclusioni divergenti. Tra le decisioni critiche:\n\nGestione di outlier e dati mancanti.\nDefinizione operativa delle variabili.\nScelta di modelli statistici e controlli.\n\nQueste scelte, spesso soggettive ma teoricamente giustificabili, definiscono un “spazio analitico” con migliaia di percorsi possibili. Ogni studio pubblicato rappresenta dunque una singola traiettoria in questo labirinto metodologico, rischiando di offrire una visione parziale e potenzialmente distorta.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "href": "chapters/replication_crisis/07_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "title": "54  I gradi di libertà del ricercatore",
    "section": "54.5 Implicazioni e Strategie di Mitigazione",
    "text": "54.5 Implicazioni e Strategie di Mitigazione\nLa variabilità sistematica impone una revisione delle pratiche di ricerca:\n\nAnalisi di sensibilità avanzate:\n\nAnalisi multiverso: testare tutte le combinazioni plausibili di scelte metodologiche.\nCurve di specificazione: mappare come i risultati variano al mutare delle assunzioni.\n\nModelli aggregati: Combinare stime da approcci diversi (es., Bayesian Model Averaging) per ridurre la dipendenza da singole specifiche.\n\nTrasparenza procedurale:\n\nPreregistrazione: fissare ipotesi e metodi prima di accedere ai dati.\nPubblicazione di codice e dati grezzi.\n\nFormazione metodologica: Rafforzare le competenze statistiche, con enfasi sulla gestione della complessità analitica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_degrees_of_freedom.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/07_degrees_of_freedom.html#riflessioni-conclusive",
    "title": "54  I gradi di libertà del ricercatore",
    "section": "54.6 Riflessioni Conclusive",
    "text": "54.6 Riflessioni Conclusive\nQuesto studio dimostra empiricamente che l’affidabilità della scienza dipende non solo dai dati, ma da come li analizziamo. La variabilità indotta dai gradi di libertà del ricercatore mina la riproducibilità, soprattutto in contesti con elevata discrezionalità analitica. La soluzione non è l’uniformità metodologica, ma una cultura della trasparenza e della pluralità analitica, dove ogni risultato sia esplicitamente contestualizzato nel suo spazio di scelte possibili. Solo così ecologia, psicologia e discipline affini potranno produrre conoscenze solide e autocritiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_degrees_of_freedom.html#bibliografia",
    "href": "chapters/replication_crisis/07_degrees_of_freedom.html#bibliografia",
    "title": "54  I gradi di libertà del ricercatore",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGould, E., Fraser, H. S., Parker, T. H., Nakagawa, S., Griffith, S. C., Vesk, P. A., Fidler, F., Hamilton, D. G., Abbey-Lee, R. N., Abbott, J. K., et al. (2025). Same data, different analysts: variation in effect sizes due to analytical decisions in ecology and evolutionary biology. BMC biology, 23(1), 35.\n\n\nO’Grady, C. (2025). Given the same data, ecologists arrive at different conclusions. Science, 387(6738), 1026.\n\n\nSilberzahn, R., Uhlmann, E. L., Martin, D. P., Anselmi, P., Aust, F., Awtrey, E., Bahnı́k, Š., Bai, F., Bannard, C., Bonnier, E., et al. (2018). Many analysts, one data set: Making transparent how variations in analytic choices affect results. Advances in Methods and Practices in Psychological Science, 1(3), 337–356.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html",
    "href": "chapters/replication_crisis/08_integrity.html",
    "title": "55  Integrità della ricerca",
    "section": "",
    "text": "55.1 Introduzione\nL’integrità della ricerca si fonda su principi e standard professionali volti a garantire l’affidabilità e la qualità degli studi scientifici. Essa si distingue dall’etica della ricerca, che invece si concentra sui principi morali. Elementi chiave per l’integrità includono la condivisione dei dati, il consenso informato e la trasparenza nelle pratiche di ricerca. I codici di condotta svolgono un ruolo cruciale nel guidare i comportamenti etici sia dei ricercatori che delle istituzioni. Tra le principali sfide da affrontare vi sono le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio e la gestione dei conflitti di interesse. Promuovere una cultura della ricerca basata su onestà, trasparenza e rispetto dei principi etici è essenziale per preservare l’integrità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "href": "chapters/replication_crisis/08_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "title": "55  Integrità della ricerca",
    "section": "55.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca",
    "text": "55.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca\nNel contesto della ricerca, aderire a principi di condotta responsabile è fondamentale. Questi principi, spesso definiti come buone pratiche di ricerca, stabiliscono standard professionali che mirano a ottimizzare la qualità e l’affidabilità degli studi. Sebbene i concetti di base su cosa costituisca una buona pratica di ricerca rimangano stabili nel tempo, la loro applicazione pratica si evolve in risposta a cambiamenti sociali, politici e tecnologici. Un esempio significativo di questa evoluzione è l’enfasi crescente sulla condivisione dei dati di ricerca, resa possibile dall’uso di repository online gratuiti. Ciò ha portato a un’aspettativa diffusa di trasparenza e accessibilità dei dati. Allo stesso modo, la condivisione del codice utilizzato per analizzare i dati è diventata una pratica sempre più incoraggiata.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "href": "chapters/replication_crisis/08_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "title": "55  Integrità della ricerca",
    "section": "55.3 Differenziazione tra Integrità ed Etica della Ricerca",
    "text": "55.3 Differenziazione tra Integrità ed Etica della Ricerca\nL’integrità della ricerca si basa su standard professionali, mentre l’etica della ricerca si fonda su principi morali come l’autonomia, la beneficenza, la non-maleficenza e la giustizia. Questi principi etici si traducono in pratiche specifiche, quali il consenso informato e la garanzia di verità e riservatezza nei confronti dei partecipanti. I ricercatori hanno l’obbligo di evitare studi che possano causare danni o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l’integrità della ricerca presentano alcune variazioni tra le diverse fonti. Ad esempio, il Codice di condotta europeo per l’integrità della ricerca sottolinea l’importanza di principi come onestà, trasparenza, accuratezza, responsabilità, affidabilità, rispetto e indipendenza. Questi principi si traducono in comportamenti specifici attesi sia dai ricercatori che dalle istituzioni, come la condivisione dei dati nel rispetto delle normative sulla protezione dei dati, tra cui il GDPR europeo.\nUn esempio pratico di come gli standard si siano evoluti è rappresentato dalla condivisione dei dati di ricerca. In passato, questa pratica era limitata dalla mancanza di infrastrutture adeguate. Oggi, grazie ai repository online e alla pressione esercitata da riviste scientifiche e finanziatori, la condivisione dei dati è diventata una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/08_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "55  Integrità della ricerca",
    "section": "55.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta",
    "text": "55.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta\nNonostante l’esistenza di codici di condotta, i ricercatori, specialmente quelli all’inizio della carriera, possono subire pressioni da parte dei supervisori per adottare comportamenti che deviano dagli standard stabiliti. Questo è spesso dovuto alla competitività nel campo scientifico e al sistema di valutazione basato sul numero di pubblicazioni. Tali dinamiche possono portare a pratiche di ricerca discutibili (PRD), come la pubblicazione selettiva dei risultati o l’uso di analisi dei dati flessibili per ottenere risultati statisticamente significativi.\nPer preservare l’integrità della ricerca, è essenziale creare un ambiente di lavoro che promuova apertura, inclusività e discussione franca delle pressioni e delle sfide etiche. Ciò richiede non solo l’adesione ai codici di condotta esistenti, ma anche un impegno attivo delle istituzioni nel promuovere la formazione etica e l’integrità tra i ricercatori. Solo attraverso un approccio di questo tipo la comunità scientifica può aspirare a una ricerca di alta qualità, sia eticamente responsabile che metodologicamente solida.\nUn esempio emblematico delle tensioni nel mondo accademico è il gioco da tavolo Publish or Perish, recentemente promosso dalla prestigiosa rivista Nature. La descrizione del gioco è provocatoria:\n\n“Falsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.”\n\nQuesta iniziativa solleva interrogativi sullo stato attuale della ricerca scientifica. Il mondo accademico sembra offrire incentivi distorti, mentre il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che spesso entra in conflitto con gli obiettivi fondamentali della ricerca. Questo contesto favorisce l’accettazione di pratiche disoneste, funzionali al mantenimento dello status quo.\nIn questo scenario complesso, emergono voci di dissenso che auspicano una riforma del sistema scientifico (McElreath, 2020; Smaldino & McElreath, 2016). È necessaria una riflessione profonda su come bilanciare la produttività accademica con l’etica e la qualità della ricerca, nonché sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_integrity.html#bibliografia",
    "href": "chapters/replication_crisis/08_integrity.html#bibliografia",
    "title": "55  Integrità della ricerca",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society Open Science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell’Inferenza Frequentista\nL’inferenza bayesiana rappresenta un approccio rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell’analisi psicologica. A differenza dei metodi frequentisti, l’approccio bayesiano consente di quantificare l’incertezza e di costruire modelli che riflettono le nostre aspettative iniziali. Questa flessibilità è particolarmente preziosa in psicologia, dove teorie e ipotesi svolgono un ruolo centrale nel guidare la ricerca. L’inferenza bayesiana rende esplicite le nostre assunzioni a priori e ci permette di valutare come i dati influenzano la nostra comprensione dei fenomeni psicologici.\nIn questo corso, abbiamo esaminato i limiti dell’inferenza frequentista, specialmente quando utilizzata come “filtro” per distinguere risultati scientifici rilevanti da quelli trascurabili. L’eccessiva dipendenza dai valori-p è stata ampiamente criticata per la sua associazione con inferenze inadeguate. Gli effetti possono essere sovrastimati, talvolta anche nella direzione sbagliata, quando la stima è vincolata alla significatività statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nNonostante le critiche di lunga data e i dibattiti sul loro uso improprio (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004), i valori-p persistono come indicatore di significatività. Questa tenacia riflette forse la necessità dei ricercatori di avere strumenti intuitivi, sebbene semplificati, per interpretare i dati. Tuttavia, l’uso rigido di soglie arbitrarie (ad esempio, 0.05, 0.01, 0.001) ha trasformato il raggiungimento della significatività in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i fenomeni sottostanti (Cohen, 1994; Kirk, 1996). Inoltre, i valori-p possono solo rifiutare l’ipotesi nulla, ma non confermarla, poiché un risultato non significativo non implica l’assenza di effetti o differenze (Wagenmakers, 2007; Amrhein et al., 2019).\nL’uso improprio dei valori-p, noto come “p-hacking” (Simmons et al., 2011), ha favorito pratiche scientifiche discutibili, contribuendo alla crisi di riproducibilità nella psicologia (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilità",
    "text": "La Crisi della Replicabilità\nLa crisi della replicabilità rappresenta una delle principali sfide che affliggono la ricerca scientifica contemporanea, con effetti particolarmente rilevanti nel campo della psicologia. Quando i risultati di uno studio non possono essere riprodotti in condizioni simili, si mette in discussione non solo la validità delle teorie su cui si basano interventi clinici e politiche pubbliche, ma anche la fiducia generale nella scienza. Questo problema va oltre l’ambito accademico, influenzando direttamente l’efficacia delle applicazioni pratiche delle ricerche.\n\nLe Cause Sottostanti\nUno dei fattori principali della crisi è legato all’uso di metodologie di ricerca e analisi dei dati insufficientemente rigorose, che spesso portano a falsi positivi. Sebbene siano stati fatti appelli per migliorare le pratiche scientifiche, tali problemi persistono, indicando che il fenomeno non è semplicemente frutto di errori o mancanza di comprensione. Secondo Smaldino e McElreath (2016), la causa radicale risiede nei sistemi di incentivi distorti che favoriscono la quantità piuttosto che la qualità della ricerca. In questo contesto, la pressione a pubblicare risultati significativi diventa prioritaria rispetto alla rigorosità metodologica, alimentando un circolo vizioso in cui la “scienza scadente” si perpetua.\nPratiche comuni, come il p-hacking (manipolazione statistica per ottenere risultati significativi) o la selezione selettiva dei dati, vengono adottate inconsciamente o intenzionalmente per massimizzare le probabilità di pubblicazione. Questo meccanismo, descritto come una forma di “selezione naturale della scienza scadente”, premia approcci che facilitano la produzione di risultati spettacolari, ma non necessariamente veritieri.\n\n\nVerso una Soluzione: Cambiare la Cultura Scientifica\nPer superare questa crisi, è fondamentale operare un cambiamento culturale all’interno della comunità scientifica. Non basta correggere gli errori metodologici; occorre modificare radicalmente gli incentivi per premiare la qualità, la trasparenza e la replicabilità della ricerca. Alcune strategie chiave includono:\n\nPromozione di Pratiche Rigorose:\n\nAdottare protocolli trasparenti, preregistrare gli studi prima del loro avvio e condividere apertamente dati e materiali.\nImplementare procedure di peer review più severe e incoraggiare la revisione post-pubblicazione.\n\nValorizzazione della Replicazione:\n\nDare maggiore riconoscimento agli studi che replicano risultati precedenti, anziché privilegiare esclusivamente nuove scoperte.\nCreare riviste specializzate che si concentriano sulla verifica e sulla riproducibilità degli studi.\n\nRiforma dei Criteri di Valutazione:\n\nSpostare l’attenzione dalla quantità delle pubblicazioni alla loro qualità e impatto scientifico.\nIncorporare metriche alternative, come l’impatto sociale e la contribuzione alla conoscenza consolidata.\n\n\n\n\nNuovi Approcci Metodologici\nAlcune proposte innovative mirano a migliorare la qualità delle analisi statistiche e ridurre la propensione a falsi positivi. Un esempio è l’adozione dell’inferenza bayesiana, che offre vantaggi significativi rispetto ai metodi tradizionali:\n\nMaggiore flessibilità nell’analisi di dati rumorosi o campioni piccoli.\nMinore propensione agli errori di tipo I.\nPossibilità di incorporare conoscenze pregresse nel processo decisionale.\n\nTuttavia, l’inferenza bayesiana da sola non può risolvere completamente il problema. È necessario affrontare anche le cause strutturali, come il sistema accademico che premia la produttività quantitativa piuttosto che la qualità.\nUn’altra prospettiva promettente è quella avanzata da Richard McElreath, che suggerisce di passare da un approccio descrittivo a uno che descrive formalmente i meccanismi generativi dei dati. Questo significa formulare ipotesi esplicite sui processi sottostanti e testarle attraverso confronti quantitativi tra modelli. Tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO) permettono di valutare la robustezza dei modelli e la loro capacità di generalizzare a nuovi contesti.\nInoltre, la “rivoluzione causale” cerca di identificare relazioni causali in contesti naturali, superando i limiti degli esperimenti controllati tradizionali. Questo approccio richiede ai ricercatori di formulare ipotesi causali esplicite e confrontare modelli alternativi, migliorando così la comprensione dei fenomeni studiati.\n\n\nImplicazioni Sociali e Educative\nLa crisi della replicabilità ha implicazioni concrete al di là del mondo accademico. Interventi clinici, politiche pubbliche e decisioni basate su ricerche non replicabili rischiano di essere inefficaci o dannose. Pertanto, garantire la replicabilità e l’affidabilità delle scoperte scientifiche è essenziale non solo per preservare l’integrità accademica, ma anche per assumersi responsabilità sociali.\nUna revisione dei metodi didattici e dei programmi accademici è altrettanto cruciale. Gli studenti devono essere formati per comprendere e applicare inferenze basate su dati empirici. Studiosi come Mine Dogucu hanno sottolineato l’importanza di integrare approcci bayesiani e causalità nei corsi di formazione, e la presente dispensa si inserisce in questo sforzo (Dogucu & Çetinkaya-Rundel, 2021; Dogucu & Hu, 2022; Johnson et al., 2022; Rosenberg et al., 2022).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nAffrontare e superare la crisi della replicabilità rappresenta una sfida fondamentale per la comunità scientifica, richiedendo un impegno collettivo per riformare profondamente la cultura della ricerca. Modificare gli incentivi che favoriscono quantità piuttosto che qualità, promuovere pratiche metodologiche rigorose e valorizzare la replicazione sono passi essenziali per costruire una scienza più affidabile. Solo attraverso un approccio multidimensionale sarà possibile ripristinare la fiducia nella psicologia scientifica e garantire che le sue applicazioni pratiche siano fondate su basi solide e verificabili.\nIn questo contesto, l’inferenza bayesiana emerge come uno strumento di grande valore per l’analisi dei dati psicologici. Offrendo metodi avanzati per gestire l’incertezza, integrare conoscenze pregresse e adattarsi a modelli complessi, essa si dimostra particolarmente utile per esplorare i fenomeni legati alla mente umana e al comportamento. La sua capacità di fornire previsioni robuste e di aggiornare le ipotesi in base a nuovi dati la rende un approccio ideale per affrontare le sfide poste dalla natura intrinsecamente dinamica del campo psicologico.\nTuttavia, è importante sottolineare che l’adozione di metodi bayesiani non costituisce da sola una soluzione completa alla crisi della replicabilità. Per migliorare realmente la qualità della ricerca, è necessario integrare queste tecniche con pratiche metodologiche rigorose. Tra queste, spiccano la formalizzazione di modelli generativi, che consentono di descrivere esplicitamente i processi sottostanti ai dati osservati, e il confronto tra modelli alternativi, fondamentale per valutare l’adeguatezza delle teorie proposte. Inoltre, l’adozione di una prospettiva causale esplicita è cruciale per identificare correttamente le relazioni di causa-effetto, superando i limiti degli studi correlazionali o degli esperimenti tradizionali.\nIn conclusione, solo un approccio integrato, che combini l’inferenza bayesiana con pratiche metodologiche avanzate e una riflessione critica sui sistemi di incentivi accademici, permetterà di progredire verso una scienza psicologica più affidabile e riproducibile. Questo sforzo collettivo non solo migliorerà la qualità delle ricerche, ma contribuirà anche a fornire una comprensione più profonda e accurata del comportamento umano, consolidando così la posizione della psicologia come disciplina scientifica solida e credibile.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDogucu, M., & Çetinkaya-Rundel, M. (2021). Web scraping in the statistics and data science curriculum: Challenges and opportunities. Journal of Statistics and Data Science Education, 29(sup1), S112–S122.\n\n\nDogucu, M., & Hu, J. (2022). The current state of undergraduate Bayesian education and recommendations for the future. The American Statistician, 76(4), 405–413.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nRosenberg, J. M., Kubsch, M., Wagenmakers, E.-J., & Dogucu, M. (2022). Making sense of uncertainty in the science classroom: A Bayesian approach. Science & Education, 31(5), 1239–1262.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html",
    "href": "chapters/appendix/a01_shell.html",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1 Che cos’è una Shell?\nUna shell è un programma che riceve comandi dall’utente tramite tastiera (o da file) e li passa al sistema operativo per l’esecuzione. Può essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "href": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nA.1.2 Windows vs macOS/Linux\n\nWindows 10: È possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l’ambiente preferito è solitamente PowerShell.\nmacOS/Linux: Zsh è la shell predefinita in entrambi i sistemi. È consigliabile sfruttare l’applicazione warp per un’esperienza utente moderna e ottimizzata.\n\n\n\nA.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nA.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nA.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilità di navigazione.\ncat: Mostra l’intero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nA.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l’utilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilità nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma più potente perché può rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nA.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nA.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilità di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l’intero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nÈ cruciale familiarizzarsi con l’utilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L’impiego dei percorsi relativi rende il processo di navigazione più intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l’utilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: È importante evitare l’inserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l’uso del trattino (-) può causare problemi; quindi è consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilità con alcuni sistemi operativi o applicazioni, rendendo più complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, è consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, è possibile ottimizzare notevolmente l’organizzazione e la gestione dei propri file, migliorando l’efficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti (es., Robbins, 2016). La familiarità con la shell è fondamentale nella data science.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#bibliografia",
    "href": "chapters/appendix/a01_shell.html#bibliografia",
    "title": "Appendice A — La Shell",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRobbins, A. (2016). Bash Pocket Reference: Help for Power Users and Sys Admins. O’Reilly Media, Inc.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html",
    "href": "chapters/appendix/a01a_files.html",
    "title": "Appendice B — Cartelle e documenti",
    "section": "",
    "text": "B.1 Introduzione\nI file su un computer sono organizzati tramite una struttura gerarchica chiamata struttura ad albero, costituita da cartelle (o directory) e file. Questa organizzazione permette una gestione ordinata e intuitiva delle informazioni.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#introduzione",
    "href": "chapters/appendix/a01a_files.html#introduzione",
    "title": "Appendice B — Cartelle e documenti",
    "section": "",
    "text": "Radice (Root): È il punto più alto dell’albero da cui partono tutte le ramificazioni.\nCartelle/Directory: Contenitori che possono includere file o altre cartelle.\nFile: Gli elementi finali che contengono dati.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "href": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.2 Unix/Linux/macOS",
    "text": "B.2 Unix/Linux/macOS\nNei sistemi Unix, l’albero ha una struttura chiara che inizia sempre dalla radice indicata con lo slash /.\nEsempio semplificato:\n/\n├── bin             # programmi di sistema essenziali\n├── etc             # file di configurazione\n├── home            # cartelle personali degli utenti\n│   └── utente\n│       ├── Documenti\n│       ├── Immagini\n│       └── Scaricati\n├── usr             # applicazioni e librerie utente\n├── var             # dati variabili come log e cache\n└── tmp             # file temporanei\nNei sistemi Unix i percorsi dei file si scrivono utilizzando lo slash (/), ad esempio:\n/home/utente/Documenti/tesi.docx",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#windows",
    "href": "chapters/appendix/a01a_files.html#windows",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.3 Windows",
    "text": "B.3 Windows\nWindows organizza i file in maniera simile ma partendo da una o più unità (dischi), tipicamente indicate da lettere come C:, D:, ecc. La radice di ogni albero corrisponde quindi all’unità disco.\nEsempio semplificato:\nC:\\\n├── Program Files   # applicazioni installate\n├── Windows         # sistema operativo e file di sistema\n├── Utenti          # dati degli utenti\n│   └── utente\n│       ├── Documenti\n│       ├── Immagini\n│       └── Download\n└── Temp            # file temporanei\nNei sistemi Windows i percorsi dei file si scrivono utilizzando il backslash (\\), ad esempio:\nC:\\Utenti\\utente\\Documenti\\tesi.docx",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#principali-comandi",
    "href": "chapters/appendix/a01a_files.html#principali-comandi",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.4 Principali Comandi",
    "text": "B.4 Principali Comandi\nQui sotto viene presentata una panoramica sintetica dei principali comandi per gestire la struttura ad albero di file e cartelle nei sistemi Unix (Linux e macOS) e Windows.\n\nB.4.1 Unix/Linux/macOS (Terminale Bash o zsh)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\npwd\nMostra la cartella corrente (Print Working Directory)\npwd → /home/utente/Documenti\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd /home/utente/Scaricati\n\n\nls\nElenca il contenuto di una cartella (List)\nls o ls -l\n\n\nmkdir\nCrea una nuova cartella (Make Directory)\nmkdir nuova_cartella\n\n\nmv\nSposta o rinomina file/cartelle (Move)\nmv file.txt Documenti/ oppure mv vecchio.txt nuovo.txt\n\n\ncp\nCopia file/cartelle (Copy)\ncp file.txt copia_file.txt\n\n\nrm\nRimuove file (Remove)\nrm file.txt\n\n\nrmdir\nRimuove una cartella vuota (Remove Directory)\nrmdir cartella_vuota\n\n\nwhoami\nMostra l’utente corrente\nwhoami → utente\n\n\n\nEsempio di uso dei comandi:\npwd\ncd /home/utente\nmkdir nuovo\ncd nuovo\ntouch prova.txt\nls\nmv prova.txt ../Documenti\ncd ../Documenti\ncp prova.txt copia_prova.txt\nrm prova.txt\nwhoami\n\n\nB.4.2 Windows (Prompt dei comandi, CMD)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd C:\\Utenti\\utente\\Documenti\n\n\ncd\nMostra la cartella corrente\ncd → C:\\Utenti\\utente\\Documenti\n\n\ndir\nElenca il contenuto della cartella\ndir\n\n\nmkdir\nCrea una nuova cartella\nmkdir nuova_cartella\n\n\nmove\nSposta o rinomina file/cartelle\nmove file.txt Documenti\\ o move vecchio.txt nuovo.txt\n\n\ncopy\nCopia file\ncopy file.txt copia_file.txt\n\n\ndel\nRimuove file\ndel file.txt\n\n\nrmdir\nRimuove cartella vuota\nrmdir cartella_vuota\n\n\nwhoami\nMostra l’utente corrente\nwhoami → utente\n\n\n\nEsempio di uso dei comandi:\ncd C:\\Utenti\\utente\nmkdir nuovo\ncd nuovo\necho prova &gt; prova.txt\ndir\nmove prova.txt ..\\Documenti\ncd ..\\Documenti\ncopy prova.txt copia_prova.txt\ndel prova.txt\nwhoami\nNota finale.\nEntrambi i sistemi operativi consentono operazioni simili, ma hanno sintassi e convenzioni leggermente diverse. Questi comandi di base permettono una gestione essenziale e rapida della struttura ad albero.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#conclusioni",
    "href": "chapters/appendix/a01a_files.html#conclusioni",
    "title": "Appendice B — Cartelle e documenti",
    "section": "Conclusioni",
    "text": "Conclusioni\nIn sintesi, entrambi i sistemi operativi utilizzano una struttura ad albero per facilitare la gestione, la navigazione e l’organizzazione dei file e delle cartelle. Cambiano principalmente la notazione (/ o \\) e la gestione della radice (una singola radice / in Unix, più radici contrassegnate da lettere come C: in Windows).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_math_symbols.html",
    "href": "chapters/appendix/a02_math_symbols.html",
    "title": "Appendice C — Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html",
    "href": "chapters/appendix/a03_latex.html",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "",
    "text": "D.1 LaTeX\nLaTeX è un potente strumento di composizione tipografica, ampiamente utilizzato per la produzione di documenti scientifici e tecnici. Una delle sue caratteristiche più apprezzate è la capacità di gestire equazioni matematiche in modo elegante e preciso. In questo articolo, esploreremo come scrivere equazioni matematiche in LaTeX, coprendo i modi matematici, le operazioni di base, l’allineamento delle equazioni e molto altro.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "href": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.2 Modelli Matematici in LaTeX",
    "text": "D.2 Modelli Matematici in LaTeX\nPer scrivere equazioni matematiche in LaTeX, esistono due modalità principali: la modalità inline e la modalità display.\n\nModalità Inline: Utilizzata per inserire equazioni all’interno del testo. Le espressioni matematiche sono racchiuse tra simboli di dollaro ($), ad esempio $E=mc^2$ produce \\(E=mc^2\\).\nModalità Display: Utilizzata per equazioni che devono essere evidenziate e centrate su una nuova linea. Le espressioni possono essere racchiuse tra $$ e $$, o all’interno di ambienti come \\begin{equation} e \\end{equation}.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "href": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.3 Scrivere Costrutti Matematici di Base",
    "text": "D.3 Scrivere Costrutti Matematici di Base\n\nD.3.1 Operazioni Aritmetiche\nLe operazioni aritmetiche possono essere scritte direttamente all’interno del testo utilizzando il simbolo del dollaro. Ad esempio:\n\nAddizione: $a + b$ produce \\(a + b\\).\nMoltiplicazione: $a \\cdot b$ o $a \\times b$ produce \\(a \\cdot b\\) o \\(a \\times b\\).\nDivisione: $a / b$ o $a \\div b$ produce \\(a / b\\) o \\(a \\div b\\).\n\n\n\nD.3.2 Frazioni e Coefficienti Binomiali\nLe frazioni si scrivono utilizzando il comando \\frac{num}{den}. Ad esempio, $\\frac{a}{b}$ produce \\(\\frac{a}{b}\\).\nPer i coefficienti binomiali, si utilizza il comando \\binom{n}{k}. Ad esempio, $\\binom{n}{k}$ produce \\(\\binom{n}{k}\\).\n\n\nD.3.3 Pedici e Apici\nI pedici si ottengono con _, mentre gli apici con ^. Ad esempio:\n\n$a_{1}$ produce \\(a_{1}\\).\n$a^{2}$ produce \\(a^{2}\\).\n\n\n\nD.3.4 Integrali e Radici\nPer gli integrali, i limiti di integrazione si scrivono come pedici e apici. Ad esempio:\n\n$\\int_{a}^{b} f(x) \\, dx$ produce \\(\\int_{a}^{b} f(x) \\, dx\\).\n\nLe radici si ottengono con il comando \\sqrt{}. Ad esempio, $\\sqrt{a + b}$ produce \\(\\sqrt{a + b}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "href": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.4 Allineamento delle Equazioni",
    "text": "D.4 Allineamento delle Equazioni\nPer allineare più equazioni, si utilizza l’ambiente align. Ad esempio:\n\\begin{align*}\na + b &= c \\\\\nd + e &= f\n\\end{align*}\nQuesto allinea le equazioni al segno di uguale.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "href": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.5 Parentesi e Operatori",
    "text": "D.5 Parentesi e Operatori\nLe parentesi possono essere ridimensionate utilizzando i comandi \\left( e \\right). Ad esempio:\n$$ \n\\left( \\frac{a}{b} \\right) \n$$\nGli operatori come seno, coseno e logaritmi si scrivono con comandi specifici come \\sin, \\cos, e \\log.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#conclusione",
    "href": "chapters/appendix/a03_latex.html#conclusione",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.6 Conclusione",
    "text": "D.6 Conclusione\nLaTeX offre una vasta gamma di strumenti per la scrittura di equazioni matematiche, rendendolo uno strumento indispensabile per chiunque lavori con documenti scientifici. Con un po’ di pratica, è possibile padroneggiare queste tecniche e produrre documenti di alta qualità con facilità.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice E — Numeri e intervalli",
    "section": "",
    "text": "E.1 Numeri binari\nI numeri binari rappresentano il sistema numerico più elementare utilizzato in informatica, poiché sono composti unicamente da due simboli: 0 e 1. Questa caratteristica li rende particolarmente adatti alla rappresentazione di situazioni dicotomiche (vero/falso, presente/assente) e consente ai computer di operare rapidamente ed efficacemente sui dati.\nUn esempio semplice d’impiego dei valori logici binari si ottiene quando raccogliamo risposte a una domanda chiusa. Immaginiamo, ad esempio, di porre la domanda “Ti piacciono i mirtilli?” a 10 studenti. Se le risposte vengono memorizzate in R come valori logici (TRUE per “Sì” e FALSE per “No”), potremmo avere:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, TRUE e FALSE corrispondono a 1 e 0 rispettivamente quando utilizzati in operazioni numeriche. Lo stesso avviene in Python, dove True è interpretato come 1 e False come 0. Questa rappresentazione binaria permette di ottenere facilmente statistiche sintetiche. Per esempio, per calcolare la proporzione di risposte positive rispetto al totale, è sufficiente sommare i valori (contando così il numero di TRUE) e dividere per la lunghezza del vettore:\nsum(opinion) / length(opinion)\n\n[1] 0.7\nQuesto fornisce immediatamente la percentuale di studenti che hanno risposto “Sì” alla domanda.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.2 Numeri interi",
    "text": "E.2 Numeri interi\nI numeri interi sono caratterizzati dall’assenza di componenti decimali. Essi includono sia i numeri naturali (1, 2, 3, …), tradizionalmente utilizzati per il conteggio, sia i loro opposti negativi. L’insieme dei numeri naturali è indicato con \\(\\mathbb{N}\\), mentre l’insieme dei numeri interi (che include i numeri naturali, i loro negativi e lo zero) si denota con \\(\\mathbb{Z}\\):\n\\[\n\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\pm 3, \\dots\\}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.3 Numeri razionali",
    "text": "E.3 Numeri razionali\nI numeri razionali sono quei numeri che possono essere espressi come il rapporto tra due numeri interi, con il denominatore diverso da zero. Essi formano l’insieme:\n\\[\n\\mathbb{Q} = \\left\\{\\frac{m}{n} \\mid m,n \\in \\mathbb{Z}, n \\neq 0\\right\\}.\n\\]\nPoiché ogni numero naturale è anche un intero, e ogni intero può essere rappresentato come razionale (ad esempio \\(5 = \\frac{5}{1}\\)), si ha una catena d’inclusioni tra i diversi insiemi di numeri:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}.\n\\]\nSe si desidera considerare solo i numeri razionali non negativi, si utilizza la notazione:\n\\[\n\\mathbb{Q}^+ = \\{q \\in \\mathbb{Q} \\mid q \\geq 0\\}.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.4 Numeri irrazionali",
    "text": "E.4 Numeri irrazionali\nNon tutti i numeri possono essere espressi come rapporto di due interi. I numeri che non hanno questa proprietà sono detti irrazionali. Essi non possono essere scritti in forma frazionaria e la loro espansione decimale è infinita e non periodica. Esempi tipici di numeri irrazionali sono:\n\n\\(\\sqrt{2}\\)\n\\(\\sqrt{3}\\)\n\\(\\pi = 3.141592...\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.5 Numeri reali",
    "text": "E.5 Numeri reali\nI numeri razionali non coprono tutti i possibili punti sulla retta reale. Per rappresentare ogni possibile misura, grandezza o punto su una linea continua, si considerano i numeri reali, denotati con \\(\\mathbb{R}\\). L’insieme dei numeri reali comprende sia i razionali sia gli irrazionali:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q} \\subseteq \\mathbb{R}.\n\\]\nIn statistica, la precisione con cui si esprime una misura è spesso legata al numero di cifre decimali utilizzate, sfruttando così appieno la “continuità” offerta dai numeri reali.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "href": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.6 Intervalli Numerici",
    "text": "E.6 Intervalli Numerici\nDefinizione: Un intervallo numerico è un sottoinsieme connesso della retta reale. Intuitivamente, rappresenta tutti i numeri reali compresi tra due estremi, che possono o meno essere inclusi nell’intervallo stesso.\nClassificazione degli intervalli: Gli intervalli vengono classificati in base all’inclusione o meno degli estremi:\n\n\nIntervallo chiuso: Include entrambi gli estremi. Si indica con \\([a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x \\leq b\\).\n\nIntervallo aperto: Non include alcun estremo. Si indica con \\((a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x &lt; b\\).\n\nIntervalli semiaperti:\n\n\nChiuso a sinistra e aperto a destra: Include l’estremo sinistro ma non quello destro. Si indica con \\([a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x &lt; b\\).\n\nAperto a sinistra e chiuso a destra: Include l’estremo destro ma non quello sinistro. Si indica con \\((a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x \\leq b\\).\n\n\n\nTabella riassuntiva:\n\n\nIntervallo\nNotazione\nCondizione\n\n\n\nChiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\nAperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nChiuso a sinistra, aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\nAperto a sinistra, chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)\n\n\n\nOsservazioni: * La scelta della notazione con parentesi quadre o tonde indica rispettivamente l’inclusione o l’esclusione degli estremi.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice F — Sommatorie",
    "section": "",
    "text": "F.1 Manipolazione di somme\nLe somme sono uno strumento fondamentale in molti contesti matematici e statistici, e per gestirle in modo efficace è essenziale disporre di una notazione chiara e precisa. Consideriamo, ad esempio, la somma dei primi \\(n\\) numeri interi, che può essere espressa come \\(1 + 2 + \\dots + (n-1) + n\\), dove i puntini di sospensione (\\(\\dots\\)) indicano che la sequenza deve essere completata seguendo il pattern definito dai termini precedenti e successivi. Tuttavia, una notazione come \\(1 + 7 + \\dots + 73.6\\) risulterebbe ambigua senza ulteriori specifiche. In generale, ci troveremo di fronte a somme della forma\n\\[\nx_1 + x_2 + \\dots + x_n,\n\\]\ndove \\(x_n\\) rappresenta un numero definito altrove. Sebbene questa notazione con i puntini di sospensione sia utile in alcuni contesti, può risultare poco chiara in altri. Per questo motivo, si preferisce utilizzare la notazione di sommatoria:\n\\[\n\\sum_{i=1}^n x_i,\n\\]\nche si legge “sommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (la lettera sigma maiuscola dell’alfabeto greco) rappresenta l’operazione di somma, \\(x_i\\) è il generico addendo, mentre \\(1\\) e \\(n\\) sono gli estremi della sommatoria, che definiscono l’intervallo di variazione dell’indice \\(i\\). Solitamente, l’estremo inferiore è \\(1\\), ma potrebbe essere qualsiasi altro numero \\(m &lt; n\\). Pertanto, possiamo scrivere:\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_2 + \\dots + x_n.\n\\]\nAd esempio, se i valori di \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), avremo:\n\\[\n\\sum_{i=1}^4 x_i = 3 + 11 + 4 + 7 = 25,\n\\]\ndove \\(x_1 = 3\\), \\(x_2 = 11\\), e così via. La quantità \\(x_i\\) è detta argomento della sommatoria, mentre la variabile \\(i\\), che assume valori interi successivi, è chiamata indice della sommatoria.\nLa notazione di sommatoria può anche essere espressa nella forma:\n\\[\n\\sum_{P(i)} x_i,\n\\]\ndove \\(P(i)\\) è una proposizione logica riguardante \\(i\\) che può essere vera o falsa. Quando è evidente che si vogliono sommare tutte le \\(n\\) osservazioni, la notazione può essere semplificata in \\(\\sum_{i} x_i\\) o addirittura \\(\\sum x_i\\). L’indice \\(i\\) può essere sostituito da altre lettere, come \\(k, j, l, \\dots\\), a seconda del contesto.\nPer semplificare i calcoli che coinvolgono le sommatorie, è utile conoscere alcune proprietà fondamentali.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice F — Sommatorie",
    "section": "",
    "text": "F.1.1 Proprietà 1 (Somma di una costante)\nLa sommatoria di \\(n\\) valori tutti uguali a una costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a}_{n \\text{ volte}} = n a.\n\\]\n\n\nF.1.2 Proprietà 2 (Proprietà distributiva)\nSe l’argomento della sommatoria contiene una costante, è possibile fattorizzarla. Ad esempio:\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n = a (x_1 + x_2 + \\dots + x_n) = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nF.1.3 Proprietà 3 (Proprietà associativa)\nSe l’argomento della sommatoria è una somma, possiamo separare i termini:\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_2) + \\dots + (a + x_n) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nIn generale, possiamo scrivere:\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nF.1.4 Proprietà 4 (Operazioni algebriche)\nSe è necessario eseguire un’operazione algebrica (come l’elevamento a potenza o il logaritmo) sull’argomento della sommatoria, questa operazione deve essere eseguita prima della somma. Ad esempio:\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left( \\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nF.1.5 Proprietà 5 (Prodotto di termini)\nNel caso di un prodotto tra termini, il prodotto deve essere eseguito prima della somma:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n.\n\\]\nInfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice F — Sommatorie",
    "section": "F.2 Doppia sommatoria",
    "text": "F.2 Doppia sommatoria\nIn alcuni contesti, si incontrano espressioni con una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{m} x_{ij}.\n\\]\nQuesta notazione implica che, per ogni valore dell’indice esterno \\(i\\) (da \\(1\\) a \\(n\\)), si deve sviluppare la sommatoria interna per \\(j\\) (da \\(1\\) a \\(m\\)). Ad esempio:\n\\[\n\\sum_{i=1}^{3} \\sum_{j=4}^{6} x_{ij} = (x_{1,4} + x_{1,5} + x_{1,6}) + (x_{2,4} + x_{2,5} + x_{2,6}) + (x_{3,4} + x_{3,5} + x_{3,6}).\n\\]\nUn caso particolare interessante è la doppia sommatoria del prodotto di due variabili:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j.\n\\]\nIn questo caso, poiché \\(x_i\\) non dipende dall’indice \\(j\\), possiamo estrarre \\(x_i\\) dalla sommatoria interna:\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo, la sommatoria interna \\(\\sum_{j=1}^{n} y_j\\) non dipende da \\(i\\), quindi può essere estratta dalla sommatoria esterna:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j = \\left( \\sum_{i=1}^{n} x_i \\right) \\left( \\sum_{j=1}^{n} y_j \\right).\n\\]\n\nF.2.1 Esempio pratico\nConsideriamo i vettori \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\). Calcoliamo la doppia sommatoria:\n\\[\n\\begin{aligned}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1 y_1 + x_1 y_2 + x_1 y_3 + x_2 y_1 + x_2 y_2 + x_2 y_3 + x_3 y_1 + x_3 y_2 + x_3 y_3 \\\\\n&= 2 \\times (1 + 4 + 9) + 3 \\times (1 + 4 + 9) + 1 \\times (1 + 4 + 9) \\\\\n&= 2 \\times 14 + 3 \\times 14 + 1 \\times 14 = 84.\n\\end{aligned}\n\\]\nD’altra parte, il prodotto delle due sommatorie è:\n\\[\n\\left( \\sum_{i=1}^3 x_i \\right) \\left( \\sum_{j=1}^3 y_j \\right) = (2 + 3 + 1) \\times (1 + 4 + 9) = 6 \\times 14 = 84.\n\\]\nI due risultati coincidono, confermando la validità della proprietà.\nPer ulteriori approfondimenti, si consiglia la consultazione del testo Concrete Mathematics: A Foundation for Computer Science (Graham et al., 1994).\nEsercizi pratici sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "href": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "title": "Appendice F — Sommatorie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGraham, R. L., Knuth, D. E., & Patashnik, O. (1994). Concrete Mathematics: A Foundation for Computer Science (2nd ed.). Addison-Wesley.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice G — Insiemi",
    "section": "",
    "text": "G.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, …) è stato definito da Georg Cantor nel modo seguente:\nMentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme:\n\\[\nA = \\{x ~\\vert~ \\text{proprietà posseduta da } x\\},\n\\]\nche si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le proprietà delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19° secolo John Venn, anche se rappresentazioni simili erano già state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le proprietà degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all’interno di essi.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice G — Insiemi",
    "section": "\nG.2 Appartenenza ad un insieme",
    "text": "G.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL’appartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice G — Insiemi",
    "section": "\nG.3 Relazioni tra insiemi",
    "text": "G.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l’insieme universo e l’insieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('È \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"È \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('È \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"È \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('È \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"È \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice G — Insiemi",
    "section": "\nG.4 Operazioni tra insiemi",
    "text": "G.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\nDiagrammi di Venn\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\nLeggi di DeMorgan\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all’unione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S è l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S è l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Δ, è un’operazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all’unione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice G — Insiemi",
    "section": "\nG.5 Coppie ordinate e prodotto cartesiano",
    "text": "G.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata) e \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPiù in generale, un prodotto cartesiano di \\(n\\) insiemi può essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento è una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non è dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento è possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all’n-esimo. Il prodotto cartesiano prende il nome da René Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalità dell'insieme prodotto cartesiano è:\")\n\n[1] \"La cardinalità dell'insieme prodotto cartesiano è:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A è un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A è un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza è costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza è costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "",
    "text": "H.1 Principio della somma\nIl calcolo combinatorio studia il numero di modi in cui è possibile combinare, ordinare o disporre elementi appartenenti a uno o più insiemi, seguendo regole ben definite. Molti problemi di probabilità richiedono strumenti combinatori per determinare la probabilità di eventi complessi. In questo capitolo, esploreremo i concetti fondamentali del calcolo combinatorio, illustrandoli attraverso il modello del campionamento dall’urna. Tratteremo i principi della somma e del prodotto, fondamentali per affrontare problemi più avanzati, come permutazioni, disposizioni e combinazioni.\nIl principio della somma si applica quando un insieme di elementi può essere suddiviso in sottoinsiemi disgiunti (ossia senza sovrapposizioni). In questo caso, il numero totale di elementi è dato dalla somma delle cardinalità dei sottoinsiemi:\n\\[\nn_{\\text{tot}} = n_1 + n_2 + \\dots + n_k .\n\\]\nEsempio\nUn distributore contiene tre scomparti di caramelle, ciascuno con un diverso tipo di dolci:\nQuante caramelle ci sono in totale nel distributore?\nSecondo il principio della somma, il numero totale di caramelle è:\n\\[\nn_{\\text{tot}} = n_A + n_B + n_C = 10 + 8 + 12 = 30.\n\\]\nCalcolo in R:\nA &lt;- 10\nB &lt;- 8\nC &lt;- 12\n\ntotale_caramelle &lt;- A + B + C\ntotale_caramelle\n#&gt; [1] 30\nRisultato: Nel distributore ci sono 30 caramelle in totale.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "",
    "text": "Scomparto A: 10 caramelle alla menta,\n\n\nScomparto B: 8 caramelle alla frutta,\n\n\nScomparto C: 12 caramelle al cioccolato.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "href": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.2 Principio del prodotto",
    "text": "H.2 Principio del prodotto\nIl principio del prodotto si applica quando un’operazione può essere suddivisa in più fasi indipendenti, ciascuna con un numero specifico di possibilità. In tal caso, il numero totale di combinazioni è dato dal prodotto delle possibilità offerte da ciascuna fase:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k .\n\\]\nEsempio\nSupponiamo di avere quattro urne contenenti palline di diverso colore:\n\n\nUrna A: 5 palline,\n\n\nUrna B: 6 palline,\n\n\nUrna C: 3 palline,\n\n\nUrna D: 2 palline.\n\nVogliamo formare insiemi di due palline, ciascuna estratta da urne differenti.\nSecondo il principio del prodotto, per ogni coppia di urne, il numero di combinazioni è dato dal prodotto del numero di palline contenute nelle due urne. Utilizziamo poi il principio della somma per ottenere il totale complessivo:\n\\[\nn_{\\text{tot}} = AB + AC + AD + BC + BD + CD.\n\\]\nCalcolo in R:\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n#&gt; [1] 91\n\nRisultato: È possibile formare 91 insiemi di due palline, ciascuna estratta da urne differenti.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.3 Il modello dell’urna e i metodi di campionamento",
    "text": "H.3 Il modello dell’urna e i metodi di campionamento\nMolti problemi di calcolo combinatorio possono essere interpretati come estrazioni di palline da un’urna. Esistono quattro modi fondamentali di effettuare un campionamento, a seconda che:\n\nle estrazioni siano con o senza ripetizione,\nl’ordine degli elementi conti o meno.\n\nQueste quattro combinazioni danno origine a quattro principali metodi di campionamento:\n\n\nCon ripetizione e con ordine: Dopo ogni estrazione, la pallina viene rimessa nell’urna. (Es. formazione di codici numerici con ripetizioni)\n\nSenza ripetizione e con ordine: Ogni estrazione rimuove definitivamente la pallina dall’urna. (Es. assegnare premi in una gara)\n\nCon ripetizione e senza ordine: Si considerano i gruppi di elementi senza preoccuparsi dell’ordine. (Es. selezionare un certo numero di ingredienti da una dispensa)\n\nSenza ripetizione e senza ordine: Si scelgono elementi distinti senza considerare l’ordine. (Es. formare squadre da un gruppo di persone)\n\n\nEsempio H.1  \n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\n# Con ripetizione e ordine\ncampionamento1 &lt;- expand.grid(urna, urna) |&gt;\n    rename(Elemento1 = Var1, Elemento2 = Var2)\n\n# Senza ripetizione e con ordine\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Con ripetizione e senza ordine\ncampionamento3 &lt;- combinations(\n    n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Senza ripetizione e senza ordine\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Risultati\nlist(\n    `Con ripetizione e ordine` = campionamento1,\n    `Senza ripetizione e con ordine` = campionamento2,\n    `Con ripetizione e senza ordine` = campionamento3,\n    `Senza ripetizione e senza ordine` = campionamento4\n)\n#&gt; $`Con ripetizione e ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         b         a\n#&gt; 3         c         a\n#&gt; 4         a         b\n#&gt; 5         b         b\n#&gt; 6         c         b\n#&gt; 7         a         c\n#&gt; 8         b         c\n#&gt; 9         c         c\n#&gt; \n#&gt; $`Senza ripetizione e con ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         a\n#&gt; 4         b         c\n#&gt; 5         c         a\n#&gt; 6         c         b\n#&gt; \n#&gt; $`Con ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         a         b\n#&gt; 3         a         c\n#&gt; 4         b         b\n#&gt; 5         b         c\n#&gt; 6         c         c\n#&gt; \n#&gt; $`Senza ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         c",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.4 Permutazioni: Disporre tutti gli elementi con ordine",
    "text": "H.4 Permutazioni: Disporre tutti gli elementi con ordine\nLe permutazioni rappresentano tutti i modi in cui è possibile ordinare \\(n\\) elementi distinti. Il numero di permutazioni è dato da:\n\\[\nP_n = n!\n\\]\ndove \\(n!\\) (n fattoriale) è il prodotto di tutti i numeri da 1 a \\(n\\):\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 1.\n\\]\n\nH.4.1 Intuizione della formula\nImmaginiamo di avere \\(n\\) elementi distinti e di doverli disporre in una sequenza. Il primo elemento può essere scelto in \\(n\\) modi. Una volta scelto il primo, rimangono \\(n-1\\) possibilità per il secondo, poi \\(n-2\\) per il terzo e così via, fino all’ultimo elemento, che avrà 1 sola possibilità. Applicando il principio del prodotto, otteniamo:\n\\[\nP_n = n \\times (n-1) \\times (n-2) \\times \\dots \\times 1 = n!\n\\]\n\nH.4.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a esaurire gli elementi.\n\n\nEsempio pratico: Ordinare i partecipanti di una gara su un podio (primo, secondo e terzo classificato).\n\nH.4.3 Esempio in R: Permutazioni di tre elementi\nSe abbiamo tre lettere {a, b, c}, le possibili permutazioni sono:\n\\[\nP_3 = 3! = 3 \\times 2 \\times 1 = 6.\n\\]\n\nA &lt;- c(\"a\", \"b\", \"c\")\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\nprint(perm)\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,] \"a\"  \"b\"  \"c\" \n#&gt; [2,] \"a\"  \"c\"  \"b\" \n#&gt; [3,] \"b\"  \"a\"  \"c\" \n#&gt; [4,] \"b\"  \"c\"  \"a\" \n#&gt; [5,] \"c\"  \"a\"  \"b\" \n#&gt; [6,] \"c\"  \"b\"  \"a\"\nnrow(perm)  # Verifica del numero di permutazioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b, c\\}, \\{a, c, b\\}, \\{b, a, c\\}, \\{b, c, a\\}, \\{c, a, b\\}, \\{c, b, a\\}.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.5 Disposizioni: Selezionare alcuni elementi con ordine",
    "text": "H.5 Disposizioni: Selezionare alcuni elementi con ordine\nLe disposizioni si usano quando si scelgono \\(k\\) elementi da un insieme di \\(n\\), rispettando l’ordine. Il numero totale di disposizioni è:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler scegliere solo \\(k\\) elementi, mantenendo l’ordine.\n\nil primo elemento può essere scelto in \\(n\\) modi;\nil secondo elemento può essere scelto tra gli \\(n-1\\) elementi rimanenti;\n\nil terzo tra gli \\(n-2\\) rimanenti.\n\nSi prosegue fino a quando si hanno scelto \\(k\\) elementi, fermandosi prima di esaurire tutti gli elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times (n-2) \\times \\dots \\times (n-k+1) .\n\\]\nQuesta espressione corrisponde alla divisione del fattoriale di \\(n\\) per il fattoriale degli elementi che non vengono selezionati:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a raggiungere il numero desiderato di elementi, fermandosi prima di esaurire tutti gli elementi.\n\n\nEsempio pratico: Estrarre casualmente 2 studenti da una classe di 10 e assegnare loro i ruoli di rappresentante e vice-rappresentante (l’ordine conta).\n\nH.5.3 Esempio in R: Disposizioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3, il numero di disposizioni è:\n\\[\nD_{3,2} = \\frac{3!}{(3-2)!} = \\frac{3 \\times 2 \\times 1}{1} = 6.\n\\]\n\ndisp &lt;- permutations(n = length(A), r = 2, v = A)\nprint(disp)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"a\" \n#&gt; [4,] \"b\"  \"c\" \n#&gt; [5,] \"c\"  \"a\" \n#&gt; [6,] \"c\"  \"b\"\nnrow(disp)  # Verifica del numero di disposizioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, a\\}, \\{b, c\\}, \\{c, a\\}, \\{c, b\\}.\n\\]\nLe disposizioni considerano l’ordine, quindi \\(\\{a, b\\}\\) è diverso da \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.6 Combinazioni: Selezionare alcuni elementi senza ordine",
    "text": "H.6 Combinazioni: Selezionare alcuni elementi senza ordine\nLe combinazioni rappresentano il numero di modi per scegliere \\(k\\) elementi da \\(n\\) senza considerare l’ordine. Il numero di combinazioni è dato da:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler selezionare \\(k\\) elementi senza considerare l’ordine.\nCome nel caso delle disposizioni, il primo elemento può essere scelto in \\(n\\) modi, il secondo in \\(n-1\\), e così via fino a selezionare \\(k\\) elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times \\dots \\times (n-k+1) .\n\\]\nTuttavia, in questo caso, l’ordine non conta, quindi ogni selezione viene duplicata per il numero di modi in cui i \\(k\\) elementi possono essere ordinati, ossia \\(k!\\) permutazioni interne. Per correggere questa duplicazione, dobbiamo dividere per \\(k!\\):\n\\[\nC_{n,k} = \\frac{D_{n,k}}{k!} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e senza ordine: si estrae una pallina e la si esclude dall’urna, ma non importa l’ordine in cui le palline vengono estratte.\n\n\nEsempio pratico: Formare una squadra di 2 studenti da un gruppo di 10 senza assegnare ruoli specifici (quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\)).\n\nH.6.3 Esempio in R: Combinazioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3 senza considerare l’ordine, otteniamo:\n\\[\nC_{3,2} = \\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3 \\times 2 \\times 1}{2 \\times 1 \\times 1} = 3.\n\\]\n\ncomb &lt;- combinations(n = length(A), r = 2, v = A)\nprint(comb)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"c\"\nnrow(comb)  # Verifica del numero di combinazioni\n#&gt; [1] 3\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, c\\}.\n\\]\nLe combinazioni non considerano l’ordine, quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "href": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.7 Sintesi: Quando usare ciascun metodo?",
    "text": "H.7 Sintesi: Quando usare ciascun metodo?\n\n\n\n\n\n\n\n\n\nMetodo\nRipetizione?\nOrdine?\nFormula\nMetodo di campionamento\n\n\n\nPermutazioni\n❌ No\n✅ Sì\n\\(n!\\)\nSenza ripetizione e con ordine\n\n\nDisposizioni\n❌ No\n✅ Sì\n\\(\\frac{n!}{(n-k)!}\\)\nSenza ripetizione e con ordine\n\n\nCombinazioni\n❌ No\n❌ No\n\\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\)\nSenza ripetizione e senza ordine\n\n\n\nIn conclusione, abbiamo visto come il modello dell’urna aiuti a comprendere i problemi combinatori. Le differenze tra permutazioni, disposizioni e combinazioni dipendono da due fattori fondamentali: ripetizione e ordine.\nQuesta classificazione è essenziale per risolvere problemi di probabilità e statistica in modo rigoroso. Gli esempi e il codice R forniscono strumenti concreti per applicare questi concetti nella pratica.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "I.1 Integrali\nIn questo capitolo, traduciamo e adattiamo il capitolo Per liberarvi dai terrori preliminari tratto da Calculus made easy.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Il terrore preliminare, che spesso impedisce agli studenti di avvicinarsi all’analisi matematica, può essere superato comprendendo il significato intuitivo dei due simboli principali utilizzati in questo campo.\nQuesti simboli, che possono sembrare intimidatori, sono in realtà molto semplici:\n\n\\(d\\): Questo simbolo significa semplicemente “un po’ di”. Ad esempio, \\(\\operatorname{d}\\!x\\) indica un piccolo incremento di \\(x\\), mentre \\(\\operatorname{d}\\!u\\) rappresenta un piccolo incremento di \\(u\\). I matematici preferiscono dire “un elemento di” invece di “un po’ di”, ma il concetto è lo stesso. Questi piccoli incrementi possono essere considerati infinitamente piccoli.\n\\(\\int\\): Questo simbolo è una S allungata e rappresenta “la somma di”. Quindi, \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i piccoli incrementi di \\(x\\), mentre \\(\\int \\operatorname{d}\\!t\\) indica la somma di tutti i piccoli incrementi di \\(t\\). I matematici chiamano questo simbolo “integrale”. Se consideri \\(x\\) come composto da tanti piccoli pezzi \\(\\operatorname{d}\\!x\\), sommandoli tutti otterrai l’intero valore di \\(x\\). La parola “integrale” significa semplicemente “il tutto”. Ad esempio, se pensi a un’ora come composta da 3600 secondi, la somma di tutti questi secondi ti darà un’ora. Quando vedi un’espressione che inizia con \\(\\int\\), significa che devi sommare tutti i piccoli pezzi indicati dai simboli che seguono.\n\nEcco, il terrore è svanito!\n\n\n\n\nI.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l’integrale di una funzione di densità, possiamo utilizzare il linguaggio di programmazione R. Consideriamo come esempio la funzione di densità gaussiana, definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R, possiamo definire questa funzione come segue:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densità su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione utilizzando il pacchetto ggplot2:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densità gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l’integrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito dalla funzione integrate di R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l’area sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell’area nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l’area sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell’area totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l’integrale di una funzione di densità in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l’obiettivo è calcolare l’area sotto la curva, che corrisponde all’integrale della funzione di densità.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#potenze",
    "href": "chapters/appendix/a15_calculus.html#potenze",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "\nI.2 Potenze",
    "text": "I.2 Potenze\nLe potenze sono un’operazione matematica che rappresenta un prodotto ripetuto. Si indicano generalmente come:\n\\[\na^n,\n\\]\ndove:\n\n\n\\(a\\) è la base,\n\n\\(n\\) è l’esponente.\n\nLa potenza rappresenta il prodotto della base \\(a\\) ripetuto \\(n\\) volte.\n\nI.2.1 Definizione di potenza\n\\[\na^n = \\underbrace{a \\cdot a \\cdot \\dots \\cdot a}_{n \\text{ fattori}} \\quad \\text{con } n \\in \\mathbb{N}.\n\\]\nAd esempio:\n\n\n\\(2^3 = 2 \\cdot 2 \\cdot 2 = 8\\),\n\n\\(3^4 = 3 \\cdot 3 \\cdot 3 \\cdot 3 = 81\\).\n\n\nI.2.2 Proprietà delle potenze\n\n\nMoltiplicazione di potenze con la stessa base:\n\\[\na^m \\cdot a^n = a^{m+n}\n\\]\nEsempio: \\(2^3 \\cdot 2^2 = 2^{3+2} = 2^5 = 32\\).\n\n\nDivisione di potenze con la stessa base:\n\\[\n\\frac{a^m}{a^n} = a^{m-n}, \\quad \\text{con } m \\geq n.\n\\]\nEsempio: \\(\\frac{5^4}{5^2} = 5^{4-2} = 5^2 = 25\\).\n\n\nPotenze di potenze:\n\\[\n(a^m)^n = a^{m \\cdot n}.\n\\]\nEsempio: \\((3^2)^3 = 3^{2 \\cdot 3} = 3^6 = 729\\).\n\n\nProdotto di potenze con basi diverse ma lo stesso esponente:\n\\[\na^n \\cdot b^n = (a \\cdot b)^n.\n\\]\nEsempio: \\(2^3 \\cdot 3^3 = (2 \\cdot 3)^3 = 6^3 = 216\\).\n\n\nDivisione di potenze con basi diverse ma lo stesso esponente:\n\\[\n\\frac{a^n}{b^n} = \\left(\\frac{a}{b}\\right)^n.\n\\]\nEsempio: \\(\\frac{4^2}{2^2} = \\left(\\frac{4}{2}\\right)^2 = 2^2 = 4\\).\n\n\nEsponente zero:\n\\[\na^0 = 1, \\quad \\text{con } a \\neq 0.\n\\]\nEsempio: \\(5^0 = 1\\).\n\n\nEsponente negativo:\n\\[\na^{-n} = \\frac{1}{a^n}.\n\\]\nEsempio: \\(2^{-3} = \\frac{1}{2^3} = \\frac{1}{8}\\).\n\n\nRadice come potenza frazionaria:\n\\[\na^{\\frac{1}{n}} = \\sqrt[n]{a}, \\quad a^{\\frac{m}{n}} = \\sqrt[n]{a^m}.\n\\]\nEsempio: \\(8^{\\frac{1}{3}} = \\sqrt[3]{8} = 2\\).\n\n\n\nI.2.3 Esempi pratici\n\n\nCalcolo semplice:\n\\[\n4^3 = 4 \\cdot 4 \\cdot 4 = 64.\n\\]\n\n\nUtilizzo delle proprietà:\n\\[\n3^5 \\cdot 3^2 = 3^{5+2} = 3^7 = 2187.\n\\]\n\n\nDivisione:\n\\[\n\\frac{6^4}{6^2} = 6^{4-2} = 6^2 = 36.\n\\]\n\n\nEsponente negativo:\n\\[\n10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01.\n\\]\n\n\nRadice come potenza:\n\\[\n16^{\\frac{1}{2}} = \\sqrt{16} = 4.\n\\]\n\n\n\nI.2.4 Nota sui numeri razionali e reali\n\nLe potenze con esponenti interi sono definite per ogni base.\nLe potenze con esponenti frazionari o reali richiedono che la base sia positiva per evitare ambiguità.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "\nI.3 Logaritmi",
    "text": "I.3 Logaritmi\nIl logaritmo è una funzione matematica che risponde alla domanda: “quante volte devo moltiplicare un certo numero (chiamato”base”) per ottenere un altro numero?” Matematicamente, questo è espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perché \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano più grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo è utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si può vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle proprietà più utili dei logaritmi è che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta proprietà è estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilità potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn’altra proprietà utile dei logaritmi è che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa proprietà è molto utilizzata in matematica, specialmente in situazioni in cui è necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare più agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli più gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html",
    "href": "chapters/appendix/a35_other_conjugate_families.html",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "",
    "text": "Panoramica del capitolo\nNei capitoli precedenti abbiamo visto come il concetto di coniugazione renda particolarmente semplice l’aggiornamento bayesiano. L’esempio Beta–Binomiale ci ha permesso di osservare in modo diretto come i parametri della distribuzione vengano modificati dai dati senza cambiare la forma della distribuzione stessa.\nIn questa appendice presentiamo altri casi di famiglie coniugate, meno immediati ma ugualmente interessanti. L’obiettivo non è memorizzare formule o cataloghi di distribuzioni, ma cogliere un principio generale: in alcune situazioni fortunate, i calcoli bayesiani diventano particolarmente trasparenti, perché il posterior appartiene alla stessa famiglia della prior.\nDal punto di vista della ricerca psicologica, non è indispensabile padroneggiare tutti questi casi. Nella pratica, la maggior parte dei modelli che incontreremo non ammetterà una forma coniugata, e dovremo ricorrere a metodi computazionali generali come il campionamento MCMC. Tuttavia, conoscere queste famiglie ha due vantaggi didattici:\nSe è la prima volta che affronti questi argomenti, puoi leggere questa sezione in modo rapido, come un approfondimento facoltativo. Nei capitoli successivi torneremo a concentrarci sui metodi computazionali, che costituiscono lo strumento essenziale per affrontare i problemi psicologici reali.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html#panoramica-del-capitolo",
    "href": "chapters/appendix/a35_other_conjugate_families.html#panoramica-del-capitolo",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "",
    "text": "Introdurre il modello Normale-Normale come esempio di famiglia coniugata.\nMostrare come combinare prior e verosimiglianza per ottenere la distribuzione a posteriori.\n\nCalcolare media e varianza a posteriori in forma chiusa.\nInterpretare il ruolo relativo di prior e dati nell’aggiornamento bayesiano.\n\nApplicare il modello a casi concreti (tempi di reazione, punteggi di QI).\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il capitolo Conjugate Families del testo di Johnson et al. (2022).\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt;\n    source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(mice)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html#perché-scegliere-una-distribuzione-normale",
    "href": "chapters/appendix/a35_other_conjugate_families.html#perché-scegliere-una-distribuzione-normale",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "\nJ.1 Perché scegliere una distribuzione normale?",
    "text": "J.1 Perché scegliere una distribuzione normale?\nLa scelta di una distribuzione a priori (e di una verosimiglianza) Normale offre numerosi vantaggi, sia dal punto di vista teorico che pratico:\n\nSimmetria e Adattabilità: La caratteristica forma “a campana” e simmetrica della distribuzione Normale ben si adatta a descrivere molti fenomeni naturali, psicologici e cognitivi, come i tempi di reazione, i punteggi di abilità, o gli errori di misurazione. Questa simmetria facilita l’interpretazione della media \\(\\mu\\) come misura di tendenza centrale e della varianza \\(\\sigma^2\\) come misura della dispersione o incertezza.\nEfficienza Parametrica: Nel modello Normale-Normale con varianza nota, l’incertezza sulla media \\(\\mu\\) nella distribuzione a priori è descritta dal singolo parametro \\(\\sigma_0^2\\) (la varianza della prior). Analogamente, la variabilità dei dati è descritta da \\(\\sigma^2\\). Questa parsimonia parametrica semplifica sia la fase di modellizzazione sia la comunicazione dei risultati.\nConvergenza con l’Inferenza Classica: Per campioni di dati sufficientemente ampi, le stime bayesiane ottenute con il modello Normale tendono a convergere verso quelle dell’inferenza frequentista. Questa proprietà, legata al teorema di Bernstein-von Mises, è talvolta indicata come calibrazione asintotica e fa sì che il modello Normale-Normale possa agire da ponte tra i due paradigmi inferenziali.\nSemplicità Computazionale: Le operazioni matematiche tra distribuzioni Normali (come il prodotto richiesto dal teorema di Bayes) risultano in un’altra distribuzione Normale. Questo permette di ottenere soluzioni analitiche in forma chiusa per i parametri della distribuzione a posteriori, evitando la necessità di ricorrere a metodi di approssimazione numerica complessi, come le simulazioni Monte Carlo Markov Chain (MCMC), almeno nei casi più semplici.\n\nIn sintesi: se le nostre conoscenze preliminari suggeriscono una distribuzione unimodale e simmetrica per il parametro di interesse, o se ci aspettiamo che la distribuzione a posteriori abbia tali caratteristiche (cosa spesso favorita dal Teorema del Limite Centrale quando si ha un campione ampio), la distribuzione Normale rappresenta una scelta robusta, elegante e computazionalmente vantaggiosa per condurre un’inferenza rigorosa.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html#inferenza-bayesiana-per-la-media-di-una-popolazione-normale-varianza-nota",
    "href": "chapters/appendix/a35_other_conjugate_families.html#inferenza-bayesiana-per-la-media-di-una-popolazione-normale-varianza-nota",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "\nJ.2 Inferenza bayesiana per la media di una popolazione normale (varianza nota)",
    "text": "J.2 Inferenza bayesiana per la media di una popolazione normale (varianza nota)\nImmaginiamo di voler stimare il tempo medio di reazione \\(\\mu\\) (in millisecondi, ms) di una popolazione di studenti impegnati in un compito Stroop. Supponiamo di aver raccolto i tempi di reazione \\(y_1, \\dots, y_n\\) da un campione di \\(n\\) studenti. Assumiamo che questi dati provengano da una distribuzione Normale \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) e, per semplificare inizialmente il modello, assumiamo che la varianza \\(\\sigma^2\\) della popolazione sia nota (ad esempio, da studi precedenti o dalla natura standardizzata del compito). Sia \\(\\sigma = 50\\) ms la deviazione standard nota.\n\nJ.2.1 I tre passi fondamentali dell’inferenza bayesiana\nIl processo di inferenza bayesiana si articola nei seguenti passaggi chiave:\n\n\n\n\n\n\n\nPasso\nSignificato Intuitivo\nFormalizzazione Matematica (Modello Normale-Normale)\n\n\n\nA. Distribuzione a Priori\nLe nostre convinzioni iniziali sulla media \\(\\mu\\).\n\\(\\mu \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)\\)\n\n\nB. Verosimiglianza dei Dati\nL’informazione su \\(\\mu\\) contenuta nei dati osservati.\n\\(y_i \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\nC. Distribuzione a Posteriori\nLe nostre convinzioni aggiornate su \\(\\mu\\) dopo i dati.\n\\(\\mu \\mid \\mathbf{y} \\sim \\mathcal{N}(\\mu_p, \\sigma_p^2)\\)\n\n\n\nQuando la varianza \\(\\sigma^2\\) dei dati è nota e la prior per \\(\\mu\\) è Normale, la distribuzione Normale è coniugata per la media \\(\\mu\\). Ciò significa che la distribuzione a posteriori per \\(\\mu\\) sarà anch’essa Normale, mantenendo la stessa forma funzionale attraverso l’aggiornamento bayesiano.\n\nJ.2.2 Distribuzione a priori\n\\(\\mu \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)\\): descrive dove crediamo sia \\(\\mu\\) e quanta incertezza abbiamo, una varianza grande significa poca informazione.\n\nJ.2.3 Verosimiglianza\n\\[\np(y\\mid\\mu,\\sigma)=\\prod_{i=1}^{n}\\frac{1}{\\sigma\\sqrt{2\\pi}}\n                  \\exp\\!\\Bigl[-\\tfrac{(y_i-\\mu)^2}{2\\sigma^2}\\Bigr].\n\\]\n\nJ.2.4 Teorema di Bayes\nIl teorema di Bayes combina prior e verosimiglianza attraverso un prodotto ponderato:\n\\[\np(\\mu\\mid y)=\\frac{p(y\\mid\\mu)\\,p(\\mu)}{p(y)} \\;\\; \\propto\\;\\;\n\\underbrace{\\mathcal{N}(\\mu_0,\\sigma_0^2)}_{\\text{prior}}\n\\; \\times \\;\n\\underbrace{\\mathcal{N}(\\bar y,\\sigma^2/n)}_{\\text{verosimiglianza}} .\n\\] Il prodotto di due distribuzioni gaussiane è una distribuzione gaussiana: basta aggiornare media e varianza.\n\nJ.2.5 Media a posteriori\n\\[\n\\mu_p=\\frac{\\tfrac{1}{\\sigma_0^2}\\,\\mu_0 + \\tfrac{n}{\\sigma^2}\\,\\bar y}\n           {\\tfrac{1}{\\sigma_0^2} + \\tfrac{n}{\\sigma^2}},\n\\qquad\n\\bar y=\\frac{1}{n}\\sum_{i=1}^{n}y_i.\n\\tag{J.1}\\]\n\n\\(\\mu_0\\): l’idea iniziale.\n\\(\\sigma_0^2\\): la fiducia in quell’idea.\n\\(\\bar y\\): ciò che dicono i dati.\n\\(n/\\sigma^2\\): la quantità di informazione empirica, aumenta con più casi e diminuisce con misure rumorose.\n\nInterpretazione: Il peso relativo di prior e dati dipende dalla loro credibilità:\n\nLa prior è influente se ha alta precisione, ovvero 1/\\(\\sigma_0^2\\) è grande, o se ci sono pochi dati, \\(n\\) piccolo.\nI dati sono dominanti se la prior ha bassa precisione o se c’è un ampio campione.\n\n\n\nJ.2.6 Varianza a posteriori\n\\[\n\\sigma_p^2=\\frac{1}{\\tfrac{1}{\\sigma_0^2}+\\tfrac{n}{\\sigma^2}}.\n\\tag{J.2}\\]\n\n\nProprietà Chiave: \\(\\sigma_p^2 \\le \\min(\\sigma_0^2, \\sigma^2/n)\\). L’incertezza diminuisce monotonicamente all’aumentare di \\(n\\).\n\n\n\n\n\n\n\nEsercizio 1.\n\n\n\n\n\nSupponiamo di voler stimare il tempo medio di reazione \\(\\mu\\) (in millisecondi) di un gruppo di studenti a un compito Stroop. Dalla letteratura o da esperienze precedenti, assumiamo che la deviazione standard dei tempi di reazione per questo tipo di compito sia \\(\\sigma = 50\\) ms.\nDefiniamo la nostra distribuzione a priori per \\(\\mu\\) basandoci su una nostra conoscenza preliminare o un’ipotesi plausibile. Ad esempio, potremmo ipotizzare che il tempo medio sia attorno ai 500 ms, con una certa incertezza: * Media a priori: \\(\\mu_0 = 500\\) ms * Deviazione standard a priori: \\(\\sigma_0 = 100\\) ms (quindi varianza a priori \\(\\sigma_0^2 = 100^2 = 10000\\))\nSuccessivamente, raccogliamo i dati da \\(n=20\\) studenti e osserviamo una media campionaria dei tempi di reazione \\(\\bar{y} = 480\\) ms.\nRiepilogo dei parametri:\n\n\nSimbolo\nDescrizione\nValore\n\n\n\n\\(\\mu_0\\)\nMedia a priori\n500 ms\n\n\n\\(\\sigma_0\\)\nDev. std. a priori\n100 ms\n\n\n\\(\\sigma_0^2\\)\nVarianza a priori\n10000 ms²\n\n\n\\(\\sigma\\)\nDev. std. dei dati (nota)\n50 ms\n\n\n\\(\\sigma^2\\)\nVarianza dei dati (nota)\n2500 ms²\n\n\n\\(n\\)\nNumero di osservazioni\n20\n\n\n\\(\\bar{y}\\)\nMedia campionaria osservata\n480 ms\n\n\n\n1. Calcolo delle Precisioni (Pesi):\n\nPrecisione a priori: \\(w_0 = \\frac{1}{\\sigma_0^2} = \\frac{1}{100^2} = \\frac{1}{10000} = 0.0001\\)\n\nPrecisione dei dati: \\(w_{\\text{dati}} = \\frac{n}{\\sigma^2} = \\frac{20}{50^2} = \\frac{20}{2500} = 0.008\\)\n\n\n2. Calcolo della Media a Posteriori (\\(\\mu_n\\)): \\[ \\mu_n = \\frac{w_0 \\mu_0 + w_{\\text{dati}} \\bar{y}}{w_0 + w_{\\text{dati}}} = \\frac{0.0001 \\times 500 + 0.008 \\times 480}{0.0001 + 0.008} = \\frac{0.05 + 3.84}{0.0081} = \\frac{3.89}{0.0081} \\approx 480.247 \\text{ ms} \\]\n3. Calcolo della Varianza a Posteriori (\\(\\sigma_n^2\\)): \\[ \\sigma_n^2 = \\frac{1}{w_0 + w_{\\text{dati}}} = \\frac{1}{0.0001 + 0.008} = \\frac{1}{0.0081} \\approx 123.457 \\text{ ms}^2 \\] La deviazione standard a posteriori è \\(\\sigma_n = \\sqrt{\\sigma_n^2} \\approx \\sqrt{123.457} \\approx 11.11 \\text{ ms}\\).\nRisultato e Interpretazione: Siamo partiti da una stima a priori di \\(\\mu \\approx 500 \\pm 100\\) ms. Dopo aver osservato 20 tempi di reazione con una media di 480 ms (e sapendo che \\(\\sigma=50\\) ms), la nostra stima aggiornata per la media dei tempi di reazione è \\(\\mu_n \\approx 480.25 \\pm 11.11\\) ms. Notiamo che la media a posteriori (480.25 ms) è molto più vicina alla media campionaria (480 ms) che alla media a priori (500 ms). Questo perché la precisione dei dati (0.008) è significativamente maggiore della precisione a priori (0.0001). Inoltre, la nostra incertezza si è drasticamente ridotta: la deviazione standard è passata da 100 ms a circa 11 ms dopo sole 20 osservazioni. Questo illustra il potere dell’aggiornamento bayesiano nel raffinare le nostre stime e ridurre l’incertezza.\n\n# ---- Parametri dell'esempio -------------------------------------------\nmu0    &lt;- 500   # Media a priori\nsigma0 &lt;- 100   # Deviazione standard a priori\nsigma  &lt;- 50    # Deviazione standard nota dei dati\nn      &lt;- 20    # Dimensione del campione\nybar   &lt;- 480   # Media campionaria osservata\n\n# ---- Calcolo dei parametri a posteriori -------------------------------\n# Precisioni\nprec_prior &lt;- 1 / sigma0^2\nprec_data  &lt;- n / sigma^2\n\n# Parametri posteriori\nsigma_p2 &lt;- 1 / (prec_prior + prec_data)  # Varianza a posteriori\nsigma_p  &lt;- sqrt(sigma_p2)                # Deviazione standard a posteriori\nmu_p     &lt;- (mu0 * prec_prior + ybar * prec_data) / (prec_prior + prec_data) # Media a posteriori\n\n# ---- Griglia di valori per il parametro mu -----------------------------\n# Definiamo un range che copra bene tutte e tre le distribuzioni\nmin_mu &lt;- min(mu0 - 3*sigma0, ybar - 3*sigma/sqrt(n), mu_p - 3*sigma_p)\nmax_mu &lt;- max(mu0 + 3*sigma0, ybar + 3*sigma/sqrt(n), mu_p + 3*sigma_p)\nmu_grid &lt;- seq(min_mu, max_mu, length.out = 1000)\n\n# ---- Calcolo delle densità delle tre curve -----------------------------\nprior_dens &lt;- dnorm(mu_grid, mean = mu0,  sd = sigma0)            # Densità a priori\npost_dens  &lt;- dnorm(mu_grid, mean = mu_p, sd = sigma_p)           # Densità a posteriori\n\n# Verosimiglianza (standardizzata per mu, basata sulla media campionaria)\n# La sd per la verosimiglianza di mu è sigma/sqrt(n)\nlik_dens_raw &lt;- dnorm(mu_grid, mean = ybar, sd = sigma / sqrt(n))\n# Riscaliamo la verosimiglianza per renderla graficamente confrontabile con la prior\n# Questo è solo per visualizzazione, la verosimiglianza non è una densità per mu in senso stretto\nlik_dens_scaled &lt;- lik_dens_raw * (max(prior_dens) / max(lik_dens_raw))\n\n# ---- Preparazione dati in formato \"lungo\" per ggplot2 ------------------\ndf &lt;- data.frame(\n  mu         = mu_grid,\n  Prior      = prior_dens,\n  Likelihood_scaled = lik_dens_scaled, # Usiamo quella riscalata\n  Posterior  = post_dens\n)\n\ndf_long &lt;- pivot_longer(df, -mu, names_to = \"Distribuzione\", values_to = \"Densita\")\ndf_long$Distribuzione &lt;- factor(df_long$Distribuzione, \n                                levels = c(\"Prior\", \"Likelihood_scaled\", \"Posterior\"),\n                                labels = c(\"A Priori\", \"Verosimiglianza (riscalata)\", \"A Posteriori\"))\n\n\n# ---- Grafico delle distribuzioni ---------------------------------------\nggplot(df_long, aes(x = mu, y = Densita, colour = Distribuzione)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x      = expression(paste(\"Media dei Tempi di Reazione \", mu, \" (ms)\")),\n    y      = \"Densità\",\n    title  = \"Aggiornamento Bayesiano: dal Prior al Posteriori\",\n    subtitle = paste0(\"Prior: N(\", mu0, \", \", sigma0^2, \"), \",\n                      \"Verosimiglianza (per μ): N(\", ybar, \", \", round((sigma^2/n),2), \"), \",\n                      \"Posteriori: N(\", round(mu_p,2), \", \", round(sigma_p2,2), \")\")\n  ) +\n  scale_color_manual(values = c(\"A Priori\" = \"dodgerblue\", \n                                \"Verosimiglianza (riscalata)\" = \"forestgreen\", \n                                \"A Posteriori\" = \"orangered\")) +\n  theme(legend.title = element_blank(), legend.position = \"top\")\n\n\n\n\n\n\nFigura J.1: Distribuzioni a priori, verosimiglianza (standardizzata e riscalata) e a posteriori per la media dei tempi di reazione (μ).\n\n\n\n\nIl grafico Figura J.1 illustra chiaramente come la distribuzione a posteriori sia “spostata” verso la verosimiglianza (che è più informativa della prior in questo caso) e come la sua varianza sia notevolmente ridotta rispetto a entrambe.\n\n\n\n\n\n\n\n\n\nMessaggi chiave sull’inferenza con varianza nota\n\n\n\n\nDialogo Costruttivo: L’inferenza bayesiana è un processo dinamico di dialogo tra le nostre ipotesi iniziali (prior) e l’evidenza empirica (dati/verosimiglianza).\nCalcoli Trasparenti: Con la varianza della popolazione \\(\\sigma^2\\) nota, i calcoli per la media e la varianza a posteriori sono diretti e possono essere eseguiti analiticamente (anche “a mano” per esempi semplici).\nRiduzione Garantita dell’Incertezza: Dopo aver osservato i dati, l’incertezza sul parametro (misurata dalla varianza a posteriori) non può che diminuire o, al limite, rimanere uguale (caso teorico di dati non informativi), rispetto alla varianza a priori.\nPeso dell’Evidenza: Con pochi dati o dati molto “rumorosi” (alta \\(\\sigma^2\\)), la distribuzione a priori esercita un’influenza maggiore sulla stima finale. Con molti dati o dati molto precisi (bassa \\(\\sigma^2\\)), l’informazione proveniente dai dati tende a dominare, e l’influenza della prior sulla stima a posteriori diminuisce.\nApplicabilità Vasta: Lo schema concettuale e matematico del modello Normale-Normale si applica a una vasta gamma di problemi in diverse discipline, inclusa la psicologia sperimentale (es. tempi di reazione, punteggi a test, ampiezze di segnali EEG), l’ingegneria, l’economia, e molte altre aree dove si misurano quantità continue. :::\n\n\n\n\n\n\n\n\n\nEsercizio 2.\n\n\n\n\n\nI test standard di Quoziente Intellettivo (QI) sono generalmente calibrati per avere una media di 100 e una deviazione standard di 15 nella popolazione di riferimento. Tuttavia, sono state sollevate questioni riguardo a possibili bias culturali che potrebbero favorire alcuni gruppi rispetto ad altri. Un’ulteriore complicazione sorge quando i punteggi QI vengono aggregati a livello nazionale, poiché le medie nazionali possono mascherare eterogeneità intra-paese significative.\nQuesto esempio, ispirato da Gill (2015) (che discute i dati di Lynn e Vanhanen, 2001), analizza i dati di QI medio riportati per 80 nazioni. L’obiettivo è stimare un QI medio “globale” \\(\\mu\\) utilizzando un approccio bayesiano Normale-Normale, e riflettere criticamente sul risultato.\nAssumiamo una deviazione standard nota \\(\\sigma = 15\\) per i punteggi QI (questa è una semplificazione, poiché la variabilità delle medie nazionali potrebbe essere diversa dalla variabilità individuale).\nI dati di QI medio per \\(n=80\\) nazioni sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImpostazione del Modello Bayesiano:\n\nPrior per \\(\\mu\\): Stabiliamo una prior basata sulla standardizzazione tipica dei test QI:\n\n\n\n\\(\\mu_0 = 100\\) (media a priori)\n\n\\(\\sigma_0 = 15\\) (deviazione standard a priori, che riflette una certa incertezza sulla media globale, o la stessa scala della \\(\\sigma\\) individuale). Quindi, \\(\\mu \\sim \\mathcal{N}(100, 15^2)\\).\n\n\nVerosimiglianza: Ogni QI nazionale \\(y_i\\) è considerato come un’osservazione della media “vera” \\(\\mu\\) con varianza \\(\\sigma^2 = 15^2\\). La media campionaria dei QI nazionali sarà \\(\\bar{y}\\).\n\n(Nota: Questa è una semplificazione. Idealmente, ogni \\(y_i\\) è già una media, e dovremmo considerare la sua precisione \\(N_i/\\sigma^2\\) se \\(N_i\\) fosse la dimensione del campione per quella nazione. Qui, trattiamo ogni media nazionale come un singolo dato \\(y_i\\) proveniente da \\(\\mathcal{N}(\\mu, \\sigma^2)\\)).\nImplementiamo le informazioni necessarie in R.\n\n# Dati IQ delle 80 nazioni (valori aggregati per paese)\niq &lt;- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, \n  87, 98, 87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, \n  90, 96, 98, 102, 78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, \n  89, 72, 101, 91, 100, 100, 66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, \n  67, 86\n) # Dati da Lynn e Vanhanen (2001) come presentati in Gill (2015)\n\n# Numero di osservazioni (nazioni)\nn &lt;- length(iq)\n\n# Media campionaria dei QI nazionali\ny_bar &lt;- mean(iq)\n\n# Deviazione standard assunta nota (per la \"popolazione\" da cui provengono le medie nazionali)\nsigma &lt;- 15\n\n# Parametri a priori\nmu_0 &lt;- 100    # Media a priori\nsigma_0 &lt;- 15  # Dev. std. a priori\n\ncat(paste(\"Numero di nazioni (n):\", n))\n#&gt; Numero di nazioni (n): 72\ncat(paste(\"\\nMedia campionaria dei QI nazionali (y_bar):\", round(y_bar, 2)))\n#&gt; \n#&gt; Media campionaria dei QI nazionali (y_bar): 89.21\n\nCalcolo dei parametri a posteriori:\nUtilizziamo le formule derivate precedentemente:\n\\[\\mu_n = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\n\\[\n\\sigma_n^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\n# Precisioni\nprec_prior_iq &lt;- 1 / sigma_0^2\nprec_data_iq  &lt;- n / sigma^2\n\n# Parametri posteriori\nmu_p_iq     &lt;- (mu_0 * prec_prior_iq + y_bar * prec_data_iq) / (prec_prior_iq + prec_data_iq)\nsigma_p_sq_iq &lt;- 1 / (prec_prior_iq + prec_data_iq)\nsigma_p_iq    &lt;- sqrt(sigma_p_sq_iq)\n\ncat(paste(\"Media a posteriori (mu_n):\", round(mu_p_iq, 2)))\n#&gt; Media a posteriori (mu_n): 89.36\ncat(paste(\"\\nVarianza a posteriori (sigma_n^2):\", round(sigma_p_sq_iq, 2)))\n#&gt; \n#&gt; Varianza a posteriori (sigma_n^2): 3.08\ncat(paste(\"\\nDeviazione standard a posteriori (sigma_n):\", round(sigma_p_iq, 2)))\n#&gt; \n#&gt; Deviazione standard a posteriori (sigma_n): 1.76\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\n# Definizione dei valori sull'asse x per il grafico della posteriori\nx_qi &lt;- seq(mu_p_iq - 4 * sigma_p_iq, mu_p_iq + 4 * sigma_p_iq, length.out = 1000)\n\n# Calcolo della densità di probabilità per la posteriori\npdf_qi &lt;- dnorm(x_qi, mean = mu_p_iq, sd = sigma_p_iq)\n\n# Creazione del grafico\nggplot(data.frame(x = x_qi, pdf = pdf_qi), aes(x = x, y = pdf)) +\n  geom_line(color = \"darkslateblue\", linewidth = 1.2) +\n  geom_area(fill = \"darkslateblue\", alpha = 0.3) +\n  labs(\n    x = \"Media 'Globale' del Quoziente di Intelligenza (μ)\",\n    y = \"Densità di Probabilità\",\n    title = \"Distribuzione a Posteriori del QI Medio Globale\",\n    subtitle = paste0(\"Posteriori: N(\", round(mu_p_iq, 2), \", \", round(sigma_p_sq_iq, 2), \")\")\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\nFigura J.2: Distribuzione a posteriori per la media ‘globale’ del QI (μ), basata sui dati di 80 nazioni.\n\n\n\n\nPer completezza, visualizziamo anche prior, likelihood e posterior:\n\nmu_grid_iq &lt;- seq(min(mu_0 - 3 * sigma_0, y_bar - 3 * sigma / sqrt(n), mu_p_iq - 3 * sigma_p_iq),\n  max(mu_0 + 3 * sigma_0, y_bar + 3 * sigma / sqrt(n), mu_p_iq + 3 * sigma_p_iq),\n  length.out = 1000\n)\n\nprior_dens_iq &lt;- dnorm(mu_grid_iq, mean = mu_0, sd = sigma_0)\nlik_dens_raw_iq &lt;- dnorm(mu_grid_iq, mean = y_bar, sd = sigma / sqrt(n)) # SD della media campionaria\nlik_dens_scaled_iq &lt;- lik_dens_raw_iq * (max(prior_dens_iq) / max(lik_dens_raw_iq, na.rm = TRUE)) # Scalata\npost_dens_iq &lt;- dnorm(mu_grid_iq, mean = mu_p_iq, sd = sigma_p_iq)\n\ndf_iq &lt;- data.frame(\n  mu = mu_grid_iq,\n  Prior = prior_dens_iq,\n  Likelihood_scaled = lik_dens_scaled_iq,\n  Posterior = post_dens_iq\n)\n\ndf_long_iq &lt;- pivot_longer(df_iq, -mu, names_to = \"Distribuzione\", values_to = \"Densita\")\ndf_long_iq$Distribuzione &lt;- factor(df_long_iq$Distribuzione,\n  levels = c(\"Prior\", \"Likelihood_scaled\", \"Posterior\"),\n  labels = c(\"A Priori\", \"Verosimiglianza (riscalata)\", \"A Posteriori\")\n)\n\nggplot(df_long_iq, aes(x = mu, y = Densita, colour = Distribuzione)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(paste(\"Media QI \", mu)),\n    y = \"Densità\",\n    title = \"Aggiornamento Bayesiano per il QI Medio 'Globale'\",\n    subtitle = paste0(\n      \"Prior: N(\", mu_0, \", \", sigma_0^2, \"), \",\n      \"Verosimiglianza (per μ): N(\", round(y_bar, 2), \", \", round((sigma^2 / n), 2), \"), \",\n      \"Posteriori: N(\", round(mu_p_iq, 2), \", \", round(sigma_p_sq_iq, 2), \")\"\n    )\n  ) +\n  scale_color_manual(values = c(\n    \"A Priori\" = \"dodgerblue\",\n    \"Verosimiglianza (riscalata)\" = \"forestgreen\",\n    \"A Posteriori\" = \"orangered\"\n  )) +\n  theme(legend.title = element_blank(), legend.position = \"top\")\n\n\n\n\n\n\n\nDiscussione critica dei risultati\nL’analisi bayesiana ha prodotto una media a posteriori per il QI “globale” di \\(\\mu_n \\approx 89.36\\), con una deviazione standard a posteriori molto piccola (\\(\\sigma_n \\approx 1.66\\)). Questo valore è notevolmente inferiore alla media standard di 100.\nTuttavia, è cruciale interpretare questo risultato con estrema cautela, considerando diversi fattori limitanti e criticità:\n\n\nEffetto di Aggregazione (Ecological Fallacy): La media a posteriori è calcolata aggregando i dati QI medi di 80 nazioni. Questa media aggregata potrebbe non riflettere accuratamente la distribuzione del QI a livello individuale all’interno delle singole nazioni, né la vera distribuzione “globale” se si potessero testare tutti gli individui. Le differenze significative tra le nazioni (in termini di medie, varianze, e contesti socio-culturali) vengono “appiattite” in un unico valore, potenzialmente mascherando eterogeneità importanti.\n\nDati Non Ponderati: L’analisi tratta ogni nazione come un’singola osservazione, indipendentemente dalla sua popolazione. Nazioni con popolazioni molto diverse contribuiscono allo stesso modo alla stima della media \\(\\bar{y}\\). Una media ponderata per la popolazione potrebbe fornire un quadro diverso, sebbene anch’esso soggetto a critiche.\n\nContesto e Fattori Concomitanti: La deviazione dalla media standard di 100 potrebbe riflettere non solo (o non principalmente) differenze “reali” nell’intelligenza media, ma anche enormi disparità nei contesti sanitari, educativi, socio-economici e politici in cui i test sono stati (eventualmente) somministrati o i dati raccolti. Fattori come l’accesso all’istruzione di qualità, la nutrizione, la salute pubblica, e l’esposizione a stimoli cognitivi variano drasticamente tra le nazioni e possono influenzare significativamente i punteggi medi.\n\nBias Culturale dei Test: I test del QI sono stati storicamente sviluppati e standardizzati in contesti culturali specifici (principalmente occidentali, industrializzati). La loro applicabilità e validità cross-culturale è oggetto di un acceso dibattito. È possibile che i test stessi presentino bias culturali che portano a sottostimare le capacità cognitive in contesti culturali diversi da quello di origine, influenzando così le medie nazionali riportate.\n\nQualità e Origine dei Dati: I dati originali di Lynn e Vanhanen sono stati oggetto di numerose critiche metodologiche riguardanti la raccolta, la comparabilità e la qualità dei punteggi QI tra diverse nazioni. Utilizzare questi dati senza un esame approfondito delle loro limitazioni può portare a conclusioni fuorvianti.\n\nAssunzione di \\(\\sigma\\) Nota e Uguale: L’assunzione che \\(\\sigma=15\\) sia la deviazione standard rilevante per le medie nazionali è una forte semplificazione. La variabilità tra le medie nazionali potrebbe essere diversa dalla variabilità individuale all’interno di una popolazione di riferimento.\n\nIn conclusione, sebbene il modello Normale-Normale fornisca una stima quantitativa (\\(\\mu_n \\approx 89.36\\)), le profonde questioni metodologiche, concettuali ed etiche legate ai dati sul QI internazionale rendono problematica un’interpretazione diretta di questo valore come “vera” media globale dell’intelligenza. Questo esempio serve più come illustrazione meccanica dell’aggiornamento bayesiano che come un’affermazione sostanziale sul QI globale. Un’analisi seria richiederebbe modelli gerarchici più complessi, una discussione approfondita della validità dei dati e una considerazione attenta dei fattori contestuali.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html#riflessioni-conclusive",
    "href": "chapters/appendix/a35_other_conjugate_families.html#riflessioni-conclusive",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nNei capitoli precedenti abbiamo visto come il concetto di coniugazione renda particolarmente semplice l’aggiornamento bayesiano. L’esempio Beta–Binomiale ci ha permesso di osservare in modo diretto come i parametri della distribuzione vengano modificati dai dati senza cambiare la forma della distribuzione stessa.\nIn questa appendice presentiamo altri casi di famiglie coniugate, meno immediati ma ugualmente interessanti. L’obiettivo non è memorizzare formule o cataloghi di distribuzioni, ma cogliere un principio generale: in alcune situazioni fortunate, i calcoli bayesiani diventano particolarmente trasparenti, perché il posterior appartiene alla stessa famiglia della prior.\nDal punto di vista della ricerca psicologica, non è indispensabile padroneggiare tutti questi casi. Nella pratica, la maggior parte dei modelli che incontreremo non ammetterà una forma coniugata, e dovremo ricorrere a metodi computazionali generali come il campionamento MCMC. Tuttavia, conoscere queste famiglie ha due vantaggi didattici:\n\npermette di consolidare l’intuizione su come i dati aggiornano i parametri, in contesti diversi da quello binomiale;\naiuta a riconoscere situazioni in cui i calcoli possono essere svolti senza simulazioni, facilitando l’analisi.\n\nSe è la prima volta che affronti questi argomenti, puoi leggere questa sezione in modo rapido, come un approfondimento facoltativo. Nei capitoli successivi torneremo a concentrarci sui metodi computazionali, che costituiscono lo strumento essenziale per affrontare i problemi psicologici reali.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nRiprendi i dati della SWLS che sono stati utilizzati nell’esercizio del ?sec-gauss-grid. Trova la media e la deviazione standard della distribuzione a posteriori usando il metodo delle distribuzioni coniugate. Confronta i risultati con quelli ottenuti con il metodo basato su griglia.\nConsegna: Carica il file .qmd, convertito in PDF, su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nPer risolvere questo esercizio con il metodo delle distribuzioni coniugate, assumiamo che i dati provengano da una distribuzione normale con deviazione standard nota e media da stimare. Nel caso di una verosimiglianza gaussiana con prior gaussiano, la distribuzione a posteriori sarà ancora una distribuzione normale. Questo approccio è analitico e ci permette di ottenere la media e la deviazione standard della distribuzione a posteriori senza dover ricorrere a metodi numerici come la discretizzazione della griglia.\nPassaggi per il calcolo della distribuzione a posteriori\n\n\nDefiniamo i dati osservati:\n\nLa media campionaria: \\(\\bar{x}\\)\n\nLa deviazione standard nota dei dati: \\(\\sigma\\)\n\nIl numero di osservazioni: \\(n\\)\n\n\n\n\nScegliamo un prior gaussiano molto diffuso:\n\nMedia a priori: \\(\\mu_0\\)\n\nDeviazione standard a priori molto grande: \\(\\sigma_0\\)\n\n\n\n\nCalcoliamo la media e la varianza della distribuzione a posteriori:\n\n\nLa media a posteriori è:\n\\[\n\\mu_{\\text{post}} = \\frac{\\sigma^2_0 \\bar{x} + \\sigma^2 n \\mu_0}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\nLa varianza a posteriori è:\n\\[\n\\sigma^2_{\\text{post}} = \\frac{\\sigma^2_0 \\sigma^2}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\n\n\nImplementazione in R\n# Caricamento librerie necessarie\nlibrary(dplyr)\nlibrary(tibble)\n\n# Dati SWLS\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n\n# Parametri comuni per entrambi i metodi\nsigma_conosciuta &lt;- sd(swls_data$soddisfazione)  # Usando la deviazione standard campionaria\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\n\ncat(\"Deviazione standard campionaria:\", sigma_conosciuta, \"\\n\")\ncat(\"Media campionaria:\", mean_x, \"\\n\")\n\n# ---- Metodo 1: Griglia ----\n# Definizione della griglia più fine e centrata intorno alla media campionaria\nmu_griglia &lt;- seq(mean_x - 3*sigma_conosciuta/sqrt(n), \n                 mean_x + 3*sigma_conosciuta/sqrt(n), \n                 length.out = 1000)\n\n# Calcolo della verosimiglianza\nlog_likelihood &lt;- numeric(length(mu_griglia))\nfor (i in seq_along(mu_griglia)) {\n  # Utilizzo della log-likelihood per evitare problemi numerici\n  log_likelihood[i] &lt;- sum(dnorm(swls_data$soddisfazione, \n                                mean = mu_griglia[i], \n                                sd = sigma_conosciuta, \n                                log = TRUE))\n}\n\n# Prior uniforme (in scala logaritmica)\nlog_prior &lt;- rep(0, length(mu_griglia))\n\n# Calcolo della posteriori\nlog_posterior &lt;- log_likelihood + log_prior\nposterior &lt;- exp(log_posterior - max(log_posterior))\nposterior &lt;- posterior / sum(posterior)\n\n# Campionamento e calcolo statistiche\nsamples_grid &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean_post_grid &lt;- mean(samples_grid)\nsd_post_grid &lt;- sd(samples_grid)\nci_grid &lt;- quantile(samples_grid, c(0.03, 0.97))\n\n# ---- Metodo 2: Soluzione analitica ----\n# Prior poco informativo ma non improprio\nmu_prior &lt;- mean_x\nsigma_prior &lt;- 10\n\n# Calcolo posteriori\nmu_post_analytic &lt;- (sigma_prior^2 * mean_x + sigma_conosciuta^2 * mu_prior/n) / \n                    (sigma_prior^2 + sigma_conosciuta^2/n)\nsigma_post_analytic &lt;- sqrt((sigma_prior^2 * sigma_conosciuta^2/n) / \n                           (sigma_prior^2 + sigma_conosciuta^2/n))\n\n# Confronto risultati\nresults &lt;- tibble(\n  Metodo = c(\"Griglia\", \"Analitico\"),\n  `Media Posteriori` = c(mean_post_grid, mu_post_analytic),\n  `Dev. Std. Posteriori` = c(sd_post_grid, sigma_post_analytic)\n)\nresults\nInterpretazione dei risultati\n\nLa media a posteriori rappresenta la miglior stima aggiornata della media della popolazione dopo aver osservato i dati.\nLa deviazione standard a posteriori ci dice quanto è incerta la nostra stima della media dopo aver integrato i dati e il prior.\n\nSiccome abbiamo scelto un prior molto diffuso (\\(\\sigma_0 = 10\\)), il risultato ottenuto è molto vicino a quello ottenuto con il metodo della griglia, dove il prior uniforme aveva un impatto minimo sulla distribuzione a posteriori.\nQuesta implementazione analitica permette di ottenere il risultato in modo efficiente senza necessità di metodi numerici approssimati.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     \n#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        \n#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       \n#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       \n#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        \n#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   \n#&gt; [16] fastmap_1.2.0         backports_1.5.0       labeling_0.4.3       \n#&gt; [19] rmarkdown_2.29        nloptr_2.2.1          ragg_1.5.0           \n#&gt; [22] purrr_1.1.0           jomo_2.7-6            xfun_0.53            \n#&gt; [25] glmnet_4.1-10         cachem_1.1.0          jsonlite_2.0.0       \n#&gt; [28] pan_1.9               broom_1.0.9           parallel_4.5.1       \n#&gt; [31] R6_2.6.1              stringi_1.8.7         RColorBrewer_1.1-3   \n#&gt; [34] rpart_4.1.24          boot_1.3-32           lubridate_1.9.4      \n#&gt; [37] estimability_1.5.1    iterators_1.0.14      knitr_1.50           \n#&gt; [40] zoo_1.8-14            pacman_0.5.1          nnet_7.3-20          \n#&gt; [43] Matrix_1.7-4          splines_4.5.1         timechange_0.3.0     \n#&gt; [46] tidyselect_1.2.1      abind_1.4-8           yaml_2.3.10          \n#&gt; [49] codetools_0.2-20      curl_7.0.0            pkgbuild_1.4.8       \n#&gt; [52] lattice_0.22-7        withr_3.0.2           bridgesampling_1.1-2 \n#&gt; [55] coda_0.19-4.1         evaluate_1.0.5        survival_3.8-3       \n#&gt; [58] RcppParallel_5.1.11-1 tensorA_0.36.2.1      checkmate_2.3.3      \n#&gt; [61] foreach_1.5.2         stats4_4.5.1          reformulas_0.4.1     \n#&gt; [64] distributional_0.5.0  generics_0.1.4        rprojroot_2.1.1      \n#&gt; [67] rstantools_2.5.0      scales_1.4.0          minqa_1.2.8          \n#&gt; [70] xtable_1.8-4          glue_1.8.0            emmeans_1.11.2-8     \n#&gt; [73] tools_4.5.1           lme4_1.1-37           mvtnorm_1.3-3        \n#&gt; [76] grid_4.5.1            rbibutils_2.3         QuickJSR_1.8.0       \n#&gt; [79] colorspace_2.1-1      nlme_3.1-168          cli_3.6.5            \n#&gt; [82] textshaping_1.0.3     svUnit_1.0.8          Brobdingnag_1.2-9    \n#&gt; [85] V8_7.0.0              gtable_0.3.6          digest_0.6.37        \n#&gt; [88] TH.data_1.1-4         htmlwidgets_1.6.4     farver_2.1.2         \n#&gt; [91] memoise_2.0.1         htmltools_0.5.8.1     lifecycle_1.0.4      \n#&gt; [94] mitml_0.4-5           MASS_7.3-65",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a35_other_conjugate_families.html#bibliografia",
    "href": "chapters/appendix/a35_other_conjugate_families.html#bibliografia",
    "title": "Appendice J — Altre famiglie coniugate",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Altre famiglie coniugate</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html",
    "href": "chapters/appendix/a36_gamma_poisson_model.html",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "Introduzione\nNei capitoli principali abbiamo introdotto l’idea di distribuzioni coniugate con il caso Beta–Binomiale, un laboratorio ideale per capire la logica dell’aggiornamento bayesiano in situazioni semplici. In questa appendice presentiamo un esempio parallelo: il modello Gamma–Poisson, particolarmente adatto per dati di conteggio, cioè quando osserviamo il numero di volte in cui si verifica un certo evento.\nLa struttura è analoga: la verosimiglianza è data dalla distribuzione di Poisson e la prior coniugata è una distribuzione Gamma. Grazie alla proprietà di coniugazione, il posterior risulta anch’esso una Gamma, ottenuta semplicemente aggiornando i parametri iniziali con i dati osservati. Questo ci permette di seguire passo passo la stessa logica vista nel caso binomiale: le assunzioni iniziali e l’evidenza empirica si combinano in modo trasparente, modificando i parametri della distribuzione senza alterarne la forma.\nLo scopo di questa appendice non è introdurre nuovo materiale concettuale, ma rafforzare l’intuizione su come funziona la coniugazione in un contesto diverso. Chi desidera un primo contatto pratico con i modelli per dati di conteggio troverà qui un esempio utile; chi preferisce concentrarsi sul flusso principale del manuale può considerare questa sezione come un approfondimento facoltativo.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#introduzione",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#introduzione",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "Panoramica del capitolo\n\nComprendere la distribuzione di Poisson come un modello probabilistico adatto per descrivere eventi rari in un intervallo di tempo o spazio fisso.\nSapere applicare il metodo basato su griglia per derivare la distribuzione a posteriori del parametro \\(\\lambda\\) della distribuzione di Poisson.\nConoscere il modello coniugato Gamma-Poisson, dimostrando come la distribuzione a priori Gamma si combini con la verosimiglianza di Poisson per produrre una distribuzione a posteriori Gamma.\nSapere come calcolare e interpretare le probabilità utilizzando la distribuzione a posteriori.\n\n\n\n\n\n\n\nPrerequisiti\n\n\n\n\n\n\nLeggere il ?sec-prob-discrete-prob-distr e il ?sec-prob-cont-prob-distr della dispensa.\n\n\n\n\n\n\n\n\n\n\nPreparazione del Notebook\n\n\n\n\n\n\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(ggdist)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#distribuzione-di-poisson",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "\nK.1 Distribuzione di Poisson",
    "text": "K.1 Distribuzione di Poisson\nLa distribuzione di Poisson descrive fenomeni di conteggio, ovvero situazioni in cui si desidera conoscere il numero di volte in cui un certo evento si verifica in un intervallo di tempo o di spazio prestabilito. L’idea di fondo è semplice: immaginiamo che gli eventi si verifichino con una frequenza media costante e che ogni evento avvenga in modo indipendente dagli altri.\nSe una variabile casuale \\(Y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), la probabilità di osservare un certo numero \\(y_i\\) di eventi è data da:\n\\[\nf(y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!}, \\quad y_i \\in \\{0,1,2,\\dots\\},\\ \\lambda &gt; 0,\n\\] dove il parametro \\(\\lambda\\) rappresenta il tasso medio di occorrenza degli eventi.\nUna caratteristica importante della distribuzione di Poisson è che la sua media e la sua varianza coincidono:\n\\[\nE(Y) = \\lambda, \\qquad \\text{Var}(Y) = \\lambda.\n\\] Ciò significa che, se in media si osservano 2 eventi per intervallo, anche la varianza attesa di questo valore sarà pari a 2.\n\nK.1.1 Un esempio psicologico\nPer rendere l’idea più concreta, immaginiamo un paziente affetto da disturbo ossessivo-compulsivo. Supponiamo che, in media, compia due azioni compulsive all’ora. In questo caso, il parametro della distribuzione di Poisson è \\(\\lambda = 2\\).\nLa formula ci permette di calcolare la probabilità di osservare esattamente k eventi in un’ora. Ad esempio:\n\nla probabilità di osservare 0 eventi è \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0.1353\\);\nla probabilità di osservare 1 evento è \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0.2707\\);\nla probabilità di osservare 2 eventi è \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0.2707\\).\n\nK.1.2 Calcoli in R\nPossiamo svolgere questi calcoli direttamente con R, utilizzando la funzione dpois:\n\nlam_true &lt;- 2\nk_values &lt;- 0:9\n\nprobabilities &lt;- dpois(k_values, lambda = lam_true)\n\nfor (i in seq_along(k_values)) {\n  cat(sprintf(\"Probabilità di %d eventi: %.4f\\n\", k_values[i], probabilities[i]))\n}\n#&gt; Probabilità di 0 eventi: 0.1353\n#&gt; Probabilità di 1 eventi: 0.2707\n#&gt; Probabilità di 2 eventi: 0.2707\n#&gt; Probabilità di 3 eventi: 0.1804\n#&gt; Probabilità di 4 eventi: 0.0902\n#&gt; Probabilità di 5 eventi: 0.0361\n#&gt; Probabilità di 6 eventi: 0.0120\n#&gt; Probabilità di 7 eventi: 0.0034\n#&gt; Probabilità di 8 eventi: 0.0009\n#&gt; Probabilità di 9 eventi: 0.0002\n\nQuesto codice calcola la probabilità di osservare tra 0 e 9 eventi in un’ora, dato che il tasso medio è 2. Si noti che i valori più probabili sono 1 o 2 eventi all’ora, mentre la probabilità di osservare molti più eventi diminuisce rapidamente.\n\nK.1.3 Visualizzazione grafica\nUn modo ancora più intuitivo per comprendere la distribuzione di Poisson è osservare il suo grafico. Il seguente codice permette di rappresentare la funzione di massa di probabilità (PMF) per \\(\\lambda = 2\\):\n\nlambd &lt;- 2\nx &lt;- 0:9  \ny &lt;- dpois(x, lambda = lambd)\n\ndf &lt;- data.frame(\n  numero_eventi = x,\n  probabilita = y\n)\n\nggplot(df, aes(x = numero_eventi, y = probabilita)) +\n  geom_segment(aes(x = numero_eventi, xend = numero_eventi, y = 0, yend = probabilita)) +\n  geom_point(size = 3) +\n  labs(x = \"Numero di eventi\", \n       y = \"Probabilità\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIl grafico mostra chiaramente che i valori centrati attorno a 2 hanno una probabilità maggiore, mentre la probabilità diminuisce rapidamente per valori più alti.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#distribuzione-gamma",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#distribuzione-gamma",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "\nK.2 Distribuzione Gamma",
    "text": "K.2 Distribuzione Gamma\nPer costruire un modello bayesiano con dati di tipo Poisson, è necessario scegliere una distribuzione a priori per il parametro di tasso \\(\\lambda\\). La scelta più comune, nonché la più conveniente dal punto di vista matematico, è la distribuzione Gamma. Questa distribuzione, infatti, è coniugata alla Poisson, il che significa che, partendo da una distribuzione a priori Gamma e aggiornandola con dati che seguono una distribuzione di Poisson, la distribuzione a posteriori appartiene ancora alla famiglia delle Gamma. In pratica, la coniugatezza ci permette di aggiornare le nostre credenze in modo semplice e diretto, senza dover affrontare calcoli complicati.\nLa densità della distribuzione Gamma è definita dalla formula:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x}, \\quad x &gt; 0.\n\\] In questa formula compaiono due parametri fondamentali:\n\n\n\\(\\alpha\\) (forma): controlla la forma della distribuzione. Con valori piccoli, la distribuzione è molto asimmetrica e concentrata vicino allo zero; aumentando il valore di \\(\\alpha\\), la distribuzione diventa più regolare e tende a assumere una forma simile a quella di una distribuzione normale.\n\n\\(\\beta\\) (tasso o “rate”): regola la scala della distribuzione. Con valori alti, la probabilità si concentra su valori più piccoli di \\(x\\); con valori bassi, invece, la distribuzione si allarga e assegna probabilità a valori più grandi.\n\nAlcuni esempi aiutano a chiarire:\n\ncon \\(\\alpha = 2\\) e \\(\\beta = 3\\), la distribuzione descrive un processo in cui gli eventi sono relativamente rari, ma non impossibili;\ncon \\(\\alpha = 10\\) e \\(\\beta = 1\\), invece, la distribuzione è molto più concentrata e simmetrica, a indicare un processo più regolare e prevedibile.\n\n\n\n\n\n\n\nIn R la distribuzione Gamma è parametrizzata usando direttamente \\(\\beta\\) come rate. Attenzione: a volte, in altri contesti, la stessa distribuzione viene scritta usando il parametro di scala (scale), che è semplicemente l’inverso del rate: \\(scale = 1/\\beta\\).\n\n\n\nIn R possiamo calcolare la densità della distribuzione Gamma con la funzione dgamma:\ndgamma(x, shape = alpha, rate = beta)\nAd esempio, per una Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\) possiamo scrivere:\n\nalpha &lt;- 2\nbeta &lt;- 3\n\nggplot(data.frame(x = c(0, 3)), aes(x = x)) +\n  stat_function(\n    fun = dgamma,\n    args = list(shape = alpha, rate = beta)\n  ) +\n  labs(\n    x = \"x\",\n    y = \"Densità di probabilità\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIl grafico mostra come la distribuzione si concentri intorno ai valori piccoli di x, ma lasci comunque una coda lunga verso destra. È proprio questa flessibilità a rendere la distribuzione gamma molto utile come modello a priori: può descrivere sia situazioni in cui ci si aspetta valori piccoli ma incerti, sia casi in cui si prevedono valori medi o alti con maggiore regolarità.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#la-coppia-coniugata-gammapoisson",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#la-coppia-coniugata-gammapoisson",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "\nK.3 La coppia coniugata Gamma–Poisson",
    "text": "K.3 La coppia coniugata Gamma–Poisson\nAbbiamo esaminato separatamente due elementi: la distribuzione di Poisson, che descrive il numero di eventi osservati, e la distribuzione Gamma, che abbiamo scelto come distribuzione a priori per il parametro di tasso \\(\\lambda\\). Ora possiamo unirli per costruire un modello bayesiano completo.\nIl cuore del ragionamento è il seguente:\n\ni dati osservati (\\(y_1, y_2, ..., y_N\\)) sono modellati come una distribuzione di Poisson con parametro \\(\\lambda\\);\nla nostra conoscenza a priori su \\(\\lambda\\) è rappresentata da una distribuzione Gamma con parametri \\(\\alpha_{\\text{prior}}\\) e \\(\\beta_{\\text{prior}}\\).\n\nQuesta combinazione è molto conveniente, perché la Gamma è coniugata alla Poisson. Ma cosa significa, concretamente, “coniugata”? Significa che, dopo aver osservato i dati, la distribuzione a posteriori di \\(\\lambda\\) rimane della stessa famiglia della distribuzione a priori, ovvero una distribuzione Gamma. In altre parole, se si parte da una distribuzione Gamma e la si aggiorna con dati di tipo Poisson, si ottiene ancora una distribuzione Gamma, ma i valori dei parametri cambiano, incorporando l’informazione proveniente dai dati.\n\nK.3.1 La distribuzione a posteriori\nLa regola di Bayes ci dice che:\n\\[\np(\\lambda \\mid y) \\propto p(\\lambda) \\cdot p(y \\mid \\lambda).\n\\] Sostituendo le due distribuzioni (Gamma per la prioritaria e Poisson per la verosimiglianza), si ottiene ancora una distribuzione Gamma. I parametri aggiornati sono:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + \\sum_{i=1}^N y_i ,\n\\]\n\\[\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + N .\n\\] Dunque, la nostra credenza su \\(\\lambda\\) dopo aver osservato i dati è rappresentata da una distribuzione:\n\\[\n\\lambda \\mid y \\sim \\text{Gamma}(\\alpha_{\\text{post}}, \\beta_{\\text{post}})\n\\]\n\nK.3.2 Intuizione\nIl meccanismo di aggiornamento bayesiano ammette un’interpretazione particolarmente intuitiva nel caso della distribuzione di Poisson. I parametri della distribuzione a posteriori, \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), si ottengono semplicemente aggiornando quelli a priori, ovvero \\(\\alpha_0\\) e \\(\\beta_0\\), con le informazioni contenute nei dati.\n\nil parametro di forma, \\(\\alpha_{\\text{post}} = \\alpha_0 + \\sum_{i=1}^N y_i\\), cresce con il numero totale di eventi osservati; Ogni evento è considerato come un’unità di “evidenza” a favore di un certo tasso \\(\\lambda\\), spostando la distribuzione a posteriori verso valori più alti man mano che si accumulano le osservazioni.\nil parametro rate (tasso), \\(\\beta_{\\text{post}} = \\beta_0 + N\\), aumenta con il numero di intervalli osservati, N. Questo parametro controlla la dispersione della distribuzione: valori più alti di \\(\\beta\\) corrispondono a una minore varianza e, quindi, a una maggiore certezza nella stima di \\(\\lambda\\). Ogni nuovo intervallo di osservazione, indipendentemente dal numero di eventi in esso registrati, restringe la distribuzione a posteriori, perfezionando la stima.\n\nK.3.3 Un esempio numerico\nRiprendiamo l’esempio visto in precedenza con i dati:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nAbbiamo \\(N = 8\\) osservazioni, e come prior scegliamo \\(\\alpha_{\\text{prior}} = 9\\) e \\(\\beta_{\\text{prior}} = 2\\).\nCalcoliamo i nuovi parametri:\n\nalpha_post &lt;- 9 + sum(y)\nbeta_post  &lt;- 2 + length(y)\n\nalpha_post; beta_post\n#&gt; [1] 22\n#&gt; [1] 10\n\nIl risultato è \\(\\alpha_{\\text{post}} = 22\\) e \\(\\beta_{\\text{post}} = 10\\). La nostra distribuzione a posteriori è quindi una Gamma(22, 10), che rappresenta la nuova convinzione su \\(\\lambda\\) dopo aver osservato i dati.\n\nK.3.4 Visualizzare la distribuzione a posteriori\nPossiamo visualizzare il cambiamento confrontando la prior e la posterior:\n\nx &lt;- seq(0, 6, length.out = 500)\n\nprior_density &lt;- dgamma(x, shape = 9, rate = 2)\npost_density  &lt;- dgamma(x, shape = alpha_post, rate = beta_post)\n\ndf &lt;- data.frame(\n  x = rep(x, 2),\n  densita = c(prior_density, post_density),\n  Distribuzione = rep(c(\"Prior\", \"Posterior\"), each = length(x))\n)\n\nggplot(df, aes(x = x, y = densita, color = Distribuzione)) +\n  geom_line(size = 1) +\n  labs(\n    x = expression(lambda),\n    y = \"Densità\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIl grafico mostra chiaramente che la posterior è più concentrata: osservare gli otto dati ci ha reso più sicuri del valore di \\(\\lambda\\). Inoltre, il centro della distribuzione si è spostato verso il valore suggerito dai dati, integrando così le informazioni empiriche con le credenze iniziali.\n\nK.3.5 Metodo basato su griglia\nOra che abbiamo introdotto il modello Gamma–Poisson, possiamo provare a calcolare la distribuzione a posteriori del parametro \\(\\lambda\\) non con formule chiuse, ma con un procedimento puramente numerico. Questo approccio prende il nome di metodo su griglia (grid approximation), ed è molto utile come strumento didattico, in quanto mostra, passo dopo passo, il funzionamento dell’aggiornamento bayesiano, trasformando le regole matematiche in un algoritmo semplice da eseguire al computer.\nL’idea è la seguente:\n\nfissiamo una griglia di possibili valori per \\(\\lambda\\);\ncalcoliamo la probabilità di ciascun valore secondo la prioria;\ncalcoliamo, per gli stessi valori, la verosimiglianza dei dati osservati;\nmoltiplichiamo i due risultati per ottenere la distribuzione a posteriori (non ancora normalizzata);\nnormalizziamo in modo che la somma totale sia pari a 1.\n\n\nK.3.5.1 I dati e la prior\nPrendiamo gli stessi dati già usati in precedenza, cioè il numero di compulsioni osservate in otto intervalli di tempo:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nLa priori scelta per \\(\\lambda\\) è una Gamma con parametri \\(\\alpha = 9\\) e \\(\\beta = 2\\), che riflette la nostra convinzione iniziale che il tasso medio sia intorno a 4–5 eventi, con un certo margine di incertezza.\nCreiamo una griglia di valori plausibili di \\(\\lambda\\), ad esempio da 0 a 10, divisa in 1000 punti:\n\nalpha_prior &lt;- 9\nbeta_prior  &lt;- 2\n\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\nQuesta curva rappresenta ciò che crediamo possibile prima di vedere i dati.\n\nK.3.5.2 La verosimiglianza\nLa seconda componente è la verosimiglianza, cioè quanto ciascun valore ipotetico di \\(\\lambda\\) rende probabili i dati osservati. Per una Poisson, la verosimiglianza è il prodotto delle probabilità individuali:\n\\[\n\\mathcal{L}(\\lambda) = \\prod_{i=1}^N P(Y = y_i \\mid \\lambda).\n\\]\nIn R possiamo calcolarla in modo vettoriale:\n\nlikelihood &lt;- sapply(lambda_grid, function(l) prod(dpois(y, l)))\n\nCosì, per ogni punto della griglia otteniamo il valore della verosimiglianza: se il dato osservato è molto coerente con un certo \\(\\lambda\\), la verosimiglianza sarà alta; altrimenti sarà vicina a zero.\n\nK.3.5.3 La distribuzione a posteriori\nIl passo successivo è combinare priori e verosimiglianza. La regola di Bayes ci dice che:\n\\[\np(\\lambda \\mid y) \\propto p(\\lambda) \\cdot \\mathcal{L}(\\lambda).\n\\] In pratica, moltiplichiamo i valori calcolati ai due passi precedenti:\n\nposterior_unnormalized &lt;- prior * likelihood\n\nQuesto ci dà una curva che ha la forma giusta, ma che non è ancora una vera distribuzione di probabilità: non somma a 1.\n\nK.3.5.4 Normalizzazione\nPer trasformarla in una distribuzione valida, dobbiamo normalizzare, cioè dividere per la somma totale (che qui approssimiamo come una somma numerica sulla griglia):\n\ngrid_width &lt;- lambda_grid[2] - lambda_grid[1]\nnormalization_factor &lt;- sum(posterior_unnormalized) * grid_width\n\nposterior &lt;- posterior_unnormalized / normalization_factor\n\nOra abbiamo davvero la distribuzione a posteriori di \\(\\lambda\\).\n\nK.3.5.5 Interpretazione e confronto visivo\nA questo punto possiamo confrontare la priori e la posteriori in un unico grafico:\n\ndf &lt;- data.frame(\n  lambda     = lambda_grid,\n  Prior      = prior,\n  Posteriori = posterior\n)\n\ndf_long &lt;- pivot_longer(df, cols = c(\"Prior\", \"Posteriori\"),\n                        names_to = \"Distribuzione\",\n                        values_to = \"Densita\")\n\nggplot(df_long, aes(x = lambda, y = Densita, color = Distribuzione)) +\n  geom_line(size = 1) +\n  labs(x = expression(lambda),\n       y = \"Densità\")\n\n\n\n\n\n\n\nIl grafico rivela due aspetti fondamentali:\n\nla posteriori è spostata rispetto alla priori, perché i dati suggeriscono valori di \\(\\lambda\\) più bassi di quanto ci aspettassimo inizialmente;\nla posteriori è anche più concentrata, cioè meno incerta: dopo aver osservato i dati, non solo abbiamo aggiornato la nostra convinzione, ma siamo anche diventati più sicuri del valore plausibile di \\(\\lambda\\).\n\nK.3.6 Perché è utile il metodo a griglia?\nQuesto metodo non è molto efficiente nei problemi complessi (dove i parametri sono numerosi e lo spazio da esplorare è vasto), ma è molto utile a scopo didattico. Ci mostra infatti in modo visivo e intuitivo il funzionamento dell’aggiornamento bayesiano: partiamo da una convinzione iniziale (la prior), la confrontiamo con i dati (la likelihood) e otteniamo una nuova convinzione aggiornata (la posterior).\nNei prossimi capitoli vedremo come affrontare lo stesso problema con strumenti più generali, come il campionamento MCMC in Stan, che diventano indispensabili quando i modelli si complicano e il metodo su griglia non è più praticabile.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#riflessioni-conclusive",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl modello Gamma–Poisson ci mostra che la logica delle famiglie coniugate non è limitata al caso dei dati binari, ma si estende in modo naturale a dati di altra natura, come i conteggi. Anche in questo caso, il teorema di Bayes fornisce un aggiornamento semplice e cumulativo: i parametri della distribuzione prior si modificano alla luce dei dati, producendo un posterior facilmente interpretabile.\nDal punto di vista didattico, questo esempio ha il valore di rendere più generale l’intuizione acquisita con il Beta–Binomiale, mostrando la ricorrenza della coniugazione in contesti diversi. Dal punto di vista applicativo, invece, è bene sottolineare che la coniugazione rimane un caso speciale. Nella maggior parte delle situazioni psicologiche reali non possiamo contare su soluzioni analitiche così eleganti, ed è per questo che nei capitoli principali del manuale ci concentriamo su metodi computazionali più generali, come il campionamento MCMC.\nIn sintesi, il modello Gamma–Poisson è un’utile illustrazione supplementare: non rappresenta un passaggio essenziale per la comprensione del manuale, ma offre un’occasione per consolidare le idee chiave e per intravedere la varietà di applicazioni in cui l’approccio bayesiano può essere adottato.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo uno studio longitudinale su coppie, dove i partecipanti registrano quotidianamente la frequenza con cui nascondono il loro comportamento di fumo al partner. Basandoci sui dati di Scholz et al. (2021), assumiamo che il tasso medio di nascondere il fumo sia di 1.52 volte al giorno. Supponiamo di avere i seguenti dati giornalieri per un partecipante:\n\nGiorno 1: 2 volte.\nGiorno 2: 0 volte.\nGiorno 3: 1 volta.\nGiorno 4: 3 volte.\n\nUtilizzare un modello Gamma-Poisson per stimare la distribuzione a posteriori del tasso individuale di nascondere il fumo per un partecipante specifico, dato il suo insieme di osservazioni giornaliere.\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nVogliamo stimare quante volte al giorno una persona tende a nascondere il proprio fumo al partner. Abbiamo quattro giorni di dati su questa persona e, grazie a un precedente studio, sappiamo che in media le persone lo fanno circa 1.52 volte al giorno.\nMa i dati di una sola persona sono pochi, quindi useremo un approccio bayesiano per combinare:\n\n\nLe informazioni preesistenti (dal precedente studio),\n\nLe nuove osservazioni (quanti eventi sono stati registrati nei quattro giorni).\n\nCon un modello Gamma-Poisson, possiamo aggiornare la nostra stima e ottenere una distribuzione a posteriori, che ci dirà quali sono i valori più probabili per il tasso di nascondimento di questa persona.\n# Dati osservati: numero di volte che la persona ha nascosto il fumo ogni giorno\nosservazioni &lt;- c(2, 0, 1, 3)\n\n# Numero totale di giorni osservati\nn_giorni &lt;- length(osservazioni)\n\n# Numero totale di eventi (quante volte ha nascosto il fumo in totale)\neventi_totali &lt;- sum(osservazioni)\n\n# Informazione a priori dallo studio precedente\nmedia_priori &lt;- 1.52\nforma_priori &lt;- 3   # Parametro di forma scelto per un'incertezza moderata\ntasso_priori &lt;- forma_priori / media_priori  # Parametro di scala\n\n# Aggiornamento bayesiano: parametri della distribuzione a posteriori\nforma_post &lt;- forma_priori + eventi_totali\ntasso_post &lt;- tasso_priori + n_giorni\n\n# Creazione della griglia di valori possibili per il tasso giornaliero (lambda)\nlambda_valori &lt;- seq(0, 5, length.out = 100)\n\n# Calcolo delle densità per le distribuzioni a priori e a posteriori\ndensita_priori &lt;- dgamma(lambda_valori, shape = forma_priori, rate = tasso_priori)\ndensita_post &lt;- dgamma(lambda_valori, shape = forma_post, rate = tasso_post)\n\n# Creazione di un dataframe per il grafico\ndati_plot &lt;- data.frame(\n  lambda = rep(lambda_valori, 2),\n  densita = c(densita_priori, densita_post),\n  distribuzione = rep(c(\"Priori\", \"Posteriori\"), each = length(lambda_valori))\n)\n\n# Creazione del grafico per confrontare la distribuzione a priori e quella aggiornata (posteriori)\nggplot(dati_plot, aes(x = lambda, y = densita, color = distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(\n    x = \"Tasso giornaliero (λ)\",\n    y = \"Densità\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\nCosa fa questo codice\n\n\nCarica i dati: abbiamo registrato per 4 giorni quante volte questa persona ha nascosto il fumo.\n\nImposta una conoscenza iniziale (priori): basata sullo studio precedente.\n\nApplica il teorema di Bayes per aggiornare la stima con i nuovi dati.\n\nGenera il grafico: confronta la distribuzione prima e dopo l’aggiornamento con i dati osservati.\n\nInterpretazione del risultato\n\nLa curva rossa (priori) rappresenta la nostra stima iniziale, basata sullo studio precedente.\nLa curva blu (posteriori) è la nostra nuova stima dopo aver considerato i dati della persona.\nSe i dati raccolti sono molto diversi dal valore medio dello studio, la curva blu si sposterà rispetto alla rossa.\n\nQuesta analisi ci permette di stimare il comportamento specifico di una persona integrando dati generali e osservazioni individuali, in modo più informativo rispetto a una semplice media.\n\n\n\n\n\n\n\n\n\nInformazioni sull’ambiente di sviluppo\n\n\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#&gt;  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#&gt;  [7] pacman_0.5.1          digest_0.6.37         timechange_0.3.0     \n#&gt; [10] estimability_1.5.1    lifecycle_1.0.4       survival_3.8-3       \n#&gt; [13] magrittr_2.0.3        compiler_4.5.1        rlang_1.1.6          \n#&gt; [16] tools_4.5.1           knitr_1.50            labeling_0.4.3       \n#&gt; [19] bridgesampling_1.1-2  htmlwidgets_1.6.4     curl_7.0.0           \n#&gt; [22] pkgbuild_1.4.8        RColorBrewer_1.1-3    abind_1.4-8          \n#&gt; [25] multcomp_1.4-28       withr_3.0.2           purrr_1.1.0          \n#&gt; [28] grid_4.5.1            stats4_4.5.1          colorspace_2.1-1     \n#&gt; [31] xtable_1.8-4          inline_0.3.21         emmeans_1.11.2-8     \n#&gt; [34] scales_1.4.0          MASS_7.3-65           cli_3.6.5            \n#&gt; [37] mvtnorm_1.3-3         rmarkdown_2.29        ragg_1.5.0           \n#&gt; [40] generics_0.1.4        RcppParallel_5.1.11-1 cachem_1.1.0         \n#&gt; [43] stringr_1.5.1         splines_4.5.1         parallel_4.5.1       \n#&gt; [46] vctrs_0.6.5           V8_7.0.0              Matrix_1.7-4         \n#&gt; [49] sandwich_3.1-1        jsonlite_2.0.0        arrayhelpers_1.1-0   \n#&gt; [52] systemfonts_1.2.3     glue_1.8.0            codetools_0.2-20     \n#&gt; [55] distributional_0.5.0  lubridate_1.9.4       stringi_1.8.7        \n#&gt; [58] gtable_0.3.6          QuickJSR_1.8.0        htmltools_0.5.8.1    \n#&gt; [61] Brobdingnag_1.2-9     R6_2.6.1              textshaping_1.0.3    \n#&gt; [64] rprojroot_2.1.1       evaluate_1.0.5        lattice_0.22-7       \n#&gt; [67] backports_1.5.0       memoise_2.0.1         broom_1.0.9          \n#&gt; [70] snakecase_0.11.1      rstantools_2.5.0      coda_0.19-4.1        \n#&gt; [73] gridExtra_2.3         nlme_3.1-168          checkmate_2.3.3      \n#&gt; [76] xfun_0.53             zoo_1.8-14            pkgconfig_2.0.3",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a36_gamma_poisson_model.html#bibliografia",
    "href": "chapters/appendix/a36_gamma_poisson_model.html#bibliografia",
    "title": "Appendice K — Modello coniugato Gamma-Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nScholz, U., Stadler, G., Berli, C., Lüscher, J., & Knoll, N. (2021). How do people experience and respond to social control from their partner? Three daily diary studies. Frontiers in Psychology, 11, 613546.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_metropolis_normal.html",
    "href": "chapters/appendix/a40_metropolis_normal.html",
    "title": "Appendice L — Metropolis: esempio Normale–Normale",
    "section": "",
    "text": "L.1 Implementazione in R\nIn questa sezione di approfondimento applichiamo l’algoritmo di Metropolis a un caso in cui conosciamo la soluzione analitica: il modello Normale–Normale. L’obiettivo non è introdurre concetti nuovi, ma mostrare ancora una volta come l’algoritmo riesca a ricostruire una distribuzione a posteriori già nota, rafforzando l’intuizione costruita nel testo principale.\nSupponiamo di voler stimare la media vera \\(\\mu\\) di una popolazione. Abbiamo:\nIl modello è quindi:\n\\[\ny_i \\sim \\mathcal{N}(\\mu, \\sigma^2), \\qquad \\mu \\sim \\mathcal{N}(30, 25).\n\\]\nDefinizione delle funzioni prior, likelihood e posterior (non normalizzata):\nprior &lt;- function(mu) dnorm(mu, mean = 30, sd = 5)\n\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\nposterior &lt;- function(mu, data) {\n  prior(mu) * likelihood(mu, data)\n}\nAlgoritmo di Metropolis:\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  samples\n}\nDati osservati:\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43,\n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nEsecuzione del campionamento:\nset.seed(123)\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Metropolis: esempio Normale–Normale</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_metropolis_normal.html#confronto-con-la-soluzione-analitica",
    "href": "chapters/appendix/a40_metropolis_normal.html#confronto-con-la-soluzione-analitica",
    "title": "Appendice L — Metropolis: esempio Normale–Normale",
    "section": "\nL.2 Confronto con la soluzione analitica",
    "text": "L.2 Confronto con la soluzione analitica\nNel caso Normale–Normale possiamo calcolare i parametri della distribuzione a posteriori esatta:\n\nmu_prior &lt;- 30; std_prior &lt;- 5; var_prior &lt;- std_prior^2\nn &lt;- length(y); sum_y &lt;- sum(y); var_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nc(mu_post = mu_post, sd_post = std_post)\n#&gt; mu_post sd_post \n#&gt;   30.88    1.17\n\nInfine, confrontiamo graficamente l’istogramma dei campioni MCMC (dopo burn-in) con la densità analitica:\n\nburnin &lt;- 50000\npost_samples &lt;- samples[(burnin+1):length(samples)]\n\nggplot() +\n  geom_histogram(\n    aes(x = post_samples, y = after_stat(density)),\n    bins = 30, fill = \"#56B4E9\", alpha = 0.5, color = NA\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = mu_post, sd = std_post),\n    color = \"#009E73\", linewidth = 1.2\n  ) +\n  labs(x = expression(mu), y = \"Densità\") \n\n\n\n\n\n\n\nIn conclusione, questo esempio conferma che l’algoritmo di Metropolis riesce a ricostruire accuratamente la distribuzione a posteriori anche in un modello con soluzione analitica nota. Dal punto di vista didattico, ciò offre un’ulteriore verifica intuitiva della validità dell’algoritmo.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Metropolis: esempio Normale–Normale</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html",
    "href": "chapters/appendix/a41_cmdstanr_intro.html",
    "title": "Appendice M — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "",
    "text": "Obiettivo\nIn questa sezione dell’appendice presentiamo una guida pratica all’implementazione di modelli Bayesiani utilizzando Stan attraverso l’interfaccia cmdstanr in R. Il framework cmdstanr rappresenta l’evoluzione moderna delle interfacce R per Stan, offrendo prestazioni ottimizzate e un workflow semplificato per l’inferenza Bayesiana.\nIllustreremo il flusso di lavoro completo attraverso i seguenti passaggi:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#obiettivo",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#obiettivo",
    "title": "Appendice M — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "",
    "text": "Preparazione e input dei dati: strutturare i dati per l’analisi in Stan.\n\nCompilazione del modello: trasformazione del codice Stan in eseguibile ottimizzato.\n\nCampionamento MCMC: esecuzione efficiente degli algoritmi di campionamento.\n\nEstrazione e analisi dei risultati: elaborazione degli output campionati.\n\nDiagnostica e visualizzazione: validazione del modello e rappresentazione grafica.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#perché-usare-cmdstanr",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#perché-usare-cmdstanr",
    "title": "Appendice M — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "\nM.1 Perché usare CmdStanR",
    "text": "M.1 Perché usare CmdStanR\nCmdStanR è l’interfaccia R per CmdStan, la versione più leggera e flessibile di Stan. A differenza di rstan, che integra il compilatore C++ dentro R, CmdStanR utilizza direttamente gli eseguibili di CmdStan. Questo porta diversi vantaggi:\n\n\nMaggiore stabilità e velocità di compilazione, grazie all’uso diretto di CmdStan.\n\nAggiornamenti indipendenti: CmdStanR si appoggia a CmdStan, che può essere aggiornato separatamente.\n\nControllo avanzato sulle opzioni di campionamento, diagnostica e gestione dei file di output.\n\nPortabilità: funziona in modo coerente su diversi sistemi operativi.\n\nInoltre, CmdStanR rappresenta oggi la soluzione consigliata dagli sviluppatori Stan, in quanto più manutenuta e allineata con le versioni più recenti del linguaggio.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#installazione",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#installazione",
    "title": "Appendice M — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "\nM.2 Installazione",
    "text": "M.2 Installazione\nPer prima cosa, installiamo il pacchetto cmdstanr da GitHub:\n# install.packages(\"pak\")\npak::pak(\"stan-dev/cmdstanr\")\nDopodiché, occorre installare CmdStan:\ncmdstanr::install_cmdstan()\nQuesto comando scarica e compila CmdStan localmente. La prima installazione può richiedere qualche minuto, ma successivamente sarà sufficiente aggiornare all’occorrenza con:\ncmdstanr::install_cmdstan(update = TRUE)\nPer verificare la corretta installazione:\n\nlibrary(cmdstanr)\ncmdstanr::cmdstan_version()\n\n[1] \"2.37.0\"",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#pacchetti-necessari",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#pacchetti-necessari",
    "title": "Appendice M — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "\nM.3 Pacchetti necessari",
    "text": "M.3 Pacchetti necessari\nPer lavorare ci servono alcuni pacchetti:\n\nsuppressPackageStartupMessages({\n  library(tidyverse)   # per manipolare i dati\n  library(cmdstanr)    # interfaccia R per Stan\n  library(posterior)   # per lavorare con i campioni MCMC\n  library(bayesplot)   # per visualizzare i risultati\n  library(here)        # per gestire i percorsi ai file\n})\n\nset.seed(42) # per riproducibilità",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a41_cmdstanr_intro.html#un-esempio-semplice-modello-beta-binomiale",
    "href": "chapters/appendix/a41_cmdstanr_intro.html#un-esempio-semplice-modello-beta-binomiale",
    "title": "Appendice M — Implementazione di modelli Bayesiani con Stan tramite cmdstanr",
    "section": "\nM.4 Un esempio semplice: modello beta-binomiale",
    "text": "M.4 Un esempio semplice: modello beta-binomiale\nConsideriamo il seguente scenario sperimentale: in un esperimento bernoulliano abbiamo osservato 6 successi su 9 prove. L’obiettivo dell’analisi è stimare la distribuzione a posteriori della probabilità di successo \\(\\theta\\).\nA questo scopo, adottiamo come distribuzione a priori una Beta(2, 2), scelta in quanto debolmente informativa e in grado di esprimere una moderata convinzione preliminare sulla simmetria della probabilità di successo, pur mantenendo una sufficiente flessibilità per permettere ai dati di guidare l’inferenza.\nIl modello Stan è già stato scritto in un file beta_binomial_model.stan. Il codice Stan è identico indipendentemente dall’interfaccia (R, Python, Julia, …).\n\nM.4.1 Passare i dati a Stan\nStan richiede che i dati siano in una lista di R con i nomi esattamente uguali a quelli usati nel file .stan.\n\ndata_list &lt;- list(\n  N = 9,          # numero di prove\n  y = 6,          # numero di successi\n  alpha_prior = 2, # parametri del prior\n  beta_prior = 2\n)\n\n\nM.4.2 Leggere e compilare il modello\nDiciamo a R dove si trova il file .stan e lo compiliamo:\n\nfile &lt;- file.path(here::here(\"stan\", \"beta_binomial_model.stan\"))\nfile\n\nmod &lt;- cmdstan_model(file)  # compila il modello\n\nL’oggetto mod rappresenta il modello Stan compilato. Possiamo visualizzarne le informazioni:\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N;                       // numero di prove\n#&gt;   int&lt;lower=0, upper=N&gt; y;              // successi osservati\n#&gt;   real&lt;lower=0&gt; alpha_prior;            // Beta prior: alpha\n#&gt;   real&lt;lower=0&gt; beta_prior;             // Beta prior: beta\n#&gt; }\n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta;         // probabilità di successo\n#&gt; }\n#&gt; model {\n#&gt;   // Prior\n#&gt;   theta ~ beta(alpha_prior, beta_prior);\n#&gt;   // Likelihood\n#&gt;   y ~ binomial(N, theta);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   // Replica del dato per pp_check\n#&gt;   int y_rep = binomial_rng(N, theta);\n#&gt; \n#&gt;   // Log-likelihood del dato osservato (per LOO/WAIC)\n#&gt;   real log_lik = binomial_lpmf(y | N, theta);\n#&gt; }\n\n\nM.4.3 Eseguire l’algoritmo MCMC\nPer stimare i parametri usiamo il metodo $sample(). Questo esegue l’algoritmo MCMC di Stan:\n\nfit &lt;- mod$sample(\n  data = data_list,\n  seed = 123,\n  chains = 4,            # numero di catene\n  parallel_chains = 4    # quante catene girano in parallelo\n)\n\nNota: per default ogni catena produce 1000 campioni dopo il warmup, quindi avremo 4000 campioni posteriori.\n\nM.4.4 Estrarre i campioni\nI campioni possono essere estratti in diversi formati. Per esempio, come array a 3 dimensioni (iterazioni × catene × variabili):\n\ndraws_arr &lt;- fit$draws()\nstr(draws_arr)\n#&gt;  'draws_array' num [1:1000, 1:4, 1:4] -8.67 -8.76 -8.68 -11.81 -8.71 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iteration: chr [1:1000] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n#&gt;   ..$ variable : chr [1:4] \"lp__\" \"theta\" \"y_rep\" \"log_lik\"\ndim(draws_arr)\n#&gt; [1] 1000    4    4\n\nOppure come data frame lungo:\n\ndraws_df &lt;- as_draws_df(fit)\nhead(draws_df)\n#&gt; # A draws_df: 6 iterations, 1 chains, and 4 variables\n#&gt;    lp__ theta y_rep log_lik\n#&gt; 1  -8.7  0.60     8    -1.4\n#&gt; 2  -8.8  0.67     9    -1.3\n#&gt; 3  -8.7  0.59     6    -1.4\n#&gt; 4 -11.8  0.89     9    -2.8\n#&gt; 5  -8.7  0.57     7    -1.5\n#&gt; 6  -8.7  0.61     8    -1.4\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nM.4.5 Statistiche riassuntive\nIl metodo $summary() calcola statistiche posteriori (medie, deviazioni standard, quantili, ecc.):\n\nfit$summary(variables = \"theta\")\n#&gt; # A tibble: 1 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 theta    0.620  0.628 0.129 0.132 0.394 0.820 1.005 1247.337 1842.290\n\nPossiamo specificare statistiche personalizzate, ad esempio:\n\nfit$summary(\n  variables = \"theta\", \n  mean, \n  sd,\n  ~quantile(.x, probs = c(0.03, 0.97))\n)\n#&gt; # A tibble: 1 × 5\n#&gt;   variable  mean    sd  `3%` `97%`\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 theta    0.620 0.129 0.362 0.843\n\n\nM.4.6 Esempio di test bayesiano\nPossiamo stimare la probabilità che \\(\\theta \\leq 0.5\\):\n\nfit$summary(\"theta\", pr_less_05 = ~ mean(. &lt;= 0.5))\n#&gt; # A tibble: 1 × 2\n#&gt;   variable pr_less_05\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 theta         0.180\n\n\nM.4.7 Visualizzare i campioni\nIl pacchetto bayesplot semplifica la creazione di grafici. Ad esempio, un istogramma della distribuzione posteriore di \\(\\theta\\):\n\nmcmc_hist(fit$draws(\"theta\"))\n\n\n\n\n\n\n\n\nM.4.8 Diagnostica del campionatore\nPer verificare che l’MCMC abbia funzionato correttamente:\n\nfit$diagnostic_summary()\n#&gt; $num_divergent\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $num_max_treedepth\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $ebfmi\n#&gt; [1] 1.150 0.882 1.223 1.165\n\nÈ anche possibile accedere alle variabili interne del campionatore (es. profondità dell’albero, divergenze):\n\nhead(fit$sampler_diagnostics(format = \"df\"))\n#&gt; # A draws_df: 6 iterations, 1 chains, and 6 variables\n#&gt;   treedepth__ divergent__ energy__ accept_stat__ stepsize__ n_leapfrog__\n#&gt; 1           2           0     11.9          1.00       0.93            3\n#&gt; 2           2           0      9.0          0.96       0.93            3\n#&gt; 3           2           0      8.7          1.00       0.93            7\n#&gt; 4           2           0     11.8          0.63       0.93            3\n#&gt; 5           2           0     11.2          1.00       0.93            7\n#&gt; 6           2           0      8.7          1.00       0.93            3\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\nSe ci sono problemi (molte divergenze, R-hat alto, ecc.), occorre rivedere il modello o i parametri di campionamento.\n\nM.4.9 Conclusioni\nIn conclusione, abbiamo visto i passaggi fondamentali per usare cmdstanr:\n\npreparare i dati in una lista;\ncompilare il modello Stan;\nlanciare il campionamento MCMC;\nestrarre e riassumere i campioni;\nvisualizzare i risultati e controllare la diagnostica.\n\nQuesta procedura è la base di ogni analisi con Stan via R: indipendentemente dal modello, i passaggi saranno sempre questi.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Implementazione di modelli Bayesiani con Stan tramite `cmdstanr`</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html",
    "href": "chapters/appendix/a47_first_order_markov.html",
    "title": "Appendice N — Catene di Markov",
    "section": "",
    "text": "N.1 Classificazione degli Stati\nIl processo di Markov di primo ordine è un concetto fondamentale in molti campi, tra cui l’intelligenza artificiale, la statistica e la teoria delle probabilità. Questo modello probabilistico rappresenta un equilibrio tra la semplicità delle variabili casuali indipendenti e la complessità delle interazioni tra variabili. Per chiarire il concetto, consideriamo una sequenza temporale di eventi rappresentata da variabili casuali \\(X_0, X_1, ..., X_n, ...\\). In molti fenomeni reali, queste variabili non sono né completamente indipendenti né totalmente interdipendenti. Una catena di Markov rappresenta un compromesso tra questi due estremi.\nIn questo contesto, ci concentreremo su catene di Markov con stati discreti e tempo discreto. Ciò significa che le variabili \\(X_n\\) possono assumere valori in un insieme finito, tipicamente indicato come \\(\\{1, 2, ..., M\\}\\), e che gli eventi si verificano in momenti distinti e numerabili. La proprietà fondamentale di una catena di Markov può essere espressa matematicamente con la seguente equazione:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, ..., X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nQuesta equazione indica che il futuro (rappresentato da \\(X_{n+1}\\)) dipende solo dal presente (\\(X_n\\)) e non dal passato (\\(X_{n-1}, ..., X_0\\)). La proprietà di Markov può essere vista come un primo allentamento dell’assunzione di indipendenza: le variabili casuali sono dipendenti in un modo specifico che risulta matematicamente conveniente.\nQuantità importanti associate a una catena di Markov sono le probabilità condizionate, chiamate probabilità di transizione:\n\\[\nP(X_{n+1} = j \\mid X_n = i).\n\\]\nLa probabilità \\(P(X_{n+1} = j \\mid X_n = i)\\), nota come probabilità di transizione, rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo.\nPer descrivere completamente una catena di Markov, si utilizza una matrice \\(Q\\), chiamata matrice di transizione. Questa è una matrice \\(M \\times M\\) in cui ogni elemento \\(q_{ij}\\) rappresenta la probabilità di transizione dallo stato \\(i\\) allo stato \\(j\\). Un’importante caratteristica della matrice di transizione è che la somma degli elementi di ogni riga deve essere pari a 1, poiché partendo da uno stato qualsiasi, il sistema deve necessariamente transitare in uno degli stati possibili.\nPer chiarire ulteriormente il concetto, consideriamo un modello di previsione del tempo a Firenze con tre possibili condizioni meteorologiche: soleggiato, piovoso e nebbioso. Di seguito è riportata una matrice di transizione che rappresenta le probabilità di passaggio da un tipo di tempo all’altro:\nVediamo come calcolare alcune probabilità:\nIl modello di Markov di base assume che le probabilità di transizione rimangano costanti nel tempo, una proprietà nota come omogeneità temporale. Questo significa che, per esempio, la probabilità di passare dallo stato “soleggiato” allo stato “piovoso” è la stessa in qualsiasi periodo dell’anno.\nIn sintesi, l’utilità del modello di Markov risiede nella sua capacità di semplificare notevolmente i calcoli probabilistici. Invece di considerare l’intera storia passata del sistema, è sufficiente conoscere solo lo stato attuale per fare previsioni sul futuro. Questa caratteristica, nota come “assenza di memoria”, rende il modello estremamente utile in molte applicazioni pratiche, dalla modellazione di fenomeni naturali alla progettazione di algoritmi di apprendimento automatico. Il processo di Markov di primo ordine offre uno strumento potente per analizzare e prevedere il comportamento di sistemi complessi nel tempo, bilanciando la necessità di catturare le dipendenze temporali con la semplicità computazionale. La sua versatilità e applicabilità in diversi campi lo rendono un concetto chiave per comprendere e modellare molti fenomeni del mondo reale.\nConsideriamo ora la terminologia usata per descrivere le varie caratteristiche di una catena di Markov.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "href": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "title": "Appendice N — Catene di Markov",
    "section": "",
    "text": "N.1.1 Catene di Markov Irriducibili\nUna catena di Markov è detta irriducibile se, per qualsiasi coppia di stati \\(i\\) e \\(j\\), esiste una probabilità positiva di passare dallo stato \\(i\\) allo stato \\(j\\) in un numero finito di passi. In altre parole, una catena irriducibile non ha stati isolati: ogni stato è raggiungibile da qualsiasi altro stato.\n\n\nN.1.2 Stati Ricorrenti\nUno stato \\(i\\) di una catena di Markov si dice ricorrente se, partendo da \\(i\\), la probabilità di ritornarvi è uguale a 1. Questo implica che una volta raggiunto lo stato \\(i\\), è garantito che la catena tornerà in \\(i\\) prima o poi. Gli stati ricorrenti possono essere ulteriormente classificati come:\n\nPositivamente ricorrenti: uno stato è positivamente ricorrente se il tempo medio atteso per ritornare in quello stato, partendo da esso, è finito.\nNullamente ricorrenti: uno stato è nullamente ricorrente se il tempo medio atteso per ritornare in quello stato è infinito.\nRicorrenti di Harris: sono stati ricorrenti che vengono visitati infinite volte quando il tempo tende all’infinito, garantendo una certa frequenza di visita.\n\n\n\nN.1.3 Aperiodicità\nUno stato \\(i\\) si dice aperiodico se il massimo comun divisore dei tempi di ritorno in \\(i\\) è 1. In altre parole, uno stato è aperiodico se non esiste un ciclo deterministico che vincola i tempi in cui la catena può ritornare in quello stato. Una catena di Markov è aperiodica se tutti i suoi stati sono aperiodici. L’aperiodicità evita che la catena rimanga bloccata in una sequenza ciclica fissa, permettendo un comportamento più variegato nel tempo.\n\n\nN.1.4 Stazionarietà\nNella teoria delle catene di Markov, una distribuzione stazionaria \\(\\pi\\) è una distribuzione di probabilità sugli stati tale che, se la catena parte con questa distribuzione iniziale, la distribuzione delle probabilità rimane invariata nel tempo. Matematicamente, se \\(\\pi\\) è la distribuzione stazionaria, allora \\(\\pi P = \\pi\\), dove \\(P\\) è la matrice di transizione della catena di Markov. La stazionarietà è fondamentale per analizzare il comportamento a lungo termine della catena, poiché una volta raggiunta, la distribuzione di probabilità sugli stati rimane costante.\n\n\nN.1.5 Ergodicità\nUna catena di Markov si dice ergodica se è irriducibile e aperiodica, e tutti i suoi stati sono positivamente ricorrenti. Questo implica che la catena, nel lungo termine, visita tutti gli stati secondo una distribuzione di probabilità che diventa stabile (stazionaria) e non dipende dallo stato iniziale. La proprietà di ergodicità è cruciale in quanto garantisce che le medie temporali di una funzione sugli stati della catena convergono alle medie rispetto alla distribuzione stazionaria.\n\n\nN.1.6 Convergenza\nLa convergenza di una catena di Markov si riferisce al processo mediante il quale la distribuzione di probabilità degli stati si avvicina alla distribuzione stazionaria \\(\\pi\\) man mano che il numero di passi \\(n\\) tende all’infinito. In altre parole, indipendentemente dalla distribuzione iniziale degli stati, la distribuzione della catena dopo un lungo periodo di tempo sarà vicina a \\(\\pi\\). Questo concetto è strettamente legato alla stazionarietà, poiché la convergenza descrive il percorso verso l’equilibrio, mentre la stazionarietà rappresenta lo stato di equilibrio raggiunto.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#sommario",
    "href": "chapters/appendix/a47_first_order_markov.html#sommario",
    "title": "Appendice N — Catene di Markov",
    "section": "N.2 Sommario",
    "text": "N.2 Sommario\nUna catena di Markov è una sequenza di variabili aleatorie \\(X_0, X_1, X_2, \\ldots\\) che soddisfa la cosiddetta proprietà di Markov. Questa proprietà stabilisce che, dato lo stato attuale della catena, il futuro è indipendente dal passato. Formalmente, questa proprietà si esprime come:\n\\[\nP(X_{n+1} = j \\mid X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j \\mid X_n = i) = q_{ij},\n\\]\ndove \\(q_{ij}\\) rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo. Queste probabilità di transizione sono organizzate in una matrice di transizione \\(Q = (q_{ij})\\), in cui ogni riga corrisponde a una distribuzione di probabilità condizionata sui possibili stati futuri dato l’attuale stato della catena.\nLa distribuzione di probabilità degli stati della catena dopo \\(n\\) passi può essere calcolata moltiplicando la matrice di transizione \\(Q\\) elevata alla potenza \\(n\\) per il vettore di probabilità iniziale \\(s\\), che descrive la distribuzione di probabilità degli stati al tempo \\(0\\). In simboli, questo è rappresentato da \\(sQ^n\\), che fornisce la distribuzione di probabilità marginale degli stati dopo \\(n\\) passi.\nGli stati di una catena di Markov possono essere classificati come ricorrenti o transitori. Uno stato è ricorrente se la catena torna a questo stato ripetutamente nel tempo; è transitorio se la catena potrebbe lasciare questo stato per non ritornarvi mai più. Gli stati possono anche avere un periodo associato, definito come il massimo comun divisore dei numeri di passi necessari per ritornare allo stato stesso. Una catena di Markov è detta irriducibile se è possibile raggiungere qualsiasi stato da qualsiasi altro stato in un numero finito di passi, ed è aperiodica se ogni stato ha periodo 1.\nUna distribuzione stazionaria di una catena di Markov è una distribuzione di probabilità che rimane invariata nel tempo. Se la catena inizia con questa distribuzione, continuerà a mantenerla in ogni passo successivo. Questa condizione si esprime matematicamente come \\(sQ = s\\), dove \\(s\\) è il vettore di probabilità stazionaria e \\(Q\\) è la matrice di transizione. Per una catena di Markov finita che è irriducibile e aperiodica, esiste una distribuzione stazionaria unica verso la quale la catena converge indipendentemente dalla distribuzione iniziale.\nUn concetto importante nelle catene di Markov è quello di reversibilità. Una catena di Markov è detta reversibile se esiste una distribuzione di probabilità \\(s\\) tale che, per ogni coppia di stati \\(i\\) e \\(j\\), la condizione di reversibilità \\(s_i q_{ij} = s_j q_{ji}\\) sia soddisfatta. Questa condizione garantisce che \\(s\\) sia una distribuzione stazionaria per la catena. Le catene di Markov reversibili sono particolarmente utili in applicazioni pratiche come gli algoritmi di simulazione Monte Carlo, ad esempio l’algoritmo di Metropolis-Hastings, poiché permettono di progettare catene che convergono rapidamente alla distribuzione di probabilità desiderata.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#letteratura",
    "href": "chapters/appendix/a47_first_order_markov.html#letteratura",
    "title": "Appendice N — Catene di Markov",
    "section": "N.3 Letteratura",
    "text": "N.3 Letteratura\nI metodi markoviani sono stati ampiamente utilizzati in vari ambiti della psicologia e dell’educazione. Una delle applicazioni più comuni di questi metodi è il clustering dei dati sequenziali (Törmänen et al. (2022); Törmänen et al. (2023); Fincham et al. (2018)). Ad esempio, i modelli nascosti di Markov (HMM) sono stati utilizzati per raggruppare le sequenze di dati tracciati da sistemi di gestione dell’apprendimento (LMS) degli studenti, al fine di identificare i loro schemi di attività, ovvero le tattiche e strategie di apprendimento (Fincham et al. (2018)). Un uso molto diffuso dei modelli di Markov di primo ordine è quello di mappare le transizioni degli studenti tra diverse attività di apprendimento. Per esempio, Matcha et al. (2020) ha utilizzato modelli di Markov di primo ordine per studiare i processi di transizione degli studenti tra diverse strategie di apprendimento. Altri usi includono lo studio delle transizioni tra diverse strategie di scrittura accademica (Peeters et al. (2020)), tra eventi di apprendimento autoregolato (Lim et al. (2023)), o all’interno di contesti di apprendimento collaborativo (Saqr & López-Pernas (2023)). Esempi più specifici nell’ambito psicologico comprendono lo studio delle influenze reciproche tra stati affettivi (Cipresso et al. (2023)) e l’analisi degli effetti psicologici che dipendono dal tempo nelle sequenze di decision-making (Gunawan et al. (2022)).\n\n\n\n\nCipresso, P., Borghesi, F., & Chirico, A. (2023). Affects affect affects: A Markov chain. Frontiers in Psychology, 14, 1162655.\n\n\nFincham, E., Gašević, D., Jovanović, J., & Pardo, A. (2018). From study tactics to learning strategies: An analytical method for extracting interpretable representations. IEEE Transactions on Learning Technologies, 12(1), 59–72.\n\n\nGunawan, D., Hawkins, G. E., Kohn, R., Tran, M.-N., & Brown, S. D. (2022). Time-evolving psychological processes over repeated decisions. Psychological Review, 129(3), 438–456.\n\n\nLim, L., Bannert, M., Graaf, J. van der, Singh, S., Fan, Y., Surendrannair, S., Rakovic, M., Molenaar, I., Moore, J., & Gašević, D. (2023). Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning. Computers in Human Behavior, 139, 107547.\n\n\nMatcha, W., Gasevic, D., Jovanovic, J., Pardo, A., Lim, L., Maldonado-Mahauad, J., Gentili, S., Pérez-Sanagustı́n, M., Tsai, Y.-S., et al. (2020). Analytics of Learning Strategies: Role of Course Design and Delivery Modality Authors. Journal of Learning Analytics, 7(2), 45–71.\n\n\nPeeters, W., Saqr, M., & Viberg, O. (2020). Applying learning analytics to map students’ self-regulated learning tactics in an academic writing course. Proceedings of the 28th International Conference on Computers in Education, 1, 245–254.\n\n\nSaqr, M., & López-Pernas, S. (2023). The temporal dynamics of online problem-based learning: Why and when sequence matters. International Journal of Computer-Supported Collaborative Learning, 18(1), 11–37.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2022). A person-centered approach to study students’ socio-emotional interaction profiles and regulation of collaborative learning. Frontiers in Education, 7, 866612.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2023). Affective states and regulation of learning during socio-emotional interactions in secondary school collaborative groups. British Journal of Educational Psychology, 93, 48–70.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "Appendice O — La funzione lineare",
    "section": "",
    "text": "O.1 Concetto di Funzione\nNello studio dei fenomeni naturali e nella risoluzione di problemi tecnici e matematici, è spesso necessario considerare la variazione di una grandezza come dipendente dalla variazione di un’altra. Ad esempio, nello studio del moto, il percorso compiuto da un oggetto può essere visto come una grandezza variabile in funzione del tempo: il cammino percorso è, dunque, una funzione del tempo.\nQuesta considerazione ci conduce alla seguente definizione:\nSe a ogni valore della variabile \\(x\\) (all’interno di un certo intervallo) corrisponde un valore ben definito di un’altra variabile \\(y\\), allora si dice che \\(y\\) è una funzione di \\(x\\). In notazione funzionale si scrive:\n\\[\ny = f(x) \\quad \\text{o anche} \\quad y = \\varphi(x).\n\\]\nLa variabile \\(x\\) è detta variabile indipendente o argomento della funzione. La relazione che lega \\(x\\) a \\(y\\) si chiama relazione funzionale. La lettera \\(f\\) nella notazione \\(y = f(x)\\) indica che per ottenere il valore di \\(y\\) a partire da \\(x\\) è necessario applicare una certa “regola” o “operazione”. In modo analogo, si possono utilizzare anche altre notazioni come \\(u = \\varphi(x)\\).\nLa notazione \\(y = C\\), dove \\(C\\) è una costante, indica una funzione il cui valore rimane invariato per qualunque valore di \\(x\\).\nL’insieme dei valori di \\(x\\) per cui la funzione \\(y = f(x)\\) è definita si chiama dominio di definizione della funzione.\nSe per valori crescenti della variabile indipendente \\(x\\) anche il valore della funzione \\(y = f(x)\\) aumenta, allora la funzione si dice crescente. Analogamente, se a valori crescenti di \\(x\\) corrispondono valori decrescenti della funzione \\(y = f(x)\\), la funzione si dice decrescente.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html#la-retta",
    "href": "chapters/appendix/a50_lin_fun.html#la-retta",
    "title": "Appendice O — La funzione lineare",
    "section": "O.2 La Retta",
    "text": "O.2 La Retta\nLa funzione lineare è definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di tale funzione è una retta. Qui, \\(b\\) è detto coefficiente angolare, mentre \\(a\\) è l’intercetta con l’asse delle \\(y\\). In altri termini, la retta interseca l’asse \\(y\\) nel punto \\((0, a)\\).\nPer comprendere il ruolo di \\(a\\) e \\(b\\), consideriamo prima il caso particolare:\n\\[\ny = b x.\n\\]\nQuesta espressione rappresenta una proporzionalità diretta tra \\(x\\) e \\(y\\): al crescere di \\(x\\), \\(y\\) varia in proporzione. Nel caso generale:\n\\[\ny = a + b x,\n\\]\nil termine \\(a\\) “trasla” verticalmente il grafico, aggiungendo una costante a ogni valore \\(b x\\).\nIl segno del coefficiente \\(b\\) determina il comportamento della funzione lineare:\n\nSe \\(b &gt; 0\\), il valore di \\(y\\) aumenta all’aumentare di \\(x\\).\n\nSe \\(b &lt; 0\\), il valore di \\(y\\) diminuisce all’aumentare di \\(x\\).\n\nSe \\(b = 0\\), il grafico è una retta orizzontale e \\(y\\) rimane costante.\n\nPossiamo dare un’interpretazione geometrica ancora più intuitiva se consideriamo variazioni (incrementi) di \\(x\\). Preso un punto \\(x_0\\) e aggiungendo un piccolo incremento \\(\\varepsilon\\), definiamo:\n\\[\n\\Delta x = (x_0 + \\varepsilon) - x_0 = \\varepsilon,\n\\] \\[\n\\Delta y = f(x_0 + \\varepsilon) - f(x_0).\n\\]\nIl coefficiente angolare \\(b\\) può essere interpretato come il rapporto tra la variazione di \\(y\\) e la variazione di \\(x\\):\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}.\n\\]\nQuesto rapporto è costante e non dipende dalla scelta di \\(x_0\\) o di \\(\\varepsilon\\). In particolare, se scegliamo \\(\\Delta x = 1\\), il coefficiente angolare \\(b\\) rappresenta semplicemente di quanto varia \\(y\\) quando \\(x\\) aumenta di un’unità.\n\n\n\n\n\n\n\nFigura O.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nCome mostrato in figura, il coefficiente \\(b\\) indica la pendenza della retta, ossia quanto “ripida” è la sua inclinazione rispetto all’asse orizzontale.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html",
    "href": "chapters/appendix/a71_install_cmdstan.html",
    "title": "Appendice P — Come installare CmdStan",
    "section": "",
    "text": "P.1 Windows\nSu macOS e Linux, questa configurazione dovrebbe essere già pronta di default.\nSu Windows è necessario installare RTools e configurare PATH:\nProblemi comuni:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>P</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html#windows",
    "href": "chapters/appendix/a71_install_cmdstan.html#windows",
    "title": "Appendice P — Come installare CmdStan",
    "section": "",
    "text": "Installazione di RTools:\n\nVai su https://cran.r-project.org/bin/windows/Rtools/\nScarica la versione di RTools compatibile con la tua versione di R (Generalmente, RTools 4.3 per R 4.3.x, RTools 4.2 per R 4.2.x, etc.)\nEsegui l’installer scaricato\nIMPORTANTE: Durante l’installazione, seleziona la casella “Add rtools to system PATH”\n\nVerifica dell’installazione e configurazione del PATH:\n\nApri PowerShell o Command Prompt\nVerifica se RTools è nel PATH digitando:\n\ngcc --version\nSe vedi la versione di gcc, RTools è nel PATH.\nSe RTools non è nel PATH, devi aggiungerlo manualmente:\n\nCerca “Impostazioni di Sistema” in Windows\nClicca su “Impostazioni di sistema avanzate”\nClicca su “Variabili d’ambiente”\nNella sezione “Variabili di sistema”, trova “Path”\nClicca “Modifica”\nClicca “Nuovo” e aggiungi questi percorsi (sostituisci X.X con la tua versione di RTools):\nC:\\rtools4X\\mingw64\\bin\nC:\\rtools4X\\usr\\bin\n\nVerifica finale:\n\nChiudi e riapri il terminale\nProva questi comandi:\n\ngcc --version\nmake --version\nSe entrambi i comandi mostrano le versioni, l’installazione è completa.\nTest in R:\n\nApri R o RStudio\nEsegui:\n\nSys.which(\"make\")\nDovrebbe mostrare il percorso di make.\n\n\n\nSe i comandi non vengono riconosciuti dopo aver aggiunto il PATH, prova a riavviare il computer.\nSe usi RStudio, potrebbe essere necessario riavviarlo dopo aver modificato il PATH.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>P</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "index.html#struttura-del-sito",
    "href": "index.html#struttura-del-sito",
    "title": "Metodi bayesiani in psicologia",
    "section": "",
    "text": "Approfondimenti concettuali — Chiarimenti e discussioni aggiuntive su temi chiave dell’inferenza e della modellazione bayesiana.\nEsempi pratici in R e Stan — Script completi e commentati che estendono gli esempi del libro.\nSezioni tematiche — Collegamenti a moduli dedicati (frequentista, probabilità classica, EDA) per chi desidera esplorare materiali propedeutici o complementari.\nRisorse per la riproducibilità — Workflow, pacchetti e strumenti per replicare e adattare le analisi.",
    "crumbs": [
      "Struttura del sito"
    ]
  },
  {
    "objectID": "index.html#come-usare-questo-companion",
    "href": "index.html#come-usare-questo-companion",
    "title": "Metodi bayesiani in psicologia",
    "section": "Come usare questo companion",
    "text": "Come usare questo companion\n\nLavora in modo attivo: copia ed esegui il codice, modifica i parametri, osserva l’effetto delle variazioni.\n\nSegui i collegamenti: le sezioni si integrano al manuale, ma aggiungono esempi e percorsi paralleli.\n\nInterpreta, non memorizzare: chiediti sempre perché i modelli differiscono, quali meccanismi psicologici esplicitano i parametri, e come comunicare l’incertezza in modo chiaro.",
    "crumbs": [
      "Struttura del sito"
    ]
  },
  {
    "objectID": "index.html#strumenti-utili",
    "href": "index.html#strumenti-utili",
    "title": "Metodi bayesiani in psicologia",
    "section": "Strumenti utili",
    "text": "Strumenti utili\nPer trarre il massimo da questi materiali è utile disporre di:\n\nSoftware: \\(\\mathsf{R}\\) (≥ 4.5) e RStudio (consigliato).\n\nEcosistema Stan: installazione di CmdStan tramite il pacchetto cmdstanr.\n→ Guida all’installazione\n\nPacchetti principali: tidyverse, brms, cmdstanr, loo.\n\nQuarto: per generare documenti e report riproducibili.",
    "crumbs": [
      "Struttura del sito"
    ]
  }
]